{"version":3,"file":"aws-amplify-datastore.js","mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,O;;;;;;;;;;;;;;;ACVwF;AACxF;AACA;AACA;AACA;AACA;AACA,qCAAqC,4CAAI;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,2DAAmB;AACtD;AACA;AACA;AACA;AACA;AACA,sCAAsC,kDAAU;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,kDAAU,IAAI,kDAAU;AAC5D,gDAAgD,IAAI,kDAAU,EAAE;AAChE;AACA;AACA;AACA;AACA;AACA,4CAA4C,IAAI,kDAAU,MAAM;AAChE;AACA;AACA,iCAAiC,kDAAU;AAC3C,iCAAiC,kDAAU;AAC3C;AACA;AACA;AACA;AACA;AACA,iCAAiC,qDAAa;AAC9C,wBAAwB,OAAO;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,IAAI,kDAAU,EAAE;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,2CAAG;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACoB;AACrB;;;;;;;;;;;;;;;;;;;ACxHA;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;;;;;;;;;;;;;;;;AC9F2B;AAC3B;;;;;;;;;;;;;;;;;;;ACD+C;AACN;AACD;AACwB;AAChE;AACA;AACA;AACA,wBAAwB,iDAAS;AACjC;AACA;AACA;AACA,YAAY,6DAAW;AACvB;AACA;AACA;AACA,6BAA6B,iEAAe;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,gDAAS;AACxB,mBAAmB,kDAAW;AAC9B;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA,wBAAwB,iDAAS;AACjC;AACA,6BAA6B,iDAAS;AACtC;AACA,uCAAuC,kDAAU;AACjD;AACA,4BAA4B,IAAI,kDAAU,EAAE;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,sBAAsB;AAClD;AACA;AACA;AACA;AACA;AACA,CAAC;AACiB;AAClB;AACA,gBAAgB,iEAAe;AAC/B,2BAA2B,kDAAU;AACrC,6BAA6B,iDAAS;AACtC;AACA;AACA;AACA,gCAAgC,kDAAU;AAC1C;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACjFA;AACA;AACgE;AAChE;AACA;AACA,yBAAyB;AACzB,MAAM,uDAAe;AACd;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACnBA;AACA;AACoD;AACR;AACF;AACU;AACpD;;;;;;;;;;;;;;;ACNA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACRA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACVA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACfO;;;;;;;;;;;;;;;;;;;;;ACAoB;AACI;AACN;;;;;;;;;;;;;;;;;ACFa;AAC/B;AACP;AACA,eAAe,mDAAQ;AACvB;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACTO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACRmE;AACN;;AAE7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,yCAAyC,IAAI;AAC9E;AACA,wBAAwB,qDAAI;AAC5B;AACA;AACA,oBAAoB,qDAAI,sDAAsD,qDAAI;AAClF,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,UAAU,IAAI;AACxC;AACA;AACA;AACA,WAAW,qDAAI;AACf;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAY;AACZ;AACA;AACA;AACA,CAAC;;AAE2B;;;;;;;;;;;;;;;;;;;;AClF5B;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEqG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxLrG,cAAc,kDAAkD,IAAI,wBAAwB,GAAG,IAAmC,EAAE,6EAA6E,0BAA0B,6EAA6E,gBAAgB,qEAAqE,cAAc,kBAAkB,cAAc,wBAAwB,mCAAmC,+BAA+B,qBAAqB,iEAAiE,uEAAuE,+DAA+D,cAAc,4BAA4B,kBAAkB,uEAAuE,mCAAmC,4BAA4B,gBAAgB,GAAG,cAAc,WAAW,4DAA4D,gBAAgB,mEAAmE,gBAAgB,8BAA8B,kBAAkB,WAAW,qDAAqD,gBAAgB,wCAAwC,cAAc,2BAA2B,cAAc,2BAA2B,cAAc,gBAAgB,cAAc,yDAAyD,YAAY,YAAY,oBAAoB,WAAW,KAAK,kBAAkB,0EAA0E,+DAA+D,EAAE,iDAAiD,gBAAgB,+HAA+H,eAAe,SAAS,aAAa,KAAK,cAAc,uDAAuD,cAAc,YAAY,oBAAoB,gBAAgB,iBAAiB,aAAa,MAAM,MAAmC,YAAY,gBAAgB,sCAAsC,cAAc,6BAA6B,cAAc,eAAe,cAAc,UAAU,uBAAuB,cAAc,WAAW,8BAA8B,gBAAgB,eAAe,iCAAiC,2KAA2K,kBAAkB,iBAAiB,WAAW,gCAAgC,sBAAsB,QAAQ,oBAAoB,+BAA+B,SAAS,eAAe,sCAAsC,sCAAsC,sBAAsB,iDAAiD,WAAW,wBAAwB,GAAG,KAAmC,oBAAoB,yDAAyD,yBAAyB,OAAO,gBAAgB,wBAAwB,yBAAyB,kBAAkB,sCAAsC,gBAAgB,WAAW,oBAAoB,gBAAgB,6CAA6C,EAAE,EAAE,2CAA2C,cAAc,4BAA4B,cAAc,0BAA0B,cAAc,kBAAkB,kBAAkB,wEAAwE,0BAA0B,kCAAkC,mCAAmC,UAAU,gBAAgB,gDAAgD,qBAAqB,sBAAsB,8BAA8B,cAAc,mCAAmC,kBAAkB,oBAAoB,MAAM,4CAA4C,uBAAuB,cAAc,0BAA0B,6BAA6B,sBAAsB,IAAI,gBAAgB,UAAU,yBAAyB,4BAA4B,YAAY,aAAa,gBAAgB,WAAW,gCAAgC,4CAA4C,cAAc,MAAM,KAAmC,mBAAmB,iBAAiB,cAAc,KAAmC,sBAAsB,GAAG,cAAc,qBAAqB,KAAK,KAAK,cAAc,oBAAoB,kBAAkB,MAAM,oBAAoB,cAAc,yCAAyC,KAAK,KAAK,WAAW,UAAU,WAAW,gCAAgC,qBAAqB,+BAA+B,aAAa,uCAAuC,cAAc,UAAU,kCAAkC,oDAAoD,mBAAmB,cAAc,+BAA+B,SAAS,SAAS,gBAAgB,uCAAuC,MAAM,8BAA8B,WAAW,0CAA0C,SAAS,YAAY,YAAY,oBAAoB,WAAW,KAAK,WAAW,+BAA+B,iDAAiD,SAAS,kCAAkC,+BAA+B,kCAAkC,oBAAoB,IAAI,mBAAmB,+CAA+C,0BAA0B,WAAW,MAAM,4BAA4B,0BAA0B,4DAA4D,oBAAoB,sCAAsC,GAAG,eAAe,iEAAiE,WAAW,YAAY,wBAAwB,WAAW,YAAY,0CAA0C,IAAI,8BAA8B,iBAAiB,eAAe,0BAA0B,EAAE,aAAa,cAAc,kBAAkB,oCAAoC,gEAAgE,qBAAqB,IAAI,6CAA6C,8CAA8C,4BAA4B,6BAA6B,cAAc,mBAAmB,YAAY,aAAa,gBAAgB,8BAA8B,gCAAgC,aAAa,KAAK,qBAAqB,mJAAmJ,wCAAwC,UAAU,wBAAwB,yBAAyB,aAAa,sBAAsB,iBAAiB,8BAA8B,yBAAyB,uBAAuB,sBAAsB,uBAAuB,4BAA4B,0BAA0B,gCAAgC,2BAA2B,iBAAiB,KAAK,qBAAqB,YAAY,8CAA8C,gBAAgB,qBAAqB,sDAAsD,yBAAyB,kBAAkB,qBAAqB,YAAY,EAAE,oBAAoB,gBAAgB,mBAAmB,eAAe,uBAAuB,EAAE,+BAA+B,GAAG,GAAG,UAAU,uCAAuC,sBAAsB,sBAAsB,YAAY,cAAc,YAAY,cAAc,YAAY,WAAW,0BAA0B,oBAAoB,QAAQ,kCAAkC,UAAU,kCAAkC,EAAE,mBAAmB,WAAW,KAAK,oBAAoB,QAAQ,0BAA0B,EAAE,2BAA2B,sDAAsD,EAAE,UAAU,gCAAgC,oBAAoB,uBAAuB,cAAc,oBAAoB,QAAQ,2BAA2B,aAAa,oBAAoB,EAAE,IAAI,8BAA8B,cAAc,oBAAoB,QAAQ,oBAAoB,aAAa,2BAA2B,EAAE,IAAI,GAAG,WAAW,qBAAqB,QAAQ,0CAA0C,UAAU,+BAA+B,GAAG,EAAE,aAAa,gBAAgB,aAAa,mBAAmB,mDAAmD,cAAc,oCAAoC,cAAc,2CAA2C,SAAS,mBAAmB,wBAAwB,gBAAgB,IAAI,cAAc,+BAA+B,oBAAoB,iCAAiC,aAAa,gCAAgC,cAAc,gBAAgB,gDAAgD,OAAO,cAAc,gBAAgB,gBAAgB,qEAAqE,MAAM,SAAS,kBAAkB,uCAAuC,eAAe,wBAAwB,oBAAoB,yBAAyB,qBAAqB,cAAc,oGAAoG,sBAAsB,yBAAyB,cAAc,qDAAqD,oBAAoB,cAAc,0DAA0D,cAAc,gBAAgB,yBAAyB,WAAW,kCAAkC,uBAAuB,GAAG,mBAAmB,cAAc,KAAK,kBAAkB,uBAAuB,2BAA2B,mBAAmB,2BAA2B,mBAAmB,yBAAyB,qBAAqB,2BAA2B,WAAW,gBAAgB,kBAAkB,mBAAmB,eAAe,iBAAiB,8BAA8B,GAAG,sBAAsB,2BAA2B,WAAW,gBAAgB,mBAAmB,mBAAmB,eAAe,mBAAmB,qBAAqB,OAAO,2BAA2B,GAAG,iBAAiB,sBAAsB,GAAG,gBAAgB,gBAAgB,gBAAgB,sEAAsE,MAAM,SAAS,kBAAkB,uCAAuC,eAAe,wBAAwB,oBAAoB,cAAc,8EAA8E,mBAAmB,cAAc,qDAAqD,sBAAsB,yBAAyB,cAAc,0EAA0E,oBAAoB,cAAc,wCAAwC,qBAAqB,cAAc,8BAA8B,sBAAsB,cAAc,+BAA+B,mBAAmB,qBAAqB,iBAAiB,qBAAqB,yBAAyB,mCAAmC,QAAQ,2CAA2C,GAAG,GAAG,YAAY,gBAAgB,kBAAkB,iBAAiB,mBAAmB,EAAE,aAAa,YAAY,cAAc,SAAS,cAAc,SAAS,gPAAgP,8LAA8L,2IAA2I,+HAA+H,2vBAA2vB,qDAAqD,yDAAyD,wCAAwC,gBAAgB,yJAAyJ,+FAA+F,kKAAkK,gBAAgB,2CAA2C,gBAAgB,4CAA4C,4FAA4F,qJAAqJ,6EAA6E,6EAA6E,SAAS,kCAAkC,0CAA0C,KAAK,MAAM,KAAK,kBAAkB,kBAAkB,WAAW,kCAAkC,eAAe,oFAAoF,QAAQ,WAAW,8DAA8D,mBAAmB,iBAAiB,qBAAqB,6BAA6B,qBAAqB,gBAAgB,oDAAoD,SAAS,sCAAsC,2CAA2C,2CAA2C,UAAU,uFAAuF,8BAA8B,6FAA6F,wCAAwC,mDAAmD,UAAU,kFAAkF,GAAG,2BAA2B,MAAM,4BAA4B,kCAAkC,2BAA2B,OAAO,OAAO,oBAAoB,iBAAiB,6DAA6D,mCAAmC,MAAM,KAAmC,gEAAgE,wBAAwB,MAAM,KAAmC,2EAA2E,kBAAkB,cAAc,WAAW,gDAAgD,+CAA+C,QAAQ,IAAI,QAAQ,mBAAmB,WAAW,kBAAkB,kDAAkD,IAAI,wBAAwB,gCAAgC,MAAM,0CAA0C,IAAI,MAAM,2EAA2E,gCAAgC,IAAI,YAAY,QAAQ,YAAY,4EAA4E,qBAAqB,eAAe,aAAa,mBAAmB,2BAA2B,uBAAuB,wCAAwC,QAAQ,uCAAuC,uCAAuC,kDAAkD,IAAI,wBAAwB,2CAA2C,qCAAqC,GAAG,+BAA+B,QAAQ,QAAQ,QAAQ,mKAAmK,kBAAkB,iCAAiC,0BAA0B,iCAAiC,wBAAwB,6BAA6B,cAAc,KAAmC,4BAA4B,UAAU,0BAA0B,6BAA6B,SAAS,6BAA6B,sBAAsB,8BAA8B,MAAM,iBAAiB,KAAK,KAAK,WAAW,wCAAwC,UAAU,OAAO,qBAAqB,+CAA+C,yBAAyB,GAAG,GAAG,yMAAyM,iEAAe,EAAE,EAAwW;AAC/gjB;;;;;;;;;;;;;;;;;;;ACDO,2CAA2C,uDAAuD;AAClG;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACd0D;AACV;AACsB;AAC1B;AACV;AACa;AACI;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E,uDAAc;AAC3F,QAAQ,gEAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,uDAAc;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,aAAa;AACb;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,yBAAyB,0DAAiB;AAC1C;AACA;AACA;AACA;AACA,yBAAyB,uBAAuB;AAChD;AACA;AACA,eAAe,yDAAa;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,qBAAqB,mBAAmB,qBAAqB,gBAAgB,wBAAwB;AAChJ,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,CAAC;AACqB;AACtB;AACA;AACA,gFAAgF,2CAAM;AACtF;AACA;AACA,oBAAoB,4DAAU,gBAAgB,4DAAU,iBAAiB,4DAAU;AACnF;AACA;AACA,sCAAsC,mDAAU,2BAA2B,6DAAc;AACzF;AACA;;;;;;;;;;;;;;;;;;;;;;ACrG4C;AACF;AACwB;AACO;AAC5B;AACM;AACnD;AACA,IAAI,gDAAS;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,kFAAuB;AAC7C;AACA;AACA;AACA;AACA,QAAQ,gEAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,+CAAQ,0CAA0C,UAAU;AAC9F;AACA;AACA;AACA;AACA,gCAAgC,QAAQ;AACxC;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,QAAQ,gEAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,QAAQ,gEAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,6DAAkB;AACrC;AACA;AACA;AACA,mBAAmB,uDAAY;AAC/B;AACA,YAAY,0DAAS;AACrB,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,mDAAU;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,CAAC,mDAAU;AACO;AACnB;AACA,IAAI,gDAAS;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wIAAwI,6DAAkB;AAC1J;AACA;AACA,CAAC;AAC2B;AAC5B;;;;;;;;;;;;;;;;;;;;;;;;;;ACjKkC;AACa;AACe;AAC5B;AACiC;AAChC;AACkE;AACvC;AACX;AACnD;AACA,IAAI,gDAAS;AACb;AACA;AACA;AACA;AACA;AACA,gBAAgB,6DAAc;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,wEAAgB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,yEAAiB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,yEAAqB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,CAAC,uDAAY;AACQ;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA,IAAI,gDAAS;AACb;AACA;AACA;AACA,YAAY,4DAAU;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,2CAAM;AAC/B;AACA,sDAAsD;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACyB;AAC1B;AACA,QAAQ,2CAAM;AACd,QAAQ,gEAAY;AACpB;AACA;AACA,QAAQ,gFAAoB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,2CAAM;AACtC,6BAA6B,uEAAe,0BAA0B,yDAAyD;AAC/H;AACO;AACP;AACA,UAAU,4CAAI;AACd;AACA,cAAc,4CAAI;AAClB;AACA;;;;;;;;;;;;;;;;;;;;;ACvLwD;AACT;AACkB;AACpB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,+CAAQ,oDAAoD,sBAAsB;AAClI;AACA;AACA;AACA;AACA,oCAAoC,QAAQ;AAC5C;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,4DAAU;AAC1B;AACA;AACA;AACA;AACA,0CAA0C,0EAAmB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,+CAAQ,uDAAuD,uBAAuB;AACnI;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,0EAAmB;AAClE,yCAAyC,oDAAa,CAAC,oDAAa,KAAK,6CAAM,WAAW,6CAAM;AAChG;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,QAAQ;AACxC;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA,0BAA0B,0EAAmB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0DAAS;AACrB;AACA;AACA;AACA;AACA,uBAAuB,0DAAS;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACuB;AACjB;AACA;AACP;AACA,uCAAuC,4DAAU,kBAAkB,4DAAU,eAAe,4DAAU;AACtG;AACA;AACA,QAAQ,4DAAU;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC9IO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACPmD;AACX;AACjC;AACP,uBAAuB,+DAAS,qBAAqB,qDAAS;AAC9D;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACLwE;AACtB;AACJ;AACH;AACuB;AACR;AACwB;AAClC;AACwD;AACxD;AACoB;AACG;AAChE;AACP,yBAAyB,mDAAU;AACnC;AACA;AACA;AACA,YAAY,8EAAmB;AAC/B;AACA;AACA,YAAY,8DAAW;AACvB;AACA;AACA,YAAY,0DAAS;AACrB;AACA;AACA,YAAY,sEAAe;AAC3B;AACA;AACA,YAAY,4DAAU;AACtB;AACA;AACA,YAAY,gFAAoB;AAChC;AACA;AACA;AACA,UAAU,8FAAgC;AAC1C;AACO;AACP,eAAe,mDAAU;AACzB,sBAAsB,0DAAiB;AACvC,YAAY,4DAAU;AACtB;AACA;AACA;AACA,KAAK;AACL;AACO;AACP,eAAe,mDAAU;AACzB,wBAAwB,wCAAwC;AAChE;AACA;AACA;AACA,KAAK;AACL;AACO;AACP,eAAe,mDAAU;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,mBAAmB,+BAA+B;AAC3D,wBAAwB,6EAAoB;AAC5C,KAAK;AACL;AACO;AACP,eAAe,mDAAU;AACzB;AACA;AACA,kCAAkC,gDAAQ,8CAA8C,oBAAoB;AAC5G;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,QAAQ;AAChC;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA,KAAK;AACL;AACO;AACP,eAAe,mDAAU;AACzB,kEAAkE,+BAA+B;AACjG,KAAK;AACL;AACO;AACP,6BAA6B,8FAAkC;AAC/D;AACA;AACA;AACA;AACA,WAAW,iDAAS;AACpB;AACA,eAAe,mDAAW;AAC1B;AACA;AACA;AACA,sCAAsC,qDAAa;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;AC9I4C;AACd;AACvB;AACP;AACA,qBAAqB,uBAAuB;AAC5C;AACA;AACA,oBAAoB,wDAAY;AAChC,WAAW,2CAAI;AACf;AACA;;;;;;;;;;;;;;;;;;ACVkC;AACS;AACpC;AACP;AACA;AACA;AACA,IAAI,gDAAS;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,CAAC,mDAAU;AACkB;AAC9B;;;;;;;;;;;;;;;;;;AC5DoD;AACY;AACzB;AAChC;AACP,WAAW,mDAAO;AAClB;AACA;AACA;AACA,oCAAoC,6EAAwB;AAC5D,4BAA4B,gEAAS;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;AC1BuC;AACyB;AACzD;AACP,WAAW,mDAAO;AAClB;AACA,yBAAyB,6EAAwB,gCAAgC,2EAA2E;AAC5J,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;ACRuC;AACyB;AACzD;AACP,WAAW,mDAAO;AAClB;AACA,yBAAyB,6EAAwB;AACjD;AACA,SAAS;AACT,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;;ACV0D;AACnB;AACyB;AACzD;AACP,4BAA4B;AAC5B,WAAW,mDAAO;AAClB,yBAAyB,6EAAwB,gCAAgC,OAAO,sEAAe,sCAAsC,gCAAgC,WAAW,gBAAgB,OAAO,sEAAe,sCAAsC,+BAA+B,WAAW,mBAAmB,OAAO,sEAAe,sCAAsC,+BAA+B,WAAW;AACva,KAAK;AACL;AACA;;;;;;;;;;;;;;;;ACTuC;AAChC;AACP,4BAA4B;AAC5B,WAAW,mDAAO;AAClB,wDAAwD,sCAAsC;AAC9F,KAAK;AACL;AACA;;;;;;;;;;;;;;;;ACP2C;AACpC;AACP,eAAe,mDAAU;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;ACjB2C;AACe;AACnD;AACP;AACA;AACA;AACA,eAAe,mDAAU;AACzB,QAAQ,sEAAe;AACvB;AACA,YAAY,sEAAe;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb,SAAS;AACT,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;;;ACtB2C;AACsB;AACjB;AACU;AACnD;AACP,eAAe,mDAAU;AACzB;AACA,QAAQ,sEAAe;AACvB,6BAA6B,sDAAe;AAC5C,YAAY,sEAAe;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT,6BAA6B,OAAO,4DAAU;AAC9C,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;;AC/BoD;AACD;AACI;AAChD;AACP,WAAW,gEAAS,aAAa,mEAAW,aAAa,+DAAS;AAClE;AACA;;;;;;;;;;;;;;;;;;ACNoD;AACD;AACI;AAChD;AACP,WAAW,gEAAS,aAAa,mEAAW,aAAa,+DAAS;AAClE;AACA;;;;;;;;;;;;;;;;;ACNgE;AACkB;AAC3E;AACP,WAAW,6EAAqB,CAAC,8FAAkC;AACnE;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACL0D;AACN;AACJ;AACM;AACU;AACE;AACpB;AACI;AACF;AACU;AACwB;AACd;AACM;AACnE;AACP;AACA,YAAY,8EAAmB;AAC/B,mBAAmB,uEAAkB;AACrC;AACA,YAAY,8DAAW;AACvB,mBAAmB,6DAAa;AAChC;AACA,YAAY,0DAAS;AACrB,mBAAmB,iEAAe;AAClC;AACA,YAAY,sEAAe;AAC3B,mBAAmB,6EAAqB;AACxC;AACA,YAAY,4DAAU;AACtB,mBAAmB,mEAAgB;AACnC;AACA,YAAY,iFAAoB;AAChC,mBAAmB,wFAA0B;AAC7C;AACA;AACA,UAAU,+FAAgC;AAC1C;AACA;;;;;;;;;;;;;;;;ACpC8C;AACvC;AACP;AACA;AACA,yBAAyB,uBAAuB;AAChD;AACA;AACA;AACA;AACA,uDAAuD,oDAAa,qBAAqB,6CAAM;AAC/F;AACA,wCAAwC,oDAAa,qBAAqB,6CAAM;AAChF,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;;;;;;;;;;;;;;;ACnBO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;;;;;;;;;;;;;;;ACPO,gCAAgC,+EAA+E;AACtH;;;;;;;;;;;;;;;;ACDsD;AAC/C,8BAA8B,mEAAgB;AACrD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;;;;;;;;;;;;;;;;ACRsD;AAC/C,0BAA0B,mEAAgB;AACjD;AACA;AACA;AACA,2GAA2G,uCAAuC;AAClJ;AACA;AACA;AACA;AACA,CAAC;AACD;;;;;;;;;;;;;;;;;;;ACX0C;AACE;AAC5C;AACA;AACA;AACO;AACP,WAAW,uDAAU;AACrB;AACO;AACP,WAAW,yDAAW;AACtB;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;ACdO;AACP;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACNO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACVmC;AACnC;AACO;AACP,QAAQ,2CAAM;AACd;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,2CAAM;AACd;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC3BO;AACP,4BAA4B;AAC5B,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACjBO;AACP;AACA;AACA;;;;;;;;;;;;;;;ACHO,kCAAkC,sEAAsE;AAC/G;;;;;;;;;;;;;;;;ACD0C;AACnC;AACP,mCAAmC,uDAAU;AAC7C;AACA;;;;;;;;;;;;;;;ACJO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;ACHuE;AAC7B;AACnC;AACP,WAAW,uDAAU,OAAO,0DAAiB;AAC7C;AACA;;;;;;;;;;;;;;;;;ACLiE;AACvB;AACnC;AACP,WAAW,uDAAU,qDAAqD,sDAAe;AACzF;AACA;;;;;;;;;;;;;;;;ACL0C;AACnC;AACP,WAAW,uDAAU;AACrB;AACA;;;;;;;;;;;;;;;;;;ACJ+D;AACrB;AACnC;AACP,WAAW,uDAAgB;AAC3B;AACA,eAAe,kDAAW;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,KAAK,EAAE,EAAc;AAC7C,+BAA+B,8CAAO;AACtC;AACA;AACA;AACA,+BAA+B,8CAAO;AACtC;AACA,mCAAmC,8CAAO;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACO;AACP,WAAW,uDAAU;AACrB;AACA;;;;;;;;;;;;;;;;ACtC0C;AACnC;AACP,oBAAoB,uDAAU;AAC9B;AACA;;;;;;;;;;;;;;;;;ACJ0C;AACnC;AACP,WAAW,uDAAU;AACrB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACnBO;AACP;;;;;;;;;;;;;;;;;ACDsC;AAC/B;AACP;AACA,qBAAqB,uBAAuB;AAC5C;AACA;AACA;AACA;AACO;AACP;AACA,eAAe,+CAAQ;AACvB;AACA;AACA;AACA;AACA;AACA,gDAAgD,kBAAkB;AAClE;AACA;AACA;;;;;;;;;;;;;;;;;ACnBmC;AAC4B;AACxD;AACP,IAAI,uEAAe;AACnB,+BAA+B,2CAAM;AACrC;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;;;;;;;;;;;;;;ACbO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,SAAS;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,SAAS;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA,6BAA6B,mBAAO,CAAC,uDAAQ;AAC7C;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEyI;;;;;;;;;;;;;;;;;;;;;;;;;;AE7JzI;AACA,iEAAe;AACf;AACA,CAAC;;;;;;;;;;;;;;;ACHD,iEAAe,cAAc,EAAE,UAAU,EAAE,eAAe,EAAE,gBAAgB,EAAE,UAAU,GAAG,yCAAyC;;;;;;;;;;;;;;;ACApI;AACA;AACA;AACA;AACA;AACe;AACf;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;;;;;;;;;;;;;;;;ACjBqC;AACrC;AACA;AACA;AACA;;AAEA;;AAEA,gBAAgB,SAAS;AACzB;AACA;;AAEO;AACP;AACA;AACA;AACA;;AAEA;AACA,6CAA6C;AAC7C;AACA;AACA;AACA;;AAEA,OAAO,wDAAQ;AACf;AACA;;AAEA;AACA;;AAEA,iEAAe,SAAS;;;;;;;;;;;;;;;;;;AChCS;AACN;AACsB;;AAEjD;AACA,MAAM,kDAAM;AACZ,WAAW,kDAAM;AACjB;;AAEA;AACA,iDAAiD,+CAAG,KAAK;;AAEzD;AACA,mCAAmC;;AAEnC;AACA;;AAEA,oBAAoB,QAAQ;AAC5B;AACA;;AAEA;AACA;;AAEA,SAAS,8DAAe;AACxB;;AAEA,iEAAe,EAAE;;;;;;;;;;;;;;;;AC5Bc;;AAE/B;AACA,qCAAqC,iDAAK;AAC1C;;AAEA,iEAAe,QAAQ;;;;;;;;;;;;;;;;ACNvB;AACA;AACA,gBAAgB,SAAS;AACzB;AACA;AACA,0BAA0B,YAAY;AACtC;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA;AACA;AACA;AACA,mEAAmE,aAAa;AAChF;AACA;AACA;AACA;AACO;AACP;AACA,oBAAoB,sBAAsB;AAC1C;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AChCA,wBAAwB,2BAA2B,2EAA2E,kCAAkC,wBAAwB,OAAO,kCAAkC,mIAAmI;;AAEpW,2CAA2C,gCAAgC,oCAAoC,oDAAoD,8DAA8D,iEAAiE,GAAG,kCAAkC;;AAEvU,iCAAiC,gBAAgB,sBAAsB,OAAO,uDAAuD,aAAa,uDAAuD,4CAA4C,KAAK,6CAA6C,6EAA6E,OAAO,iDAAiD,mFAAmF,OAAO;;AAEtgB,4CAA4C,kBAAkB,kCAAkC,oEAAoE,KAAK,OAAO,oBAAoB;;AAEpM,kDAAkD,0CAA0C;;AAE5F,4CAA4C,gBAAgB,kBAAkB,OAAO,2BAA2B,wDAAwD,gCAAgC,uDAAuD;;AAE/P,8DAA8D,sEAAsE,8DAA8D;;AAElM,2CAA2C,+DAA+D,6EAA6E,yEAAyE,eAAe,uDAAuD,GAAG;;AAEzU,iCAAiC,6DAA6D,yCAAyC,8CAA8C,iCAAiC,mDAAmD,2DAA2D,OAAO,yCAAyC;;AAEpX,kDAAkD,0EAA0E,eAAe;;AAE3I,wCAAwC,uBAAuB,yFAAyF;;AAExJ,mCAAmC,gEAAgE,sDAAsD,+DAA+D,mCAAmC,6EAA6E,qCAAqC,iDAAiD,8BAA8B,qBAAqB,0EAA0E,qDAAqD,eAAe,yEAAyE,GAAG,2CAA2C;;AAEttB,2CAA2C,mCAAmC,kCAAkC,OAAO,wDAAwD,gBAAgB,uBAAuB,kDAAkD,kCAAkC,uDAAuD,sBAAsB;;AAEvX,uCAAuC,wEAAwE,0CAA0C,8CAA8C,MAAM,uEAAuE,IAAI,eAAe,YAAY;;AAEnT,iCAAiC;;AAEjC,iCAAiC,4EAA4E,iBAAiB,aAAa;;AAE3I,8BAA8B,gGAAgG,mDAAmD;;AAE1H;AACS;AACT;AAC4B;AACnF;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;;AAEA;;AAEA;AACA,mBAAmB,eAAe;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,0GAA0G;;AAE1G;AACA;;AAEA,iHAAiH,oBAAoB;AACrI;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,qDAAqD;;AAErD;AACA;AACA;AACA,KAAK;AACL;AACA,aAAa,mEAAW;AACxB,KAAK;AACL,aAAa,mEAAW;AACxB,KAAK;AACL;AACA;;AAEA,8BAA8B,qEAAY;AAC1C,yCAAyC;AACzC,MAAM;AACN;AACA,MAAM;AACN;;;AAGA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,KAAK,GAAG;;AAER;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,MAAM;;;AAGN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,MAAM;AACN;;AAEA,GAAG;AACH,SAAS,wEAAoB;AAC7B;AACA;AACA;AACA,GAAG;;AAEH;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGO;AACP;;AAEA;AACA,mDAAmD,4BAA4B;AAC/E;;AAEA;AACA,2BAA2B,0EAAa;AACxC;AACA;AACA,IAAI;AACJ,2DAA2D,gCAAgC;AAC3F;AACA,yBAAyB,gFAAmB;AAC5C;AACA;;AAEA;AACA;;;;;;;;;;;;;;;;;AC5OkD;AAClD;AACA;AACA;AACA;;AAEO;AACP,aAAa,2DAAY;AACzB;;;;;;;;;;;;;;;;;;ACRwC;AACgC;AACxE;AACA;AACA;;AAEe;AACf;AACA,8BAA8B,0DAAS;AACvC,sCAAsC;;AAEtC,MAAM,sEAAyB;AAC/B,0BAA0B,sEAAyB;AACnD;AACA;;;;;;;;;;;;;;;;ACde;AACf,6CAA6C;;AAE7C;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACNA,wBAAwB,2BAA2B,2EAA2E,kCAAkC,wBAAwB,OAAO,kCAAkC,mIAAmI;;AAEpW;AACwE;AACxE;AACA;AACA;AACA;AACA;;AAEe;AACf;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,mDAAmD;;AAEnD;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA,cAAc;AACd;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH,YAAY,+BAA+B;AAC3C;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,kBAAkB,SAAS;AAC3B;AACA;;AAEA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;;AAEA;AACA,sCAAsC,sEAAyB;;AAE/D;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;;;;;;;;;;;;;;;;AC3HA,wBAAwB,2BAA2B,2EAA2E,kCAAkC,wBAAwB,OAAO,kCAAkC,mIAAmI;;AAEhU;AACpC;AACA;AACA;AACA;;AAEA;AACA;AACA,iEAAe,MAAqC;AACpD;AACA,CAEC,CAAC;AACF;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,6BAA6B,wDAAO;AACpC;AACA;AACA;;AAEA;AACA,CAAC,EAAC;;;;;;;;;;;;;;;;AClCa;AACf,6CAA6C;;AAE7C;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACNA,wBAAwB,2BAA2B,2EAA2E,kCAAkC,wBAAwB,OAAO,kCAAkC,mIAAmI;;AAEpW;AACA;AACA;AACA;AACe;AACf;AACA;;;;;;;;;;;;;;;;ACRA;AACA;AACA,iEAAe,yBAAyB,EAAC;;;;;;;;;;;;;;;;;;;ACFgB;;AAEzD;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,CAAC,IAAI;;AAEL,sEAAa;AACb;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,CAAC,IAAI;;AAEL,sEAAa;AACb;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACrHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,+CAA+C;;AAE/C;;AAEA;AACA,oBAAoB,kBAAkB;AACtC;AACA;AACA,IAAI;;;AAGJ;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,IAAI;;;AAGJ;AACA;;AAEA;AACA,kBAAkB,gBAAgB;AAClC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;;AAGO;AACP;;AAEA;AACA;AACA;AACA;;AAEA,kBAAkB,kBAAkB;AACpC;AACA;AACA;AACA;AACA,eAAe;AACf;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;;AAEnB;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;;;;;;;;;;;;;;;AC3HA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;;;;;;;;;;;;;;;;AC5BA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC7DuD;AACrB;AACU;AACe;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,+BAA+B,2CAAK,CAAC,qDAAS;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,uBAAuB,qDAAS;AAChC;AACA;;AAEA;AACA;AACA,QAAQ,sBAAsB,qDAAS;AACvC;;AAEA;AACA;;AAEA;AACA,CAAC;AACD;AACA;AACA;;AAEO;AACP,kBAAkB,qDAAS,kBAAkB,qDAAS,oBAAoB,qDAAS,iBAAiB,qDAAS,qBAAqB,qDAAS,qBAAqB,qDAAS,oBAAoB,qDAAS,mBAAmB,qDAAS,oBAAoB,qDAAS,gBAAgB,qDAAS,uBAAuB,qDAAS,uBAAuB,qDAAS,qBAAqB,qDAAS,kBAAkB,qDAAS;AACjZ;;AAEA;AACA;AACA,kBAAkB,qDAAS;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,0CAA0C;;;AAG1C;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,mBAAmB,2CAAK,CAAC,qDAAS;;AAElC;AACA;AACA;;AAEA;AACA;AACA,mBAAmB,2CAAK,CAAC,qDAAS;;AAElC;AACA;AACA,mBAAmB,2CAAK,CAAC,qDAAS;;AAElC;AACA;AACA,mBAAmB,2CAAK,CAAC,qDAAS;;AAElC;AACA;AACA,mBAAmB,2CAAK,CAAC,qDAAS;;AAElC;AACA;AACA;AACA,qBAAqB,2CAAK,CAAC,qDAAS;AACpC;;AAEA;;AAEA;AACA;AACA,mBAAmB,2CAAK,CAAC,qDAAS;;AAElC;AACA;AACA,mBAAmB,2CAAK,CAAC,qDAAS;;AAElC;AACA;AACA,mBAAmB,2CAAK,CAAC,qDAAS;;AAElC;AACA;AACA,mBAAmB,2CAAK,CAAC,qDAAS;;AAElC;AACA;AACA,mBAAmB,2CAAK,CAAC,qDAAS;;AAElC;AACA;AACA,mBAAmB,2CAAK,CAAC,qDAAS;;AAElC;AACA;AACA,mBAAmB,2CAAK,CAAC,qDAAS;;AAElC;AACA;AACA,mBAAmB,2CAAK,CAAC,qDAAS;;AAElC;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA,UAAU,mEAAW;AACrB;;AAEA;AACA;AACA,aAAa,2CAAK,CAAC,qDAAS;AAC5B;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;;AAEA;AACA;AACA,IAAI;AACJ;;AAEA,aAAa,2CAAK,CAAC,qDAAS;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,YAAY,mEAAW;AACvB;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,IAAI;;;AAGJ;AACA,UAAU,mEAAW;AACrB;;AAEA,aAAa,2CAAK,WAAW,qDAAS,SAAS,qDAAS;AACxD;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,MAAM,kCAAkC;;;AAGxC;AACA;;AAEA,QAAQ,mEAAW;AACnB;AACA;AACA;AACA;AACA,yCAAyC,EAAE;AAC3C;;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,iBAAiB,2CAAK,CAAC,qDAAS;AAChC,MAAM;;;AAGN;AACA,YAAY,mEAAW;AACvB;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,oBAAoB,mEAAW;AAC/B;;AAEA;AACA;AACA;AACA;;AAEA;AACA,gBAAgB,mEAAW;AAC3B;;AAEA;AACA;AACA;AACA;;AAEA,QAAQ,mEAAW;AACnB;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,iBAAiB,2CAAK,CAAC,qDAAS,qDAAqD,wEAAsB;AAC3G,MAAM;;;AAGN;AACA,YAAY,mEAAW;AACvB;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,QAAQ;AACR;AACA;;AAEA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA,QAAQ,mEAAW;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,aAAa,2CAAK,CAAC,qDAAS;AAC5B,EAAE;;;AAGF;AACA;AACA;;;;;;;;;;;;;;;;ACnqBA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;ACvBuD;AACpB;AACE;AACO;AACI;AACY;AACD;AAC3D;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA,qBAAqB,qDAAS;AAC9B;AACA,qBAAqB,qDAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA,qBAAqB,qDAAS;AAC9B;AACA,qBAAqB,qDAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA,oBAAoB,qDAAQ,wBAAwB,+CAAM;AAC1D,sBAAsB,6CAAK;AAC3B;AACA;AACA;AACA;AACA;;;AAGA;;AAEA;AACA,iCAAiC,qDAAS;AAC1C;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,YAAY,4CAAI;AAChB,6BAA6B,qDAAS,4BAA4B,qDAAS;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,kBAAkB,qDAAS;AAC3B;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,MAAM,mBAAmB,qDAAS;AAClC;AACA,MAAM;AACN;AACA;;AAEA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,kBAAkB,qDAAS;AAC3B;AACA,cAAc,4CAAI;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,kBAAkB,qDAAS;AAC3B;AACA;;AAEA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,0CAA0C,qDAAS;;AAEnD;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,6BAA6B,qDAAS,wCAAwC,qDAAS;AACvF;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,YAAY,4CAAI;AAChB;AACA,8BAA8B,qDAAS;AACvC,6CAA6C,qDAAS;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,qBAAqB,qDAAS;AAC9B;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;;AAEA;AACA;AACA;AACA,YAAY,4CAAI;AAChB,4BAA4B,qDAAS,+BAA+B,qDAAS;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,qBAAqB,qDAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,iCAAiC,qDAAS;AAC1C;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA,8BAA8B,qDAAS;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,6BAA6B,qDAAS,gBAAgB,qDAAS;AAC/D;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,qBAAqB,qDAAS;AAC9B;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,YAAY,4CAAI;AAChB;AACA,+BAA+B,qDAAS;AACxC;AACA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,qBAAqB,qDAAS;AAC9B;;AAEA,uCAAuC,qDAAS;AAChD;AACA,cAAc,4CAAI;AAClB;AACA;AACA;AACA;AACA;;AAEA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,oCAAoC;AACpC;AACA;;AAEA;AACA;AACA,cAAc,4CAAI;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,WAAW,qDAAS;AACpB;;AAEA,WAAW,qDAAS;AACpB;;AAEA,WAAW,qDAAS;AACpB;;AAEA;AACA,gBAAgB,4CAAI;AACpB;AACA;AACA;;AAEA,WAAW,qDAAS;AACpB;;AAEA;AACA,gBAAgB,4CAAI;AACpB;AACA;AACA;;AAEA,WAAW,qDAAS;AACpB,WAAW,qDAAS;AACpB;;AAEA,WAAW,qDAAS;AACpB;;AAEA;AACA;AACA;AACA,oBAAoB,4CAAI;AACxB;AACA;AACA;;AAEA;AACA;AACA,oBAAoB,4CAAI;AACxB;AACA;AACA;;AAEA;AACA;AACA,oBAAoB,4CAAI;AACxB;AACA;;AAEA;AACA;AACA,oBAAoB,4CAAI;AACxB;AACA;AACA;AACA;;AAEA,WAAW,qDAAS;AACpB;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA,YAAY,4CAAI;AAChB;AACA,4BAA4B,qDAAS;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA,YAAY,4CAAI;AAChB,uBAAuB,qDAAS,kBAAkB,qDAAS;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA,YAAY,4CAAI;AAChB,uBAAuB,qDAAS,gBAAgB,qDAAS;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,qBAAqB,qDAAS;AAC9B;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;;AAEA;AACA;;AAEA,qBAAqB,qDAAS;AAC9B;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,qBAAqB,qDAAS;AAC9B;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,iCAAiC,qDAAS;AAC1C;AACA,uBAAuB,qDAAS;AAChC;AACA,cAAc,4CAAI;AAClB;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA,iCAAiC,qDAAS;AAC1C;AACA,cAAc,4CAAI;AAClB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,8BAA8B,qDAAS;AACvC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,qBAAqB,qDAAS,sBAAsB,qDAAS;AAC7D;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE;AACjE;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,mCAAmC,qDAAS,6CAA6C,qDAAS;AAClG;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,qBAAqB,qDAAS;AAC9B;AACA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,sBAAsB;;AAEtB,+BAA+B,qDAAS;;AAExC;AACA;AACA,QAAQ,gCAAgC,qDAAS,mBAAmB,qDAAS;;AAE7E;AACA;;AAEA,8BAA8B,qDAAS;AACvC;AACA;AACA,0BAA0B;AAC1B;AACA;;AAEA;AACA;;AAEA;AACA,8JAA8J,qDAAS,8CAA8C,qDAAS;AAC9N;;AAEA;;AAEA;AACA;;AAEA,6BAA6B,qDAAS,qCAAqC,qDAAS;AACpF;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,qBAAqB,qDAAS;AAC9B;AACA;AACA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,6BAA6B,qDAAS,mCAAmC,qDAAS;AAClF;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,qBAAqB,qDAAS;AAC9B;AACA;;AAEA,iCAAiC,qDAAS;AAC1C;AACA;;AAEA;AACA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,oCAAoC,qDAAS,8BAA8B,qDAAS;AACpF;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;;AAEA;AACA,6BAA6B,qDAAS,yCAAyC,qDAAS;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA;;AAEA;AACA,6BAA6B,qDAAS,mCAAmC,qDAAS;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,8BAA8B,qDAAS;AACvC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,2CAA2C;AAC3C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,2CAA2C,qDAAS,6CAA6C,qDAAS;;AAE1G;AACA;AACA;;AAEA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,qBAAqB,qDAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,4CAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,8BAA8B,qDAAS;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,QAAQ,qEAAiB;AACzB;AACA;;AAEA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,iBAAiB,8CAAQ;AACzB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,UAAU,mEAAW;AACrB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,uBAAuB,qDAAS;AAChC;AACA,MAAM;AACN,YAAY,mEAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,uBAAuB,qDAAS;AAChC;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,WAAW,mEAAW;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,QAAQ;;AAER;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,MAAM;;AAEN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,MAAM;;AAEN;AACA;;AAEA;AACA,CAAC;AACD;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA,SAAS,iEAAqB;AAC9B;;;;;;;;;;;;;;;;;;AC1gD6C;AAC7C;AACA;AACA;;AAEO;AACP,8CAA8C,0DAAW;AACzD;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;;AAEvC;AACA;AACA;AACA;;AAEA,oBAAoB,yBAAyB;AAC7C;AACA;;AAEA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;;;;;;;;;;;ACjEsC;AACe;AACrD;AACA;AACA;AACA;;AAEO;AACP,SAAS,mDAAK;AACd;AACA,GAAG;AACH;AACA,0BAA0B;;AAE1B;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,0CAA0C;AAC1C;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,2BAA2B,kEAAgB;AAC3C,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,aAAa,2BAA2B;AACxC,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,gBAAgB;AAChB;;;AAGA;AACA,gBAAgB,oCAAoC;AACpD;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACxTA,4CAA4C,gBAAgB,kBAAkB,OAAO,2BAA2B,wDAAwD,gCAAgC,uDAAuD;;AAE/P,8DAA8D,sEAAsE,8DAA8D;;AAElI;AACnB;AACI;AACE;;AAEnD;AACA;AACA;AACA;AACA,oEAAoE,qBAAqB;AACzF;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,kEAAS,+CAA+C,gEAAO;AAC/F;AACA;AACA;AACA,oCAAoC,kEAAS;AAC7C,sCAAsC,kEAAS;AAC/C,IAAI;;;AAGJ;AACA,SAAS,wEAAoB;AAC7B;AACA;AACA;AACA,GAAG;;AAEH;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;;AAEA;AACO;AACP,SAAS,mEAAU;AACnB;;;;;;;;;;;;;;;;AClDA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;AC9B6C;AACV;AACnC;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,4BAA4B;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;;AAEO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,UAAU;AACV;;AAEA,+DAA+D,4BAA4B;AAC3F;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA,yBAAyB,mBAAmB;AAC5C;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,WAAW,gDAAM;AACjB,oDAAoD,gEAAO;AAC3D;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;;AAEA;AACA,gBAAgB,gDAAM;AACtB;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,IAAI;;AAEJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA,sBAAsB,qBAAqB;AAC3C;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,cAAc;AACd;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,sBAAsB,qBAAqB;AAC3C;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;;AAEA;AACA;AACA,WAAW;AACX;AACA;;AAEA;;AAEA;AACA,WAAW,QAAQ,UAAU;AAC7B;AACA;AACA,IAAI;AACJ;;AAEA;AACA;AACA,aAAa,UAAU;AACvB;AACA;;AAEA;;AAEA;AACA,aAAa,SAAS,WAAW,WAAW;AAC5C;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC9XA;AACA;AACO,gHAAgH;AACvH;;AAEO,qIAAqI;;AAErI;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACPP;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,SAAS,gBAAgB,sCAAsC,kBAAkB;AACjF,wBAAwB;AACxB;AACA;;AAEO;AACP;AACA;AACA;AACA,kBAAkB;AAClB;AACA;;AAEO;AACP;AACA,+CAA+C,OAAO;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA,2DAA2D,cAAc;AACzE;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA,2CAA2C,QAAQ;AACnD;AACA;;AAEO;AACP,kCAAkC;AAClC;;AAEO;AACP,uBAAuB,uFAAuF;AAC9G;AACA;AACA,yGAAyG;AACzG;AACA,sCAAsC,QAAQ;AAC9C;AACA,gEAAgE;AAChE;AACA,8CAA8C,yFAAyF;AACvI,8DAA8D,2CAA2C;AACzG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA,kBAAkB,yBAAyB;AAC3C;AACA;AACA;AACA;;AAEO;AACP;AACA;;AAEO;AACP;AACA,4CAA4C,yEAAyE;AACrH;;AAEO;AACP;AACA;;AAEO;AACP,0BAA0B,+DAA+D,iBAAiB;AAC1G;AACA,kCAAkC,MAAM,+BAA+B,YAAY;AACnF,iCAAiC,MAAM,mCAAmC,YAAY;AACtF,8BAA8B;AAC9B;AACA,GAAG;AACH;;AAEO;AACP,YAAY,6BAA6B,0BAA0B,cAAc,qBAAqB;AACtG,2IAA2I,cAAc;AACzJ,qBAAqB,sBAAsB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC,iCAAiC,SAAS;AAC1C,iCAAiC,WAAW,UAAU;AACtD,wCAAwC,cAAc;AACtD;AACA,4GAA4G,OAAO;AACnH,+EAA+E,iBAAiB;AAChG,uDAAuD,gBAAgB,QAAQ;AAC/E,6CAA6C,gBAAgB,gBAAgB;AAC7E;AACA,gCAAgC;AAChC;AACA;AACA,QAAQ,YAAY,aAAa,SAAS,UAAU;AACpD,kCAAkC,SAAS;AAC3C;AACA;;AAEO;AACP;AACA;AACA;AACA,eAAe,oCAAoC;AACnD;AACA;AACA,CAAC;AACD;AACA;AACA,CAAC;;AAEM;AACP;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,MAAM;AACxB;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;;AAEA;AACO;AACP,2BAA2B,sBAAsB;AACjD;AACA;AACA;;AAEA;AACO;AACP,gDAAgD,QAAQ;AACxD,uCAAuC,QAAQ;AAC/C,uDAAuD,QAAQ;AAC/D;AACA;AACA;;AAEO;AACP,2EAA2E,OAAO;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;;AAEO;AACP;AACA;AACA,wMAAwM,cAAc;AACtN,4BAA4B,sBAAsB;AAClD,wBAAwB,YAAY,sBAAsB,qCAAqC,2CAA2C,MAAM;AAChJ,0BAA0B,MAAM,iBAAiB,YAAY;AAC7D,qBAAqB;AACrB,4BAA4B;AAC5B,2BAA2B;AAC3B,0BAA0B;AAC1B;;AAEO;AACP;AACA,eAAe,6CAA6C,UAAU,sDAAsD,cAAc;AAC1I,wBAAwB,6BAA6B,oBAAoB,uCAAuC,kBAAkB;AAClI;;AAEO;AACP;AACA;AACA,yGAAyG,uFAAuF,cAAc;AAC9M,qBAAqB,8BAA8B,gDAAgD,wDAAwD;AAC3J,2CAA2C,sCAAsC,UAAU,mBAAmB,IAAI;AAClH;;AAEO;AACP,+BAA+B,uCAAuC,YAAY,KAAK,OAAO;AAC9F;AACA;;AAEA;AACA,wCAAwC,4BAA4B;AACpE,CAAC;AACD;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP,2CAA2C;AAC3C;;AAEO;AACP;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,MAAM,oBAAoB,YAAY;AAC5E,qBAAqB,8CAA8C;AACnE;AACA;AACA,qBAAqB,aAAa;AAClC;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uFAAuF,SAAS,gBAAgB;AAChH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,iEAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,EAAC;;;;;;;;;;;;;;;;;;;;;ACzXyF;AACd;AACJ;AACY;;AAErF;AACA;AACA;AACA;AACA;AACA,yCAAyC,iFAAoB;AAC7D;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,iGAAiG;AACzI,gBAAgB,gFAAgF;AAChG;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,iGAA0B;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa,gFAAiB,GAAG,sFAAmB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB,aAAa;AACb,kBAAkB,yDAAa;AAC/B;AACA;AACA;AACA;AACA;AACA,6EAA6E,aAAa;AAC1F,gBAAgB,yBAAyB;AACzC,gBAAgB,2CAA2C,IAAI;AAC/D,4BAA4B,gCAAgC;AAC5D,qBAAqB,yDAAa;AAClC;AACA;AACA;AACA;AACA,gEAAgE,GAAG;AACnE;AACA,4BAA4B,mBAAmB;AAC/C;AACA,yBAAyB,mBAAmB;AAC5C;AACA;AACA;AACA;AACA,kBAAkB,yDAAa;AAC/B;AACA;AACA;AACA,gBAAgB,WAAW,sBAAsB,sEAA0B,GAAG,IAAI,IAAI;AACtF;AACA;AACA;AACA,gBAAgB,WAAW,WAAW,gCAAgC,IAAI,SAAS,IAAI,IAAI;AAC3F,iBAAiB;AACjB;AACA;;AAEsC;AACtC;;;;;;;;;;;;;;;;;;;;;AC7FuF;;AAEvF;AACA;AACA;AACA,6CAA6C,GAAG,kBAAkB,EAAE,UAAU,GAAG;AACjF,0CAA0C,GAAG,cAAc,EAAE,UAAU,GAAG;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,yEAAU;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,sCAAsC;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,qFAAsB;AAC7C;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,qFAAsB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,+DAA+D,yBAAyB,eAAe;AACnH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE0I;AAC1I;;;;;;;;;;;;;;;;;;;;;AC1GoE;AACO;AACZ;AACC;;AAEhE;AACA;AACA,mBAAmB,4DAAa;AAChC,oCAAoC,MAAM;AAC1C,0BAA0B,mEAAgB;AAC1C;AACA;AACA;AACA;AACA;AACA,yCAAyC,eAAe;AACxD;AACA,sDAAsD,EAAE;AACxD;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,wDAAwD;AAC9F;AACA;AACA;AACA;AACA,yBAAyB,mEAAgB;AACzC;AACA,gBAAgB,uBAAuB,EAAE,aAAa;AACtD;AACA;AACA,mBAAmB,GAAG,wEAA4B,EAAE;AACpD;AACA,yBAAyB,yFAAW;AACpC;AACA;AACA,iBAAiB,yEAAU;AAC3B;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,kCAAkC,gCAAgC;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,6GAA6G;AACzJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,oBAAoB;AAChE;AACA;AACA;AACA;AACA;AACA,kBAAkB,yEAAU;AAC5B;AACA;AACA,4CAA4C,mCAAmC;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEsC;AACtC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChGkC;AACK;AACgB;AAC0G;AAC3F;AACgN;AACnL;AACT;AACgC;AAC3D;;AAE/D;AACA;AACA;AACA,IAAI,kDAAG,oCAAoC,6DAAc;AACzD;AACA;AACA;AACA;AACA,4BAA4B,yDAAa;AACzC,gCAAgC,sEAA0B;AAC1D;AACA,0CAA0C,qFAAsB;AAChE,uCAAuC,+EAAmB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE,eAAe;AACrF;AACA;AACA;AACA;AACA;AACA,wBAAwB,uBAAuB;AAC/C,oBAAoB,+DAAmB;AACvC;AACA;AACA,oBAAoB,qEAAyB;AAC7C,8BAA8B,gFAAiB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,4DAAa;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,yDAAa;AACzC,2CAA2C,gFAAiB;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,mBAAmB,4CAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,mCAAmC,8EAAW;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,6CAA6C,0DAAW,kCAAkC,IAAI,IAAI;AAClG,2DAA2D,gFAAiB;AAC5E,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,8CAA8C,4CAAU;AACxD;AACA,aAAa;AACb;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,kCAAkC,yDAAa;AAC/C;AACA;AACA;AACA;AACA;AACA,kCAAkC,yDAAa;AAC/C;AACA;AACA;AACA;AACA;AACA,gBAAgB,6DAA6D;AAC7E,gBAAgB,0BAA0B,QAAQ,6EAA4B;AAC9E,2CAA2C,gFAAiB;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,+BAA+B,8EAAW;AAC1C,gBAAgB,gDAAgD,QAAQ,6EAA4B;AACpG;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA;AACA;AACA,sCAAsC,+DAAmB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,IAAI;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,mEAAuB;AAC9C;AACA;AACA;AACA,iBAAiB;AACjB,gDAAgD,gBAAgB;AAChE,aAAa;AACb;AACA;AACA,oCAAoC,8DAAe;AACnD,gDAAgD,0EAAc;AAC9D;AACA;AACA;AACA;AACA,gBAAgB,8DAAe;AAC/B,gBAAgB,8DAAe;AAC/B,gBAAgB,8DAAe;AAC/B,gBAAgB,8DAAe;AAC/B,gBAAgB,8DAAe;AAC/B,gBAAgB,8DAAe;AAC/B;AACA,gDAAgD,0EAAc;AAC9D;AACA,SAAS;AACT;AACA,qDAAqD,4DAA4D;AACjH,gBAAgB,mBAAmB;AACnC,gBAAgB,gDAAgD,QAAQ,6EAA4B;AACpG;AACA;AACA;AACA,sCAAsC;AACtC,+BAA+B,+DAAmB;AAClD;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,wDAAwD;AACxE;AACA;AACA;AACA,+BAA+B,+DAAmB;AAClD;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA,aAAa,EAAE,6DAAiB;AAChC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,KAAK;AACjC;AACA;AACA,2CAA2C,gFAAiB;AAC5D;AACA,qCAAqC,8DAAe;AACpD;AACA,gBAAgB,uFAAmB;AACnC;AACA;AACA;AACA,mCAAmC,kDAAY,IAAI,0DAAW,mBAAmB,IAAI,QAAQ;AAC7F,yBAAyB;AACzB;AACA,iBAAiB;AACjB;AACA;AACA,qCAAqC,0DAAW,mBAAmB,IAAI,QAAQ;AAC/E;AACA,oBAAoB,6BAA6B;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA,sCAAsC,+DAAmB;AACzD;AACA,4BAA4B,4EAA4E;AACxG;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,yDAAa;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,KAAK;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,yDAAa;AAC7C;AACA;AACA,2CAA2C,gFAAiB;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,yDAAa;AAC7C,+CAA+C,gFAAiB;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,oBAAoB;AACpC,gBAAgB,2CAA2C,8EAA8E;AACzI,qBAAqB,yDAAa;AAClC,qBAAqB,yDAAa;AAClC,wDAAwD,iBAAiB,kBAAkB,EAAE;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,0DAAW;AAClC,wBAAwB,kBAAkB;AAC1C;AACA,aAAa;AACb,sCAAsC,+DAAmB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,+CAA+C,gFAAiB;AAChE;AACA;AACA,qBAAqB,yDAAa;AAClC;AACA;AACA;AACA;AACA;AACA,sCAAsC,0DAAW;AACjD,aAAa;AACb;AACA,mDAAmD,gFAAiB;AACpE,aAAa,EAAE,4EAAgC;AAC/C,+CAA+C,gFAAiB;AAChE;AACA;AACA,qBAAqB,yDAAa;AAClC,sCAAsC,+DAAmB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,qCAAqC,0DAAW,mBAAmB,IAAI,gCAAgC;AACvG;AACA;AACA;AACA,mCAAmC,kDAAY,IAAI,0DAAW,mBAAmB,IAAI,gCAAgC;AACrH,yBAAyB;AACzB;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,IAAI;AACnD;AACA,+CAA+C,gFAAiB;AAChE;AACA;AACA,4BAA4B,yDAAa;AACzC;AACA;AACA;AACA;AACA,oBAAoB,6BAA6B;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,+DAAmB;AACtD,aAAa;AACb,+CAA+C,gFAAiB;AAChE,2EAA2E,kBAAkB;AAC7F;AACA;AACA,qCAAqC,sFAAsF;AAC3H,kCAAkC,yDAAa;AAC/C;AACA;AACA;AACA;AACA;AACA,qCAAqC,2BAA2B;AAChE,sCAAsC,yDAAa;AACnD;AACA,wCAAwC,yDAAa;AACrD;AACA,6CAA6C;AAC7C,6CAA6C,6EAA0B;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,0CAA0C,6EAAa;AACvD;AACA;AACA,qBAAqB;AACrB,2DAA2D,cAAc;AACzE,wCAAwC,6EAA4B;AACpE,2CAA2C,2EAA0B;AACrE;AACA,iDAAiD,KAAK;AACtD;AACA;AACA,qBAAqB;AACrB,wCAAwC,yDAAa;AACrD;AACA;AACA;AACA;AACA,iDAAiD,KAAK;AACtD;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,yDAAa;AACrD;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,cAAc,4FAAwB,sEAAsE,wDAAY;AACxH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,sBAAsB;AAC3E;AACA;AACA,sDAAsD,aAAa;AACnE;AACA;AACA;AACA;AACA;AACA;AACA,oFAAoF,cAAc;AAClG;AACA,wBAAwB,OAAO;AAC/B;AACA,6BAA6B,yDAAa;AAC1C;AACA;AACA;AACA;AACA;AACA,6BAA6B,yDAAa;AAC1C,4BAA4B,uBAAuB;AACnD;AACA;AACA,6BAA6B,sBAAsB;AACnD;AACA;AACA;AACA,sBAAsB,yDAAa;AACnC;AACA;AACA;AACA;AACA,uDAAuD,gFAAiB;AACxE,+GAA+G,mEAAuB,EAAE;AACxI;AACA;AACA;AACA;AACA,aAAa,EAAE,mEAAuB;AACtC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,0DAAW;AAC7C;AACA;AACA,kDAAkD,aAAa;AAC/D,kCAAkC,0DAAW;AAC7C;AACA;AACA;;AAEgC;AAChC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpoBmE;;AAEnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AACvC;AACA;AACA;AACA;AACA;AACA,CAAC,kDAAkD;AACnD;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AACvC;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEiU;AACjU;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzIuC;AACL;AACkD;AAC9B;AACuC;AACE;AACpC;AACgB;AACS;AACxB;AACU;AAC9B;AACwD;AACQ;AACpD;;AAEpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,uGAA0B;AAC7D;AACA,gBAAgB;AAChB,wBAAwB,mEAAM;AAC9B,+BAA+B,gEAAa;AAC5C,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,8CAAK;AACzB;AACA,iBAAiB,0BAA0B;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iCAAiC,uBAAuB;AAC/E;AACA,cAAc,8CAAK;AACnB,cAAc,8CAAK,CAAC,8CAAK;AACzB,gCAAgC;AAChC,gBAAgB,2BAA2B;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,4BAA4B;AAC3F;AACA;AACA;AACA;AACA;AACA,8EAA8E,4BAA4B;AAC1G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,4BAA4B;AACrF;AACA,2DAA2D,cAAc;AACzE;AACA;AACA,8BAA8B,8CAA8C,wBAAwB;AACpG,gBAAgB,2GAA2G,EAAE,uEAAa;AAC1I;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,0CAA0C,EAAE,uFAAqB;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,yEAAU;AACnC,6BAA6B,8CAAK;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,iEAAe;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2EAA2E,QAAQ;AACnF;AACA;AACA;AACA,2BAA2B,8CAAK;AAChC;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,qCAAqC,sFAAmB;AACxD,aAAa;AACb;AACA;AACA,mBAAmB,8CAAK;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,6GAA4B,KAAK,+EAAe,CAAC,qEAAW;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,qBAAqB;AACzC,yBAAyB,yEAAU;AACnC;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,6GAA4B;AACnD;AACA,YAAY,sHAA2B;AACvC,kBAAkB,iGAA0B;AAC5C;AACA;AACA;AACA;AACA;AACA,eAAe,KAAK;AACpB,gBAAgB,SAAS;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,KAAK;AACpB;AACA;AACA;AACA;AACA;AACA,iCAAiC,8CAA8C,wBAAwB;AACvG,uBAAuB,uEAAa;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,gCAAgC,EAAE,uFAAqB;AACvE;AACA;AACA,mBAAmB,8CAAK;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,kBAAkB,iDAAU;AAC5B;AACA,sBAAsB,iGAA0B;AAChD;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEuD;AACvD;;;;;;;;;;;;;;;;;;ACrQsE;AAC9B;AACvB;AAC8H;;AAE/I;AACA;AACA,gFAAgF;AAChF;AACA;AACA;AACA;AACA,0BAA0B,8EAAe,CAAC,mEAAU;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,8EAAe,CAAC,6EAAoB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,8EAAe;AACzC,uBAAuB,0EAAiB;AACxC;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,0BAA0B,8EAAe,CAAC,4EAAmB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,8EAAe,CAAC,6EAAoB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE2B;AAC3B;;;;;;;;;;;;;;;;AC/DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEuC;AACvC;;;;;;;;;;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,kCAAkC;AACnC,WAAW,QAAQ;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0CAA0C;;AAEH;AACxC;;;;;;;;;;;;;;;;;;;;;;;;AC9C4D;;AAE5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEyF;AACzF;;;;;;;;;;;;;;;;;;;;;;ACzB+C;AACO;AACgB;;AAEtE;AACA;AACA;AACA,yBAAyB,6BAA6B;AACtD,kBAAkB,2BAA2B;AAC7C,8BAA8B,8BAA8B;AAC5D;AACA;AACA;AACA,KAAK;AACL,0BAA0B,yCAAyC;AACnE;AACA;AACA;AACA,KAAK;AACL,cAAc,iCAAiC;AAC/C,cAAc,2BAA2B;AACzC,eAAe,8BAA8B;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,mFAAmB,gBAAgB,QAAQ;AAC3F;AACA;AACA,SAAS;AACT;AACA,gBAAgB,4CAAU;AAC1B;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,mFAAmB,gBAAgB,QAAQ;AAC7F;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,6BAA6B;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,yCAAG;AACrB;AACA,SAAS;AACT,kBAAkB,4CAAM;AACxB;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA,iCAAiC,yEAAyE;AAC1G;AACA,mBAAmB,8DAAe;AAClC;AACA;AACA,mBAAmB,8DAAe;AAClC;AACA;AACA;AACA,mBAAmB,8DAAe;AAClC;AACA;AACA,mBAAmB,8DAAe;AAClC;AACA,mBAAmB,8DAAe;AAClC;AACA;AACA,mBAAmB,8DAAe;AAClC;AACA,mBAAmB,8DAAe;AAClC,eAAe,8DAAe;AAC9B;AACA;;AAEqD;AACrD;;;;;;;;;;;;;;;;;ACnIiE;;AAEjE;AACA;AACA,sCAAsC,2EAAY;;AAEnB;AAC/B;;;;;;;;;;;;;;;;;;ACPiF;;AAEjF;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,EAAE,wEAAkB;AACzC,iBAAiB,EAAE,qEAAe;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;;AAE+C;AAC/C;;;;;;;;;;;;;;;;;ACpEiE;;AAEjE;AACA;AACA;AACA;AACA;AACA,8BAA8B,2EAAY;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE2B;AAC3B;;;;;;;;;;;;;;;;;;AClBwD;AACF;;AAEtD;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,8BAA8B,EAAE,+DAAkB;AAC9D;AACA,kBAAkB,iEAAe,GAAG,mCAAmC;AACvE;AACA;;AAEiC;AACjC;;;;;;;;;;;;;;;;;;;;;;AChByD;;AAEzD;AACA;AACA;AACA;AACA;AACA,aAAa,8DAAgB;AAC7B;AACA;AACA;AACA;AACA;AACA,aAAa,8DAAgB;AAC7B;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,aAAa,8DAAgB;AAC7B;AACA;AACA;AACA;AACA;AACA,aAAa,8DAAgB;AAC7B;AACA;AACA;AACA;AACA;AACA,aAAa,8DAAgB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;;AAEuH;AACvH;;;;;;;;;;;;;;;;;AC7CuC;;AAEvC;AACA;AACA;AACA;AACA,gBAAgB;AAChB,qBAAqB,iDAAY;AACjC;AACA;;AAEwC;AACxC;;;;;;;;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE,iBAAiB;AACpF;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEsC;AACtC;;;;;;;;;;;;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wDAAwD;AACzD;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;;AAEsD;AACtD;;;;;;;;;;;;;;;;;;;ACzBkD;AACP;AACgC;AACV;AAChD;;AAEjB;AACA;AACA,mBAAmB,4DAAa;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,mFAAmF;AAC/F;AACA;AACA,IAAI,wFAAqB,6CAA6C,0EAAsB;AAC5F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEyB;AACzB;;;;;;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;;AAEiC;AACjC;;;;;;;;;;;;;;;;;;;;;;;;;ACZ8I;AACnG;AACN;AACmC;AACxB;AACoB;AACJ;;AAEhE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,2DAA2D;AACvE;AACA;AACA;AACA;AACA;AACA,4BAA4B,yEAAc;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,6FAAe,CAAC,6EAAwB;AAC9D,sBAAsB,yFAAe;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,6EAAgB;AACnD;AACA;AACA,yBAAyB,kGAAoB;AAC7C;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,yBAAyB,oGAAsB;AAC/C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,cAAc;AAC9B;AACA;AACA;AACA;AACA;AACA,QAAQ,qDAAM;AACd;AACA;AACA;;AAE2B;AAC3B;;;;;;;;;;;;;;;;;;;;;;;AC/EwF;AAClC;AACX;AACN;AACL;AACoD;AACpC;;AAEhD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA,eAAe;AACf;AACA,eAAe,oBAAoB;AACnC;AACA;AACA;AACA,cAAc,qBAAqB;AACnC;AACA,yBAAyB,+BAA+B;AACxD;AACA,4BAA4B,iGAA0B;AACtD,yBAAyB,6DAAe;AACxC;AACA;AACA;AACA;AACA,SAAS,EAAE,yFAA6B;AACxC;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEsD;AACtD;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9FwF;AACpB;AACd;AACX;AACN;AACyB;AACd;AACiC;AACjC;;AAEhD;AACA;AACA,oDAAoD,iGAA0B;AAC9E,YAAY,iCAAiC,kBAAkB;AAC/D,gBAAgB,uEAAa;AAC7B;AACA;AACA,KAAK;AACL,YAAY,kCAAkC;AAC9C;AACA;AACA;AACA;AACA;AACA,+BAA+B,6EAAgB;AAC/C;AACA;AACA,KAAK;AACL,IAAI,qDAAM,qDAAqD,mCAAmC;AAClG,WAAW,6DAAe;AAC1B;AACA;AACA;AACA;AACA;AACA,KAAK,EAAE,sFAA0B;AACjC,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;;AAE4C;AAC5C;;;;;;;;;;;;;;;;;;;;;;;AC7C4C;AACyF;;AAErI;AACA;AACA;AACA;AACA,WAAW,UAAU;AACrB,aAAa,cAAc;AAC3B,cAAc;AACd;AACA;AACA;AACA,YAAY,qBAAqB;AACjC;AACA,WAAW,OAAO;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,qBAAqB;AACjC;AACA,WAAW,mBAAmB,OAAO,uBAAuB;AAC5D;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,2DAAK,CAAC,sDAAO;AACpC;AACA;AACA,WAAW,WAAW;AACtB,aAAa,eAAe;AAC5B,cAAc;AACd;AACA;AACA;AACA,YAAY,sBAAsB;AAClC;AACA,WAAW,OAAO;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sBAAsB;AAClC;AACA,WAAW,mBAAmB,QAAQ,uBAAuB;AAC7D;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,4DAAM,CAAC,sDAAO;AACtC;AACA;AACA,WAAW,UAAU;AACrB,aAAa,cAAc;AAC3B,cAAc;AACd;AACA;AACA;AACA,YAAY,qBAAqB;AACjC;AACA,WAAW,OAAO;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA,YAAY,qBAAqB;AACjC;AACA,WAAW,mBAAmB,OAAO,uBAAuB;AAC5D;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,2DAAK,CAAC,sDAAO;AACpC;AACA;AACA,WAAW,aAAa;AACxB,aAAa,iBAAiB;AAC9B,cAAc;AACd;AACA;AACA;AACA,YAAY,MAAM;AAClB;AACA,WAAW,aAAa;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,uBAAuB,2DAAK,CAAC,sDAAO;AACpC;AACA;AACA,WAAW,WAAW;AACtB,aAAa,eAAe;AAC5B,cAAc;AACd;AACA;AACA;AACA,YAAY,sBAAsB;AAClC;AACA,WAAW,sBAAsB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,wBAAwB,4DAAM,CAAC,sDAAO;AACtC;AACA;AACA,WAAW,YAAY;AACvB,aAAa,gBAAgB;AAC7B,cAAc;AACd;AACA;AACA;AACA,YAAY,QAAQ;AACpB;AACA,WAAW,OAAO;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,uBAAuB;AACnC;AACA,WAAW,mBAAmB,SAAS,uBAAuB;AAC9D;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,6DAAO,CAAC,sDAAO;;AAEI;AAC5C;;;;;;;;;;;;;;;;;;ACjNkD;;AAElD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,2DAAY;AACxC,2BAA2B;AAC3B;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,SAAS;AACpB;AACA;AACA;;AAEwC;AACxC;;;;;;;;;;;;;;;;;ACjC6D;;AAE7D;AACA;AACA,2BAA2B,uEAAQ;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEwB;AACxB;;;;;;;;;;;;;;;;;;ACdkD;AACI;;AAEtD;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,8BAA8B,EAAE,+DAAkB;AAC9D;AACA,kBAAkB,2DAAY,GAAG,mCAAmC;AACpE;AACA;;AAEiC;AACjC;;;;;;;;;;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA,CAAC,gEAAgE;AACjE;AACA;AACA;AACA;AACA,KAAK;AACL;;AAE0D;AAC1D;;;;;;;;;;;;;;;;;;;;;;;;ACd2D;AACS;AACpE;;;;;;;;;;;;;;;;;;;ACF6F;AAC7F;;;;;;;;;;;;;;;;;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;;AAE4H;AAC5H;;;;;;;;;;;;;;;;;;;;ACZ4D;AACjB;AACT;AAC4B;AACxB;;AAEtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,2EAAwB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,oEAAa;AACvD,qCAAqC,SAAS;AAC9C;AACA;AACA,iBAAiB;AACjB,gBAAgB,+CAAM;AACtB;AACA;AACA,YAAY,+CAAM;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;;AAEsC;AACtC;;;;;;;;;;;;;;;;;AClEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,SAAS;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,SAAS;;AAEsB;AACrE;;;;;;;;;;;;;;;;;AClCkD;;AAElD;AACA;AACA,mBAAmB,4DAAa;;AAEd;AAClB;;;;;;;;;;;;;;;;;ACPsH;;AAEtH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0BAA0B,4EAAgC,0BAA0B,sEAA0B,IAAI;AAC9H;AACA,YAAY,WAAW;AACvB,gCAAgC,iEAAqB;AACrD,oBAAoB,4EAAgC;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE4B;AAC5B;;;;;;;;;;;;;;;;;;;;ACxCuF;AAC7B;AACiB;AACe;;AAE1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,uFAAqB,WAAW,8EAA0B;AAC9D;AACA,wBAAwB,yEAAU;AAClC;AACA,0CAA0C,qFAAsB;AAChE;AACA;AACA,aAAa;AACb,6BAA6B,qFAAsB;AACnD;AACA;AACA;AACA;AACA,kBAAkB,kEAAY;AAC9B,kBAAkB,8EAA0B;AAC5C,eAAe,sEAAkB,CAAC,8EAA0B;AAC5D,qGAAqG,OAAO;AAC5G,SAAS;AACT;AACA;;AAEyB;AACzB;;;;;;;;;;;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE0B;AAC1B;;;;;;;;;;;;;;;;;;;ACvB8E;AACpB;AACxB;;AAElC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,4FAAc;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,kEAAY;AACzC;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,yCAAyC,4BAA4B;AACrE;;AAEoC;AACpC;;;;;;;;;;;;;;;;;;;;;AChG6E;AAC1B;AACqB;;AAExE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,oDAAK;AAC1B,+BAA+B,uFAAuB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,uEAAQ;AAC9B,oBAAoB,wEAAS;AAC7B;AACA;AACA,wCAAwC,sDAAO;AAC/C;AACA;AACA;;AAEyC;AACzC;;;;;;;;;;;;;;;;AC/CA;AACA;AACA;AACA;AACA,gDAAgD,QAAQ;AACxD;AACA;;AAEyC;AACzC;;;;;;;;;;;;;;;;;;ACToF;AACxB;;AAE5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,qEAA6B;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,uBAAuB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,8BAA8B;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,qEAA6B;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,qEAA6B;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,qEAA6B;AAC5D;AACA;AACA;AACA,sCAAsC,6FAA6B;AACnE,kCAAkC,WAAW;AAC7C,qCAAqC,YAAY;AACjD,oCAAoC;AACpC;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qEAA6B;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qFAAqF,cAAc;AACnG;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,qEAA6B;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,qEAA6B;AACnD;AACA;;AAEoC;AACpC;;;;;;;;;;;;;;;;ACzRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sEAAsE;;AAE9B;AACzC;;;;;;;;;;;;;;;;;;;;;;ACtB4D;AACK;AACE;AACnB;AACc;AACe;AAC3C;;AAElC;AACA;AACA,mBAAmB,oEAAa;AAChC;AACA;AACA;AACA,2BAA2B,uEAAkB;AAC7C;AACA;AACA;AACA;AACA;AACA,wBAAwB,+EAA2B;AACnD,gBAAgB,6BAA6B,yEAAe,WAAW;AACvE;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,cAAc;AAC9B;AACA,wBAAwB,yBAAyB;AACjD;AACA,uCAAuC,0EAAiB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,gBAAgB,QAAQ;AACxB;AACA;AACA,sDAAsD,yDAAa;AACnE;AACA,+BAA+B,mEAAc;AAC7C;AACA;AACA;AACA;;AAEwB;AACxB;;;;;;;;;;;;;;;;;;;;ACxD4D;AACI;AAC4B;AAC1B;;AAElE;AACA;AACA,mBAAmB,oEAAa;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,0BAA0B;AAC5C;AACA,eAAe,yDAAa;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA,mDAAmD,0EAAiB;AACpE;AACA,4CAA4C,0EAAiB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB;AACA,gBAAgB;AAChB;AACA;AACA,yCAAyC,IAAI,aAAa,OAAO,gBAAgB,QAAQ;AACzF,4BAA4B,0DAAc;AAC1C,8EAA8E,0DAAc,CAAC;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,uEAAc;AACzD;AACA;AACA;AACA;AACA;AACA,+BAA+B,sBAAsB,EAAE,IAAI;AAC3D;AACA;AACA;AACA,0CAA0C,KAAK;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,EAAE;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB;AACA,gBAAgB,SAAS;AACzB;AACA;AACA,yCAAyC,KAAK,eAAe,QAAQ;AACrE;AACA,4BAA4B,0DAAc;AAC1C,8EAA8E,0DAAc,CAAC;AAC7F;AACA;AACA,+BAA+B,sBAAsB,EAAE,IAAI;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,EAAE;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,gBAAgB;AAChB;AACA;AACA,4CAA4C,IAAI;AAChD,4BAA4B,0DAAc;AAC1C,8EAA8E,0DAAc,CAAC;AAC7F;AACA;AACA,+BAA+B,sBAAsB,EAAE,IAAI;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,EAAE;AAChD;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,EAAE;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAM,gBAAgB,mEAAc,sBAAsB,IAAI;AACtE;AACA,YAAY,uEAAc;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAM,gBAAgB,mEAAc,sBAAsB,YAAY;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,gBAAgB;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,uEAAc;AACrC,yBAAyB,uEAAc;AACvC;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,sEAAa;AACrC;AACA,wBAAwB,sEAAa;AACrC;AACA;AACA;AACA;AACA;AACA,sCAAsC,yDAAa;AACnD;AACA;AACA;AACA,0CAA0C,yDAAa;AACvD;AACA;AACA;AACA;AACA,2CAA2C,yDAAa;AACxD;AACA;AACA;AACA;AACA;AACA,0CAA0C,yDAAa;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,0EAAiB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,0EAAiB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,uEAAc;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,WAAW;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,sBAAsB,EAAE,IAAI;AACnE;AACA;AACA;AACA;AACA,yCAAyC,EAAE;AAC3C;AACA;AACA;;AAE8B;AAC9B;;;;;;;;;;;;;;;;;ACpdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEyC;AACzC;;;;;;;;;;;;;;;;;AChBkD;;AAElD;AACA;AACA,kBAAkB,2DAAY;;AAEb;AACjB;;;;;;;;;;;;;;;;;;;;ACPkD;;AAElD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,QAAQ;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,UAAU,EAAE,0DAAc,CAAC;;AAEA;AACvE;;;;;;;;;;;;;;;;;;AC7CmF;AACnD;AACO;;AAEvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,eAAe,4FAAuB;;AAEJ;AAClC;;;;;;;;;;;;;;;;;;;;;;AC1B4D;AACS;AACX;AAC7B;AACO;;AAEpC;AACA;AACA;AACA;AACA;AACA,mBAAmB,oEAAa;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,QAAQ;AACpD;AACA;AACA;AACA,gCAAgC,UAAU;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,SAAS;AACjD;AACA;AACA;AACA;AACA,uBAAuB,YAAY;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,kEAAY;AAClC,sBAAsB,6EAAiC;AACvD;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,gBAAgB,mBAAmB;AACnC;AACA;AACA;AACA,+CAA+C,SAAS;AACxD;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEsD;AACtD;;;;;;;;;;;;;;;;;;ACvH2D;AACrB;;AAEtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB;AACA,8BAA8B,+CAAO;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,gBAAgB;AAC/B,eAAe,eAAe;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,+CAAO;AAC5B;AACA;AACA,qBAAqB,+CAAO;AAC5B;AACA;AACA;AACA,yBAAyB,+CAAO;AAChC;AACA;AACA,yBAAyB,+CAAO;AAChC;AACA;AACA;AACA,2BAA2B,KAAK,IAAI,YAAY,EAAE,UAAU;AAC5D;AACA;AACA,yBAAyB,QAAQ,IAAI,OAAO;AAC5C;AACA;AACA;AACA,yBAAyB,QAAQ,EAAE,OAAO;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,QAAQ,IAAI,QAAQ,EAAE,IAAI;AACnD,mBAAmB,QAAQ,IAAI,OAAO;AACtC;AACA;AACA,yBAAyB,QAAQ,EAAE,IAAI;AACvC;AACA;AACA;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,eAAe;AAC9B;AACA;AACA,kBAAkB,+CAAO;AACzB;AACA;AACA;AACA;AACA;AACA,eAAe,eAAe;AAC9B;AACA;AACA,kBAAkB,+CAAO;AACzB;AACA;AACA;AACA;AACA;AACA,eAAe,eAAe;AAC9B;AACA;AACA,kBAAkB,+CAAO;AACzB;AACA;AACA;AACA;AACA;AACA,eAAe,eAAe;AAC9B;AACA;AACA,kBAAkB,+CAAO;AACzB;AACA;AACA;AACA;AACA;AACA,eAAe,eAAe;AAC9B;AACA;AACA,kBAAkB,+CAAO;AACzB;AACA;AACA;AACA;AACA;AACA,eAAe,eAAe;AAC9B;AACA;AACA,kBAAkB,+CAAO;AACzB;AACA;AACA,yDAAyD,mEAAuB;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEyB;AACzB;;;;;;;;;;;;;;;;AC7KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0BAA0B;;AAER;AACnB;;;;;;;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEiB;AACjB;;;;;;;;;;;;;;;;;ACvEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK,6CAA6C;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEkD;AAClD;;;;;;;;;;;;;;;;;;;;;ACtDwC;AACO;;AAE/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B,8BAA8B;AAC9B,oCAAoC;AACpC;AACA;AACA,yBAAyB,4DAAM;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,qBAAqB,iDAAS;AAC9B,qBAAqB,iDAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;;AAE0F;AAC1F;;;;;;;;;;;;;;;;;;ACrE4E;;AAE5E;AACA;AACA;AACA;AACA,gDAAgD,4DAAc;AAC9D,8CAA8C,0DAAY;AAC1D;AACA;AACA;AACA,aAAa,2DAAa;AAC1B;AACA;AACA;AACA;;AAE8C;AAC9C;;;;;;;;;;;;;;;;;AClB6C;;AAE7C;AACA;AACA;AACA;AACA,WAAW,0DAAY;AACvB;;AAEsB;AACtB;;;;;;;;;;;;;;;;;;ACV2E;;AAE3E;AACA;AACA;AACA;AACA,YAAY,0DAAY;AACxB;AACA;AACA;AACA;AACA,YAAY,0DAAY;AACxB,SAAS,4DAAc,sBAAsB,4DAAc;AAC3D;;AAEwC;AACxC;;;;;;;;;;;;;;;;;;AChB2D;;AAE3D;AACA;AACA;AACA;AACA,YAAY,0DAAY;AACxB;AACA;AACA;AACA;AACA,YAAY,0DAAY;AACxB;;AAEwC;AACxC;;;;;;;;;;;;;;;;;;ACf8D;;AAE9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,4DAAc;AACzB;AACA;AACA,YAAY,2DAAa;AACzB;AACA;AACA;AACA;;AAE0C;AAC1C;;;;;;;;;;;;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE6B;AAC7B;;;;;;;;;;;;;;;;;;ACV4E;;AAE5E;AACA;AACA;AACA;AACA,WAAW,0DAAY,MAAM,4DAAc;AAC3C;AACA;AACA,YAAY,2DAAa;AACzB;AACA;AACA;;AAE4C;AAC5C;;;;;;;;;;;;;;;;;;ACf2E;;AAE3E;AACA;AACA;AACA;AACA,WAAW,0DAAY,MAAM,4DAAc;AAC3C;AACA;AACA,WAAW,0DAAY,MAAM,4DAAc;AAC3C;;AAEsC;AACtC;;;;;;;;;;;;;;;;;ACb6C;;AAE7C;AACA;AACA;AACA,WAAW,0DAAY;AACvB;;AAEqB;AACrB;;;;;;;;;;;;;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEuG;AACvG;;;;;;;;;;;;;;;;;;;;;;;;;;ACtByC;AACoB;AACN;AACS;AACN;AACA;AACS;AACb;AACd;AACF;;AAEtC;AACA;AACA;AACA;AACA;AACA,MAAM,UAAU,iDAAS,wBAAwB,iDAAU,EAAE;AAC7D,MAAM,UAAU,iDAAS,+BAA+B,+DAAiB,EAAE;AAC3E;AACA,MAAM,UAAU,iDAAS,0BAA0B,oDAAa,EAAE;AAClE,MAAM,UAAU,iDAAS,wBAAwB,oDAAa,EAAE;AAChE,MAAM,UAAU,iDAAS,2BAA2B,0DAAgB,EAAE;AACtE,MAAM,UAAU,iDAAS,yBAAyB,sDAAc,EAAE;AAClE,MAAM,UAAU,iDAAS,yBAAyB,kDAAY,EAAE;AAChE,MAAM,UAAU,iDAAS,0BAA0B,wDAAe,EAAE;AACpE,MAAM,UAAU,iDAAS,8BAA8B,+CAAS,EAAE;AAClE;AACA,MAAM,UAAU,iDAAS,6BAA6B,oDAAa,EAAE;AACrE,MAAM,UAAU,iDAAS,2BAA2B,oDAAa,EAAE;AACnE,MAAM,UAAU,iDAAS,4BAA4B,sDAAc,EAAE;AACrE,MAAM,UAAU,iDAAS,4BAA4B,kDAAY,EAAE;AACnE,MAAM,UAAU,iDAAS,8BAA8B,0DAAgB,EAAE;AACzE,MAAM,UAAU,iDAAS,6BAA6B,wDAAe,EAAE;AACvE;AACA;AACA;AACA,sBAAsB,iDAAS;AAC/B;;AAEkB;AAClB;;;;;;;;;;;;;;;;;;;;;;;ACxCwC;AACA;AACyC;AACtB;;AAE3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,gBAAgB,GAAG,uBAAuB,iDAAO,EAAE;AAC/E;AACA;AACA,eAAe,qEAAe;AAC9B;AACA;AACA,mCAAmC,iDAAS;AAC5C,+BAA+B,iDAAS;AACxC;AACA;AACA,QAAQ,6EAAuB;AAC/B;AACA;AACA;AACA,qCAAqC,oBAAoB,IAAI;AAC7D;AACA,iDAAiD,iDAAO;AACxD;AACA;AACA;AACA;AACA,iCAAiC,qEAAe;AAChD;AACA,4BAA4B,wEAAkB;AAC9C;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qEAAqE,SAAS,GAAG,WAAW;AAC5F;AACA;AACA;;AAE4F;AAC5F;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B;AAC7B;AACA;AACA;AACA;AACA,CAAC,0CAA0C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AACjC;AACA;AACA;AACA;AACA,CAAC,0CAA0C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AAC/B;AACA;AACA;AACA;AACA;AACA,CAAC,oDAAoD;AACrD;AACA;AACA;AACA,CAAC,gDAAgD;AACjD;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;AACA;AACA;AACA,CAAC,oCAAoC;AACrC;AACA;AACA;AACA;AACA,CAAC,wDAAwD;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;;AAEwL;AAC/N;;;;;;;;;;;;;;;;ACxJA;AACA;;AAEmB;AACnB;;;;;;;;;;;;;;;;;;;ACJwC;AACU;AACK;AACrB;;AAElC;AACA;AACA;AACA;AACA,0BAA0B,mEAAW;AACrC;AACA;AACA;AACA,mBAAmB,0CAAI,IAAI,cAAc;AACzC;AACA,mBAAmB,4CAAU;AAC7B,4BAA4B,oCAAoC;AAChE;AACA,gCAAgC,cAAc;AAC9C;AACA;AACA,gCAAgC,eAAe;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEwB;AACxB;;;;;;;;;;;;;;;;;;;;;AC/C4E;AACvB;AAChB;AACL;AACgD;AACI;AACJ;AAC7B;;AAEnD;AACA;AACA,6BAA6B,4FAAsB,CAAC,4DAAoB;AACxE,IAAI,4FAA0B;AAC9B,IAAI,oFAAsB;AAC1B,IAAI,wFAAwB;AAC5B;;AAEgC;AAChC;;;;;;;;;;;;;;;;;;;AClB6D;AACH;AACnB;AACoB;;AAE3D;AACA;AACA;AACA;AACA,sCAAsC,4BAA4B,IAAI,gDAAgD;AACtH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,sBAAsB,kEAAY;AAClC,sBAAsB,+DAAgB;AACtC;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD;AACvD,cAAc,uEAAe;AAC7B,cAAc,uEAAe;AAC7B,cAAc,uEAAe;AAC7B,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEgC;AAChC;;;;;;;;;;;;;;;;;;;;ACtD4E;AACvB;AAChB;AACL;AACoD;AACJ;AAC7B;;AAEnD;AACA;AACA,+BAA+B,4FAAsB,CAAC,4DAAoB,GAAG,4FAA0B,EAAE,oFAAsB;;AAE7F;AAClC;;;;;;;;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,QAAQ;AAChD;AACA;AACA;AACA;AACA;AACA;;AAEkC;AAClC;;;;;;;;;;;;;;;;;;ACtB6D;AACH;;AAE1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,uEAAgB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,+DAAgB;AACpB;AACA;AACA;AACA;AACA;;AAE2B;AAC3B;;;;;;;;;;;;;;;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE4B;AAC5B;;;;;;;;;;;;;;;;;ACvBwD;AACwC;AACxD;;AAExC;AACA;AACA;AACA;AACA;AACA,0BAA0B,iFAAiB;AAC3C;AACA;AACA;AACA;AACA;;AAE2B;AAC3B;;;;;;;;;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,gFAAgF;AAClH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,uCAAuC;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C;AAC7C;AACA;AACA;;AAEkC;AAClC;;;;;;;;;;;;;;;;;;;;;AC3FmE;AACpC;AACI;AACqC;AACc;;AAEtF;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,qDAAqD;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,yBAAyB,qFAAoB;AAC7C;AACA;AACA;AACA;AACA,oCAAoC,gFAAW;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,mGAA2B;AAClE;AACA;AACA;AACA;AACA,yBAAyB,UAAU,IAAI;;AAEH;AACpC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE2V;AAC3V;;;;;;;;;;;;;;;;;;;;ACzBgE;AACA;AACuD;AAC/D;;AAExD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,6EAAgB;AAC1C,YAAY,uDAAuD;AACnE;AACA,sBAAsB;AACtB,YAAY,uDAAW;AACvB,YAAY,2DAAe;AAC3B;AACA,gBAAgB,wDAAY;AAC5B;AACA,4BAA4B;AAC5B;AACA,sBAAsB,qEAAY;AAClC,0CAA0C,YAAY,GAAG,gBAAgB;AACzE,gDAAgD,6EAAgB,UAAU;AAC1E,wCAAwC,UAAU;AAClD,YAAY,uDAAW;AACvB,WAAW,uEAA2B,EAAE,EAAE,gBAAgB,IAAI,mBAAmB,IAAI,eAAe;AACpG;AACA;;AAEuB;AACvB;;;;;;;;;;;;;;;;;;;ACpC+C;AACG;;AAElD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,yDAAM;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,gEAAK;AAChB;;AAE6C;AAC7C;;;;;;;;;;;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA,qBAAqB,UAAU,GAAG,YAAY;AAC9C;;AAE+B;AAC/B;;;;;;;;;;;;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,4BAA4B,eAAe,GAAG,eAAe;AAC7D;AACA;AACA,6BAA6B,2CAA2C;;AAErC;AACnC;;;;;;;;;;;;;;;;;;;;;AC1BgE;AACQ;AAChB;AACE;AACA;;AAE1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,4BAA4B;AAC3D;AACA,IAAI,qEAAe;AACnB,IAAI,qFAAuB;AAC3B,IAAI,6EAAmB;AACvB,IAAI,uEAAgB;AACpB,IAAI,uEAAgB;AACpB;;AAE+B;AAC/B;;;;;;;;;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE2B;AAC3B;;;;;;;;;;;;;;;;;ACpBuD;;AAEvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,KAAK,GAAG,OAAO,GAAG,QAAQ,GAAG,+DAAmB,CAAC;;AAE5E;AAC9B;;;;;;;;;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,EAAE;AAC7D;AACA;AACA;AACA;AACA;;AAE6B;AAC7B;;;;;;;;;;;;;;;;;;ACrBgE;AACL;;AAE3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,sDAAU;AACzB;AACA;AACA,2BAA2B,wEAAkB;AAC7C;AACA;AACA;AACA,WAAW,4DAAgB;AAC3B;AACA;AACA;AACA;;AAE4B;AAC5B;;;;;;;;;;;;;;;;;;;;AC/B2D;AACK;AACZ;AACI;;AAExD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,sGAAsG;AACvI;AACA,6BAA6B,6EAAmB;AAChD;AACA,0BAA0B,wEAAkB;AAC5C;AACA,yBAAyB,qEAAe;AACxC;AACA,sBAAsB,wEAAkB,CAAC,iEAAa;AACtD;AACA;;AAEwB;AACxB;;;;;;;;;;;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA,qFAAqF;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;;AAEgB;AAC5B;;;;;;;;;;;;;;;;;;ACjB6E;AACvB;;AAEtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,gEAAoB,CAAC,EAAE,gBAAgB;AAC1D,oBAAoB,mEAAa;AACjC,sBAAsB,mEAAa;AACnC,uBAAuB,mEAAa;AACpC,uBAAuB,mEAAa,aAAa,+DAAmB;AACpE;AACA;;AAEyB;AACzB;;;;;;;;;;;;;;;;;;AC3B8D;AACF;;AAE5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,6FAA6F;AACzH;AACA,YAAY,6CAA6C;AACzD;AACA,YAAY,sBAAsB,EAAE,yEAAiB;AACrD;AACA,4BAA4B,2EAAkB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE4B;AAC5B;;;;;;;;;;;;;;;;;AClC+D;;AAE/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE,uEAA2B;;AAEnE;AAC3B;;;;;;;;;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEgC;AAChC;;;;;;;;;;;;;;;;;ACdoD;;AAEpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,iEAAa;AACrB;AACA;AACA;AACA;;AAEuC;AACvC;;;;;;;;;;;;;;;;;ACpBkE;;AAElE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uFAAuF,+EAAoB;AAC3G;;AAEyB;AACzB;;;;;;;;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,4DAA4D;AAClG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,6BAA6B,EAAE,eAAe;AACnE;AACA;AACA;AACA;AACA;AACA;;AAEsC;AACtC;;;;;;;;;;;;;;;;;;AC1BmD;;AAEnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,gEAAa;AAChC,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,gEAAa;AAChC,KAAK;AACL;;AAEyC;AACzC;;;;;;;;;;;;;;;;AC/CA;AACA;AACA;AACA,YAAY,sBAAsB;AAClC;AACA,gEAAgE;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEyB;AACzB;;;;;;;;;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE2B;AAC3B;;;;;;;;;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEyF;AACzF;;;;;;;;;;;;;;;;;ACTkD;;AAElD;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,2DAAY;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qBAAqB;AACpC,CAAC;;AAEmB;AACpB;;;;;;;;;;;;;;;;ACjCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,qDAAqD;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEwB;AACxB;;;;;;;;;;;;;;;;;;ACxBuD;AACL;;AAElD;AACA;AACA,wCAAwC,2DAAY;AACpD;AACA;AACA,kBAAkB,+DAAgB;AAClC;AACA,SAAS;AACT;AACA;;AAEqC;AACrC;;;;;;;;;;;;;;;;;ACfkD;;AAElD;AACA;AACA,4DAA4D,2DAAY;AACxE,YAAY,8BAA8B;AAC1C;AACA;AACA;AACA;AACA,qBAAqB,SAAS,EAAE,kBAAkB;AAClD;AACA;AACA,SAAS;AACT;AACA;;AAEmC;AACnC;;;;;;;;;;;;;;;;;;AClB2D;AACF;AAC7B;AACO;;AAEnC;AACA;AACA,mBAAmB,oEAAa;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,sBAAsB;AAC9E;AACA;AACA;AACA,4CAA4C,uBAAuB;AACnE;AACA,oCAAoC;AACpC;AACA,kBAAkB,kEAAY;AAC9B;AACA;AACA;AACA,SAAS;AACT;AACA,YAAY,2vBAA2vB;AACvwB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,YAAY,uBAAuB;AACnC;AACA;AACA,oBAAoB,gBAAgB;AACpC;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA;AACA,oBAAoB,gBAAgB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,+BAA+B;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,gBAAgB;AAC/C,KAAK,KAAK;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,gBAAgB,0BAA0B;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,kCAAkC;AAC1D;AACA;AACA;AACA;AACA,wCAAwC,UAAU;AAClD,uCAAuC,SAAS;AAChD,qBAAqB;AACrB;AACA,aAAa,IAAI;AACjB;AACA;AACA;AACA;AACA;AACA,gBAAgB,mBAAmB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,SAAS;AAC7C,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,+DAA+D;AACzF;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA,KAAK;AACL;;AAE2B;AAC3B;;;;;;;;;;;;;;;;;;AC7OA;AACA;AACA;AACA;AACA,YAAY,UAAU;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,mCAAmC;AAC/C;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,8MAA8M;AAC1N;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kGAAkG,kBAAkB,kBAAkB,KAAK;AAC3I;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,kBAAkB;AAC9B;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,yDAAyD;AACrE;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,6EAA6E;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,uDAAuD;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,+CAA+C;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,0DAA0D;AACjF;AACA,8DAA8D,KAAK;AACnE;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEiE;AACjE;;;;;;;;;;;;;;;;;;;;;;;;ACxPuD;AACL;AAChB;AACmB;AACrB;AACqB;AACvC;AACuD;AACxC;AACO;AACG;AACM;AACd;AACI;AACJ;AACA;AACgB;AACL;AACE;;AAE5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,sDAAS;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,iFAAkB;AACzD;AACA;AACA;AACA;AACA;AACA,+BAA+B,iEAAU;AACzC;AACA,QAAQ,+CAAG;AACX;AACA;AACA,SAAS,eAAe,0DAAc;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,8DAAkB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEiC;AACjC;;;;;;;;;;;;;;;;;;AC/F+D;;AAE/D;AACA;AACA,mBAAmB,oEAAa;AAChC,0BAA0B,wBAAwB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,oBAAoB;AACnC;AACA;AACA;AACA,iDAAiD,kBAAkB;AACnE;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qFAAqF,QAAQ;;AAExD;AACrC;;;;;;;;;;;;;;;;;;ACjFyC;AACgD;;AAEzF;AACA;AACA;AACA;AACA;AACA,WAAW,oBAAoB;AAC/B;AACA;AACA,YAAY,iBAAiB;AAC7B;AACA;AACA;AACA,WAAW,gFAAkB,CAAC,iDAAO;AACrC;;AAE4B;AAC5B;;;;;;;;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;;AAE4B;AAC5B;;;;;;;;;;;;;;;;ACPA;AACA;AACA;;AAE8B;AAC9B;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE2B;AAC3B;;;;;;;;;;;;;;;;;ACjCoF;AAChD;;AAEpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB,iBAAiB,QAAQ;AACzB;AACA;AACA;AACA,sBAAsB,4FAAyB;AAC/C;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB;AACA,iBAAiB,QAAQ;AACzB;AACA;AACA;AACA,sBAAsB,4FAAyB;AAC/C;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,iBAAiB,QAAQ;AACzB;AACA;AACA;AACA,sBAAsB,4FAAyB;AAC/C;AACA;AACA;AACA;AACA,iBAAiB,QAAQ;AACzB;AACA;AACA;AACA,sBAAsB,4FAAyB;AAC/C;AACA;AACA;;AAE2B;AAC3B;;;;;;;;;;;;;;;;;;;ACxD4D;AACJ;;AAExD;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,oEAAa;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,iEAAe;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,iEAAe;AAClC;AACA;;AAEsE;AACtE;;;;;;;;;;;;;;;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C;;AAEjB;AAC5B;;;;;;;;;;;;;;;;;ACXoE;;AAEpE;AACA;AACA;AACA;AACA;AACA,WAAW,WAAW;AACtB,YAAY,QAAQ;AACpB;AACA;AACA;AACA;AACA,YAAY,QAAQ;AACpB,YAAY,WAAW;AACvB;AACA;AACA,oBAAoB,cAAc;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,YAAY;AACpC,uBAAuB,iFAAqB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEqB;AACrB;;;;;;;;;;;;;;;;;ACjDA;AACA;AACA;AACA;;AAE8C;AAC9C;;;;;;;;;;;;;;;;;ACN0B;;AAE1B;AACA;AACA,oBAAoB,4CAAE;;AAEC;AACvB;;;;;;;;;;;;;;;;;;ACPwD;AACJ;;AAEpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,6DAA6D,iEAAa;AAC1E,yBAAyB,iEAAO;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEyB;AACzB;;;;;;;;;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;;AAEyB;AACzB;;;;;;;;;;;;;;;;;ACPsD;;AAEtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mEAAS;AAC5B;AACA;AACA;;AAEiC;AACjC;;;;;;;;;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEsB;AACtB;;;;;;;;;;;;;;;;;;;ACd6D;AAC7B;AACO;;AAEvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,kEAAY;AAC1B;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,kEAAY;AAC1B;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,kEAAY;AAC1B;AACA;AACA,KAAK;AACL;;AAEuC;AACvC;;;;;;;;;;;;;;;;ACjDA;AACA;AACA;;AAEqB;AACrB;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEuB;AACvB;;;;;;;;;;;;;;;;;;ACZyD;AAC0B;;AAEnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qEAAe;AAC9B;AACA,aAAa,0EAAgB;AAC7B,eAAe,6EAAmB;AAClC;AACA;AACA;AACA;AACA;;AAE8B;AAC9B;;;;;;;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE6B;AAC7B;;;;;;;;;;;;;;;;ACVA;AACA;AACA;;AAEwB;AACxB;;;;;;;;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;;AAE+B;AAC/B;;;;;;;;;;;;;;;;;ACR+C;;AAE/C;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,wDAAY;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;;AAE2B;AAC3B;;;;;;;;;;;;;;;;;;;AClB+C;AACS;AACpB;;AAEpC;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE,wDAAY,kBAAkB,iDAAK,wBAAwB,qEAAe;;AAE5G;AACpC;;;;;;;;;;;;;;;;;;ACb+D;AACC;;AAEhE;AACA;AACA,mBAAmB,oEAAa;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,4BAA4B,sBAAsB,WAAW,SAAS,kBAAkB,qBAAqB;AAC7G;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,qBAAqB;AAC9D,oBAAoB,6EAAmB;AACvC,oCAAoC,sBAAsB;AAC1D;AACA;AACA;AACA;AACA,gCAAgC,sBAAsB,cAAc,SAAS;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C;AAC3C;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEiB;AACjB;;;;;;;;;;;;;;;;ACxEA;AACA;AACA;AACA;;AAE+B;AAC/B;;;;;;;;;;;;;;;;;;ACNqD;AAC8B;;AAEnF;AACA;AACA;AACA;AACA;AACA,eAAe,kEAA0B;AACzC;AACA;AACA;AACA,eAAe,kEAA0B;AACzC;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAuB;AAC/B,QAAQ,+DAAuB;AAC/B,QAAQ,+DAAuB;AAC/B,QAAQ,+DAAuB;AAC/B,QAAQ,+DAAuB;AAC/B;AACA;AACA,QAAQ,kEAA0B;AAClC,QAAQ,kEAA0B;AAClC,QAAQ,kEAA0B;AAClC,QAAQ,kEAA0B;AAClC,QAAQ,kEAA0B;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,wBAAwB,qBAAqB;AAC7C;AACA;AACA;AACA;AACA,iBAAiB,+DAAuB;AACxC;AACA;AACA,sCAAsC,kEAA0B;AAChE;AACA;AACA;AACA,iBAAiB,+DAAuB;AACxC,iBAAiB,+DAAuB;AACxC;AACA;AACA,0CAA0C,kEAA0B;AACpE;AACA;AACA,+CAA+C,kEAA0B;AACzE;AACA;AACA;AACA;AACA;AACA,iBAAiB,+DAAuB;AACxC;AACA;AACA;AACA;AACA,0CAA0C,kEAA0B;AACpE;AACA;AACA,+CAA+C,kEAA0B;AACzE;AACA;AACA;AACA;AACA;AACA,iBAAiB,+DAAuB;AACxC,sCAAsC,kEAA0B;AAChE;AACA;AACA;AACA,sCAAsC,kEAA0B;AAChE;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,kBAAkB;AACzC;AACA;AACA,yCAAyC,mBAAmB;AAC5D;AACA;AACA,kCAAkC,mEAAgB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,aAAa;AACzB;AACA;AACA;AACA;AACA,kCAAkC,iCAAiC;AACnE;AACA;AACA;AACA;;AAE6B;AAC7B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChIyD;AACc;AACE;AACiB;AAChD;AAC0C;AACJ;AACC;AACvB;AACM;AACD;AACqH;AACyM;AACrS;AACjC;AAClB;AAC8B;;AAEnE;AACA;AACA,oDAAa;AACb,oDAAa;AACb,mBAAmB,4DAAa;AAChC,aAAa,+DAAoB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,6DAAkB;AAC7B;AACA;AACA;AACA;AACA,mDAAmD,sBAAsB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,sEAA2B;AAC3C;AACA;AACA,WAAW,2EAAqB;AAChC;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0CAA0C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,oBAAoB;AAC1D;AACA;AACA,cAAc,2CAAI;AAClB;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,kEAAgB;AAC7C,0BAA0B,uDAAU;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,kCAAkC,mEAAwB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,6DAAkB;AACtC;AACA;AACA;AACA;AACA,uFAAuF,kBAAkB;AACzG;AACA;AACA;AACA,yCAAyC,sEAA2B;AACpE;AACA,yBAAyB;AACzB,qBAAqB;AACrB;AACA,aAAa;AACb;AACA;AACA,0CAA0C;AAC1C,oBAAoB,UAAU;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,eAAe,IAAI,IAAI;AAC7E;AACA;AACA,oHAAoH,uCAAuC,aAAa,aAAa,GAAG,aAAa;AACrM;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,4CAA4C;AAC5C;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,mDAAmD;AACnE,2BAA2B,uEAA2B;AACtD,cAAc,6DAAkB;AAChC;AACA;AACA;AACA;AACA;AACA,qCAAqC,MAAM;AAC3C;AACA,YAAY,uEAA2B;AACvC,aAAa,sDAAW;AACxB,yBAAyB,sEAA2B;AACpD;AACA,6BAA6B,oDAAa,kBAAkB,aAAa;AACzE,gCAAgC,oDAAa;AAC7C;AACA;AACA,YAAY,+DAAmB;AAC/B,2BAA2B,yDAAiB;AAC5C,mCAAmC,yDAAiB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,MAAM,6BAA6B,EAAE;AACtF;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,QAAQ;AAC/C;AACA;AACA,6CAA6C,MAAM,qBAAqB,cAAc,KAAK,UAAU,YAAY,EAAE;AACnH;AACA,qBAAqB,4DAAiB;AACtC,gCAAgC,4DAAiB;AACjD;AACA;AACA;AACA,2DAA2D,MAAM,0BAA0B,cAAc,KAAK,UAAU,cAAc,EAAE;AACxI;AACA,uCAAuC,4DAAiB;AACxD;AACA,6BAA6B,4DAAiB;AAC9C;AACA;AACA,iCAAiC,4DAAiB;AAClD;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,+DAA+D,MAAM,0BAA0B,KAAK,gDAAgD,EAAE;AACtJ;AACA;AACA;AACA;AACA;AACA,yCAAyC,MAAM,oBAAoB,OAAO,IAAI,UAAU,YAAY,EAAE;AACtG;AACA,sBAAsB,4DAAiB;AACvC;AACA;AACA;AACA,yCAAyC,MAAM,oBAAoB,KAAK,uBAAuB,EAAE;AACjG;AACA;AACA,iBAAiB,+DAAmB;AACpC;AACA,iBAAiB,4DAAiB;AAClC;AACA;AACA;AACA;AACA;AACA,2CAA2C,eAAe;AAC1D;AACA;AACA,iDAAiD,MAAM,qBAAqB,cAAc,KAAK,UAAU,YAAY,EAAE;AACvH;AACA;AACA,6BAA6B,4DAAiB;AAC9C;AACA,mEAAmE,MAAM,0BAA0B,cAAc,KAAK,YAAY,cAAc,KAAK;AACrJ;AACA,6BAA6B,4DAAiB;AAC9C;AACA;AACA,6BAA6B;AAC7B;AACA,qBAAqB;AACrB;AACA;AACA;AACA,iDAAiD,MAAM,oBAAoB,cAAc,IAAI,UAAU,YAAY,EAAE;AACrH;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,gBAAgB;AAC5B;AACA;AACA;AACA;AACA,YAAY,+DAAmB;AAC/B,YAAY,4DAAgB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,8CAAO;AACxC;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,UAAU;AAClC,oBAAoB,sDAAW;AAC/B;AACA;AACA;AACA;AACA,8BAA8B,8EAAW;AACzC;AACA;AACA;AACA,yBAAyB,gEAAqB;AAC9C;AACA;AACA,oCAAoC,8EAAW;AAC/C;AACA;AACA;AACA;AACA,wBAAwB,qCAAqC;AAC7D;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,+BAA+B,8CAAO;AACtC;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,uEAAuE;AACvE;AACA;AACA,oCAAoC,QAAQ;AAC5C;AACA;AACA;AACA,0BAA0B,8CAAO;AACjC;AACA,iCAAiC,sEAA2B;AAC5D;AACA;AACA;AACA,gFAAgF,IAAI,+BAA+B,QAAQ;AAC3H;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,0CAA0C,uDAAY;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,UAAU,4CAAS;AACnB,2CAA2C,6BAA6B;AACxE;AACA;AACA;AACA,kCAAkC,wEAAiB;AACnD;AACA;AACA,iBAAiB,sEAA2B;AAC5C,KAAK;AACL;AACA,gBAAgB,QAAQ;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kFAAkF;AAClF;AACA;AACA,2DAA2D,qBAAqB,GAAG,OAAO;AAC1F,gDAAgD,OAAO;AACvD;AACA;AACA;AACA;AACA,2DAA2D,qBAAqB,GAAG,OAAO,wBAAwB,yCAAyC;AAC3J,gDAAgD,OAAO;AACvD;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,yCAAyC;AAC7E;AACA;AACA;AACA;AACA;AACA,mEAAmE;AACnE;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D;AAC/D;AACA,iEAAiE;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE,qBAAqB,GAAG,MAAM;AAChG;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,SAAS;AAC3D;AACA;AACA,oBAAoB,iCAAiC,IAAI;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,SAAS;AACrB;AACA;AACA,+BAA+B,KAAK;AACpC;AACA,KAAK;AACL;AACA;AACA;AACA,YAAY,SAAS;AACrB;AACA;AACA;AACA;AACA,+BAA+B,KAAK;AACpC;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,6BAA6B,8CAAO;AACpC;AACA,aAAa;AACb;AACA;AACA;AACA,UAAU,4CAAS;AACnB,2CAA2C,4BAA4B;AACvE,IAAI,gEAAqB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,4CAA4C;AACxD,YAAY,WAAW;AACvB,oDAAoD,yBAAyB;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,gDAAS;AACtB;AACA;AACA,aAAa,2CAAI;AACjB;AACA;AACA,aAAa,2CAAI;AACjB;AACA;AACA,aAAa,8CAAO;AACpB;AACA;AACA;AACA,kDAAkD,cAAc;AAChE;AACA;AACA;AACA;AACA;AACA,yEAAyE,UAAU,eAAe,cAAc;AAChH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,gDAAS;AACvD;AACA,kEAAkE,wEAAqB;AACvF,mBAAmB,OAAO,8BAA8B;AACxD,SAAS,KAAK,mBAAmB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,cAAc,gDAAS;AACvB,yBAAyB;AACzB,iBAAiB;AACjB,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACA;AACA;AACA,2BAA2B,oEAAW;AACtC,qBAAqB,qDAAK;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,wFAAwB;AAC5D;AACA;AACA;AACA,wDAAwD;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA,mCAAmC,kEAAgB;AACnD;AACA;AACA;AACA,wBAAwB,8BAA8B;AACtD;AACA;AACA;AACA,oCAAoC,uDAAU;AAC9C,8FAA8F;AAC9F;AACA,iCAAiC,kDAAkD;AACnF;AACA,iCAAiC,YAAY;AAC7C;AACA;AACA;AACA;AACA;AACA,8CAA8C,mDAAM;AACpD,kCAAkC,2DAAc;AAChD,kCAAkC,2DAAc;AAChD;AACA;AACA;AACA,4BAA4B,mDAAG;AAC/B;AACA;AACA,6BAA6B;AAC7B,yBAAyB;AACzB;AACA;AACA;AACA,yBAAyB;AACzB,qBAAqB;AACrB;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,kBAAkB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,sEAA2B;AAC7D;AACA;AACA,oCAAoC,oDAAa;AACjD,4CAA4C,WAAW;AACvD;AACA;AACA,sCAAsC,wEAAqB,6CAA6C,sCAAsC;AAC9I;AACA;AACA;AACA;AACA,wBAAwB,8DAAkB;AAC1C,0CAA0C,wEAAqB;AAC/D;AACA;AACA;AACA,wBAAwB,sEAAe;AACvC;AACA;AACA;AACA,8CAA8C,2EAAqB;AACnE;AACA;AACA,qCAAqC,sEAA2B;AAChE,yBAAyB;AACzB,0CAA0C,+DAAS;AACnD;AACA,iCAAiC,6DAAkB;AACnD;AACA;AACA;AACA;AACA,oBAAoB,8DAAkB;AACtC;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,OAAO;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,sEAA2B;AACxD;AACA;AACA;AACA;AACA,oDAAoD,wEAAiB;AACrE;AACA;AACA;AACA,+FAA+F,wEAAqB;AACpH;AACA;AACA,iFAAiF,sBAAsB,GAAG,sBAAsB;AAChI,yEAAyE,mBAAmB;AAC5F;AACA,wCAAwC,oCAAoC;AAC5E;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,sBAAsB,+DAAS,WAAW,kEAAY;AACtD;AACA;AACA;AACA,qDAAqD,wEAAqB;AAC1E,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA,oBAAoB,6BAA6B;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,6BAA6B;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,oBAAoB;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,sBAAsB;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,sEAA2B;AACrE;AACA,wCAAwC,oDAAa;AACrD,gDAAgD,WAAW;AAC3D;AACA;AACA,oCAAoC,wEAAqB,6CAA6C,sCAAsC;AAC5I;AACA;AACA,4BAA4B,8DAAkB;AAC9C,wCAAwC,wEAAqB;AAC7D;AACA;AACA,wCAAwC,+DAAS,sBAAsB,kEAAY;AACnF;AACA;AACA,yCAAyC,sEAA2B;AACpE,6BAA6B;AAC7B;AACA;AACA,6BAA6B,wEAAqB;AAClD;AACA,gDAAgD,WAAW;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E;AAC9E;AACA;AACA;AACA,4CAA4C,OAAO;AACnD;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,wEAAqB;AAC7D;AACA;AACA;AACA,gDAAgD,sBAAsB;AACtE;AACA;AACA,oCAAoC,+DAAS,sBAAsB,kEAAY;AAC/E;AACA;AACA,qCAAqC,sEAA2B;AAChE,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,wCAAwC,OAAO;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,8DAAkB;AAClC,4BAA4B,oDAAa;AACzC,oCAAoC,qCAAqC;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,kBAAkB;AACtD;AACA;AACA;AACA;AACA,qCAAqC,+DAAS;AAC9C;AACA;AACA,qCAAqC,+DAAS;AAC9C;AACA,uBAAuB,6CAAU;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,6CAAM,IAAI,OAAO,kCAAkC,2CAAI;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,sEAA2B;AACjF,iEAAiE,sEAA2B;AAC5F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA,yBAAyB;AACzB;AACA;AACA,yBAAyB;AACzB,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA,uBAAuB,6CAAU;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,8BAA8B;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,+DAAwB;AACnE;AACA;AACA;AACA,iBAAiB;AACjB,wBAAwB,OAAO;AAC/B,6CAA6C,OAAO;AACpD;AACA;AACA;AACA;AACA;AACA,yCAAyC,+DAAS;AAClD;AACA,yBAAyB,sEAAe;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,oEAAkB;AAC7D;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA,kEAAkE,uCAAuC;AACzG;AACA;AACA,+CAA+C,oEAAkB;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,gDAAgD,8BAA8B;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,oEAAkB;AACzD;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,4EAAyB;AACpE;AACA,0CAA0C,8DAAmB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,SAAS;AAChD,4BAA4B,cAAc;AAC1C,kCAAkC,2DAAc;AAChD;AACA;AACA;AACA;AACA;AACA,kCAAkC,mDAAG;AACrC;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA,qCAAqC;AACrC;AACA,oBAAoB,6UAA6U;AACjW,yCAAyC,uDAAO;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,4DAAoB;AACpC;AACA,qBAAqB,4DAAoB;AACzC,4CAA4C,6FAAiB;AAC7D;AACA,qBAAqB,4DAAoB;AACzC,4CAA4C,6FAAmB;AAC/D;AACA;AACA,4CAA4C,6FAAmB;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,UAAU,0BAA0B,WAAW;AAC9G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,kEAAgB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,oBAAoB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,4EAAyB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sCAAsC;AAC1D;AACA;AACA;AACA;AACA,gBAAgB,sEAAe;AAC/B;AACA;AACA,8BAA8B,+DAAS,WAAW,kEAAY;AAC9D;AACA;AACA,yBAAyB,sEAA2B;AACpD,aAAa;AACb;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,OAAO;AAC/B;AACA,gDAAgD,MAAM;AACtD;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,8BAA8B;AACtD;AACA;AACA,0BAA0B,UAAU,GAAG,UAAU;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,mDAAG;AACH;AACA,6BAA6B;AAC7B;AACA,CAAC;;AAE2I;AAC5I;;;;;;;;;;;;;;;;ACt3DA;AACA;AACA;AACA;AACA;;AAEkB;AAClB;;;;;;;;;;;;;;;;;;;;;;;ACPmF;AAC5B;;AAEvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,KAAK,OAAO;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,sEAA2B;AACrD,0BAA0B,kEAAuB;AACjD;AACA;AACA;AACA,yBAAyB,WAAW;AACpC,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE,OAAO,SAAS;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ,mBAAmB;AACtC,WAAW,OAAO,qBAAqB;AACvC,WAAW;AACX;AACA,aAAa,gBAAgB,eAAe;AAC5C,aAAa,gBAAgB,eAAe;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ,mBAAmB;AACtC,WAAW,OAAO,qBAAqB;AACvC,WAAW;AACX;AACA,aAAa,gBAAgB,eAAe;AAC5C,aAAa,gBAAgB,eAAe;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE4F;AAC5F;;;;;;;;;;;;;;;;;;;;;;;;AChPqD;AACW;AACZ;AACgB;;AAEpE;AACA;AACA,gBAAgB,sDAAc;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,6DAAqB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,cAAc;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,OAAO,EAAE,YAAY;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,cAAc,QAAQ,EAAE;AAChF;AACA;AACA,wDAAwD,cAAc;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,OAAO;AACjC,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,wEAAiB;AACtD;AACA;AACA;AACA;AACA,wCAAwC,yCAAyC;AACjF;AACA;AACA;AACA,iCAAiC;AACjC,6BAA6B;AAC7B;AACA,iDAAiD,yBAAyB;AAC1E;AACA,sCAAsC,6DAAqB;AAC3D;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,oDAAS;AAC5B;AACA;AACA,mBAAmB,qDAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,6DAAqB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,kEAAkE;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,kCAAkC;AACtD;AACA;AACA,wDAAwD,GAAG;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,gBAAgB,kCAAkC;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,kCAAkC;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA,qBAAqB,IAAI;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE0F;AAC1F;;;;;;;;;;;;;;;;ACvvBA;AACA;AACA,gBAAgB,kBAAkB;AAClC;AACA,sCAAsC;AACtC;AACA;AACA;AACA,uEAAuE,cAAc,WAAW,UAAU;AAC1G;AACA;AACA;AACA;AACA,iCAAiC,sBAAsB;AACvD;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEqC;AACrC;;;;;;;;;;;;;;;;;;;;;ACjDmD;AAC+G;AACpG;AACA;;AAE9D;AACA;AACA,kCAAkC,uEAAkB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iEAAoB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,uDAAY;AACtC,qBAAqB,uDAAY;AACjC;AACA;AACA;AACA,oCAAoC,wDAAa;AACjD;AACA,oBAAoB,WAAW,0BAA0B,kCAAkC;AAC3F;AACA,uBAAuB,oDAAS;AAChC,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,8CAA8C,0EAAmC;AACjF;AACA;AACA;AACA,gBAAgB,kDAAkD;AAClE;AACA;AACA;AACA;AACA,oBAAoB,wDAAwD;AAC5E;AACA;AACA,+CAA+C,8CAAM,UAAU,8CAAM;AACrE,gBAAgB,oDAAS;AACzB,2BAA2B,8CAAM;AACjC,wFAAwF,0EAAmC;AAC3H;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,4EAA4E;AAC5F;AACA;AACA,kDAAkD,0EAAmC;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,kCAAkC;AAClD;AACA;AACA,8BAA8B,4DAAiB;AAC/C;AACA;AACA;AACA;AACA,eAAe,6DAAkB;AACjC;AACA,mDAAmD,gDAAQ;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,mBAAmB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,0EAAmC;AAC9F;AACA;AACA;;AAEiE;AACjE;;;;;;;;;;;;;;;;;;;AChJmD;AAC2D;AACpD;;AAE1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,uEAAmB;AAC1C;AACA;AACA;AACA,yBAAyB,QAAQ;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,QAAQ;AACjC;AACA;AACA;AACA;AACA,iDAAiD,+DAAoB;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,4DAAiB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,WAAW;AAC/B;AACA,uDAAuD,0EAAmC;AAC1F;AACA;AACA,qEAAqE,0EAAmC;AACxG;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,0EAAmC;AAC7D;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,cAAc;AACtC;AACA;AACA;AACA,0BAA0B,0EAAmC;AAC7D;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA,kDAAkD,8CAAM;AACxD;AACA;AACA;AACA;AACA,mDAAmD,8CAAM,UAAU,8CAAM;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,gDAAQ;AACvD;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA,aAAa;AACb;AACA;AACA;AACA,sBAAsB;AACtB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,sBAAsB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,0CAA0C,IAAI,KAAK,IAAI,GAAG;AAC5E;AACA;AACA,kBAAkB,0CAA0C,IAAI,GAAG;AACnE;AACA;AACA,kBAAkB,QAAQ,IAAI,UAAU,IAAI,KAAK;AACjD;AACA;;AAE2C;AAC3C;;;;;;;;;;;;;;;;;ACtQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE8C;AAC9C;;;;;;;;;;;;;;;;;;;;;ACxC2B;AACuB;AACmC;AACoE;AAC3F;;AAE9D;AACA;AACA,mBAAmB,4DAAa;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,uEAAkB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uCAAU;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,uDAAY;AAC1D;AACA,yBAAyB;AACzB,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,UAAU;AAC7D;AACA,oCAAoC,2BAA2B;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,OAAO,EAAE,WAAW;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,uDAAY;AAC/D,6BAA6B;AAC7B;AACA;AACA;AACA,6BAA6B;AAC7B,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,yCAAY;AAC1B;AACA;AACA;AACA;AACA;AACA,gBAAgB,uDAAuD;AACvE;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,wDAAwD;AAC5E;AACA;AACA;AACA,+CAA+C,8CAAM,UAAU,8CAAM;AACrE,gBAAgB,oDAAS;AACzB,2BAA2B,8CAAM;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,4EAA4E;AAC5F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,mDAAmD,gDAAQ;AAC3D;AACA;AACA;AACA;AACA;AACA,mDAAmD,gDAAQ;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,QAAQ;AACxB;AACA;AACA,oCAAoC,wDAAa;AACjD;AACA,oBAAoB,WAAW;AAC/B;AACA;AACA;AACA,wBAAwB,WAAW,0BAA0B,kCAAkC;AAC/F;AACA,2BAA2B,oDAAS;AACpC,iBAAiB;AACjB;AACA;AACA,0BAA0B,8CAAM,UAAU,8CAAM;AAChD;AACA;AACA;AACA;AACA,mCAAmC,8CAAM;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,WAAW;AACnE;AACA,SAAS;AACT;AACA;AACA,oBAAoB,mBAAmB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,wDAAa;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,oEAAyB;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,gBAAgB,UAAU;AAC1B;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,kCAAkC;AAChD;AACA,6BAA6B,MAAM,KAAK,OAAO,6BAA6B;AAC5E;AACA;AACA;AACA,YAAY,4DAAgB;AAC5B;AACA,eAAe,OAAO;AACtB;AACA;AACA,0DAA0D,0DAAc;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,4DAAgB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,0DAAc;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,kCAAkC;AAClD,gBAAgB,4BAA4B;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,4DAAiB;AAC5D;AACA;AACA;AACA;AACA,eAAe,6DAAkB;AACjC;AACA;AACA;AACA;AACA,oBAAoB,sBAAsB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEyC;AACzC;;;;;;;;;;;;;;;;;;;;;ACjiBkD;AACiB;AAClB;AACuH;AAChH;;AAExD,mBAAmB,4DAAa;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,QAAQ,GAAG,UAAU;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,kBAAkB;AAClC,eAAe,uDAAY;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,uDAAY;AACjC,eAAe,kEAAuB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,wDAAa;AAC7C;AACA,2EAA2E,2BAA2B;AACtG,sCAAsC,uDAAY;AAClD;AACA,yBAAyB,uDAAY;AACrC,qBAAqB;AACrB,SAAS;AACT;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,wEAAqB;AAChD,gBAAgB,kCAAkC;AAClD,wBAAwB,4DAAiB;AACzC;AACA;AACA,gCAAgC,yCAAyC;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,WAAW;AACjE,mBAAmB,uDAAY;AAC/B,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,OAAO,MAAM,YAAY,IAAI,WAAW,YAAY;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,4BAA4B;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0DAAc;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,wEAAqB;AAC7D,wBAAwB,uDAAY;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,6DAAkB;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,OAAO;AACxE;AACA;AACA;AACA;AACA;AACA,iEAAiE,OAAO;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,OAAO;AAC9C;AACA;AACA,mCAAmC,wEAAqB;AACxD,wBAAwB,kCAAkC;AAC1D,gCAAgC,4DAAiB;AACjD;AACA;AACA,wCAAwC,yCAAyC;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,OAAO;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,sEAA2B;AACpD;AACA,kCAAkC,gEAAiB;AACnD;AACA;AACA;AACA,sFAAsF,wEAAqB;AAC3G;AACA;AACA;AACA;AACA;AACA,uBAAuB,uDAAY;AACnC;AACA,SAAS;AACT;AACA;;AAE8B;AAC9B;;;;;;;;;;;;;;;;;;;;AClS2E;AACpB;AACM;;AAE7D;AACA;AACA;AACA,SAAS,wEAAS,0BAA0B,8EAAW;AACvD,eAAe,6DAAgB;AAC/B;AACA,WAAW,gEAAmB;AAC9B;;AAEwC;AACxC;;;;;;;;;;;;;;;;;ACdkD;;AAElD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,8DAAkB;AAC/B,+BAA+B,kBAAkB,GAAG,OAAO;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,8DAAkB;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,iCAAiC;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,kCAAkC;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE6B;AAC7B;;;;;;;;;;;;;;;;;;;;;;;;;;AC9Q4C;AACc;AACR;AACc;AACS;AACiB;AACnC;AACe;;AAEtE;AACA;AACA,mBAAmB,4DAAa;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,gFAAiB;AACxD,8BAA8B,yCAAO;AACrC;AACA;AACA;AACA,kBAAkB,8CAAO;AACzB,6BAA6B;AAC7B,qBAAqB;AACrB,sBAAsB;AACtB,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,8CAAM,sBAAsB,8CAAM;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,wEAAqB;AACzC;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,6DAAkB;AACnD;AACA,iEAAiE;AACjE;AACA;AACA;AACA;AACA,4BAA4B,mEAAkB;AAC9C;AACA,SAAS;AACT,aAAa,6DAAkB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,6DAAkB;AACnC,gCAAgC,mEAAkB;AAClD;AACA,sBAAsB,wEAAqB;AAC3C;AACA;AACA;AACA;AACA,wBAAwB,8CAAM;AAC9B;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,gDAAQ;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,mBAAmB,gBAAgB,wEAAqB;AACxE;AACA;AACA,kBAAkB,4CAAM,IAAI,SAAS;AACrC;AACA,SAAS;AACT,kBAAkB,yCAAG,IAAI,+BAA+B;AACxD;AACA,iCAAiC,4CAAM,IAAI,gBAAgB;AAC3D;AACA;AACA;AACA;AACA,2BAA2B,4DAAiB;AAC5C;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,SAAS;AACzB,gBAAgB,iCAAiC;AACjD;AACA;AACA,gCAAgC,mEAAuB;AACvD;AACA;AACA;AACA;AACA,yBAAyB,sDAAW;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,sDAAW;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,yCAAyC;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,oEAAK;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,6DAAkB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,mDAAmD,gDAAQ;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE4B;AAC5B;;;;;;;;;;;;;;;;;;AC7UkC;AACsC;;AAExE;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,4CAAU;AAC7B;AACA;AACA,gCAAgC,iFAAmB,cAAc,QAAQ;AACzE;AACA,yCAAyC,4BAA4B;AACrE;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,eAAe,GAAG;AACnD;AACA,yCAAyC,4BAA4B;AACrE;AACA,aAAa,oBAAoB;AACjC;AACA;AACA;;AAE4C;AAC5C;;;;;;;;;;;;;;;;;ACpDiE;;AAEjE;AACA;AACA,gCAAgC,2EAAY;;AAEb;AAC/B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACP6E;AACtB;AACT;AACoE;AAClD;AAC1B;AACW;AACe;AACrB;AACQ;AACW;AACqB;AAC7B;AACkE;;AAExH;AACA;AACA,mBAAmB,4DAAa;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACA;AACA,2KAA2K;AAC3K;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,uFAAwB;AAC5D;AACA;AACA,SAAS;AACT;AACA;AACA,0BAA0B,4DAAmB;AAC7C,+BAA+B,oDAAW;AAC1C,wCAAwC,+DAAa;AACrD,0CAA0C,+EAAqB;AAC/D,sCAAsC,uEAAiB;AACvD;AACA,4CAA4C,kEAAqB;AACjE;AACA;AACA,mBAAmB,4CAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2EAA2E,QAAQ;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC;AACrC,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,qEAAW;AACvE;AACA;AACA,6CAA6C;AAC7C;AACA;AACA;AACA;AACA,6CAA6C;AAC7C,yCAAyC;AACzC;AACA,qCAAqC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,OAAO;AAC/D;AACA;AACA;AACA;AACA;AACA,6CAA6C;AAC7C;AACA;AACA,6CAA6C;AAC7C;AACA;AACA,6CAA6C;AAC7C,yCAAyC;AACzC;AACA;AACA;AACA,qCAAqC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,uCAAuC;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC,qCAAqC;AACrC;AACA;AACA;AACA;AACA,yCAAyC;AACzC,qCAAqC;AACrC,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC;AACrC,iCAAiC;AACjC;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA,yBAAyB;AACzB,iBAAiB;AACjB;AACA;AACA,0BAA0B,4CAAM,IAAI,OAAO;AAC3C;AACA;AACA,iBAAiB;AACjB;AACA,mCAAmC,mCAAmC;AACtE;AACA;AACA;AACA;AACA,iDAAiD,wEAA2B;AAC5E,8CAA8C,qFAAwC;AACtF;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,yBAAyB;AACzB;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb,SAAS;AACT;AACA;AACA,+JAA+J,4DAA4D;AAC3N;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,mBAAmB,yCAAE,GAAG,GAAG;AAC3B;AACA,mBAAmB,4CAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA,+CAA+C,iEAAiE;AAChH;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC,gDAAgD,kDAAM;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,+DAAkB;AAC7E;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,+CAAM;AAC3D;AACA;AACA,qDAAqD,+CAAM;AAC3D;AACA;AACA,qDAAqD,+CAAM;AAC3D;AACA;AACA;AACA,sFAAsF,OAAO;AAC7F;AACA,yCAAyC;AACzC,qCAAqC;AACrC;AACA,gDAAgD,kBAAkB;AAClE;AACA;AACA,gDAAgD,iCAAiC;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C;AAC7C,yCAAyC;AACzC;AACA;AACA,2DAA2D,kDAAM;AACjE;AACA;AACA;AACA,6CAA6C;AAC7C;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA,iCAAiC;AACjC,6BAA6B;AAC7B;AACA;AACA;AACA,gFAAgF,MAAM;AACtF,iCAAiC;AACjC,6BAA6B;AAC7B,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,uBAAuB,YAAY,sCAAsC;AAClI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA,yBAAyB;AACzB;AACA,iBAAiB;AACjB,SAAS;AACT;AACA;AACA;AACA;AACA,gBAAgB,kEAAa;AAC7B,gBAAgB,kEAAa;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,mBAAmB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,UAAU;AACrC;AACA;AACA,uCAAuC,4CAAI;AAC3C;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA,kCAAkC,yEAAqB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,SAAS;AACT;AACA;AACA,oBAAoB,mBAAmB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,yEAAqB,sCAAsC,4CAAI,oCAAoC,QAAQ,aAAa,iBAAiB,IAAI,SAAS,aAAa,GAAG;AAChM;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,4CAAI;AACtB,6BAA6B;AAC7B;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB,qBAAqB;AACrB,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,mDAAG;AAClB;AACA,uCAAuC,8EAAuB;AAC9D;AACA;AACA;AACA;AACA;AACA,yBAAyB,sEAAe;AACxC;AACA;AACA,yBAAyB,sEAAe;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;;AAEsC;AACtC;;;;;;;;;;;;;;;;;;ACltBsC;AACW;;AAEjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,8CAAM;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,8DAAkB;AAC9C;AACA;AACA;AACA;AACA;AACA;;AAEuB;AACvB;;;;;;;;;;;;;;;;;;;;AC3CgE;AACxB;AACwB;AACU;;AAE1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE,2CAAI;AAC5E;AACA;AACA,8BAA8B,wEAAqB;AACnD;AACA,sBAAsB,WAAW,6BAA6B;AAC9D,sBAAsB,MAAM,sCAAsC;AAClE;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,kCAAkC;AACtD,oCAAoC,+DAAuB;AAC3D,6CAA6C,+DAAuB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,wBAAwB,mCAAmC;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,gDAAQ;AACzE;AACA;AACA;AACA;AACA,oEAAoE,2CAAI;AACxE,wBAAwB,8DAAkB;AAC1C,wEAAwE,wEAAqB;AAC7F,mBAAmB,WAAW,eAAe;AAC7C,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,kCAAkC,SAAS;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,uDAAuD;AACvE;AACA;AACA;AACA;AACA;AACA,gBAAgB,8FAA8F;AAC9G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,gEAAqB;AAClC;AACA;AACA,oEAAoE,2CAAI;AACxE;AACA,yBAAyB,8DAAkB;AAC3C,0BAA0B,wEAAqB;AAC/C;AACA,kBAAkB,WAAW,gBAAgB;AAC7C,kBAAkB,MAAM,sCAAsC;AAC9D;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA,gBAAgB,sDAAsD;AACtE,gBAAgB,4FAA4F;AAC5G;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,2CAAI;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE+B;AAC/B;;;;;;;;;;;;;;;;;;;;;;;ACxM6D;;AAE7D;AACA,6BAA6B,yEAA6B;AAC1D;AACA;AACA;AACA,gBAAgB,UAAU;AAC1B;AACA,qFAAqF;AACrF,KAAK;AACL;AACA;AACA;AACA,QAAQ,yEAA6B;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,mBAAmB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEkJ;AAClJ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzEyD;AAC0F;AACjH;AACgB;AACwD;AACrC;AAC6F;AAC3G;;AAEvD;AACA,mBAAmB,4DAAa;AAChC;AACA,8GAA8G;AAC9G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,uFAAwB;AAC5D;AACA,+CAA+C,mEAAW;AAC1D;AACA;AACA;AACA;AACA;AACA,2BAA2B,UAAU;AACrC;AACA,yCAAyC,iEAAqB;AAC9D,yCAAyC,iEAAqB;AAC9D,yCAAyC,iEAAqB;AAC9D;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,oCAAoC,uFAAwB;AAC5D,+BAA+B,4CAAU;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,2CAAI;AAC1C;AACA;AACA;AACA;AACA,4BAA4B,oCAAoC;AAChE;AACA;AACA;AACA;AACA;AACA,qDAAqD,6DAAiB;AACtE;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA,mFAAmF,qCAAqC;AACxH;AACA,0FAA0F,qCAAqC;AAC/H;AACA;AACA;AACA;AACA;AACA,mFAAmF,yCAAyC;AAC5H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,oEAAoB;AAC3E,qDAAqD,mDAAW;AAChE;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACA;AACA;AACA,+EAA+E,yCAAyC,4BAA4B,qCAAqC;AACzL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,eAAe,wEAAK;AACpB;AACA,oCAAoC,iEAAqB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,uEAAQ;AAClC,wBAAwB,8EAAe;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,iBAAiB,cAAc,OAAO;AACtE;AACA,sCAAsC,iFAAiB;AACvD;AACA;AACA;AACA;AACA;AACA,0CAA0C,iFAAiB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,+CAAO;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,+CAAO;AACrD;AACA,sEAAsE,iEAAqB;AAC3F,2DAA2D,iEAAqB;AAChF;AACA;AACA,iDAAiD,wBAAwB;AACzE;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA,oDAAoD,oFAAwC;AAC5F;AACA,sCAAsC,iFAAiB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,oEAAoB;AACnE;AACA,6CAA6C,mDAAW;AACxD;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,QAAQ,wBAAwB;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,iFAAiB;AACnD;AACA;AACA;AACA,cAAc;AACd,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,aAAa;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,0BAA0B;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yCAAE;AAC1B;AACA;AACA,0BAA0B,+DAAuB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,sCAAsC;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,4DAAgB;AACpC;AACA,wBAAwB,mEAAuB;AAC/C;AACA,4CAA4C,oEAAyB;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,+DAAuB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,+DAAuB;AACrD;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,iBAAiB,+DAAuB;AACxC,uBAAuB,8CAAM;AAC7B,iBAAiB,+DAAuB;AACxC,uBAAuB,8CAAM;AAC7B,iBAAiB,+DAAuB;AACxC,uBAAuB,8CAAM;AAC7B,iBAAiB,+DAAuB;AACxC;AACA;AACA,qDAAqD,UAAU;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,mFAAe;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;;AAEkD;AAClD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpbyD;AACgB;AAC+B;AACtE;AACsC;AAC1B;AACiM;AAC5K;AAChB;AACQ;;AAE3D,mBAAmB,4DAAa;AAChC;AACA;AACA;AACA,CAAC,kCAAkC;AACnC;AACA;AACA;AACA;AACA;AACA,CAAC,4CAA4C;AAC7C;AACA,0DAA0D;AAC1D,mBAAmB;AACnB,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,uFAAwB;AAC5D;AACA;AACA,gBAAgB,iCAAiC;AACjD,gBAAgB,kCAAkC;AAClD,wCAAwC,6EAAiC;AACzE,iBAAiB;AACjB;AACA;AACA,sBAAsB,iEAAqB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,kEAAsB;AACjE;AACA;AACA,qBAAqB;AACrB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,WAAW,OAAO,IAAI;AACtC,sBAAsB,iEAAa;AACnC;AACA;AACA;AACA;AACA;AACA,yCAAyC,uFAAwB;AACjE,kCAAkC,4CAAU;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,mEAAgB;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,mEAAgB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,UAAU;AAC7C;AACA;AACA,yDAAyD,6DAAiB;AAC1E;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA,qCAAqC,+DAAuB;AAC5D,qCAAqC,+DAAuB;AAC5D,qCAAqC,+DAAuB;AAC5D,iCAAiC;AACjC;AACA;AACA,gCAAgC,+DAAuB;AACvD,gCAAgC,+DAAuB;AACvD,gCAAgC,+DAAuB;AACvD;AACA;AACA,iCAAiC,+DAAuB;AACxD,iCAAiC,+DAAuB;AACxD,iCAAiC,+DAAuB;AACxD;AACA,oDAAoD,wEAAqB;AACzE;AACA;AACA;AACA;AACA;AACA,wCAAwC,6FAA6F;AACrI,wDAAwD,iEAAqB;AAC7E;AACA;AACA,8CAA8C,uEAAQ;AACtD,4CAA4C,8EAAe;AAC3D;AACA;AACA;AACA,wCAAwC,oEAAwB;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,WAAW,8BAA8B,oDAAoD;AACxJ;AACA;AACA;AACA,yCAAyC,UAAU;AACnD;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA,gDAAgD,eAAe;AAC/D;AACA,2EAA2E,SAAS;AACpF,qGAAqG,oBAAoB;AACzH;AACA;AACA;AACA,wEAAwE,wEAAqB;AAC7F,gDAAgD,mBAAmB;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC;AACrC;AACA,gDAAgD,WAAW,eAAe,IAAI,KAAK;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,iEAAa;AAC1E,6DAA6D,iEAAa;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,WAAW,qCAAqC,wDAAwD;AACxK;AACA;AACA;AACA;AACA,gEAAgE,WAAW,qCAAqC,wDAAwD,4BAA4B,oDAAoD;AACxP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,wEAAwB;AACnF,yDAAyD,oDAAW;AACpE;AACA;AACA,6CAA6C;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC;AACrC,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE,mDAAG;AACzE,qCAAqC;AACrC;AACA,iCAAiC;AACjC;AACA;AACA,yBAAyB;AACzB,iBAAiB;AACjB;AACA;AACA;AACA,qBAAqB;AACrB,aAAa;AACb;AACA;AACA,6CAA6C,+DAAuB;AACpE;AACA,qBAAqB;AACrB,6CAA6C,+DAAuB;AACpE;AACA,qBAAqB;AACrB,6CAA6C,+DAAuB;AACpE;AACA,qBAAqB;AACrB,iBAAiB;AACjB,aAAa;AACb,SAAS;AACT,mCAAmC,4CAAU;AAC7C;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,mBAAmB;AACnC,eAAe,6DAAiB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8DAA8D,gDAAQ;AACtE,uDAAuD,gDAAQ;AAC/D,wDAAwD,gDAAQ;AAChE,wDAAwD,gDAAQ;AAChE,+DAA+D,gDAAQ;AACvE,8FAA8F,gDAAQ;AACtG;AACA;AACA;AACA,uCAAuC,kEAAsB;AAC7D,2BAA2B,OAAO,IAAI,QAAQ,IAAI,mBAAmB;AACrE;AACA;AACA;AACA;AACA;;AAEgE;AAChE;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1XyD;AACvB;AACmH;AAC9F;AACT;AACsH;AACjG;AAChB;;AAEnD;AACA;AACA;AACA;AACA;AACA,mBAAmB,4DAAa;AAChC;AACA,0DAA0D;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,uFAAwB;AAC5D,mEAAmE,mEAAW;AAC9E;AACA;AACA;AACA;AACA;AACA,2BAA2B,UAAU;AACrC;AACA,6CAA6C,iEAAqB;AAClE;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,gCAAgC,wEAAqB;AACrD;AACA;AACA;AACA,eAAe,oEAAwB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,6DAAiB;AACtD;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,gCAAgC;AAC/F;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,+DAA+D,gCAAgC;AAC/F;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,SAAS;AACxE,wBAAwB,kEAAsB,WAAW,6DAAiB;AAC1E;AACA,qEAAqE,QAAQ,iBAAiB,SAAS;AACvG;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA,2DAA2D,oCAAoC,4BAA4B,gCAAgC;AAC3J;AACA;AACA;AACA,gBAAgB,OAAO;AACvB,gBAAgB,qBAAqB;AACrC,gBAAgB,4CAA4C;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,mEAAmE;AAC7F,eAAe,2FAAwB;AACvC;AACA,wCAAwC,iEAAqB;AAC7D;AACA,8BAA8B,uEAAQ;AACtC,4BAA4B,8EAAe;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,sDAAsD,kEAAsB,WAAW,6DAAiB;AACxG;AACA;AACA,8BAA8B,gFAAiB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,gEAAgB;AAC3D,yCAAyC,mDAAW;AACpD;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA,qBAAqB;AACrB,oBAAoB,mDAAG;AACvB;AACA;AACA;AACA;AACA,yBAAyB;AACzB,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,qBAAqB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,sCAAsC;AAC1E;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,gEAAgB;AACnD,iCAAiC,mDAAW;AAC5C;AACA;AACA,qBAAqB;AACrB,8BAA8B,gFAAiB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,gBAAgB,iCAAiC;AACjD;AACA,+BAA+B,6CAAU;AACzC;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,4BAA4B,UAAU;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iFAAiF,UAAU,GAAG,OAAO;AACrG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sGAAsG,qBAAqB;AAC3H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,8BAA8B;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,gEAAgB;AACnE,iDAAiD,mDAAW;AAC5D;AACA;AACA,qCAAqC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,0BAA0B;AAC1B;AACA,qBAAqB;AACrB,0CAA0C,UAAU,GAAG,qBAAqB;AAC5E;AACA,iBAAiB,kBAAkB,qBAAqB;AACxD;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEyB;AACzB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClUoD;AACF;AACsK;AAC1G;;AAE9G;AACA;AACA,mBAAmB,4DAAa;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0DAA0D;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,MAAM;AACtB;AACA;AACA,QAAQ,yDAAa;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,uEAA2B;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,YAAY,SAAS;AACrB;AACA;AACA,YAAY,+DAAmB,gBAAgB,2DAAe;AAC9D;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK,IAAI;AACT;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,aAAa;AAChC,oBAAoB,mBAAmB;AACvC,gBAAgB,iBAAiB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,mEAAuB;AAC3C;AACA;AACA;AACA,4CAA4C,mEAAwB;AACpE;AACA;AACA;AACA;AACA;AACA,uCAAuC,QAAQ,EAAE,sBAAsB,UAAU;AACjF;AACA;AACA;AACA,uCAAuC,QAAQ,aAAa;AAC5D;AACA;AACA;AACA;AACA,2DAA2D,eAAe;AAC1E;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,qDAAqD,YAAY;AACjE,YAAY,+DAAmB;AAC/B;AACA,uFAAuF,mBAAmB;AAC1G;AACA;AACA,wBAAwB,mCAAmC;AAC3D,oBAAoB,+DAAmB;AACvC;AACA,mCAAmC,aAAa,EAAE,0DAA0D;AAC5G;AACA,aAAa;AACb,2BAA2B,QAAQ,EAAE,wBAAwB,EAAE,mBAAmB;AAClF;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,cAAc,aAAa,OAAO;AAC9C;AACA;AACA;AACA;AACA,gBAAgB,oOAAoO;AACpP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,cAAc,iBAAiB,eAAe,OAAO,OAAO;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,YAAY,iBAAiB;AAC7B,wBAAwB,wBAAwB,EAAE,SAAS;AAC3D;AACA;AACA;AACA,kDAAkD,SAAS;AAC3D;AACA;AACA;AACA,yBAAyB,WAAW;AACpC,uBAAuB,WAAW,KAAK,WAAW;AAClD;AACA,wCAAwC,kBAAkB;AAC1D,sCAAsC,iBAAiB;AACvD;AACA;AACA;AACA,iCAAiC;AACjC,KAAK,OAAO,EAAE;AACd,MAAM;AACN;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,YAAY,6CAA6C;AACzD;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,eAAe;AAC9C,uGAAuG,SAAS;AAChH;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,iCAAiC,SAAS;AAC1C,6CAA6C,SAAS;AACtD;AACA;AACA;AACA;AACA,iCAAiC,SAAS;AAC1C,6CAA6C,SAAS,2BAA2B,SAAS;AAC1F;AACA;AACA;AACA;AACA,iCAAiC,SAAS;AAC1C,6CAA6C,SAAS,2BAA2B,SAAS;AAC1F;AACA;AACA;AACA;AACA,8BAA8B,SAAS;AACvC;AACA;AACA;AACA;AACA;AACA,qDAAqD,cAAc;AACnE;AACA;AACA;AACA;AACA;AACA,eAAe,qCAAqC,WAAW;AAC/D,IAAI,UAAU,EAAE;AAChB,KAAK;AACL;AACA,EAAE;AACF;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,8CAAM;AACnB;AACA;AACA,aAAa,8CAAM;AACnB;AACA;AACA,aAAa,8CAAM;AACnB;AACA;AACA;AACA,8CAA8C,OAAO;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,8CAAM,kBAAkB,KAAK;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,sEAA2B;AACjD;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,MAAM,OAAO,OAAO,aAAa,YAAY,GAAG;AAChD;AACA;AACA;AACA,MAAM,OAAO,YAAY,YAAY;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,mBAAmB;AAC/B;AACA;AACA;AACA;AACA,YAAY,0DAAc;AAC1B,oBAAoB,2BAA2B;AAC/C;AACA;AACA;AACA,2BAA2B,qBAAqB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,aAAa;AACzB;AACA;AACA;AACA,YAAY,0DAAc;AAC1B;AACA;AACA,iBAAiB,4DAAgB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,KAAK,yDAAyD;AAC9D,KAAK,sDAAsD;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,4DAAgB;AAC5B,oBAAoB,mBAAmB;AACvC,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,OAAO,yDAAyD;AAChE,OAAO,yDAAyD;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,sBAAsB,WAAW,oBAAoB,0BAA0B,gBAAgB;AAC/J;AACA;AACA;AACA;AACA,8CAA8C,4BAA4B,iDAAiD,qBAAqB;AAChJ;AACA;AACA;AACA;AACA,gEAAgE,sBAAsB,WAAW,oBAAoB;AACrH;AACA;AACA;AACA;AACA,8CAA8C,4BAA4B,iDAAiD,qBAAqB;AAChJ;AACA;AACA;AACA;AACA,yDAAyD,sBAAsB,gCAAgC,eAAe;AAC9H;AACA,0DAA0D,sBAAsB;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,uDAAuD;AAC1F,qCAAqC,sDAAc;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,4DAA4D,UAAU;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,8CAA8C;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,8DAAgB;AAC/D;AACA;AACA;AACA;AACA;AACA,iEAAiE;AACjE;AACA,gBAAgB,iBAAiB,uBAAuB,IAAI,4BAA4B,IAAI;AAC5F;AACA;AACA,wBAAwB,QAAQ;AAChC;AACA;AACA;AACA,yFAAyF,MAAM;AAC/F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,sEAA2B;AACpD,wDAAwD,+DAAwB;AAChF;AACA;;AAEghB;AAChhB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtqB2K;;AAE3K;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,0DAA0D;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gEAAgE;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,gDAAS;AAChC;AACA,uBAAuB,gDAAS;AAChC;AACA,uBAAuB,oDAAa;AACpC;AACA,uBAAuB,qDAAc;AACrC;AACA,uBAAuB,iDAAU;AACjC;AACA,uBAAuB,gDAAS;AAChC;AACA,uBAAuB,+CAAQ;AAC/B;AACA,uBAAuB,iDAAU;AACjC;AACA,uBAAuB,qDAAc;AACrC;AACA;AACA;AACA;AACA;AACA,CAAC,8CAA8C;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,sEAA2B;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wBAAwB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,4BAA4B;AAC7B;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AACvC;AACA;AACA;AACA;AACA,CAAC,oDAAoD;AACrD;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;AACA;AACA;AACA;AACA;AACA,YAAY,4BAA4B;AACxC,YAAY,gBAAgB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,kCAAkC;AACnC;AACA;AACA;AACA;AACA;AACA,CAAC,oEAAoE;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEukB;AACvkB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACnUwC;AAC+C;AACzC;AAC6I;AAC3J;AACkC;;AAElE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,gCAAgC;AACjC,QAAQ,YAAY;AACpB,QAAQ,OAAO;AACf,QAAQ,OAAO;AACf,QAAQ,UAAU;AAClB;AACA;AACA,mCAAmC,IAAI;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,UAAU;AACjD;AACA;AACA,YAAY,0DAAc;AAC1B,oBAAoB,2BAA2B;AAC/C;AACA;AACA;AACA,YAAY,4DAAgB;AAC5B,oBAAoB,mBAAmB;AACvC;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,uBAAuB,8EAAW;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,8EAAW;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,SAAS;AACzB;AACA;AACA,0BAA0B,YAAY;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA;AACA;AACA;AACA,mEAAmE,aAAa;AAChF;AACA;AACA;AACA;AACA;AACA,oBAAoB,wEAAS;AAC7B;AACA;AACA;AACA;AACA,iBAAiB,sDAAgB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,uBAAuB;AAC3C;AACA,qDAAqD,qDAAa;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,OAAO,QAAQ;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,2EAAyB;AAC5D;AACA;AACA;AACA;AACA;AACA,gBAAgB,sBAAsB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,EAAE,IAAI,EAAE,IAAI,EAAE,UAAU,EAAE,IAAI,EAAE,OAAO,EAAE;AAC3D;AACA;AACA,kBAAkB,EAAE,IAAI,EAAE,KAAK,EAAE,mBAAmB,EAAE,IAAI,EAAE,OAAO,EAAE;AACrE;AACA;AACA,kBAAkB,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,KAAK,EAAE,mBAAmB,EAAE,IAAI,EAAE,OAAO,EAAE;AACvF;AACA;AACA;AACA;AACA;AACA,yCAAyC,EAAE,gCAAgC,KAAK,6CAA6C,KAAK;AAClI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,yEAAU;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,EAAE,yBAAyB,EAAE,yBAAyB,EAAE,0CAA0C,IAAI,GAAG,EAAE,aAAa,IAAI,mBAAmB,IAAI,GAAG,EAAE,cAAc,IAAI,yEAAyE,EAAE,oBAAoB,IAAI,GAAG,EAAE,gBAAgB,IAAI,EAAE,IAAI,2EAA2E,EAAE,oBAAoB,IAAI,GAAG,EAAE,gBAAgB,IAAI,EAAE,IAAI,iBAAiB,IAAI,2EAA2E,EAAE,qBAAqB,IAAI,GAAG,EAAE,gBAAgB,IAAI,EAAE,IAAI,iBAAiB,IAAI,EAAE,IAAI,yEAAyE,EAAE,qBAAqB,IAAI,GAAG,EAAE,gBAAgB,IAAI,EAAE,IAAI,iBAAiB,IAAI,EAAE,IAAI,yEAAyE,EAAE,qBAAqB,IAAI,GAAG,EAAE,gBAAgB,IAAI,EAAE,IAAI,iBAAiB,IAAI,EAAE,IAAI,yEAAyE,EAAE,yBAAyB,IAAI,EAAE,IAAI,iBAAiB,IAAI,EAAE,IAAI,yEAAyE,EAAE;AACjqC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,oEAA4B;AACpD,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,oEAA4B;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,8CAAO;AACX,QAAQ,mDAAY;AACpB,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA;AACA,yBAAyB,UAAU,GAAG,UAAU;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,uCAAuC;AACvC;AACA,mCAAmC,GAAG;AACtC;AACA,gBAAgB,oEAA4B;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,2DAAmB;AAC9E;AACA;AACA;AACA;AACA,wBAAwB,sEAA0B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,sEAA0B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,sEAA0B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,iBAAiB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,qBAAqB,+DAAmB;AACxC;AACA;AACA,wBAAwB,SAAS;AACjC,oBAAoB,sEAA0B;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,cAAc;AAC5B;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,KAAK,EAAE,yBAAyB,EAAE,IAAI;AACxD,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEm9B;AACn9B;;;;;;;UCr3BA;UACA;;UAEA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;;UAEA;UACA;;UAEA;UACA;UACA;;;;;WCtBA;WACA;WACA;WACA;WACA,yCAAyC,wCAAwC;WACjF;WACA;WACA;;;;;WCPA;;;;;WCAA;WACA;WACA;WACA,uDAAuD,iBAAiB;WACxE;WACA,gDAAgD,aAAa;WAC7D;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACN+G;AACvE;AACsE;AACnC;AAC+gB;AACxhB;;AAElE;AACA;AACA;AACA,QAAQ;AACR,iBAAiB;AACjB,qBAAqB;AACrB,yBAAyB;AACzB,sBAAsB;AACtB;;AAEiB;AACjB","sources":["webpack:///webpack/universalModuleDefinition","webpack:///./node_modules/@aws-crypto/sha256-js/build/module/RawSha256.js","webpack:///./node_modules/@aws-crypto/sha256-js/build/module/constants.js","webpack:///./node_modules/@aws-crypto/sha256-js/build/module/index.js","webpack:///./node_modules/@aws-crypto/sha256-js/build/module/jsSha256.js","webpack:///./node_modules/@aws-crypto/util/build/module/convertToBuffer.js","webpack:///./node_modules/@aws-crypto/util/build/module/index.js","webpack:///./node_modules/@aws-crypto/util/build/module/isEmptyData.js","webpack:///./node_modules/@aws-crypto/util/build/module/numToUint8.js","webpack:///./node_modules/@aws-crypto/util/build/module/uint32ArrayFrom.js","webpack:///./node_modules/@aws-crypto/util/node_modules/@smithy/util-utf8/dist-es/fromUtf8.browser.js","webpack:///./node_modules/@aws-crypto/util/node_modules/@smithy/util-utf8/dist-es/index.js","webpack:///./node_modules/@aws-crypto/util/node_modules/@smithy/util-utf8/dist-es/toUint8Array.js","webpack:///./node_modules/@aws-crypto/util/node_modules/@smithy/util-utf8/dist-es/toUtf8.browser.js","webpack:///./node_modules/idb/build/esm/index.js","webpack:///./node_modules/idb/build/esm/wrap-idb-value.js","webpack:///./node_modules/immer/dist/immer.esm.js","webpack:///./node_modules/rxjs/dist/esm5/internal/NotificationFactories.js","webpack:///./node_modules/rxjs/dist/esm5/internal/Observable.js","webpack:///./node_modules/rxjs/dist/esm5/internal/Subject.js","webpack:///./node_modules/rxjs/dist/esm5/internal/Subscriber.js","webpack:///./node_modules/rxjs/dist/esm5/internal/Subscription.js","webpack:///./node_modules/rxjs/dist/esm5/internal/config.js","webpack:///./node_modules/rxjs/dist/esm5/internal/observable/from.js","webpack:///./node_modules/rxjs/dist/esm5/internal/observable/innerFrom.js","webpack:///./node_modules/rxjs/dist/esm5/internal/observable/of.js","webpack:///./node_modules/rxjs/dist/esm5/internal/operators/OperatorSubscriber.js","webpack:///./node_modules/rxjs/dist/esm5/internal/operators/catchError.js","webpack:///./node_modules/rxjs/dist/esm5/internal/operators/filter.js","webpack:///./node_modules/rxjs/dist/esm5/internal/operators/map.js","webpack:///./node_modules/rxjs/dist/esm5/internal/operators/observeOn.js","webpack:///./node_modules/rxjs/dist/esm5/internal/operators/subscribeOn.js","webpack:///./node_modules/rxjs/dist/esm5/internal/scheduled/scheduleArray.js","webpack:///./node_modules/rxjs/dist/esm5/internal/scheduled/scheduleAsyncIterable.js","webpack:///./node_modules/rxjs/dist/esm5/internal/scheduled/scheduleIterable.js","webpack:///./node_modules/rxjs/dist/esm5/internal/scheduled/scheduleObservable.js","webpack:///./node_modules/rxjs/dist/esm5/internal/scheduled/schedulePromise.js","webpack:///./node_modules/rxjs/dist/esm5/internal/scheduled/scheduleReadableStreamLike.js","webpack:///./node_modules/rxjs/dist/esm5/internal/scheduled/scheduled.js","webpack:///./node_modules/rxjs/dist/esm5/internal/scheduler/timeoutProvider.js","webpack:///./node_modules/rxjs/dist/esm5/internal/symbol/iterator.js","webpack:///./node_modules/rxjs/dist/esm5/internal/symbol/observable.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/ObjectUnsubscribedError.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/UnsubscriptionError.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/args.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/arrRemove.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/createErrorClass.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/errorContext.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/executeSchedule.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/identity.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/isArrayLike.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/isAsyncIterable.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/isFunction.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/isInteropObservable.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/isIterable.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/isPromise.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/isReadableStreamLike.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/isScheduler.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/lift.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/noop.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/pipe.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/reportUnhandledError.js","webpack:///./node_modules/rxjs/dist/esm5/internal/util/throwUnobservableError.js","webpack:///./node_modules/ulid/dist/index.esm.js","webpack:///./node_modules/ulid/stubs/crypto.js","webpack:///./node_modules/uuid/dist/esm-browser/native.js","webpack:///./node_modules/uuid/dist/esm-browser/regex.js","webpack:///./node_modules/uuid/dist/esm-browser/rng.js","webpack:///./node_modules/uuid/dist/esm-browser/stringify.js","webpack:///./node_modules/uuid/dist/esm-browser/v4.js","webpack:///./node_modules/uuid/dist/esm-browser/validate.js","webpack:///./node_modules/@smithy/util-hex-encoding/dist-es/index.js","webpack:///./node_modules/graphql/error/GraphQLError.mjs","webpack:///./node_modules/graphql/error/syntaxError.mjs","webpack:///./node_modules/graphql/jsutils/defineInspect.mjs","webpack:///./node_modules/graphql/jsutils/devAssert.mjs","webpack:///./node_modules/graphql/jsutils/inspect.mjs","webpack:///./node_modules/graphql/jsutils/instanceOf.mjs","webpack:///./node_modules/graphql/jsutils/invariant.mjs","webpack:///./node_modules/graphql/jsutils/isObjectLike.mjs","webpack:///./node_modules/graphql/jsutils/nodejsCustomInspectSymbol.mjs","webpack:///./node_modules/graphql/language/ast.mjs","webpack:///./node_modules/graphql/language/blockString.mjs","webpack:///./node_modules/graphql/language/directiveLocation.mjs","webpack:///./node_modules/graphql/language/kinds.mjs","webpack:///./node_modules/graphql/language/lexer.mjs","webpack:///./node_modules/graphql/language/location.mjs","webpack:///./node_modules/graphql/language/parser.mjs","webpack:///./node_modules/graphql/language/printLocation.mjs","webpack:///./node_modules/graphql/language/printer.mjs","webpack:///./node_modules/graphql/language/source.mjs","webpack:///./node_modules/graphql/language/tokenKind.mjs","webpack:///./node_modules/graphql/language/visitor.mjs","webpack:///./node_modules/graphql/polyfills/symbols.mjs","webpack:///./node_modules/tslib/tslib.es6.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/Providers/AWSAppSyncRealTimeProvider/index.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/Providers/AWSWebSocketProvider/appsyncUrl.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/Providers/AWSWebSocketProvider/authHeaders.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/Providers/AWSWebSocketProvider/index.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/Providers/constants.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/internals/InternalGraphQLAPI.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/internals/graphqlAuth.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/internals/utils/runtimeTypeGuards/isGraphQLResponseWithErrors.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/types/PubSub.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/types/index.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/utils/ConnectionStateMonitor.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/utils/ReachabilityMonitor/index.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/utils/ReconnectionMonitor.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/utils/errors/GraphQLApiError.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/utils/errors/assertValidationError.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/utils/errors/constants.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/utils/errors/createGraphQLResultWithError.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/utils/errors/repackageAuthError.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/utils/errors/validation.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/utils/resolveConfig.mjs","webpack:///./node_modules/@aws-amplify/api-graphql/dist/esm/utils/resolveLibraryOptions.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/apis/common/handler.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/apis/common/internalPost.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/apis/common/publicApis.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/apis/index.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/errors/CanceledError.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/errors/RestApiError.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/errors/assertValidatonError.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/errors/validation.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/index.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/internals/index.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/utils/constants.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/utils/createCancellableOperation.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/utils/isIamAuthApplicable.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/utils/logger.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/utils/parseSigningInfo.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/utils/resolveApiUrl.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/utils/resolveHeaders.mjs","webpack:///./node_modules/@aws-amplify/api-rest/dist/esm/utils/serviceError.mjs","webpack:///./node_modules/@aws-amplify/api/dist/esm/internals/InternalAPI.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/BackgroundProcessManager/BackgroundManagerNotOpenError.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/BackgroundProcessManager/BackgroundProcessManager.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/BackgroundProcessManager/types.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Cache/StorageCache.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Cache/StorageCacheCommon.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Cache/constants.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Cache/index.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Cache/utils/cacheHelpers.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Cache/utils/errorHelpers.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Hub/index.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Logger/ConsoleLogger.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Logger/types.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Mutex/Mutex.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/customUserAgent.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/detectFramework.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/detection/Angular.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/detection/Expo.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/detection/Next.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/detection/Nuxt.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/detection/React.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/detection/ReactNative.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/detection/Svelte.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/detection/Vue.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/detection/Web.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/detection/helpers.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/detection/index.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/index.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/types.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Platform/version.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/Reachability/Reachability.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/handlers/authenticated.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/handlers/fetch.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/handlers/unauthenticated.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/internal/composeTransferHandler.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/retry/defaultRetryDecider.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/retry/isClockSkewError.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/retry/jitteredBackoff.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/retry/middleware.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/middleware.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/signer/signatureV4/constants.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/signer/signatureV4/signRequest.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/signer/signatureV4/utils/dataHashHelpers.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/signer/signatureV4/utils/getCanonicalHeaders.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/signer/signatureV4/utils/getCanonicalQueryString.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/signer/signatureV4/utils/getCanonicalRequest.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/signer/signatureV4/utils/getCanonicalUri.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/signer/signatureV4/utils/getCredentialScope.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/signer/signatureV4/utils/getFormattedDates.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/signer/signatureV4/utils/getHashedPayload.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/signer/signatureV4/utils/getSignature.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/signer/signatureV4/utils/getSignedHeaders.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/signer/signatureV4/utils/getSigningKey.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/signer/signatureV4/utils/getSigningValues.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/signer/signatureV4/utils/getStringToSign.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/utils/getSkewCorrectedDate.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/utils/getUpdatedSystemClockOffset.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/signing/utils/isClockSkewed.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/middleware/userAgent/middleware.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/serde/json.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/serde/responseInfo.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/clients/utils/memoization.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/constants.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/errors/APIError.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/errors/AmplifyError.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/errors/PlatformNotSupportedError.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/errors/createAssertionFunction.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/parseAWSExports.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/parseAmplifyOutputs.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/singleton/Amplify.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/singleton/Auth/index.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/singleton/apis/fetchAuthSession.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/singleton/apis/internal/fetchAuthSession.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/singleton/constants.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/storage/InMemoryStorage.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/storage/KeyValueStorage.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/storage/utils.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/types/errors.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/WordArray.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/amplifyUrl/index.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/amplifyUuid/index.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/convert/base64/base64Encoder.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/convert/base64/bytesToString.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/cryptoSecureRandomInt.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/deepFreeze.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/globalHelpers/index.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/isBrowser.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/isWebWorker.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/parseAmplifyConfig.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/retry/NonRetryableError.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/retry/constants.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/retry/isNonRetryableError.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/retry/jitteredBackoff.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/retry/jitteredExponentialRetry.mjs","webpack:///./node_modules/@aws-amplify/core/dist/esm/utils/retry/retry.mjs","webpack:///./dist/esm/authModeStrategies/defaultAuthStrategy.mjs","webpack:///./dist/esm/authModeStrategies/multiAuthStrategy.mjs","webpack:///./dist/esm/datastore/datastore.mjs","webpack:///./dist/esm/datastore/utils.mjs","webpack:///./dist/esm/predicates/index.mjs","webpack:///./dist/esm/predicates/next.mjs","webpack:///./dist/esm/predicates/sort.mjs","webpack:///./dist/esm/storage/adapter/AsyncStorageAdapter.mjs","webpack:///./dist/esm/storage/adapter/AsyncStorageDatabase.mjs","webpack:///./dist/esm/storage/adapter/InMemoryStore.mjs","webpack:///./dist/esm/storage/adapter/IndexedDBAdapter.mjs","webpack:///./dist/esm/storage/adapter/StorageAdapterBase.mjs","webpack:///./dist/esm/storage/adapter/getDefaultAdapter/index.mjs","webpack:///./dist/esm/storage/relationship.mjs","webpack:///./dist/esm/storage/storage.mjs","webpack:///./dist/esm/sync/datastoreConnectivity.mjs","webpack:///./dist/esm/sync/datastoreReachability/index.mjs","webpack:///./dist/esm/sync/index.mjs","webpack:///./dist/esm/sync/merger.mjs","webpack:///./dist/esm/sync/outbox.mjs","webpack:///./dist/esm/sync/processors/errorMaps.mjs","webpack:///./dist/esm/sync/processors/mutation.mjs","webpack:///./dist/esm/sync/processors/subscription.mjs","webpack:///./dist/esm/sync/processors/sync.mjs","webpack:///./dist/esm/sync/utils.mjs","webpack:///./dist/esm/types.mjs","webpack:///./dist/esm/util.mjs","webpack:///webpack/bootstrap","webpack:///webpack/runtime/define property getters","webpack:///webpack/runtime/hasOwnProperty shorthand","webpack:///webpack/runtime/make namespace object","webpack:///./dist/esm/index.mjs"],"sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"aws_amplify_datastore\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"aws_amplify_datastore\"] = factory();\n\telse\n\t\troot[\"aws_amplify_datastore\"] = factory();\n})(self, () => {\nreturn ","import { BLOCK_SIZE, DIGEST_LENGTH, INIT, KEY, MAX_HASHABLE_LENGTH } from \"./constants\";\n/**\n * @internal\n */\nvar RawSha256 = /** @class */ (function () {\n    function RawSha256() {\n        this.state = Int32Array.from(INIT);\n        this.temp = new Int32Array(64);\n        this.buffer = new Uint8Array(64);\n        this.bufferLength = 0;\n        this.bytesHashed = 0;\n        /**\n         * @internal\n         */\n        this.finished = false;\n    }\n    RawSha256.prototype.update = function (data) {\n        if (this.finished) {\n            throw new Error(\"Attempted to update an already finished hash.\");\n        }\n        var position = 0;\n        var byteLength = data.byteLength;\n        this.bytesHashed += byteLength;\n        if (this.bytesHashed * 8 > MAX_HASHABLE_LENGTH) {\n            throw new Error(\"Cannot hash more than 2^53 - 1 bits\");\n        }\n        while (byteLength > 0) {\n            this.buffer[this.bufferLength++] = data[position++];\n            byteLength--;\n            if (this.bufferLength === BLOCK_SIZE) {\n                this.hashBuffer();\n                this.bufferLength = 0;\n            }\n        }\n    };\n    RawSha256.prototype.digest = function () {\n        if (!this.finished) {\n            var bitsHashed = this.bytesHashed * 8;\n            var bufferView = new DataView(this.buffer.buffer, this.buffer.byteOffset, this.buffer.byteLength);\n            var undecoratedLength = this.bufferLength;\n            bufferView.setUint8(this.bufferLength++, 0x80);\n            // Ensure the final block has enough room for the hashed length\n            if (undecoratedLength % BLOCK_SIZE >= BLOCK_SIZE - 8) {\n                for (var i = this.bufferLength; i < BLOCK_SIZE; i++) {\n                    bufferView.setUint8(i, 0);\n                }\n                this.hashBuffer();\n                this.bufferLength = 0;\n            }\n            for (var i = this.bufferLength; i < BLOCK_SIZE - 8; i++) {\n                bufferView.setUint8(i, 0);\n            }\n            bufferView.setUint32(BLOCK_SIZE - 8, Math.floor(bitsHashed / 0x100000000), true);\n            bufferView.setUint32(BLOCK_SIZE - 4, bitsHashed);\n            this.hashBuffer();\n            this.finished = true;\n        }\n        // The value in state is little-endian rather than big-endian, so flip\n        // each word into a new Uint8Array\n        var out = new Uint8Array(DIGEST_LENGTH);\n        for (var i = 0; i < 8; i++) {\n            out[i * 4] = (this.state[i] >>> 24) & 0xff;\n            out[i * 4 + 1] = (this.state[i] >>> 16) & 0xff;\n            out[i * 4 + 2] = (this.state[i] >>> 8) & 0xff;\n            out[i * 4 + 3] = (this.state[i] >>> 0) & 0xff;\n        }\n        return out;\n    };\n    RawSha256.prototype.hashBuffer = function () {\n        var _a = this, buffer = _a.buffer, state = _a.state;\n        var state0 = state[0], state1 = state[1], state2 = state[2], state3 = state[3], state4 = state[4], state5 = state[5], state6 = state[6], state7 = state[7];\n        for (var i = 0; i < BLOCK_SIZE; i++) {\n            if (i < 16) {\n                this.temp[i] =\n                    ((buffer[i * 4] & 0xff) << 24) |\n                        ((buffer[i * 4 + 1] & 0xff) << 16) |\n                        ((buffer[i * 4 + 2] & 0xff) << 8) |\n                        (buffer[i * 4 + 3] & 0xff);\n            }\n            else {\n                var u = this.temp[i - 2];\n                var t1_1 = ((u >>> 17) | (u << 15)) ^ ((u >>> 19) | (u << 13)) ^ (u >>> 10);\n                u = this.temp[i - 15];\n                var t2_1 = ((u >>> 7) | (u << 25)) ^ ((u >>> 18) | (u << 14)) ^ (u >>> 3);\n                this.temp[i] =\n                    ((t1_1 + this.temp[i - 7]) | 0) + ((t2_1 + this.temp[i - 16]) | 0);\n            }\n            var t1 = ((((((state4 >>> 6) | (state4 << 26)) ^\n                ((state4 >>> 11) | (state4 << 21)) ^\n                ((state4 >>> 25) | (state4 << 7))) +\n                ((state4 & state5) ^ (~state4 & state6))) |\n                0) +\n                ((state7 + ((KEY[i] + this.temp[i]) | 0)) | 0)) |\n                0;\n            var t2 = ((((state0 >>> 2) | (state0 << 30)) ^\n                ((state0 >>> 13) | (state0 << 19)) ^\n                ((state0 >>> 22) | (state0 << 10))) +\n                ((state0 & state1) ^ (state0 & state2) ^ (state1 & state2))) |\n                0;\n            state7 = state6;\n            state6 = state5;\n            state5 = state4;\n            state4 = (state3 + t1) | 0;\n            state3 = state2;\n            state2 = state1;\n            state1 = state0;\n            state0 = (t1 + t2) | 0;\n        }\n        state[0] += state0;\n        state[1] += state1;\n        state[2] += state2;\n        state[3] += state3;\n        state[4] += state4;\n        state[5] += state5;\n        state[6] += state6;\n        state[7] += state7;\n    };\n    return RawSha256;\n}());\nexport { RawSha256 };\n//# sourceMappingURL=RawSha256.js.map","/**\n * @internal\n */\nexport var BLOCK_SIZE = 64;\n/**\n * @internal\n */\nexport var DIGEST_LENGTH = 32;\n/**\n * @internal\n */\nexport var KEY = new Uint32Array([\n    0x428a2f98,\n    0x71374491,\n    0xb5c0fbcf,\n    0xe9b5dba5,\n    0x3956c25b,\n    0x59f111f1,\n    0x923f82a4,\n    0xab1c5ed5,\n    0xd807aa98,\n    0x12835b01,\n    0x243185be,\n    0x550c7dc3,\n    0x72be5d74,\n    0x80deb1fe,\n    0x9bdc06a7,\n    0xc19bf174,\n    0xe49b69c1,\n    0xefbe4786,\n    0x0fc19dc6,\n    0x240ca1cc,\n    0x2de92c6f,\n    0x4a7484aa,\n    0x5cb0a9dc,\n    0x76f988da,\n    0x983e5152,\n    0xa831c66d,\n    0xb00327c8,\n    0xbf597fc7,\n    0xc6e00bf3,\n    0xd5a79147,\n    0x06ca6351,\n    0x14292967,\n    0x27b70a85,\n    0x2e1b2138,\n    0x4d2c6dfc,\n    0x53380d13,\n    0x650a7354,\n    0x766a0abb,\n    0x81c2c92e,\n    0x92722c85,\n    0xa2bfe8a1,\n    0xa81a664b,\n    0xc24b8b70,\n    0xc76c51a3,\n    0xd192e819,\n    0xd6990624,\n    0xf40e3585,\n    0x106aa070,\n    0x19a4c116,\n    0x1e376c08,\n    0x2748774c,\n    0x34b0bcb5,\n    0x391c0cb3,\n    0x4ed8aa4a,\n    0x5b9cca4f,\n    0x682e6ff3,\n    0x748f82ee,\n    0x78a5636f,\n    0x84c87814,\n    0x8cc70208,\n    0x90befffa,\n    0xa4506ceb,\n    0xbef9a3f7,\n    0xc67178f2\n]);\n/**\n * @internal\n */\nexport var INIT = [\n    0x6a09e667,\n    0xbb67ae85,\n    0x3c6ef372,\n    0xa54ff53a,\n    0x510e527f,\n    0x9b05688c,\n    0x1f83d9ab,\n    0x5be0cd19\n];\n/**\n * @internal\n */\nexport var MAX_HASHABLE_LENGTH = Math.pow(2, 53) - 1;\n//# sourceMappingURL=constants.js.map","export * from \"./jsSha256\";\n//# sourceMappingURL=index.js.map","import { __awaiter, __generator } from \"tslib\";\nimport { BLOCK_SIZE } from \"./constants\";\nimport { RawSha256 } from \"./RawSha256\";\nimport { isEmptyData, convertToBuffer } from \"@aws-crypto/util\";\nvar Sha256 = /** @class */ (function () {\n    function Sha256(secret) {\n        this.secret = secret;\n        this.hash = new RawSha256();\n        this.reset();\n    }\n    Sha256.prototype.update = function (toHash) {\n        if (isEmptyData(toHash) || this.error) {\n            return;\n        }\n        try {\n            this.hash.update(convertToBuffer(toHash));\n        }\n        catch (e) {\n            this.error = e;\n        }\n    };\n    /* This synchronous method keeps compatibility\n     * with the v2 aws-sdk.\n     */\n    Sha256.prototype.digestSync = function () {\n        if (this.error) {\n            throw this.error;\n        }\n        if (this.outer) {\n            if (!this.outer.finished) {\n                this.outer.update(this.hash.digest());\n            }\n            return this.outer.digest();\n        }\n        return this.hash.digest();\n    };\n    /* The underlying digest method here is synchronous.\n     * To keep the same interface with the other hash functions\n     * the default is to expose this as an async method.\n     * However, it can sometimes be useful to have a sync method.\n     */\n    Sha256.prototype.digest = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2 /*return*/, this.digestSync()];\n            });\n        });\n    };\n    Sha256.prototype.reset = function () {\n        this.hash = new RawSha256();\n        if (this.secret) {\n            this.outer = new RawSha256();\n            var inner = bufferFromSecret(this.secret);\n            var outer = new Uint8Array(BLOCK_SIZE);\n            outer.set(inner);\n            for (var i = 0; i < BLOCK_SIZE; i++) {\n                inner[i] ^= 0x36;\n                outer[i] ^= 0x5c;\n            }\n            this.hash.update(inner);\n            this.outer.update(outer);\n            // overwrite the copied key in memory\n            for (var i = 0; i < inner.byteLength; i++) {\n                inner[i] = 0;\n            }\n        }\n    };\n    return Sha256;\n}());\nexport { Sha256 };\nfunction bufferFromSecret(secret) {\n    var input = convertToBuffer(secret);\n    if (input.byteLength > BLOCK_SIZE) {\n        var bufferHash = new RawSha256();\n        bufferHash.update(input);\n        input = bufferHash.digest();\n    }\n    var buffer = new Uint8Array(BLOCK_SIZE);\n    buffer.set(input);\n    return buffer;\n}\n//# sourceMappingURL=jsSha256.js.map","// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport { fromUtf8 as fromUtf8Browser } from \"@smithy/util-utf8\";\n// Quick polyfill\nvar fromUtf8 = typeof Buffer !== \"undefined\" && Buffer.from\n    ? function (input) { return Buffer.from(input, \"utf8\"); }\n    : fromUtf8Browser;\nexport function convertToBuffer(data) {\n    // Already a Uint8, do nothing\n    if (data instanceof Uint8Array)\n        return data;\n    if (typeof data === \"string\") {\n        return fromUtf8(data);\n    }\n    if (ArrayBuffer.isView(data)) {\n        return new Uint8Array(data.buffer, data.byteOffset, data.byteLength / Uint8Array.BYTES_PER_ELEMENT);\n    }\n    return new Uint8Array(data);\n}\n//# sourceMappingURL=convertToBuffer.js.map","// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexport { convertToBuffer } from \"./convertToBuffer\";\nexport { isEmptyData } from \"./isEmptyData\";\nexport { numToUint8 } from \"./numToUint8\";\nexport { uint32ArrayFrom } from './uint32ArrayFrom';\n//# sourceMappingURL=index.js.map","// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexport function isEmptyData(data) {\n    if (typeof data === \"string\") {\n        return data.length === 0;\n    }\n    return data.byteLength === 0;\n}\n//# sourceMappingURL=isEmptyData.js.map","// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nexport function numToUint8(num) {\n    return new Uint8Array([\n        (num & 0xff000000) >> 24,\n        (num & 0x00ff0000) >> 16,\n        (num & 0x0000ff00) >> 8,\n        num & 0x000000ff,\n    ]);\n}\n//# sourceMappingURL=numToUint8.js.map","// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// IE 11 does not support Array.from, so we do it manually\nexport function uint32ArrayFrom(a_lookUpTable) {\n    if (!Uint32Array.from) {\n        var return_array = new Uint32Array(a_lookUpTable.length);\n        var a_index = 0;\n        while (a_index < a_lookUpTable.length) {\n            return_array[a_index] = a_lookUpTable[a_index];\n            a_index += 1;\n        }\n        return return_array;\n    }\n    return Uint32Array.from(a_lookUpTable);\n}\n//# sourceMappingURL=uint32ArrayFrom.js.map","export const fromUtf8 = (input) => new TextEncoder().encode(input);\n","export * from \"./fromUtf8\";\nexport * from \"./toUint8Array\";\nexport * from \"./toUtf8\";\n","import { fromUtf8 } from \"./fromUtf8\";\nexport const toUint8Array = (data) => {\n    if (typeof data === \"string\") {\n        return fromUtf8(data);\n    }\n    if (ArrayBuffer.isView(data)) {\n        return new Uint8Array(data.buffer, data.byteOffset, data.byteLength / Uint8Array.BYTES_PER_ELEMENT);\n    }\n    return new Uint8Array(data);\n};\n","export const toUtf8 = (input) => {\n    if (typeof input === \"string\") {\n        return input;\n    }\n    if (typeof input !== \"object\" || typeof input.byteOffset !== \"number\" || typeof input.byteLength !== \"number\") {\n        throw new Error(\"@smithy/util-utf8: toUtf8 encoder function only accepts string | Uint8Array.\");\n    }\n    return new TextDecoder(\"utf-8\").decode(input);\n};\n","import { w as wrap, r as replaceTraps } from './wrap-idb-value.js';\nexport { u as unwrap, w as wrap } from './wrap-idb-value.js';\n\n/**\n * Open a database.\n *\n * @param name Name of the database.\n * @param version Schema version.\n * @param callbacks Additional callbacks.\n */\nfunction openDB(name, version, { blocked, upgrade, blocking, terminated } = {}) {\n    const request = indexedDB.open(name, version);\n    const openPromise = wrap(request);\n    if (upgrade) {\n        request.addEventListener('upgradeneeded', (event) => {\n            upgrade(wrap(request.result), event.oldVersion, event.newVersion, wrap(request.transaction));\n        });\n    }\n    if (blocked)\n        request.addEventListener('blocked', () => blocked());\n    openPromise\n        .then((db) => {\n        if (terminated)\n            db.addEventListener('close', () => terminated());\n        if (blocking)\n            db.addEventListener('versionchange', () => blocking());\n    })\n        .catch(() => { });\n    return openPromise;\n}\n/**\n * Delete a database.\n *\n * @param name Name of the database.\n */\nfunction deleteDB(name, { blocked } = {}) {\n    const request = indexedDB.deleteDatabase(name);\n    if (blocked)\n        request.addEventListener('blocked', () => blocked());\n    return wrap(request).then(() => undefined);\n}\n\nconst readMethods = ['get', 'getKey', 'getAll', 'getAllKeys', 'count'];\nconst writeMethods = ['put', 'add', 'delete', 'clear'];\nconst cachedMethods = new Map();\nfunction getMethod(target, prop) {\n    if (!(target instanceof IDBDatabase &&\n        !(prop in target) &&\n        typeof prop === 'string')) {\n        return;\n    }\n    if (cachedMethods.get(prop))\n        return cachedMethods.get(prop);\n    const targetFuncName = prop.replace(/FromIndex$/, '');\n    const useIndex = prop !== targetFuncName;\n    const isWrite = writeMethods.includes(targetFuncName);\n    if (\n    // Bail if the target doesn't exist on the target. Eg, getAll isn't in Edge.\n    !(targetFuncName in (useIndex ? IDBIndex : IDBObjectStore).prototype) ||\n        !(isWrite || readMethods.includes(targetFuncName))) {\n        return;\n    }\n    const method = async function (storeName, ...args) {\n        // isWrite ? 'readwrite' : undefined gzipps better, but fails in Edge :(\n        const tx = this.transaction(storeName, isWrite ? 'readwrite' : 'readonly');\n        let target = tx.store;\n        if (useIndex)\n            target = target.index(args.shift());\n        const returnVal = await target[targetFuncName](...args);\n        if (isWrite)\n            await tx.done;\n        return returnVal;\n    };\n    cachedMethods.set(prop, method);\n    return method;\n}\nreplaceTraps((oldTraps) => ({\n    ...oldTraps,\n    get: (target, prop, receiver) => getMethod(target, prop) || oldTraps.get(target, prop, receiver),\n    has: (target, prop) => !!getMethod(target, prop) || oldTraps.has(target, prop),\n}));\n\nexport { deleteDB, openDB };\n","const instanceOfAny = (object, constructors) => constructors.some((c) => object instanceof c);\n\nlet idbProxyableTypes;\nlet cursorAdvanceMethods;\n// This is a function to prevent it throwing up in node environments.\nfunction getIdbProxyableTypes() {\n    return (idbProxyableTypes ||\n        (idbProxyableTypes = [\n            IDBDatabase,\n            IDBObjectStore,\n            IDBIndex,\n            IDBCursor,\n            IDBTransaction,\n        ]));\n}\n// This is a function to prevent it throwing up in node environments.\nfunction getCursorAdvanceMethods() {\n    return (cursorAdvanceMethods ||\n        (cursorAdvanceMethods = [\n            IDBCursor.prototype.advance,\n            IDBCursor.prototype.continue,\n            IDBCursor.prototype.continuePrimaryKey,\n        ]));\n}\nconst cursorRequestMap = new WeakMap();\nconst transactionDoneMap = new WeakMap();\nconst transactionStoreNamesMap = new WeakMap();\nconst transformCache = new WeakMap();\nconst reverseTransformCache = new WeakMap();\nfunction promisifyRequest(request) {\n    const promise = new Promise((resolve, reject) => {\n        const unlisten = () => {\n            request.removeEventListener('success', success);\n            request.removeEventListener('error', error);\n        };\n        const success = () => {\n            resolve(wrap(request.result));\n            unlisten();\n        };\n        const error = () => {\n            reject(request.error);\n            unlisten();\n        };\n        request.addEventListener('success', success);\n        request.addEventListener('error', error);\n    });\n    promise\n        .then((value) => {\n        // Since cursoring reuses the IDBRequest (*sigh*), we cache it for later retrieval\n        // (see wrapFunction).\n        if (value instanceof IDBCursor) {\n            cursorRequestMap.set(value, request);\n        }\n        // Catching to avoid \"Uncaught Promise exceptions\"\n    })\n        .catch(() => { });\n    // This mapping exists in reverseTransformCache but doesn't doesn't exist in transformCache. This\n    // is because we create many promises from a single IDBRequest.\n    reverseTransformCache.set(promise, request);\n    return promise;\n}\nfunction cacheDonePromiseForTransaction(tx) {\n    // Early bail if we've already created a done promise for this transaction.\n    if (transactionDoneMap.has(tx))\n        return;\n    const done = new Promise((resolve, reject) => {\n        const unlisten = () => {\n            tx.removeEventListener('complete', complete);\n            tx.removeEventListener('error', error);\n            tx.removeEventListener('abort', error);\n        };\n        const complete = () => {\n            resolve();\n            unlisten();\n        };\n        const error = () => {\n            reject(tx.error || new DOMException('AbortError', 'AbortError'));\n            unlisten();\n        };\n        tx.addEventListener('complete', complete);\n        tx.addEventListener('error', error);\n        tx.addEventListener('abort', error);\n    });\n    // Cache it for later retrieval.\n    transactionDoneMap.set(tx, done);\n}\nlet idbProxyTraps = {\n    get(target, prop, receiver) {\n        if (target instanceof IDBTransaction) {\n            // Special handling for transaction.done.\n            if (prop === 'done')\n                return transactionDoneMap.get(target);\n            // Polyfill for objectStoreNames because of Edge.\n            if (prop === 'objectStoreNames') {\n                return target.objectStoreNames || transactionStoreNamesMap.get(target);\n            }\n            // Make tx.store return the only store in the transaction, or undefined if there are many.\n            if (prop === 'store') {\n                return receiver.objectStoreNames[1]\n                    ? undefined\n                    : receiver.objectStore(receiver.objectStoreNames[0]);\n            }\n        }\n        // Else transform whatever we get back.\n        return wrap(target[prop]);\n    },\n    set(target, prop, value) {\n        target[prop] = value;\n        return true;\n    },\n    has(target, prop) {\n        if (target instanceof IDBTransaction &&\n            (prop === 'done' || prop === 'store')) {\n            return true;\n        }\n        return prop in target;\n    },\n};\nfunction replaceTraps(callback) {\n    idbProxyTraps = callback(idbProxyTraps);\n}\nfunction wrapFunction(func) {\n    // Due to expected object equality (which is enforced by the caching in `wrap`), we\n    // only create one new func per func.\n    // Edge doesn't support objectStoreNames (booo), so we polyfill it here.\n    if (func === IDBDatabase.prototype.transaction &&\n        !('objectStoreNames' in IDBTransaction.prototype)) {\n        return function (storeNames, ...args) {\n            const tx = func.call(unwrap(this), storeNames, ...args);\n            transactionStoreNamesMap.set(tx, storeNames.sort ? storeNames.sort() : [storeNames]);\n            return wrap(tx);\n        };\n    }\n    // Cursor methods are special, as the behaviour is a little more different to standard IDB. In\n    // IDB, you advance the cursor and wait for a new 'success' on the IDBRequest that gave you the\n    // cursor. It's kinda like a promise that can resolve with many values. That doesn't make sense\n    // with real promises, so each advance methods returns a new promise for the cursor object, or\n    // undefined if the end of the cursor has been reached.\n    if (getCursorAdvanceMethods().includes(func)) {\n        return function (...args) {\n            // Calling the original function with the proxy as 'this' causes ILLEGAL INVOCATION, so we use\n            // the original object.\n            func.apply(unwrap(this), args);\n            return wrap(cursorRequestMap.get(this));\n        };\n    }\n    return function (...args) {\n        // Calling the original function with the proxy as 'this' causes ILLEGAL INVOCATION, so we use\n        // the original object.\n        return wrap(func.apply(unwrap(this), args));\n    };\n}\nfunction transformCachableValue(value) {\n    if (typeof value === 'function')\n        return wrapFunction(value);\n    // This doesn't return, it just creates a 'done' promise for the transaction,\n    // which is later returned for transaction.done (see idbObjectHandler).\n    if (value instanceof IDBTransaction)\n        cacheDonePromiseForTransaction(value);\n    if (instanceOfAny(value, getIdbProxyableTypes()))\n        return new Proxy(value, idbProxyTraps);\n    // Return the same value back if we're not going to transform it.\n    return value;\n}\nfunction wrap(value) {\n    // We sometimes generate multiple promises from a single IDBRequest (eg when cursoring), because\n    // IDB is weird and a single IDBRequest can yield many responses, so these can't be cached.\n    if (value instanceof IDBRequest)\n        return promisifyRequest(value);\n    // If we've already transformed this value before, reuse the transformed value.\n    // This is faster, but it also provides object equality.\n    if (transformCache.has(value))\n        return transformCache.get(value);\n    const newValue = transformCachableValue(value);\n    // Not all types are transformed.\n    // These may be primitive types, so they can't be WeakMap keys.\n    if (newValue !== value) {\n        transformCache.set(value, newValue);\n        reverseTransformCache.set(newValue, value);\n    }\n    return newValue;\n}\nconst unwrap = (value) => reverseTransformCache.get(value);\n\nexport { reverseTransformCache as a, instanceOfAny as i, replaceTraps as r, unwrap as u, wrap as w };\n","function n(n){for(var t=arguments.length,r=Array(t>1?t-1:0),e=1;e<t;e++)r[e-1]=arguments[e];if(\"production\"!==process.env.NODE_ENV){var i=Y[n],o=i?\"function\"==typeof i?i.apply(null,r):i:\"unknown error nr: \"+n;throw Error(\"[Immer] \"+o)}throw Error(\"[Immer] minified error nr: \"+n+(r.length?\" \"+r.map((function(n){return\"'\"+n+\"'\"})).join(\",\"):\"\")+\". Find the full error at: https://bit.ly/3cXEKWf\")}function t(n){return!!n&&!!n[Q]}function r(n){return!!n&&(function(n){if(!n||\"object\"!=typeof n)return!1;var t=Object.getPrototypeOf(n);if(null===t)return!0;var r=Object.hasOwnProperty.call(t,\"constructor\")&&t.constructor;return r===Object||\"function\"==typeof r&&Function.toString.call(r)===Z}(n)||Array.isArray(n)||!!n[L]||!!n.constructor[L]||s(n)||v(n))}function e(r){return t(r)||n(23,r),r[Q].t}function i(n,t,r){void 0===r&&(r=!1),0===o(n)?(r?Object.keys:nn)(n).forEach((function(e){r&&\"symbol\"==typeof e||t(e,n[e],n)})):n.forEach((function(r,e){return t(e,r,n)}))}function o(n){var t=n[Q];return t?t.i>3?t.i-4:t.i:Array.isArray(n)?1:s(n)?2:v(n)?3:0}function u(n,t){return 2===o(n)?n.has(t):Object.prototype.hasOwnProperty.call(n,t)}function a(n,t){return 2===o(n)?n.get(t):n[t]}function f(n,t,r){var e=o(n);2===e?n.set(t,r):3===e?(n.delete(t),n.add(r)):n[t]=r}function c(n,t){return n===t?0!==n||1/n==1/t:n!=n&&t!=t}function s(n){return X&&n instanceof Map}function v(n){return q&&n instanceof Set}function p(n){return n.o||n.t}function l(n){if(Array.isArray(n))return Array.prototype.slice.call(n);var t=tn(n);delete t[Q];for(var r=nn(t),e=0;e<r.length;e++){var i=r[e],o=t[i];!1===o.writable&&(o.writable=!0,o.configurable=!0),(o.get||o.set)&&(t[i]={configurable:!0,writable:!0,enumerable:o.enumerable,value:n[i]})}return Object.create(Object.getPrototypeOf(n),t)}function d(n,e){return void 0===e&&(e=!1),y(n)||t(n)||!r(n)?n:(o(n)>1&&(n.set=n.add=n.clear=n.delete=h),Object.freeze(n),e&&i(n,(function(n,t){return d(t,!0)}),!0),n)}function h(){n(2)}function y(n){return null==n||\"object\"!=typeof n||Object.isFrozen(n)}function b(t){var r=rn[t];return r||n(18,t),r}function m(n,t){rn[n]||(rn[n]=t)}function _(){return\"production\"===process.env.NODE_ENV||U||n(0),U}function j(n,t){t&&(b(\"Patches\"),n.u=[],n.s=[],n.v=t)}function O(n){g(n),n.p.forEach(S),n.p=null}function g(n){n===U&&(U=n.l)}function w(n){return U={p:[],l:U,h:n,m:!0,_:0}}function S(n){var t=n[Q];0===t.i||1===t.i?t.j():t.O=!0}function P(t,e){e._=e.p.length;var i=e.p[0],o=void 0!==t&&t!==i;return e.h.g||b(\"ES5\").S(e,t,o),o?(i[Q].P&&(O(e),n(4)),r(t)&&(t=M(e,t),e.l||x(e,t)),e.u&&b(\"Patches\").M(i[Q],t,e.u,e.s)):t=M(e,i,[]),O(e),e.u&&e.v(e.u,e.s),t!==H?t:void 0}function M(n,t,r){if(y(t))return t;var e=t[Q];if(!e)return i(t,(function(i,o){return A(n,e,t,i,o,r)}),!0),t;if(e.A!==n)return t;if(!e.P)return x(n,e.t,!0),e.t;if(!e.I){e.I=!0,e.A._--;var o=4===e.i||5===e.i?e.o=l(e.k):e.o;i(3===e.i?new Set(o):o,(function(t,i){return A(n,e,o,t,i,r)})),x(n,o,!1),r&&n.u&&b(\"Patches\").R(e,r,n.u,n.s)}return e.o}function A(e,i,o,a,c,s){if(\"production\"!==process.env.NODE_ENV&&c===o&&n(5),t(c)){var v=M(e,c,s&&i&&3!==i.i&&!u(i.D,a)?s.concat(a):void 0);if(f(o,a,v),!t(v))return;e.m=!1}if(r(c)&&!y(c)){if(!e.h.F&&e._<1)return;M(e,c),i&&i.A.l||x(e,c)}}function x(n,t,r){void 0===r&&(r=!1),n.h.F&&n.m&&d(t,r)}function z(n,t){var r=n[Q];return(r?p(r):n)[t]}function I(n,t){if(t in n)for(var r=Object.getPrototypeOf(n);r;){var e=Object.getOwnPropertyDescriptor(r,t);if(e)return e;r=Object.getPrototypeOf(r)}}function k(n){n.P||(n.P=!0,n.l&&k(n.l))}function E(n){n.o||(n.o=l(n.t))}function R(n,t,r){var e=s(t)?b(\"MapSet\").N(t,r):v(t)?b(\"MapSet\").T(t,r):n.g?function(n,t){var r=Array.isArray(n),e={i:r?1:0,A:t?t.A:_(),P:!1,I:!1,D:{},l:t,t:n,k:null,o:null,j:null,C:!1},i=e,o=en;r&&(i=[e],o=on);var u=Proxy.revocable(i,o),a=u.revoke,f=u.proxy;return e.k=f,e.j=a,f}(t,r):b(\"ES5\").J(t,r);return(r?r.A:_()).p.push(e),e}function D(e){return t(e)||n(22,e),function n(t){if(!r(t))return t;var e,u=t[Q],c=o(t);if(u){if(!u.P&&(u.i<4||!b(\"ES5\").K(u)))return u.t;u.I=!0,e=F(t,c),u.I=!1}else e=F(t,c);return i(e,(function(t,r){u&&a(u.t,t)===r||f(e,t,n(r))})),3===c?new Set(e):e}(e)}function F(n,t){switch(t){case 2:return new Map(n);case 3:return Array.from(n)}return l(n)}function N(){function r(n,t){var r=s[n];return r?r.enumerable=t:s[n]=r={configurable:!0,enumerable:t,get:function(){var t=this[Q];return\"production\"!==process.env.NODE_ENV&&f(t),en.get(t,n)},set:function(t){var r=this[Q];\"production\"!==process.env.NODE_ENV&&f(r),en.set(r,n,t)}},r}function e(n){for(var t=n.length-1;t>=0;t--){var r=n[t][Q];if(!r.P)switch(r.i){case 5:a(r)&&k(r);break;case 4:o(r)&&k(r)}}}function o(n){for(var t=n.t,r=n.k,e=nn(r),i=e.length-1;i>=0;i--){var o=e[i];if(o!==Q){var a=t[o];if(void 0===a&&!u(t,o))return!0;var f=r[o],s=f&&f[Q];if(s?s.t!==a:!c(f,a))return!0}}var v=!!t[Q];return e.length!==nn(t).length+(v?0:1)}function a(n){var t=n.k;if(t.length!==n.t.length)return!0;var r=Object.getOwnPropertyDescriptor(t,t.length-1);return!(!r||r.get)}function f(t){t.O&&n(3,JSON.stringify(p(t)))}var s={};m(\"ES5\",{J:function(n,t){var e=Array.isArray(n),i=function(n,t){if(n){for(var e=Array(t.length),i=0;i<t.length;i++)Object.defineProperty(e,\"\"+i,r(i,!0));return e}var o=tn(t);delete o[Q];for(var u=nn(o),a=0;a<u.length;a++){var f=u[a];o[f]=r(f,n||!!o[f].enumerable)}return Object.create(Object.getPrototypeOf(t),o)}(e,n),o={i:e?5:4,A:t?t.A:_(),P:!1,I:!1,D:{},l:t,t:n,k:i,o:null,O:!1,C:!1};return Object.defineProperty(i,Q,{value:o,writable:!0}),i},S:function(n,r,o){o?t(r)&&r[Q].A===n&&e(n.p):(n.u&&function n(t){if(t&&\"object\"==typeof t){var r=t[Q];if(r){var e=r.t,o=r.k,f=r.D,c=r.i;if(4===c)i(o,(function(t){t!==Q&&(void 0!==e[t]||u(e,t)?f[t]||n(o[t]):(f[t]=!0,k(r)))})),i(e,(function(n){void 0!==o[n]||u(o,n)||(f[n]=!1,k(r))}));else if(5===c){if(a(r)&&(k(r),f.length=!0),o.length<e.length)for(var s=o.length;s<e.length;s++)f[s]=!1;else for(var v=e.length;v<o.length;v++)f[v]=!0;for(var p=Math.min(o.length,e.length),l=0;l<p;l++)void 0===f[l]&&n(o[l])}}}}(n.p[0]),e(n.p))},K:function(n){return 4===n.i?o(n):a(n)}})}function T(){function e(n){if(!r(n))return n;if(Array.isArray(n))return n.map(e);if(s(n))return new Map(Array.from(n.entries()).map((function(n){return[n[0],e(n[1])]})));if(v(n))return new Set(Array.from(n).map(e));var t=Object.create(Object.getPrototypeOf(n));for(var i in n)t[i]=e(n[i]);return u(n,L)&&(t[L]=n[L]),t}function f(n){return t(n)?e(n):n}var c=\"add\";m(\"Patches\",{$:function(t,r){return r.forEach((function(r){for(var i=r.path,u=r.op,f=t,s=0;s<i.length-1;s++){var v=o(f),p=\"\"+i[s];0!==v&&1!==v||\"__proto__\"!==p&&\"constructor\"!==p||n(24),\"function\"==typeof f&&\"prototype\"===p&&n(24),\"object\"!=typeof(f=a(f,p))&&n(15,i.join(\"/\"))}var l=o(f),d=e(r.value),h=i[i.length-1];switch(u){case\"replace\":switch(l){case 2:return f.set(h,d);case 3:n(16);default:return f[h]=d}case c:switch(l){case 1:return f.splice(h,0,d);case 2:return f.set(h,d);case 3:return f.add(d);default:return f[h]=d}case\"remove\":switch(l){case 1:return f.splice(h,1);case 2:return f.delete(h);case 3:return f.delete(r.value);default:return delete f[h]}default:n(17,u)}})),t},R:function(n,t,r,e){switch(n.i){case 0:case 4:case 2:return function(n,t,r,e){var o=n.t,s=n.o;i(n.D,(function(n,i){var v=a(o,n),p=a(s,n),l=i?u(o,n)?\"replace\":c:\"remove\";if(v!==p||\"replace\"!==l){var d=t.concat(n);r.push(\"remove\"===l?{op:l,path:d}:{op:l,path:d,value:p}),e.push(l===c?{op:\"remove\",path:d}:\"remove\"===l?{op:c,path:d,value:f(v)}:{op:\"replace\",path:d,value:f(v)})}}))}(n,t,r,e);case 5:case 1:return function(n,t,r,e){var i=n.t,o=n.D,u=n.o;if(u.length<i.length){var a=[u,i];i=a[0],u=a[1];var s=[e,r];r=s[0],e=s[1]}for(var v=0;v<i.length;v++)if(o[v]&&u[v]!==i[v]){var p=t.concat([v]);r.push({op:\"replace\",path:p,value:f(u[v])}),e.push({op:\"replace\",path:p,value:f(i[v])})}for(var l=i.length;l<u.length;l++){var d=t.concat([l]);r.push({op:c,path:d,value:f(u[l])})}i.length<u.length&&e.push({op:\"replace\",path:t.concat([\"length\"]),value:i.length})}(n,t,r,e);case 3:return function(n,t,r,e){var i=n.t,o=n.o,u=0;i.forEach((function(n){if(!o.has(n)){var i=t.concat([u]);r.push({op:\"remove\",path:i,value:n}),e.unshift({op:c,path:i,value:n})}u++})),u=0,o.forEach((function(n){if(!i.has(n)){var o=t.concat([u]);r.push({op:c,path:o,value:n}),e.unshift({op:\"remove\",path:o,value:n})}u++}))}(n,t,r,e)}},M:function(n,t,r,e){r.push({op:\"replace\",path:[],value:t===H?void 0:t}),e.push({op:\"replace\",path:[],value:n.t})}})}function C(){function t(n,t){function r(){this.constructor=n}a(n,t),n.prototype=(r.prototype=t.prototype,new r)}function e(n){n.o||(n.D=new Map,n.o=new Map(n.t))}function o(n){n.o||(n.o=new Set,n.t.forEach((function(t){if(r(t)){var e=R(n.A.h,t,n);n.p.set(t,e),n.o.add(e)}else n.o.add(t)})))}function u(t){t.O&&n(3,JSON.stringify(p(t)))}var a=function(n,t){return(a=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(n,t){n.__proto__=t}||function(n,t){for(var r in t)t.hasOwnProperty(r)&&(n[r]=t[r])})(n,t)},f=function(){function n(n,t){return this[Q]={i:2,l:t,A:t?t.A:_(),P:!1,I:!1,o:void 0,D:void 0,t:n,k:this,C:!1,O:!1},this}t(n,Map);var o=n.prototype;return Object.defineProperty(o,\"size\",{get:function(){return p(this[Q]).size}}),o.has=function(n){return p(this[Q]).has(n)},o.set=function(n,t){var r=this[Q];return u(r),p(r).has(n)&&p(r).get(n)===t||(e(r),k(r),r.D.set(n,!0),r.o.set(n,t),r.D.set(n,!0)),this},o.delete=function(n){if(!this.has(n))return!1;var t=this[Q];return u(t),e(t),k(t),t.D.set(n,!1),t.o.delete(n),!0},o.clear=function(){var n=this[Q];u(n),p(n).size&&(e(n),k(n),n.D=new Map,i(n.t,(function(t){n.D.set(t,!1)})),n.o.clear())},o.forEach=function(n,t){var r=this;p(this[Q]).forEach((function(e,i){n.call(t,r.get(i),i,r)}))},o.get=function(n){var t=this[Q];u(t);var i=p(t).get(n);if(t.I||!r(i))return i;if(i!==t.t.get(n))return i;var o=R(t.A.h,i,t);return e(t),t.o.set(n,o),o},o.keys=function(){return p(this[Q]).keys()},o.values=function(){var n,t=this,r=this.keys();return(n={})[V]=function(){return t.values()},n.next=function(){var n=r.next();return n.done?n:{done:!1,value:t.get(n.value)}},n},o.entries=function(){var n,t=this,r=this.keys();return(n={})[V]=function(){return t.entries()},n.next=function(){var n=r.next();if(n.done)return n;var e=t.get(n.value);return{done:!1,value:[n.value,e]}},n},o[V]=function(){return this.entries()},n}(),c=function(){function n(n,t){return this[Q]={i:3,l:t,A:t?t.A:_(),P:!1,I:!1,o:void 0,t:n,k:this,p:new Map,O:!1,C:!1},this}t(n,Set);var r=n.prototype;return Object.defineProperty(r,\"size\",{get:function(){return p(this[Q]).size}}),r.has=function(n){var t=this[Q];return u(t),t.o?!!t.o.has(n)||!(!t.p.has(n)||!t.o.has(t.p.get(n))):t.t.has(n)},r.add=function(n){var t=this[Q];return u(t),this.has(n)||(o(t),k(t),t.o.add(n)),this},r.delete=function(n){if(!this.has(n))return!1;var t=this[Q];return u(t),o(t),k(t),t.o.delete(n)||!!t.p.has(n)&&t.o.delete(t.p.get(n))},r.clear=function(){var n=this[Q];u(n),p(n).size&&(o(n),k(n),n.o.clear())},r.values=function(){var n=this[Q];return u(n),o(n),n.o.values()},r.entries=function(){var n=this[Q];return u(n),o(n),n.o.entries()},r.keys=function(){return this.values()},r[V]=function(){return this.values()},r.forEach=function(n,t){for(var r=this.values(),e=r.next();!e.done;)n.call(t,e.value,e.value,this),e=r.next()},n}();m(\"MapSet\",{N:function(n,t){return new f(n,t)},T:function(n,t){return new c(n,t)}})}function J(){N(),C(),T()}function K(n){return n}function $(n){return n}var G,U,W=\"undefined\"!=typeof Symbol&&\"symbol\"==typeof Symbol(\"x\"),X=\"undefined\"!=typeof Map,q=\"undefined\"!=typeof Set,B=\"undefined\"!=typeof Proxy&&void 0!==Proxy.revocable&&\"undefined\"!=typeof Reflect,H=W?Symbol.for(\"immer-nothing\"):((G={})[\"immer-nothing\"]=!0,G),L=W?Symbol.for(\"immer-draftable\"):\"__$immer_draftable\",Q=W?Symbol.for(\"immer-state\"):\"__$immer_state\",V=\"undefined\"!=typeof Symbol&&Symbol.iterator||\"@@iterator\",Y={0:\"Illegal state\",1:\"Immer drafts cannot have computed properties\",2:\"This object has been frozen and should not be mutated\",3:function(n){return\"Cannot use a proxy that has been revoked. Did you pass an object from inside an immer function to an async process? \"+n},4:\"An immer producer returned a new value *and* modified its draft. Either return a new value *or* modify the draft.\",5:\"Immer forbids circular references\",6:\"The first or second argument to `produce` must be a function\",7:\"The third argument to `produce` must be a function or undefined\",8:\"First argument to `createDraft` must be a plain object, an array, or an immerable object\",9:\"First argument to `finishDraft` must be a draft returned by `createDraft`\",10:\"The given draft is already finalized\",11:\"Object.defineProperty() cannot be used on an Immer draft\",12:\"Object.setPrototypeOf() cannot be used on an Immer draft\",13:\"Immer only supports deleting array indices\",14:\"Immer only supports setting array indices and the 'length' property\",15:function(n){return\"Cannot apply patch, path doesn't resolve: \"+n},16:'Sets cannot have \"replace\" patches.',17:function(n){return\"Unsupported patch operation: \"+n},18:function(n){return\"The plugin for '\"+n+\"' has not been loaded into Immer. To enable the plugin, import and call `enable\"+n+\"()` when initializing your application.\"},20:\"Cannot use proxies if Proxy, Proxy.revocable or Reflect are not available\",21:function(n){return\"produce can only be called on things that are draftable: plain objects, arrays, Map, Set or classes that are marked with '[immerable]: true'. Got '\"+n+\"'\"},22:function(n){return\"'current' expects a draft, got: \"+n},23:function(n){return\"'original' expects a draft, got: \"+n},24:\"Patching reserved attributes like __proto__, prototype and constructor is not allowed\"},Z=\"\"+Object.prototype.constructor,nn=\"undefined\"!=typeof Reflect&&Reflect.ownKeys?Reflect.ownKeys:void 0!==Object.getOwnPropertySymbols?function(n){return Object.getOwnPropertyNames(n).concat(Object.getOwnPropertySymbols(n))}:Object.getOwnPropertyNames,tn=Object.getOwnPropertyDescriptors||function(n){var t={};return nn(n).forEach((function(r){t[r]=Object.getOwnPropertyDescriptor(n,r)})),t},rn={},en={get:function(n,t){if(t===Q)return n;var e=p(n);if(!u(e,t))return function(n,t,r){var e,i=I(t,r);return i?\"value\"in i?i.value:null===(e=i.get)||void 0===e?void 0:e.call(n.k):void 0}(n,e,t);var i=e[t];return n.I||!r(i)?i:i===z(n.t,t)?(E(n),n.o[t]=R(n.A.h,i,n)):i},has:function(n,t){return t in p(n)},ownKeys:function(n){return Reflect.ownKeys(p(n))},set:function(n,t,r){var e=I(p(n),t);if(null==e?void 0:e.set)return e.set.call(n.k,r),!0;if(!n.P){var i=z(p(n),t),o=null==i?void 0:i[Q];if(o&&o.t===r)return n.o[t]=r,n.D[t]=!1,!0;if(c(r,i)&&(void 0!==r||u(n.t,t)))return!0;E(n),k(n)}return n.o[t]===r&&\"number\"!=typeof r&&(void 0!==r||t in n.o)||(n.o[t]=r,n.D[t]=!0,!0)},deleteProperty:function(n,t){return void 0!==z(n.t,t)||t in n.t?(n.D[t]=!1,E(n),k(n)):delete n.D[t],n.o&&delete n.o[t],!0},getOwnPropertyDescriptor:function(n,t){var r=p(n),e=Reflect.getOwnPropertyDescriptor(r,t);return e?{writable:!0,configurable:1!==n.i||\"length\"!==t,enumerable:e.enumerable,value:r[t]}:e},defineProperty:function(){n(11)},getPrototypeOf:function(n){return Object.getPrototypeOf(n.t)},setPrototypeOf:function(){n(12)}},on={};i(en,(function(n,t){on[n]=function(){return arguments[0]=arguments[0][0],t.apply(this,arguments)}})),on.deleteProperty=function(t,r){return\"production\"!==process.env.NODE_ENV&&isNaN(parseInt(r))&&n(13),en.deleteProperty.call(this,t[0],r)},on.set=function(t,r,e){return\"production\"!==process.env.NODE_ENV&&\"length\"!==r&&isNaN(parseInt(r))&&n(14),en.set.call(this,t[0],r,e,t[0])};var un=function(){function e(t){var e=this;this.g=B,this.F=!0,this.produce=function(t,i,o){if(\"function\"==typeof t&&\"function\"!=typeof i){var u=i;i=t;var a=e;return function(n){var t=this;void 0===n&&(n=u);for(var r=arguments.length,e=Array(r>1?r-1:0),o=1;o<r;o++)e[o-1]=arguments[o];return a.produce(n,(function(n){var r;return(r=i).call.apply(r,[t,n].concat(e))}))}}var f;if(\"function\"!=typeof i&&n(6),void 0!==o&&\"function\"!=typeof o&&n(7),r(t)){var c=w(e),s=R(e,t,void 0),v=!0;try{f=i(s),v=!1}finally{v?O(c):g(c)}return\"undefined\"!=typeof Promise&&f instanceof Promise?f.then((function(n){return j(c,o),P(n,c)}),(function(n){throw O(c),n})):(j(c,o),P(f,c))}if(!t||\"object\"!=typeof t){if((f=i(t))===H)return;return void 0===f&&(f=t),e.F&&d(f,!0),f}n(21,t)},this.produceWithPatches=function(n,t){return\"function\"==typeof n?function(t){for(var r=arguments.length,i=Array(r>1?r-1:0),o=1;o<r;o++)i[o-1]=arguments[o];return e.produceWithPatches(t,(function(t){return n.apply(void 0,[t].concat(i))}))}:[e.produce(n,t,(function(n,t){r=n,i=t})),r,i];var r,i},\"boolean\"==typeof(null==t?void 0:t.useProxies)&&this.setUseProxies(t.useProxies),\"boolean\"==typeof(null==t?void 0:t.autoFreeze)&&this.setAutoFreeze(t.autoFreeze)}var i=e.prototype;return i.createDraft=function(e){r(e)||n(8),t(e)&&(e=D(e));var i=w(this),o=R(this,e,void 0);return o[Q].C=!0,g(i),o},i.finishDraft=function(t,r){var e=t&&t[Q];\"production\"!==process.env.NODE_ENV&&(e&&e.C||n(9),e.I&&n(10));var i=e.A;return j(i,r),P(void 0,i)},i.setAutoFreeze=function(n){this.F=n},i.setUseProxies=function(t){t&&!B&&n(20),this.g=t},i.applyPatches=function(n,r){var e;for(e=r.length-1;e>=0;e--){var i=r[e];if(0===i.path.length&&\"replace\"===i.op){n=i.value;break}}var o=b(\"Patches\").$;return t(n)?o(n,r):this.produce(n,(function(n){return o(n,r.slice(e+1))}))},e}(),an=new un,fn=an.produce,cn=an.produceWithPatches.bind(an),sn=an.setAutoFreeze.bind(an),vn=an.setUseProxies.bind(an),pn=an.applyPatches.bind(an),ln=an.createDraft.bind(an),dn=an.finishDraft.bind(an);export default fn;export{un as Immer,pn as applyPatches,K as castDraft,$ as castImmutable,ln as createDraft,D as current,J as enableAllPlugins,N as enableES5,C as enableMapSet,T as enablePatches,dn as finishDraft,d as freeze,L as immerable,t as isDraft,r as isDraftable,H as nothing,e as original,fn as produce,cn as produceWithPatches,sn as setAutoFreeze,vn as setUseProxies};\n//# sourceMappingURL=immer.esm.js.map\n","export var COMPLETE_NOTIFICATION = (function () { return createNotification('C', undefined, undefined); })();\nexport function errorNotification(error) {\n    return createNotification('E', undefined, error);\n}\nexport function nextNotification(value) {\n    return createNotification('N', value, undefined);\n}\nexport function createNotification(kind, value, error) {\n    return {\n        kind: kind,\n        value: value,\n        error: error,\n    };\n}\n//# sourceMappingURL=NotificationFactories.js.map","import { SafeSubscriber, Subscriber } from './Subscriber';\nimport { isSubscription } from './Subscription';\nimport { observable as Symbol_observable } from './symbol/observable';\nimport { pipeFromArray } from './util/pipe';\nimport { config } from './config';\nimport { isFunction } from './util/isFunction';\nimport { errorContext } from './util/errorContext';\nvar Observable = (function () {\n    function Observable(subscribe) {\n        if (subscribe) {\n            this._subscribe = subscribe;\n        }\n    }\n    Observable.prototype.lift = function (operator) {\n        var observable = new Observable();\n        observable.source = this;\n        observable.operator = operator;\n        return observable;\n    };\n    Observable.prototype.subscribe = function (observerOrNext, error, complete) {\n        var _this = this;\n        var subscriber = isSubscriber(observerOrNext) ? observerOrNext : new SafeSubscriber(observerOrNext, error, complete);\n        errorContext(function () {\n            var _a = _this, operator = _a.operator, source = _a.source;\n            subscriber.add(operator\n                ?\n                    operator.call(subscriber, source)\n                : source\n                    ?\n                        _this._subscribe(subscriber)\n                    :\n                        _this._trySubscribe(subscriber));\n        });\n        return subscriber;\n    };\n    Observable.prototype._trySubscribe = function (sink) {\n        try {\n            return this._subscribe(sink);\n        }\n        catch (err) {\n            sink.error(err);\n        }\n    };\n    Observable.prototype.forEach = function (next, promiseCtor) {\n        var _this = this;\n        promiseCtor = getPromiseCtor(promiseCtor);\n        return new promiseCtor(function (resolve, reject) {\n            var subscriber = new SafeSubscriber({\n                next: function (value) {\n                    try {\n                        next(value);\n                    }\n                    catch (err) {\n                        reject(err);\n                        subscriber.unsubscribe();\n                    }\n                },\n                error: reject,\n                complete: resolve,\n            });\n            _this.subscribe(subscriber);\n        });\n    };\n    Observable.prototype._subscribe = function (subscriber) {\n        var _a;\n        return (_a = this.source) === null || _a === void 0 ? void 0 : _a.subscribe(subscriber);\n    };\n    Observable.prototype[Symbol_observable] = function () {\n        return this;\n    };\n    Observable.prototype.pipe = function () {\n        var operations = [];\n        for (var _i = 0; _i < arguments.length; _i++) {\n            operations[_i] = arguments[_i];\n        }\n        return pipeFromArray(operations)(this);\n    };\n    Observable.prototype.toPromise = function (promiseCtor) {\n        var _this = this;\n        promiseCtor = getPromiseCtor(promiseCtor);\n        return new promiseCtor(function (resolve, reject) {\n            var value;\n            _this.subscribe(function (x) { return (value = x); }, function (err) { return reject(err); }, function () { return resolve(value); });\n        });\n    };\n    Observable.create = function (subscribe) {\n        return new Observable(subscribe);\n    };\n    return Observable;\n}());\nexport { Observable };\nfunction getPromiseCtor(promiseCtor) {\n    var _a;\n    return (_a = promiseCtor !== null && promiseCtor !== void 0 ? promiseCtor : config.Promise) !== null && _a !== void 0 ? _a : Promise;\n}\nfunction isObserver(value) {\n    return value && isFunction(value.next) && isFunction(value.error) && isFunction(value.complete);\n}\nfunction isSubscriber(value) {\n    return (value && value instanceof Subscriber) || (isObserver(value) && isSubscription(value));\n}\n//# sourceMappingURL=Observable.js.map","import { __extends, __values } from \"tslib\";\nimport { Observable } from './Observable';\nimport { Subscription, EMPTY_SUBSCRIPTION } from './Subscription';\nimport { ObjectUnsubscribedError } from './util/ObjectUnsubscribedError';\nimport { arrRemove } from './util/arrRemove';\nimport { errorContext } from './util/errorContext';\nvar Subject = (function (_super) {\n    __extends(Subject, _super);\n    function Subject() {\n        var _this = _super.call(this) || this;\n        _this.closed = false;\n        _this.currentObservers = null;\n        _this.observers = [];\n        _this.isStopped = false;\n        _this.hasError = false;\n        _this.thrownError = null;\n        return _this;\n    }\n    Subject.prototype.lift = function (operator) {\n        var subject = new AnonymousSubject(this, this);\n        subject.operator = operator;\n        return subject;\n    };\n    Subject.prototype._throwIfClosed = function () {\n        if (this.closed) {\n            throw new ObjectUnsubscribedError();\n        }\n    };\n    Subject.prototype.next = function (value) {\n        var _this = this;\n        errorContext(function () {\n            var e_1, _a;\n            _this._throwIfClosed();\n            if (!_this.isStopped) {\n                if (!_this.currentObservers) {\n                    _this.currentObservers = Array.from(_this.observers);\n                }\n                try {\n                    for (var _b = __values(_this.currentObservers), _c = _b.next(); !_c.done; _c = _b.next()) {\n                        var observer = _c.value;\n                        observer.next(value);\n                    }\n                }\n                catch (e_1_1) { e_1 = { error: e_1_1 }; }\n                finally {\n                    try {\n                        if (_c && !_c.done && (_a = _b.return)) _a.call(_b);\n                    }\n                    finally { if (e_1) throw e_1.error; }\n                }\n            }\n        });\n    };\n    Subject.prototype.error = function (err) {\n        var _this = this;\n        errorContext(function () {\n            _this._throwIfClosed();\n            if (!_this.isStopped) {\n                _this.hasError = _this.isStopped = true;\n                _this.thrownError = err;\n                var observers = _this.observers;\n                while (observers.length) {\n                    observers.shift().error(err);\n                }\n            }\n        });\n    };\n    Subject.prototype.complete = function () {\n        var _this = this;\n        errorContext(function () {\n            _this._throwIfClosed();\n            if (!_this.isStopped) {\n                _this.isStopped = true;\n                var observers = _this.observers;\n                while (observers.length) {\n                    observers.shift().complete();\n                }\n            }\n        });\n    };\n    Subject.prototype.unsubscribe = function () {\n        this.isStopped = this.closed = true;\n        this.observers = this.currentObservers = null;\n    };\n    Object.defineProperty(Subject.prototype, \"observed\", {\n        get: function () {\n            var _a;\n            return ((_a = this.observers) === null || _a === void 0 ? void 0 : _a.length) > 0;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    Subject.prototype._trySubscribe = function (subscriber) {\n        this._throwIfClosed();\n        return _super.prototype._trySubscribe.call(this, subscriber);\n    };\n    Subject.prototype._subscribe = function (subscriber) {\n        this._throwIfClosed();\n        this._checkFinalizedStatuses(subscriber);\n        return this._innerSubscribe(subscriber);\n    };\n    Subject.prototype._innerSubscribe = function (subscriber) {\n        var _this = this;\n        var _a = this, hasError = _a.hasError, isStopped = _a.isStopped, observers = _a.observers;\n        if (hasError || isStopped) {\n            return EMPTY_SUBSCRIPTION;\n        }\n        this.currentObservers = null;\n        observers.push(subscriber);\n        return new Subscription(function () {\n            _this.currentObservers = null;\n            arrRemove(observers, subscriber);\n        });\n    };\n    Subject.prototype._checkFinalizedStatuses = function (subscriber) {\n        var _a = this, hasError = _a.hasError, thrownError = _a.thrownError, isStopped = _a.isStopped;\n        if (hasError) {\n            subscriber.error(thrownError);\n        }\n        else if (isStopped) {\n            subscriber.complete();\n        }\n    };\n    Subject.prototype.asObservable = function () {\n        var observable = new Observable();\n        observable.source = this;\n        return observable;\n    };\n    Subject.create = function (destination, source) {\n        return new AnonymousSubject(destination, source);\n    };\n    return Subject;\n}(Observable));\nexport { Subject };\nvar AnonymousSubject = (function (_super) {\n    __extends(AnonymousSubject, _super);\n    function AnonymousSubject(destination, source) {\n        var _this = _super.call(this) || this;\n        _this.destination = destination;\n        _this.source = source;\n        return _this;\n    }\n    AnonymousSubject.prototype.next = function (value) {\n        var _a, _b;\n        (_b = (_a = this.destination) === null || _a === void 0 ? void 0 : _a.next) === null || _b === void 0 ? void 0 : _b.call(_a, value);\n    };\n    AnonymousSubject.prototype.error = function (err) {\n        var _a, _b;\n        (_b = (_a = this.destination) === null || _a === void 0 ? void 0 : _a.error) === null || _b === void 0 ? void 0 : _b.call(_a, err);\n    };\n    AnonymousSubject.prototype.complete = function () {\n        var _a, _b;\n        (_b = (_a = this.destination) === null || _a === void 0 ? void 0 : _a.complete) === null || _b === void 0 ? void 0 : _b.call(_a);\n    };\n    AnonymousSubject.prototype._subscribe = function (subscriber) {\n        var _a, _b;\n        return (_b = (_a = this.source) === null || _a === void 0 ? void 0 : _a.subscribe(subscriber)) !== null && _b !== void 0 ? _b : EMPTY_SUBSCRIPTION;\n    };\n    return AnonymousSubject;\n}(Subject));\nexport { AnonymousSubject };\n//# sourceMappingURL=Subject.js.map","import { __extends } from \"tslib\";\nimport { isFunction } from './util/isFunction';\nimport { isSubscription, Subscription } from './Subscription';\nimport { config } from './config';\nimport { reportUnhandledError } from './util/reportUnhandledError';\nimport { noop } from './util/noop';\nimport { nextNotification, errorNotification, COMPLETE_NOTIFICATION } from './NotificationFactories';\nimport { timeoutProvider } from './scheduler/timeoutProvider';\nimport { captureError } from './util/errorContext';\nvar Subscriber = (function (_super) {\n    __extends(Subscriber, _super);\n    function Subscriber(destination) {\n        var _this = _super.call(this) || this;\n        _this.isStopped = false;\n        if (destination) {\n            _this.destination = destination;\n            if (isSubscription(destination)) {\n                destination.add(_this);\n            }\n        }\n        else {\n            _this.destination = EMPTY_OBSERVER;\n        }\n        return _this;\n    }\n    Subscriber.create = function (next, error, complete) {\n        return new SafeSubscriber(next, error, complete);\n    };\n    Subscriber.prototype.next = function (value) {\n        if (this.isStopped) {\n            handleStoppedNotification(nextNotification(value), this);\n        }\n        else {\n            this._next(value);\n        }\n    };\n    Subscriber.prototype.error = function (err) {\n        if (this.isStopped) {\n            handleStoppedNotification(errorNotification(err), this);\n        }\n        else {\n            this.isStopped = true;\n            this._error(err);\n        }\n    };\n    Subscriber.prototype.complete = function () {\n        if (this.isStopped) {\n            handleStoppedNotification(COMPLETE_NOTIFICATION, this);\n        }\n        else {\n            this.isStopped = true;\n            this._complete();\n        }\n    };\n    Subscriber.prototype.unsubscribe = function () {\n        if (!this.closed) {\n            this.isStopped = true;\n            _super.prototype.unsubscribe.call(this);\n            this.destination = null;\n        }\n    };\n    Subscriber.prototype._next = function (value) {\n        this.destination.next(value);\n    };\n    Subscriber.prototype._error = function (err) {\n        try {\n            this.destination.error(err);\n        }\n        finally {\n            this.unsubscribe();\n        }\n    };\n    Subscriber.prototype._complete = function () {\n        try {\n            this.destination.complete();\n        }\n        finally {\n            this.unsubscribe();\n        }\n    };\n    return Subscriber;\n}(Subscription));\nexport { Subscriber };\nvar _bind = Function.prototype.bind;\nfunction bind(fn, thisArg) {\n    return _bind.call(fn, thisArg);\n}\nvar ConsumerObserver = (function () {\n    function ConsumerObserver(partialObserver) {\n        this.partialObserver = partialObserver;\n    }\n    ConsumerObserver.prototype.next = function (value) {\n        var partialObserver = this.partialObserver;\n        if (partialObserver.next) {\n            try {\n                partialObserver.next(value);\n            }\n            catch (error) {\n                handleUnhandledError(error);\n            }\n        }\n    };\n    ConsumerObserver.prototype.error = function (err) {\n        var partialObserver = this.partialObserver;\n        if (partialObserver.error) {\n            try {\n                partialObserver.error(err);\n            }\n            catch (error) {\n                handleUnhandledError(error);\n            }\n        }\n        else {\n            handleUnhandledError(err);\n        }\n    };\n    ConsumerObserver.prototype.complete = function () {\n        var partialObserver = this.partialObserver;\n        if (partialObserver.complete) {\n            try {\n                partialObserver.complete();\n            }\n            catch (error) {\n                handleUnhandledError(error);\n            }\n        }\n    };\n    return ConsumerObserver;\n}());\nvar SafeSubscriber = (function (_super) {\n    __extends(SafeSubscriber, _super);\n    function SafeSubscriber(observerOrNext, error, complete) {\n        var _this = _super.call(this) || this;\n        var partialObserver;\n        if (isFunction(observerOrNext) || !observerOrNext) {\n            partialObserver = {\n                next: (observerOrNext !== null && observerOrNext !== void 0 ? observerOrNext : undefined),\n                error: error !== null && error !== void 0 ? error : undefined,\n                complete: complete !== null && complete !== void 0 ? complete : undefined,\n            };\n        }\n        else {\n            var context_1;\n            if (_this && config.useDeprecatedNextContext) {\n                context_1 = Object.create(observerOrNext);\n                context_1.unsubscribe = function () { return _this.unsubscribe(); };\n                partialObserver = {\n                    next: observerOrNext.next && bind(observerOrNext.next, context_1),\n                    error: observerOrNext.error && bind(observerOrNext.error, context_1),\n                    complete: observerOrNext.complete && bind(observerOrNext.complete, context_1),\n                };\n            }\n            else {\n                partialObserver = observerOrNext;\n            }\n        }\n        _this.destination = new ConsumerObserver(partialObserver);\n        return _this;\n    }\n    return SafeSubscriber;\n}(Subscriber));\nexport { SafeSubscriber };\nfunction handleUnhandledError(error) {\n    if (config.useDeprecatedSynchronousErrorHandling) {\n        captureError(error);\n    }\n    else {\n        reportUnhandledError(error);\n    }\n}\nfunction defaultErrorHandler(err) {\n    throw err;\n}\nfunction handleStoppedNotification(notification, subscriber) {\n    var onStoppedNotification = config.onStoppedNotification;\n    onStoppedNotification && timeoutProvider.setTimeout(function () { return onStoppedNotification(notification, subscriber); });\n}\nexport var EMPTY_OBSERVER = {\n    closed: true,\n    next: noop,\n    error: defaultErrorHandler,\n    complete: noop,\n};\n//# sourceMappingURL=Subscriber.js.map","import { __read, __spreadArray, __values } from \"tslib\";\nimport { isFunction } from './util/isFunction';\nimport { UnsubscriptionError } from './util/UnsubscriptionError';\nimport { arrRemove } from './util/arrRemove';\nvar Subscription = (function () {\n    function Subscription(initialTeardown) {\n        this.initialTeardown = initialTeardown;\n        this.closed = false;\n        this._parentage = null;\n        this._finalizers = null;\n    }\n    Subscription.prototype.unsubscribe = function () {\n        var e_1, _a, e_2, _b;\n        var errors;\n        if (!this.closed) {\n            this.closed = true;\n            var _parentage = this._parentage;\n            if (_parentage) {\n                this._parentage = null;\n                if (Array.isArray(_parentage)) {\n                    try {\n                        for (var _parentage_1 = __values(_parentage), _parentage_1_1 = _parentage_1.next(); !_parentage_1_1.done; _parentage_1_1 = _parentage_1.next()) {\n                            var parent_1 = _parentage_1_1.value;\n                            parent_1.remove(this);\n                        }\n                    }\n                    catch (e_1_1) { e_1 = { error: e_1_1 }; }\n                    finally {\n                        try {\n                            if (_parentage_1_1 && !_parentage_1_1.done && (_a = _parentage_1.return)) _a.call(_parentage_1);\n                        }\n                        finally { if (e_1) throw e_1.error; }\n                    }\n                }\n                else {\n                    _parentage.remove(this);\n                }\n            }\n            var initialFinalizer = this.initialTeardown;\n            if (isFunction(initialFinalizer)) {\n                try {\n                    initialFinalizer();\n                }\n                catch (e) {\n                    errors = e instanceof UnsubscriptionError ? e.errors : [e];\n                }\n            }\n            var _finalizers = this._finalizers;\n            if (_finalizers) {\n                this._finalizers = null;\n                try {\n                    for (var _finalizers_1 = __values(_finalizers), _finalizers_1_1 = _finalizers_1.next(); !_finalizers_1_1.done; _finalizers_1_1 = _finalizers_1.next()) {\n                        var finalizer = _finalizers_1_1.value;\n                        try {\n                            execFinalizer(finalizer);\n                        }\n                        catch (err) {\n                            errors = errors !== null && errors !== void 0 ? errors : [];\n                            if (err instanceof UnsubscriptionError) {\n                                errors = __spreadArray(__spreadArray([], __read(errors)), __read(err.errors));\n                            }\n                            else {\n                                errors.push(err);\n                            }\n                        }\n                    }\n                }\n                catch (e_2_1) { e_2 = { error: e_2_1 }; }\n                finally {\n                    try {\n                        if (_finalizers_1_1 && !_finalizers_1_1.done && (_b = _finalizers_1.return)) _b.call(_finalizers_1);\n                    }\n                    finally { if (e_2) throw e_2.error; }\n                }\n            }\n            if (errors) {\n                throw new UnsubscriptionError(errors);\n            }\n        }\n    };\n    Subscription.prototype.add = function (teardown) {\n        var _a;\n        if (teardown && teardown !== this) {\n            if (this.closed) {\n                execFinalizer(teardown);\n            }\n            else {\n                if (teardown instanceof Subscription) {\n                    if (teardown.closed || teardown._hasParent(this)) {\n                        return;\n                    }\n                    teardown._addParent(this);\n                }\n                (this._finalizers = (_a = this._finalizers) !== null && _a !== void 0 ? _a : []).push(teardown);\n            }\n        }\n    };\n    Subscription.prototype._hasParent = function (parent) {\n        var _parentage = this._parentage;\n        return _parentage === parent || (Array.isArray(_parentage) && _parentage.includes(parent));\n    };\n    Subscription.prototype._addParent = function (parent) {\n        var _parentage = this._parentage;\n        this._parentage = Array.isArray(_parentage) ? (_parentage.push(parent), _parentage) : _parentage ? [_parentage, parent] : parent;\n    };\n    Subscription.prototype._removeParent = function (parent) {\n        var _parentage = this._parentage;\n        if (_parentage === parent) {\n            this._parentage = null;\n        }\n        else if (Array.isArray(_parentage)) {\n            arrRemove(_parentage, parent);\n        }\n    };\n    Subscription.prototype.remove = function (teardown) {\n        var _finalizers = this._finalizers;\n        _finalizers && arrRemove(_finalizers, teardown);\n        if (teardown instanceof Subscription) {\n            teardown._removeParent(this);\n        }\n    };\n    Subscription.EMPTY = (function () {\n        var empty = new Subscription();\n        empty.closed = true;\n        return empty;\n    })();\n    return Subscription;\n}());\nexport { Subscription };\nexport var EMPTY_SUBSCRIPTION = Subscription.EMPTY;\nexport function isSubscription(value) {\n    return (value instanceof Subscription ||\n        (value && 'closed' in value && isFunction(value.remove) && isFunction(value.add) && isFunction(value.unsubscribe)));\n}\nfunction execFinalizer(finalizer) {\n    if (isFunction(finalizer)) {\n        finalizer();\n    }\n    else {\n        finalizer.unsubscribe();\n    }\n}\n//# sourceMappingURL=Subscription.js.map","export var config = {\n    onUnhandledError: null,\n    onStoppedNotification: null,\n    Promise: undefined,\n    useDeprecatedSynchronousErrorHandling: false,\n    useDeprecatedNextContext: false,\n};\n//# sourceMappingURL=config.js.map","import { scheduled } from '../scheduled/scheduled';\nimport { innerFrom } from './innerFrom';\nexport function from(input, scheduler) {\n    return scheduler ? scheduled(input, scheduler) : innerFrom(input);\n}\n//# sourceMappingURL=from.js.map","import { __asyncValues, __awaiter, __generator, __values } from \"tslib\";\nimport { isArrayLike } from '../util/isArrayLike';\nimport { isPromise } from '../util/isPromise';\nimport { Observable } from '../Observable';\nimport { isInteropObservable } from '../util/isInteropObservable';\nimport { isAsyncIterable } from '../util/isAsyncIterable';\nimport { createInvalidObservableTypeError } from '../util/throwUnobservableError';\nimport { isIterable } from '../util/isIterable';\nimport { isReadableStreamLike, readableStreamLikeToAsyncGenerator } from '../util/isReadableStreamLike';\nimport { isFunction } from '../util/isFunction';\nimport { reportUnhandledError } from '../util/reportUnhandledError';\nimport { observable as Symbol_observable } from '../symbol/observable';\nexport function innerFrom(input) {\n    if (input instanceof Observable) {\n        return input;\n    }\n    if (input != null) {\n        if (isInteropObservable(input)) {\n            return fromInteropObservable(input);\n        }\n        if (isArrayLike(input)) {\n            return fromArrayLike(input);\n        }\n        if (isPromise(input)) {\n            return fromPromise(input);\n        }\n        if (isAsyncIterable(input)) {\n            return fromAsyncIterable(input);\n        }\n        if (isIterable(input)) {\n            return fromIterable(input);\n        }\n        if (isReadableStreamLike(input)) {\n            return fromReadableStreamLike(input);\n        }\n    }\n    throw createInvalidObservableTypeError(input);\n}\nexport function fromInteropObservable(obj) {\n    return new Observable(function (subscriber) {\n        var obs = obj[Symbol_observable]();\n        if (isFunction(obs.subscribe)) {\n            return obs.subscribe(subscriber);\n        }\n        throw new TypeError('Provided object does not correctly implement Symbol.observable');\n    });\n}\nexport function fromArrayLike(array) {\n    return new Observable(function (subscriber) {\n        for (var i = 0; i < array.length && !subscriber.closed; i++) {\n            subscriber.next(array[i]);\n        }\n        subscriber.complete();\n    });\n}\nexport function fromPromise(promise) {\n    return new Observable(function (subscriber) {\n        promise\n            .then(function (value) {\n            if (!subscriber.closed) {\n                subscriber.next(value);\n                subscriber.complete();\n            }\n        }, function (err) { return subscriber.error(err); })\n            .then(null, reportUnhandledError);\n    });\n}\nexport function fromIterable(iterable) {\n    return new Observable(function (subscriber) {\n        var e_1, _a;\n        try {\n            for (var iterable_1 = __values(iterable), iterable_1_1 = iterable_1.next(); !iterable_1_1.done; iterable_1_1 = iterable_1.next()) {\n                var value = iterable_1_1.value;\n                subscriber.next(value);\n                if (subscriber.closed) {\n                    return;\n                }\n            }\n        }\n        catch (e_1_1) { e_1 = { error: e_1_1 }; }\n        finally {\n            try {\n                if (iterable_1_1 && !iterable_1_1.done && (_a = iterable_1.return)) _a.call(iterable_1);\n            }\n            finally { if (e_1) throw e_1.error; }\n        }\n        subscriber.complete();\n    });\n}\nexport function fromAsyncIterable(asyncIterable) {\n    return new Observable(function (subscriber) {\n        process(asyncIterable, subscriber).catch(function (err) { return subscriber.error(err); });\n    });\n}\nexport function fromReadableStreamLike(readableStream) {\n    return fromAsyncIterable(readableStreamLikeToAsyncGenerator(readableStream));\n}\nfunction process(asyncIterable, subscriber) {\n    var asyncIterable_1, asyncIterable_1_1;\n    var e_2, _a;\n    return __awaiter(this, void 0, void 0, function () {\n        var value, e_2_1;\n        return __generator(this, function (_b) {\n            switch (_b.label) {\n                case 0:\n                    _b.trys.push([0, 5, 6, 11]);\n                    asyncIterable_1 = __asyncValues(asyncIterable);\n                    _b.label = 1;\n                case 1: return [4, asyncIterable_1.next()];\n                case 2:\n                    if (!(asyncIterable_1_1 = _b.sent(), !asyncIterable_1_1.done)) return [3, 4];\n                    value = asyncIterable_1_1.value;\n                    subscriber.next(value);\n                    if (subscriber.closed) {\n                        return [2];\n                    }\n                    _b.label = 3;\n                case 3: return [3, 1];\n                case 4: return [3, 11];\n                case 5:\n                    e_2_1 = _b.sent();\n                    e_2 = { error: e_2_1 };\n                    return [3, 11];\n                case 6:\n                    _b.trys.push([6, , 9, 10]);\n                    if (!(asyncIterable_1_1 && !asyncIterable_1_1.done && (_a = asyncIterable_1.return))) return [3, 8];\n                    return [4, _a.call(asyncIterable_1)];\n                case 7:\n                    _b.sent();\n                    _b.label = 8;\n                case 8: return [3, 10];\n                case 9:\n                    if (e_2) throw e_2.error;\n                    return [7];\n                case 10: return [7];\n                case 11:\n                    subscriber.complete();\n                    return [2];\n            }\n        });\n    });\n}\n//# sourceMappingURL=innerFrom.js.map","import { popScheduler } from '../util/args';\nimport { from } from './from';\nexport function of() {\n    var args = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        args[_i] = arguments[_i];\n    }\n    var scheduler = popScheduler(args);\n    return from(args, scheduler);\n}\n//# sourceMappingURL=of.js.map","import { __extends } from \"tslib\";\nimport { Subscriber } from '../Subscriber';\nexport function createOperatorSubscriber(destination, onNext, onComplete, onError, onFinalize) {\n    return new OperatorSubscriber(destination, onNext, onComplete, onError, onFinalize);\n}\nvar OperatorSubscriber = (function (_super) {\n    __extends(OperatorSubscriber, _super);\n    function OperatorSubscriber(destination, onNext, onComplete, onError, onFinalize, shouldUnsubscribe) {\n        var _this = _super.call(this, destination) || this;\n        _this.onFinalize = onFinalize;\n        _this.shouldUnsubscribe = shouldUnsubscribe;\n        _this._next = onNext\n            ? function (value) {\n                try {\n                    onNext(value);\n                }\n                catch (err) {\n                    destination.error(err);\n                }\n            }\n            : _super.prototype._next;\n        _this._error = onError\n            ? function (err) {\n                try {\n                    onError(err);\n                }\n                catch (err) {\n                    destination.error(err);\n                }\n                finally {\n                    this.unsubscribe();\n                }\n            }\n            : _super.prototype._error;\n        _this._complete = onComplete\n            ? function () {\n                try {\n                    onComplete();\n                }\n                catch (err) {\n                    destination.error(err);\n                }\n                finally {\n                    this.unsubscribe();\n                }\n            }\n            : _super.prototype._complete;\n        return _this;\n    }\n    OperatorSubscriber.prototype.unsubscribe = function () {\n        var _a;\n        if (!this.shouldUnsubscribe || this.shouldUnsubscribe()) {\n            var closed_1 = this.closed;\n            _super.prototype.unsubscribe.call(this);\n            !closed_1 && ((_a = this.onFinalize) === null || _a === void 0 ? void 0 : _a.call(this));\n        }\n    };\n    return OperatorSubscriber;\n}(Subscriber));\nexport { OperatorSubscriber };\n//# sourceMappingURL=OperatorSubscriber.js.map","import { innerFrom } from '../observable/innerFrom';\nimport { createOperatorSubscriber } from './OperatorSubscriber';\nimport { operate } from '../util/lift';\nexport function catchError(selector) {\n    return operate(function (source, subscriber) {\n        var innerSub = null;\n        var syncUnsub = false;\n        var handledResult;\n        innerSub = source.subscribe(createOperatorSubscriber(subscriber, undefined, undefined, function (err) {\n            handledResult = innerFrom(selector(err, catchError(selector)(source)));\n            if (innerSub) {\n                innerSub.unsubscribe();\n                innerSub = null;\n                handledResult.subscribe(subscriber);\n            }\n            else {\n                syncUnsub = true;\n            }\n        }));\n        if (syncUnsub) {\n            innerSub.unsubscribe();\n            innerSub = null;\n            handledResult.subscribe(subscriber);\n        }\n    });\n}\n//# sourceMappingURL=catchError.js.map","import { operate } from '../util/lift';\nimport { createOperatorSubscriber } from './OperatorSubscriber';\nexport function filter(predicate, thisArg) {\n    return operate(function (source, subscriber) {\n        var index = 0;\n        source.subscribe(createOperatorSubscriber(subscriber, function (value) { return predicate.call(thisArg, value, index++) && subscriber.next(value); }));\n    });\n}\n//# sourceMappingURL=filter.js.map","import { operate } from '../util/lift';\nimport { createOperatorSubscriber } from './OperatorSubscriber';\nexport function map(project, thisArg) {\n    return operate(function (source, subscriber) {\n        var index = 0;\n        source.subscribe(createOperatorSubscriber(subscriber, function (value) {\n            subscriber.next(project.call(thisArg, value, index++));\n        }));\n    });\n}\n//# sourceMappingURL=map.js.map","import { executeSchedule } from '../util/executeSchedule';\nimport { operate } from '../util/lift';\nimport { createOperatorSubscriber } from './OperatorSubscriber';\nexport function observeOn(scheduler, delay) {\n    if (delay === void 0) { delay = 0; }\n    return operate(function (source, subscriber) {\n        source.subscribe(createOperatorSubscriber(subscriber, function (value) { return executeSchedule(subscriber, scheduler, function () { return subscriber.next(value); }, delay); }, function () { return executeSchedule(subscriber, scheduler, function () { return subscriber.complete(); }, delay); }, function (err) { return executeSchedule(subscriber, scheduler, function () { return subscriber.error(err); }, delay); }));\n    });\n}\n//# sourceMappingURL=observeOn.js.map","import { operate } from '../util/lift';\nexport function subscribeOn(scheduler, delay) {\n    if (delay === void 0) { delay = 0; }\n    return operate(function (source, subscriber) {\n        subscriber.add(scheduler.schedule(function () { return source.subscribe(subscriber); }, delay));\n    });\n}\n//# sourceMappingURL=subscribeOn.js.map","import { Observable } from '../Observable';\nexport function scheduleArray(input, scheduler) {\n    return new Observable(function (subscriber) {\n        var i = 0;\n        return scheduler.schedule(function () {\n            if (i === input.length) {\n                subscriber.complete();\n            }\n            else {\n                subscriber.next(input[i++]);\n                if (!subscriber.closed) {\n                    this.schedule();\n                }\n            }\n        });\n    });\n}\n//# sourceMappingURL=scheduleArray.js.map","import { Observable } from '../Observable';\nimport { executeSchedule } from '../util/executeSchedule';\nexport function scheduleAsyncIterable(input, scheduler) {\n    if (!input) {\n        throw new Error('Iterable cannot be null');\n    }\n    return new Observable(function (subscriber) {\n        executeSchedule(subscriber, scheduler, function () {\n            var iterator = input[Symbol.asyncIterator]();\n            executeSchedule(subscriber, scheduler, function () {\n                iterator.next().then(function (result) {\n                    if (result.done) {\n                        subscriber.complete();\n                    }\n                    else {\n                        subscriber.next(result.value);\n                    }\n                });\n            }, 0, true);\n        });\n    });\n}\n//# sourceMappingURL=scheduleAsyncIterable.js.map","import { Observable } from '../Observable';\nimport { iterator as Symbol_iterator } from '../symbol/iterator';\nimport { isFunction } from '../util/isFunction';\nimport { executeSchedule } from '../util/executeSchedule';\nexport function scheduleIterable(input, scheduler) {\n    return new Observable(function (subscriber) {\n        var iterator;\n        executeSchedule(subscriber, scheduler, function () {\n            iterator = input[Symbol_iterator]();\n            executeSchedule(subscriber, scheduler, function () {\n                var _a;\n                var value;\n                var done;\n                try {\n                    (_a = iterator.next(), value = _a.value, done = _a.done);\n                }\n                catch (err) {\n                    subscriber.error(err);\n                    return;\n                }\n                if (done) {\n                    subscriber.complete();\n                }\n                else {\n                    subscriber.next(value);\n                }\n            }, 0, true);\n        });\n        return function () { return isFunction(iterator === null || iterator === void 0 ? void 0 : iterator.return) && iterator.return(); };\n    });\n}\n//# sourceMappingURL=scheduleIterable.js.map","import { innerFrom } from '../observable/innerFrom';\nimport { observeOn } from '../operators/observeOn';\nimport { subscribeOn } from '../operators/subscribeOn';\nexport function scheduleObservable(input, scheduler) {\n    return innerFrom(input).pipe(subscribeOn(scheduler), observeOn(scheduler));\n}\n//# sourceMappingURL=scheduleObservable.js.map","import { innerFrom } from '../observable/innerFrom';\nimport { observeOn } from '../operators/observeOn';\nimport { subscribeOn } from '../operators/subscribeOn';\nexport function schedulePromise(input, scheduler) {\n    return innerFrom(input).pipe(subscribeOn(scheduler), observeOn(scheduler));\n}\n//# sourceMappingURL=schedulePromise.js.map","import { scheduleAsyncIterable } from './scheduleAsyncIterable';\nimport { readableStreamLikeToAsyncGenerator } from '../util/isReadableStreamLike';\nexport function scheduleReadableStreamLike(input, scheduler) {\n    return scheduleAsyncIterable(readableStreamLikeToAsyncGenerator(input), scheduler);\n}\n//# sourceMappingURL=scheduleReadableStreamLike.js.map","import { scheduleObservable } from './scheduleObservable';\nimport { schedulePromise } from './schedulePromise';\nimport { scheduleArray } from './scheduleArray';\nimport { scheduleIterable } from './scheduleIterable';\nimport { scheduleAsyncIterable } from './scheduleAsyncIterable';\nimport { isInteropObservable } from '../util/isInteropObservable';\nimport { isPromise } from '../util/isPromise';\nimport { isArrayLike } from '../util/isArrayLike';\nimport { isIterable } from '../util/isIterable';\nimport { isAsyncIterable } from '../util/isAsyncIterable';\nimport { createInvalidObservableTypeError } from '../util/throwUnobservableError';\nimport { isReadableStreamLike } from '../util/isReadableStreamLike';\nimport { scheduleReadableStreamLike } from './scheduleReadableStreamLike';\nexport function scheduled(input, scheduler) {\n    if (input != null) {\n        if (isInteropObservable(input)) {\n            return scheduleObservable(input, scheduler);\n        }\n        if (isArrayLike(input)) {\n            return scheduleArray(input, scheduler);\n        }\n        if (isPromise(input)) {\n            return schedulePromise(input, scheduler);\n        }\n        if (isAsyncIterable(input)) {\n            return scheduleAsyncIterable(input, scheduler);\n        }\n        if (isIterable(input)) {\n            return scheduleIterable(input, scheduler);\n        }\n        if (isReadableStreamLike(input)) {\n            return scheduleReadableStreamLike(input, scheduler);\n        }\n    }\n    throw createInvalidObservableTypeError(input);\n}\n//# sourceMappingURL=scheduled.js.map","import { __read, __spreadArray } from \"tslib\";\nexport var timeoutProvider = {\n    setTimeout: function (handler, timeout) {\n        var args = [];\n        for (var _i = 2; _i < arguments.length; _i++) {\n            args[_i - 2] = arguments[_i];\n        }\n        var delegate = timeoutProvider.delegate;\n        if (delegate === null || delegate === void 0 ? void 0 : delegate.setTimeout) {\n            return delegate.setTimeout.apply(delegate, __spreadArray([handler, timeout], __read(args)));\n        }\n        return setTimeout.apply(void 0, __spreadArray([handler, timeout], __read(args)));\n    },\n    clearTimeout: function (handle) {\n        var delegate = timeoutProvider.delegate;\n        return ((delegate === null || delegate === void 0 ? void 0 : delegate.clearTimeout) || clearTimeout)(handle);\n    },\n    delegate: undefined,\n};\n//# sourceMappingURL=timeoutProvider.js.map","export function getSymbolIterator() {\n    if (typeof Symbol !== 'function' || !Symbol.iterator) {\n        return '@@iterator';\n    }\n    return Symbol.iterator;\n}\nexport var iterator = getSymbolIterator();\n//# sourceMappingURL=iterator.js.map","export var observable = (function () { return (typeof Symbol === 'function' && Symbol.observable) || '@@observable'; })();\n//# sourceMappingURL=observable.js.map","import { createErrorClass } from './createErrorClass';\nexport var ObjectUnsubscribedError = createErrorClass(function (_super) {\n    return function ObjectUnsubscribedErrorImpl() {\n        _super(this);\n        this.name = 'ObjectUnsubscribedError';\n        this.message = 'object unsubscribed';\n    };\n});\n//# sourceMappingURL=ObjectUnsubscribedError.js.map","import { createErrorClass } from './createErrorClass';\nexport var UnsubscriptionError = createErrorClass(function (_super) {\n    return function UnsubscriptionErrorImpl(errors) {\n        _super(this);\n        this.message = errors\n            ? errors.length + \" errors occurred during unsubscription:\\n\" + errors.map(function (err, i) { return i + 1 + \") \" + err.toString(); }).join('\\n  ')\n            : '';\n        this.name = 'UnsubscriptionError';\n        this.errors = errors;\n    };\n});\n//# sourceMappingURL=UnsubscriptionError.js.map","import { isFunction } from './isFunction';\nimport { isScheduler } from './isScheduler';\nfunction last(arr) {\n    return arr[arr.length - 1];\n}\nexport function popResultSelector(args) {\n    return isFunction(last(args)) ? args.pop() : undefined;\n}\nexport function popScheduler(args) {\n    return isScheduler(last(args)) ? args.pop() : undefined;\n}\nexport function popNumber(args, defaultValue) {\n    return typeof last(args) === 'number' ? args.pop() : defaultValue;\n}\n//# sourceMappingURL=args.js.map","export function arrRemove(arr, item) {\n    if (arr) {\n        var index = arr.indexOf(item);\n        0 <= index && arr.splice(index, 1);\n    }\n}\n//# sourceMappingURL=arrRemove.js.map","export function createErrorClass(createImpl) {\n    var _super = function (instance) {\n        Error.call(instance);\n        instance.stack = new Error().stack;\n    };\n    var ctorFunc = createImpl(_super);\n    ctorFunc.prototype = Object.create(Error.prototype);\n    ctorFunc.prototype.constructor = ctorFunc;\n    return ctorFunc;\n}\n//# sourceMappingURL=createErrorClass.js.map","import { config } from '../config';\nvar context = null;\nexport function errorContext(cb) {\n    if (config.useDeprecatedSynchronousErrorHandling) {\n        var isRoot = !context;\n        if (isRoot) {\n            context = { errorThrown: false, error: null };\n        }\n        cb();\n        if (isRoot) {\n            var _a = context, errorThrown = _a.errorThrown, error = _a.error;\n            context = null;\n            if (errorThrown) {\n                throw error;\n            }\n        }\n    }\n    else {\n        cb();\n    }\n}\nexport function captureError(err) {\n    if (config.useDeprecatedSynchronousErrorHandling && context) {\n        context.errorThrown = true;\n        context.error = err;\n    }\n}\n//# sourceMappingURL=errorContext.js.map","export function executeSchedule(parentSubscription, scheduler, work, delay, repeat) {\n    if (delay === void 0) { delay = 0; }\n    if (repeat === void 0) { repeat = false; }\n    var scheduleSubscription = scheduler.schedule(function () {\n        work();\n        if (repeat) {\n            parentSubscription.add(this.schedule(null, delay));\n        }\n        else {\n            this.unsubscribe();\n        }\n    }, delay);\n    parentSubscription.add(scheduleSubscription);\n    if (!repeat) {\n        return scheduleSubscription;\n    }\n}\n//# sourceMappingURL=executeSchedule.js.map","export function identity(x) {\n    return x;\n}\n//# sourceMappingURL=identity.js.map","export var isArrayLike = (function (x) { return x && typeof x.length === 'number' && typeof x !== 'function'; });\n//# sourceMappingURL=isArrayLike.js.map","import { isFunction } from './isFunction';\nexport function isAsyncIterable(obj) {\n    return Symbol.asyncIterator && isFunction(obj === null || obj === void 0 ? void 0 : obj[Symbol.asyncIterator]);\n}\n//# sourceMappingURL=isAsyncIterable.js.map","export function isFunction(value) {\n    return typeof value === 'function';\n}\n//# sourceMappingURL=isFunction.js.map","import { observable as Symbol_observable } from '../symbol/observable';\nimport { isFunction } from './isFunction';\nexport function isInteropObservable(input) {\n    return isFunction(input[Symbol_observable]);\n}\n//# sourceMappingURL=isInteropObservable.js.map","import { iterator as Symbol_iterator } from '../symbol/iterator';\nimport { isFunction } from './isFunction';\nexport function isIterable(input) {\n    return isFunction(input === null || input === void 0 ? void 0 : input[Symbol_iterator]);\n}\n//# sourceMappingURL=isIterable.js.map","import { isFunction } from \"./isFunction\";\nexport function isPromise(value) {\n    return isFunction(value === null || value === void 0 ? void 0 : value.then);\n}\n//# sourceMappingURL=isPromise.js.map","import { __asyncGenerator, __await, __generator } from \"tslib\";\nimport { isFunction } from './isFunction';\nexport function readableStreamLikeToAsyncGenerator(readableStream) {\n    return __asyncGenerator(this, arguments, function readableStreamLikeToAsyncGenerator_1() {\n        var reader, _a, value, done;\n        return __generator(this, function (_b) {\n            switch (_b.label) {\n                case 0:\n                    reader = readableStream.getReader();\n                    _b.label = 1;\n                case 1:\n                    _b.trys.push([1, , 9, 10]);\n                    _b.label = 2;\n                case 2:\n                    if (!true) return [3, 8];\n                    return [4, __await(reader.read())];\n                case 3:\n                    _a = _b.sent(), value = _a.value, done = _a.done;\n                    if (!done) return [3, 5];\n                    return [4, __await(void 0)];\n                case 4: return [2, _b.sent()];\n                case 5: return [4, __await(value)];\n                case 6: return [4, _b.sent()];\n                case 7:\n                    _b.sent();\n                    return [3, 2];\n                case 8: return [3, 10];\n                case 9:\n                    reader.releaseLock();\n                    return [7];\n                case 10: return [2];\n            }\n        });\n    });\n}\nexport function isReadableStreamLike(obj) {\n    return isFunction(obj === null || obj === void 0 ? void 0 : obj.getReader);\n}\n//# sourceMappingURL=isReadableStreamLike.js.map","import { isFunction } from './isFunction';\nexport function isScheduler(value) {\n    return value && isFunction(value.schedule);\n}\n//# sourceMappingURL=isScheduler.js.map","import { isFunction } from './isFunction';\nexport function hasLift(source) {\n    return isFunction(source === null || source === void 0 ? void 0 : source.lift);\n}\nexport function operate(init) {\n    return function (source) {\n        if (hasLift(source)) {\n            return source.lift(function (liftedSource) {\n                try {\n                    return init(liftedSource, this);\n                }\n                catch (err) {\n                    this.error(err);\n                }\n            });\n        }\n        throw new TypeError('Unable to lift unknown Observable type');\n    };\n}\n//# sourceMappingURL=lift.js.map","export function noop() { }\n//# sourceMappingURL=noop.js.map","import { identity } from './identity';\nexport function pipe() {\n    var fns = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        fns[_i] = arguments[_i];\n    }\n    return pipeFromArray(fns);\n}\nexport function pipeFromArray(fns) {\n    if (fns.length === 0) {\n        return identity;\n    }\n    if (fns.length === 1) {\n        return fns[0];\n    }\n    return function piped(input) {\n        return fns.reduce(function (prev, fn) { return fn(prev); }, input);\n    };\n}\n//# sourceMappingURL=pipe.js.map","import { config } from '../config';\nimport { timeoutProvider } from '../scheduler/timeoutProvider';\nexport function reportUnhandledError(err) {\n    timeoutProvider.setTimeout(function () {\n        var onUnhandledError = config.onUnhandledError;\n        if (onUnhandledError) {\n            onUnhandledError(err);\n        }\n        else {\n            throw err;\n        }\n    });\n}\n//# sourceMappingURL=reportUnhandledError.js.map","export function createInvalidObservableTypeError(input) {\n    return new TypeError(\"You provided \" + (input !== null && typeof input === 'object' ? 'an invalid object' : \"'\" + input + \"'\") + \" where a stream was expected. You can provide an Observable, Promise, ReadableStream, Array, AsyncIterable, or Iterable.\");\n}\n//# sourceMappingURL=throwUnobservableError.js.map","function createError(message) {\n    var err = new Error(message);\n    err.source = \"ulid\";\n    return err;\n}\n// These values should NEVER change. If\n// they do, we're no longer making ulids!\nvar ENCODING = \"0123456789ABCDEFGHJKMNPQRSTVWXYZ\"; // Crockford's Base32\nvar ENCODING_LEN = ENCODING.length;\nvar TIME_MAX = Math.pow(2, 48) - 1;\nvar TIME_LEN = 10;\nvar RANDOM_LEN = 16;\nfunction replaceCharAt(str, index, char) {\n    if (index > str.length - 1) {\n        return str;\n    }\n    return str.substr(0, index) + char + str.substr(index + 1);\n}\nfunction incrementBase32(str) {\n    var done = undefined;\n    var index = str.length;\n    var char = void 0;\n    var charIndex = void 0;\n    var maxCharIndex = ENCODING_LEN - 1;\n    while (!done && index-- >= 0) {\n        char = str[index];\n        charIndex = ENCODING.indexOf(char);\n        if (charIndex === -1) {\n            throw createError(\"incorrectly encoded string\");\n        }\n        if (charIndex === maxCharIndex) {\n            str = replaceCharAt(str, index, ENCODING[0]);\n            continue;\n        }\n        done = replaceCharAt(str, index, ENCODING[charIndex + 1]);\n    }\n    if (typeof done === \"string\") {\n        return done;\n    }\n    throw createError(\"cannot increment this string\");\n}\nfunction randomChar(prng) {\n    var rand = Math.floor(prng() * ENCODING_LEN);\n    if (rand === ENCODING_LEN) {\n        rand = ENCODING_LEN - 1;\n    }\n    return ENCODING.charAt(rand);\n}\nfunction encodeTime(now, len) {\n    if (isNaN(now)) {\n        throw new Error(now + \" must be a number\");\n    }\n    if (now > TIME_MAX) {\n        throw createError(\"cannot encode time greater than \" + TIME_MAX);\n    }\n    if (now < 0) {\n        throw createError(\"time must be positive\");\n    }\n    if (Number.isInteger(now) === false) {\n        throw createError(\"time must be an integer\");\n    }\n    var mod = void 0;\n    var str = \"\";\n    for (; len > 0; len--) {\n        mod = now % ENCODING_LEN;\n        str = ENCODING.charAt(mod) + str;\n        now = (now - mod) / ENCODING_LEN;\n    }\n    return str;\n}\nfunction encodeRandom(len, prng) {\n    var str = \"\";\n    for (; len > 0; len--) {\n        str = randomChar(prng) + str;\n    }\n    return str;\n}\nfunction decodeTime(id) {\n    if (id.length !== TIME_LEN + RANDOM_LEN) {\n        throw createError(\"malformed ulid\");\n    }\n    var time = id.substr(0, TIME_LEN).split(\"\").reverse().reduce(function (carry, char, index) {\n        var encodingIndex = ENCODING.indexOf(char);\n        if (encodingIndex === -1) {\n            throw createError(\"invalid character found: \" + char);\n        }\n        return carry += encodingIndex * Math.pow(ENCODING_LEN, index);\n    }, 0);\n    if (time > TIME_MAX) {\n        throw createError(\"malformed ulid, timestamp too large\");\n    }\n    return time;\n}\nfunction detectPrng() {\n    var allowInsecure = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n    var root = arguments[1];\n\n    if (!root) {\n        root = typeof window !== \"undefined\" ? window : null;\n    }\n    var browserCrypto = root && (root.crypto || root.msCrypto);\n    if (browserCrypto) {\n        return function () {\n            var buffer = new Uint8Array(1);\n            browserCrypto.getRandomValues(buffer);\n            return buffer[0] / 0xff;\n        };\n    } else {\n        try {\n            var nodeCrypto = require(\"crypto\");\n            return function () {\n                return nodeCrypto.randomBytes(1).readUInt8() / 0xff;\n            };\n        } catch (e) {}\n    }\n    if (allowInsecure) {\n        try {\n            console.error(\"secure crypto unusable, falling back to insecure Math.random()!\");\n        } catch (e) {}\n        return function () {\n            return Math.random();\n        };\n    }\n    throw createError(\"secure crypto unusable, insecure Math.random not allowed\");\n}\nfunction factory(currPrng) {\n    if (!currPrng) {\n        currPrng = detectPrng();\n    }\n    return function ulid(seedTime) {\n        if (isNaN(seedTime)) {\n            seedTime = Date.now();\n        }\n        return encodeTime(seedTime, TIME_LEN) + encodeRandom(RANDOM_LEN, currPrng);\n    };\n}\nfunction monotonicFactory(currPrng) {\n    if (!currPrng) {\n        currPrng = detectPrng();\n    }\n    var lastTime = 0;\n    var lastRandom = void 0;\n    return function ulid(seedTime) {\n        if (isNaN(seedTime)) {\n            seedTime = Date.now();\n        }\n        if (seedTime <= lastTime) {\n            var incrementedRandom = lastRandom = incrementBase32(lastRandom);\n            return encodeTime(lastTime, TIME_LEN) + incrementedRandom;\n        }\n        lastTime = seedTime;\n        var newRandom = lastRandom = encodeRandom(RANDOM_LEN, currPrng);\n        return encodeTime(seedTime, TIME_LEN) + newRandom;\n    };\n}\nvar ulid = factory();\n\nexport { replaceCharAt, incrementBase32, randomChar, encodeTime, encodeRandom, decodeTime, detectPrng, factory, monotonicFactory, ulid };\n","","const randomUUID = typeof crypto !== 'undefined' && crypto.randomUUID && crypto.randomUUID.bind(crypto);\nexport default {\n  randomUUID\n};","export default /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;","// Unique ID creation requires a high quality random # generator. In the browser we therefore\n// require the crypto API and do not support built-in fallback to lower quality random number\n// generators (like Math.random()).\nlet getRandomValues;\nconst rnds8 = new Uint8Array(16);\nexport default function rng() {\n  // lazy load so that environments that need to polyfill have a chance to do so\n  if (!getRandomValues) {\n    // getRandomValues needs to be invoked in a context where \"this\" is a Crypto implementation.\n    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);\n\n    if (!getRandomValues) {\n      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');\n    }\n  }\n\n  return getRandomValues(rnds8);\n}","import validate from './validate.js';\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\n\nconst byteToHex = [];\n\nfor (let i = 0; i < 256; ++i) {\n  byteToHex.push((i + 0x100).toString(16).slice(1));\n}\n\nexport function unsafeStringify(arr, offset = 0) {\n  // Note: Be careful editing this code!  It's been tuned for performance\n  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434\n  return byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]];\n}\n\nfunction stringify(arr, offset = 0) {\n  const uuid = unsafeStringify(arr, offset); // Consistency check for valid UUID.  If this throws, it's likely due to one\n  // of the following:\n  // - One or more input array values don't map to a hex octet (leading to\n  // \"undefined\" in the uuid)\n  // - Invalid input values for the RFC `version` or `variant` fields\n\n  if (!validate(uuid)) {\n    throw TypeError('Stringified UUID is invalid');\n  }\n\n  return uuid;\n}\n\nexport default stringify;","import native from './native.js';\nimport rng from './rng.js';\nimport { unsafeStringify } from './stringify.js';\n\nfunction v4(options, buf, offset) {\n  if (native.randomUUID && !buf && !options) {\n    return native.randomUUID();\n  }\n\n  options = options || {};\n  const rnds = options.random || (options.rng || rng)(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n\n  rnds[6] = rnds[6] & 0x0f | 0x40;\n  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided\n\n  if (buf) {\n    offset = offset || 0;\n\n    for (let i = 0; i < 16; ++i) {\n      buf[offset + i] = rnds[i];\n    }\n\n    return buf;\n  }\n\n  return unsafeStringify(rnds);\n}\n\nexport default v4;","import REGEX from './regex.js';\n\nfunction validate(uuid) {\n  return typeof uuid === 'string' && REGEX.test(uuid);\n}\n\nexport default validate;","const SHORT_TO_HEX = {};\nconst HEX_TO_SHORT = {};\nfor (let i = 0; i < 256; i++) {\n    let encodedByte = i.toString(16).toLowerCase();\n    if (encodedByte.length === 1) {\n        encodedByte = `0${encodedByte}`;\n    }\n    SHORT_TO_HEX[i] = encodedByte;\n    HEX_TO_SHORT[encodedByte] = i;\n}\nexport function fromHex(encoded) {\n    if (encoded.length % 2 !== 0) {\n        throw new Error(\"Hex encoded strings must have an even number length\");\n    }\n    const out = new Uint8Array(encoded.length / 2);\n    for (let i = 0; i < encoded.length; i += 2) {\n        const encodedByte = encoded.slice(i, i + 2).toLowerCase();\n        if (encodedByte in HEX_TO_SHORT) {\n            out[i / 2] = HEX_TO_SHORT[encodedByte];\n        }\n        else {\n            throw new Error(`Cannot decode unrecognized sequence ${encodedByte} as hexadecimal`);\n        }\n    }\n    return out;\n}\nexport function toHex(bytes) {\n    let out = \"\";\n    for (let i = 0; i < bytes.byteLength; i++) {\n        out += SHORT_TO_HEX[bytes[i]];\n    }\n    return out;\n}\n","function _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }\n\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(Object(source), true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _wrapNativeSuper(Class) { var _cache = typeof Map === \"function\" ? new Map() : undefined; _wrapNativeSuper = function _wrapNativeSuper(Class) { if (Class === null || !_isNativeFunction(Class)) return Class; if (typeof Class !== \"function\") { throw new TypeError(\"Super expression must either be null or a function\"); } if (typeof _cache !== \"undefined\") { if (_cache.has(Class)) return _cache.get(Class); _cache.set(Class, Wrapper); } function Wrapper() { return _construct(Class, arguments, _getPrototypeOf(this).constructor); } Wrapper.prototype = Object.create(Class.prototype, { constructor: { value: Wrapper, enumerable: false, writable: true, configurable: true } }); return _setPrototypeOf(Wrapper, Class); }; return _wrapNativeSuper(Class); }\n\nfunction _construct(Parent, args, Class) { if (_isNativeReflectConstruct()) { _construct = Reflect.construct; } else { _construct = function _construct(Parent, args, Class) { var a = [null]; a.push.apply(a, args); var Constructor = Function.bind.apply(Parent, a); var instance = new Constructor(); if (Class) _setPrototypeOf(instance, Class.prototype); return instance; }; } return _construct.apply(null, arguments); }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Date.prototype.toString.call(Reflect.construct(Date, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _isNativeFunction(fn) { return Function.toString.call(fn).indexOf(\"[native code]\") !== -1; }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\nimport isObjectLike from \"../jsutils/isObjectLike.mjs\";\nimport { SYMBOL_TO_STRING_TAG } from \"../polyfills/symbols.mjs\";\nimport { getLocation } from \"../language/location.mjs\";\nimport { printLocation, printSourceLocation } from \"../language/printLocation.mjs\";\n/**\n * A GraphQLError describes an Error found during the parse, validate, or\n * execute phases of performing a GraphQL operation. In addition to a message\n * and stack trace, it also includes information about the locations in a\n * GraphQL document and/or execution result that correspond to the Error.\n */\n\nexport var GraphQLError = /*#__PURE__*/function (_Error) {\n  _inherits(GraphQLError, _Error);\n\n  var _super = _createSuper(GraphQLError);\n\n  /**\n   * An array of { line, column } locations within the source GraphQL document\n   * which correspond to this error.\n   *\n   * Errors during validation often contain multiple locations, for example to\n   * point out two things with the same name. Errors during execution include a\n   * single location, the field which produced the error.\n   *\n   * Enumerable, and appears in the result of JSON.stringify().\n   */\n\n  /**\n   * An array describing the JSON-path into the execution response which\n   * corresponds to this error. Only included for errors during execution.\n   *\n   * Enumerable, and appears in the result of JSON.stringify().\n   */\n\n  /**\n   * An array of GraphQL AST Nodes corresponding to this error.\n   */\n\n  /**\n   * The source GraphQL document for the first location of this error.\n   *\n   * Note that if this Error represents more than one node, the source may not\n   * represent nodes after the first node.\n   */\n\n  /**\n   * An array of character offsets within the source GraphQL document\n   * which correspond to this error.\n   */\n\n  /**\n   * The original error thrown from a field resolver during execution.\n   */\n\n  /**\n   * Extension fields to add to the formatted error.\n   */\n  function GraphQLError(message, nodes, source, positions, path, originalError, extensions) {\n    var _nodeLocations, _nodeLocations2, _nodeLocations3;\n\n    var _this;\n\n    _classCallCheck(this, GraphQLError);\n\n    _this = _super.call(this, message);\n    _this.name = 'GraphQLError';\n    _this.originalError = originalError !== null && originalError !== void 0 ? originalError : undefined; // Compute list of blame nodes.\n\n    _this.nodes = undefinedIfEmpty(Array.isArray(nodes) ? nodes : nodes ? [nodes] : undefined);\n    var nodeLocations = [];\n\n    for (var _i2 = 0, _ref3 = (_this$nodes = _this.nodes) !== null && _this$nodes !== void 0 ? _this$nodes : []; _i2 < _ref3.length; _i2++) {\n      var _this$nodes;\n\n      var _ref4 = _ref3[_i2];\n      var loc = _ref4.loc;\n\n      if (loc != null) {\n        nodeLocations.push(loc);\n      }\n    }\n\n    nodeLocations = undefinedIfEmpty(nodeLocations); // Compute locations in the source for the given nodes/positions.\n\n    _this.source = source !== null && source !== void 0 ? source : (_nodeLocations = nodeLocations) === null || _nodeLocations === void 0 ? void 0 : _nodeLocations[0].source;\n    _this.positions = positions !== null && positions !== void 0 ? positions : (_nodeLocations2 = nodeLocations) === null || _nodeLocations2 === void 0 ? void 0 : _nodeLocations2.map(function (loc) {\n      return loc.start;\n    });\n    _this.locations = positions && source ? positions.map(function (pos) {\n      return getLocation(source, pos);\n    }) : (_nodeLocations3 = nodeLocations) === null || _nodeLocations3 === void 0 ? void 0 : _nodeLocations3.map(function (loc) {\n      return getLocation(loc.source, loc.start);\n    });\n    _this.path = path !== null && path !== void 0 ? path : undefined;\n    var originalExtensions = originalError === null || originalError === void 0 ? void 0 : originalError.extensions;\n\n    if (extensions == null && isObjectLike(originalExtensions)) {\n      _this.extensions = _objectSpread({}, originalExtensions);\n    } else {\n      _this.extensions = extensions !== null && extensions !== void 0 ? extensions : {};\n    } // By being enumerable, JSON.stringify will include bellow properties in the resulting output.\n    // This ensures that the simplest possible GraphQL service adheres to the spec.\n\n\n    Object.defineProperties(_assertThisInitialized(_this), {\n      message: {\n        enumerable: true\n      },\n      locations: {\n        enumerable: _this.locations != null\n      },\n      path: {\n        enumerable: _this.path != null\n      },\n      extensions: {\n        enumerable: _this.extensions != null && Object.keys(_this.extensions).length > 0\n      },\n      name: {\n        enumerable: false\n      },\n      nodes: {\n        enumerable: false\n      },\n      source: {\n        enumerable: false\n      },\n      positions: {\n        enumerable: false\n      },\n      originalError: {\n        enumerable: false\n      }\n    }); // Include (non-enumerable) stack trace.\n\n    if (originalError !== null && originalError !== void 0 && originalError.stack) {\n      Object.defineProperty(_assertThisInitialized(_this), 'stack', {\n        value: originalError.stack,\n        writable: true,\n        configurable: true\n      });\n      return _possibleConstructorReturn(_this);\n    } // istanbul ignore next (See: 'https://github.com/graphql/graphql-js/issues/2317')\n\n\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(_assertThisInitialized(_this), GraphQLError);\n    } else {\n      Object.defineProperty(_assertThisInitialized(_this), 'stack', {\n        value: Error().stack,\n        writable: true,\n        configurable: true\n      });\n    }\n\n    return _this;\n  }\n\n  _createClass(GraphQLError, [{\n    key: \"toString\",\n    value: function toString() {\n      return printError(this);\n    } // FIXME: workaround to not break chai comparisons, should be remove in v16\n    // $FlowFixMe[unsupported-syntax] Flow doesn't support computed properties yet\n\n  }, {\n    key: SYMBOL_TO_STRING_TAG,\n    get: function get() {\n      return 'Object';\n    }\n  }]);\n\n  return GraphQLError;\n}( /*#__PURE__*/_wrapNativeSuper(Error));\n\nfunction undefinedIfEmpty(array) {\n  return array === undefined || array.length === 0 ? undefined : array;\n}\n/**\n * Prints a GraphQLError to a string, representing useful location information\n * about the error's position in the source.\n */\n\n\nexport function printError(error) {\n  var output = error.message;\n\n  if (error.nodes) {\n    for (var _i4 = 0, _error$nodes2 = error.nodes; _i4 < _error$nodes2.length; _i4++) {\n      var node = _error$nodes2[_i4];\n\n      if (node.loc) {\n        output += '\\n\\n' + printLocation(node.loc);\n      }\n    }\n  } else if (error.source && error.locations) {\n    for (var _i6 = 0, _error$locations2 = error.locations; _i6 < _error$locations2.length; _i6++) {\n      var location = _error$locations2[_i6];\n      output += '\\n\\n' + printSourceLocation(error.source, location);\n    }\n  }\n\n  return output;\n}\n","import { GraphQLError } from \"./GraphQLError.mjs\";\n/**\n * Produces a GraphQLError representing a syntax error, containing useful\n * descriptive information about the syntax error's position in the source.\n */\n\nexport function syntaxError(source, position, description) {\n  return new GraphQLError(\"Syntax Error: \".concat(description), undefined, source, [position]);\n}\n","import invariant from \"./invariant.mjs\";\nimport nodejsCustomInspectSymbol from \"./nodejsCustomInspectSymbol.mjs\";\n/**\n * The `defineInspect()` function defines `inspect()` prototype method as alias of `toJSON`\n */\n\nexport default function defineInspect(classObject) {\n  var fn = classObject.prototype.toJSON;\n  typeof fn === 'function' || invariant(0);\n  classObject.prototype.inspect = fn; // istanbul ignore else (See: 'https://github.com/graphql/graphql-js/issues/2317')\n\n  if (nodejsCustomInspectSymbol) {\n    classObject.prototype[nodejsCustomInspectSymbol] = fn;\n  }\n}\n","export default function devAssert(condition, message) {\n  var booleanCondition = Boolean(condition); // istanbul ignore else (See transformation done in './resources/inlineInvariant.js')\n\n  if (!booleanCondition) {\n    throw new Error(message);\n  }\n}\n","function _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\n/* eslint-disable flowtype/no-weak-types */\nimport nodejsCustomInspectSymbol from \"./nodejsCustomInspectSymbol.mjs\";\nvar MAX_ARRAY_LENGTH = 10;\nvar MAX_RECURSIVE_DEPTH = 2;\n/**\n * Used to print values in error messages.\n */\n\nexport default function inspect(value) {\n  return formatValue(value, []);\n}\n\nfunction formatValue(value, seenValues) {\n  switch (_typeof(value)) {\n    case 'string':\n      return JSON.stringify(value);\n\n    case 'function':\n      return value.name ? \"[function \".concat(value.name, \"]\") : '[function]';\n\n    case 'object':\n      if (value === null) {\n        return 'null';\n      }\n\n      return formatObjectValue(value, seenValues);\n\n    default:\n      return String(value);\n  }\n}\n\nfunction formatObjectValue(value, previouslySeenValues) {\n  if (previouslySeenValues.indexOf(value) !== -1) {\n    return '[Circular]';\n  }\n\n  var seenValues = [].concat(previouslySeenValues, [value]);\n  var customInspectFn = getCustomFn(value);\n\n  if (customInspectFn !== undefined) {\n    var customValue = customInspectFn.call(value); // check for infinite recursion\n\n    if (customValue !== value) {\n      return typeof customValue === 'string' ? customValue : formatValue(customValue, seenValues);\n    }\n  } else if (Array.isArray(value)) {\n    return formatArray(value, seenValues);\n  }\n\n  return formatObject(value, seenValues);\n}\n\nfunction formatObject(object, seenValues) {\n  var keys = Object.keys(object);\n\n  if (keys.length === 0) {\n    return '{}';\n  }\n\n  if (seenValues.length > MAX_RECURSIVE_DEPTH) {\n    return '[' + getObjectTag(object) + ']';\n  }\n\n  var properties = keys.map(function (key) {\n    var value = formatValue(object[key], seenValues);\n    return key + ': ' + value;\n  });\n  return '{ ' + properties.join(', ') + ' }';\n}\n\nfunction formatArray(array, seenValues) {\n  if (array.length === 0) {\n    return '[]';\n  }\n\n  if (seenValues.length > MAX_RECURSIVE_DEPTH) {\n    return '[Array]';\n  }\n\n  var len = Math.min(MAX_ARRAY_LENGTH, array.length);\n  var remaining = array.length - len;\n  var items = [];\n\n  for (var i = 0; i < len; ++i) {\n    items.push(formatValue(array[i], seenValues));\n  }\n\n  if (remaining === 1) {\n    items.push('... 1 more item');\n  } else if (remaining > 1) {\n    items.push(\"... \".concat(remaining, \" more items\"));\n  }\n\n  return '[' + items.join(', ') + ']';\n}\n\nfunction getCustomFn(object) {\n  var customInspectFn = object[String(nodejsCustomInspectSymbol)];\n\n  if (typeof customInspectFn === 'function') {\n    return customInspectFn;\n  }\n\n  if (typeof object.inspect === 'function') {\n    return object.inspect;\n  }\n}\n\nfunction getObjectTag(object) {\n  var tag = Object.prototype.toString.call(object).replace(/^\\[object /, '').replace(/]$/, '');\n\n  if (tag === 'Object' && typeof object.constructor === 'function') {\n    var name = object.constructor.name;\n\n    if (typeof name === 'string' && name !== '') {\n      return name;\n    }\n  }\n\n  return tag;\n}\n","function _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nimport inspect from \"./inspect.mjs\";\n/**\n * A replacement for instanceof which includes an error warning when multi-realm\n * constructors are detected.\n */\n\n// See: https://expressjs.com/en/advanced/best-practice-performance.html#set-node_env-to-production\n// See: https://webpack.js.org/guides/production/\nexport default process.env.NODE_ENV === 'production' ? // istanbul ignore next (See: 'https://github.com/graphql/graphql-js/issues/2317')\n// eslint-disable-next-line no-shadow\nfunction instanceOf(value, constructor) {\n  return value instanceof constructor;\n} : // eslint-disable-next-line no-shadow\nfunction instanceOf(value, constructor) {\n  if (value instanceof constructor) {\n    return true;\n  }\n\n  if (_typeof(value) === 'object' && value !== null) {\n    var _value$constructor;\n\n    var className = constructor.prototype[Symbol.toStringTag];\n    var valueClassName = // We still need to support constructor's name to detect conflicts with older versions of this library.\n    Symbol.toStringTag in value ? value[Symbol.toStringTag] : (_value$constructor = value.constructor) === null || _value$constructor === void 0 ? void 0 : _value$constructor.name;\n\n    if (className === valueClassName) {\n      var stringifiedValue = inspect(value);\n      throw new Error(\"Cannot use \".concat(className, \" \\\"\").concat(stringifiedValue, \"\\\" from another module or realm.\\n\\nEnsure that there is only one instance of \\\"graphql\\\" in the node_modules\\ndirectory. If different versions of \\\"graphql\\\" are the dependencies of other\\nrelied on modules, use \\\"resolutions\\\" to ensure only one version is installed.\\n\\nhttps://yarnpkg.com/en/docs/selective-version-resolutions\\n\\nDuplicate \\\"graphql\\\" modules cannot be used at the same time since different\\nversions may have different capabilities and behavior. The data from one\\nversion used in the function from another could produce confusing and\\nspurious results.\"));\n    }\n  }\n\n  return false;\n};\n","export default function invariant(condition, message) {\n  var booleanCondition = Boolean(condition); // istanbul ignore else (See transformation done in './resources/inlineInvariant.js')\n\n  if (!booleanCondition) {\n    throw new Error(message != null ? message : 'Unexpected invariant triggered.');\n  }\n}\n","function _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\n/**\n * Return true if `value` is object-like. A value is object-like if it's not\n * `null` and has a `typeof` result of \"object\".\n */\nexport default function isObjectLike(value) {\n  return _typeof(value) == 'object' && value !== null;\n}\n","// istanbul ignore next (See: 'https://github.com/graphql/graphql-js/issues/2317')\nvar nodejsCustomInspectSymbol = typeof Symbol === 'function' && typeof Symbol.for === 'function' ? Symbol.for('nodejs.util.inspect.custom') : undefined;\nexport default nodejsCustomInspectSymbol;\n","import defineInspect from \"../jsutils/defineInspect.mjs\";\n\n/**\n * Contains a range of UTF-8 character offsets and token references that\n * identify the region of the source from which the AST derived.\n */\nexport var Location = /*#__PURE__*/function () {\n  /**\n   * The character offset at which this Node begins.\n   */\n\n  /**\n   * The character offset at which this Node ends.\n   */\n\n  /**\n   * The Token at which this Node begins.\n   */\n\n  /**\n   * The Token at which this Node ends.\n   */\n\n  /**\n   * The Source document the AST represents.\n   */\n  function Location(startToken, endToken, source) {\n    this.start = startToken.start;\n    this.end = endToken.end;\n    this.startToken = startToken;\n    this.endToken = endToken;\n    this.source = source;\n  }\n\n  var _proto = Location.prototype;\n\n  _proto.toJSON = function toJSON() {\n    return {\n      start: this.start,\n      end: this.end\n    };\n  };\n\n  return Location;\n}(); // Print a simplified form when appearing in `inspect` and `util.inspect`.\n\ndefineInspect(Location);\n/**\n * Represents a range of characters represented by a lexical token\n * within a Source.\n */\n\nexport var Token = /*#__PURE__*/function () {\n  /**\n   * The kind of Token.\n   */\n\n  /**\n   * The character offset at which this Node begins.\n   */\n\n  /**\n   * The character offset at which this Node ends.\n   */\n\n  /**\n   * The 1-indexed line number on which this Token appears.\n   */\n\n  /**\n   * The 1-indexed column number at which this Token begins.\n   */\n\n  /**\n   * For non-punctuation tokens, represents the interpreted value of the token.\n   */\n\n  /**\n   * Tokens exist as nodes in a double-linked-list amongst all tokens\n   * including ignored tokens. <SOF> is always the first node and <EOF>\n   * the last.\n   */\n  function Token(kind, start, end, line, column, prev, value) {\n    this.kind = kind;\n    this.start = start;\n    this.end = end;\n    this.line = line;\n    this.column = column;\n    this.value = value;\n    this.prev = prev;\n    this.next = null;\n  }\n\n  var _proto2 = Token.prototype;\n\n  _proto2.toJSON = function toJSON() {\n    return {\n      kind: this.kind,\n      value: this.value,\n      line: this.line,\n      column: this.column\n    };\n  };\n\n  return Token;\n}(); // Print a simplified form when appearing in `inspect` and `util.inspect`.\n\ndefineInspect(Token);\n/**\n * @internal\n */\n\nexport function isNode(maybeNode) {\n  return maybeNode != null && typeof maybeNode.kind === 'string';\n}\n/**\n * The list of all possible AST node types.\n */\n","/**\n * Produces the value of a block string from its parsed raw value, similar to\n * CoffeeScript's block string, Python's docstring trim or Ruby's strip_heredoc.\n *\n * This implements the GraphQL spec's BlockStringValue() static algorithm.\n *\n * @internal\n */\nexport function dedentBlockStringValue(rawString) {\n  // Expand a block string's raw value into independent lines.\n  var lines = rawString.split(/\\r\\n|[\\n\\r]/g); // Remove common indentation from all lines but first.\n\n  var commonIndent = getBlockStringIndentation(rawString);\n\n  if (commonIndent !== 0) {\n    for (var i = 1; i < lines.length; i++) {\n      lines[i] = lines[i].slice(commonIndent);\n    }\n  } // Remove leading and trailing blank lines.\n\n\n  var startLine = 0;\n\n  while (startLine < lines.length && isBlank(lines[startLine])) {\n    ++startLine;\n  }\n\n  var endLine = lines.length;\n\n  while (endLine > startLine && isBlank(lines[endLine - 1])) {\n    --endLine;\n  } // Return a string of the lines joined with U+000A.\n\n\n  return lines.slice(startLine, endLine).join('\\n');\n}\n\nfunction isBlank(str) {\n  for (var i = 0; i < str.length; ++i) {\n    if (str[i] !== ' ' && str[i] !== '\\t') {\n      return false;\n    }\n  }\n\n  return true;\n}\n/**\n * @internal\n */\n\n\nexport function getBlockStringIndentation(value) {\n  var _commonIndent;\n\n  var isFirstLine = true;\n  var isEmptyLine = true;\n  var indent = 0;\n  var commonIndent = null;\n\n  for (var i = 0; i < value.length; ++i) {\n    switch (value.charCodeAt(i)) {\n      case 13:\n        //  \\r\n        if (value.charCodeAt(i + 1) === 10) {\n          ++i; // skip \\r\\n as one symbol\n        }\n\n      // falls through\n\n      case 10:\n        //  \\n\n        isFirstLine = false;\n        isEmptyLine = true;\n        indent = 0;\n        break;\n\n      case 9: //   \\t\n\n      case 32:\n        //  <space>\n        ++indent;\n        break;\n\n      default:\n        if (isEmptyLine && !isFirstLine && (commonIndent === null || indent < commonIndent)) {\n          commonIndent = indent;\n        }\n\n        isEmptyLine = false;\n    }\n  }\n\n  return (_commonIndent = commonIndent) !== null && _commonIndent !== void 0 ? _commonIndent : 0;\n}\n/**\n * Print a block string in the indented block form by adding a leading and\n * trailing blank line. However, if a block string starts with whitespace and is\n * a single-line, adding a leading blank line would strip that whitespace.\n *\n * @internal\n */\n\nexport function printBlockString(value) {\n  var indentation = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : '';\n  var preferMultipleLines = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n  var isSingleLine = value.indexOf('\\n') === -1;\n  var hasLeadingSpace = value[0] === ' ' || value[0] === '\\t';\n  var hasTrailingQuote = value[value.length - 1] === '\"';\n  var hasTrailingSlash = value[value.length - 1] === '\\\\';\n  var printAsMultipleLines = !isSingleLine || hasTrailingQuote || hasTrailingSlash || preferMultipleLines;\n  var result = ''; // Format a multi-line block quote to account for leading space.\n\n  if (printAsMultipleLines && !(isSingleLine && hasLeadingSpace)) {\n    result += '\\n' + indentation;\n  }\n\n  result += indentation ? value.replace(/\\n/g, '\\n' + indentation) : value;\n\n  if (printAsMultipleLines) {\n    result += '\\n';\n  }\n\n  return '\"\"\"' + result.replace(/\"\"\"/g, '\\\\\"\"\"') + '\"\"\"';\n}\n","/**\n * The set of allowed directive location values.\n */\nexport var DirectiveLocation = Object.freeze({\n  // Request Definitions\n  QUERY: 'QUERY',\n  MUTATION: 'MUTATION',\n  SUBSCRIPTION: 'SUBSCRIPTION',\n  FIELD: 'FIELD',\n  FRAGMENT_DEFINITION: 'FRAGMENT_DEFINITION',\n  FRAGMENT_SPREAD: 'FRAGMENT_SPREAD',\n  INLINE_FRAGMENT: 'INLINE_FRAGMENT',\n  VARIABLE_DEFINITION: 'VARIABLE_DEFINITION',\n  // Type System Definitions\n  SCHEMA: 'SCHEMA',\n  SCALAR: 'SCALAR',\n  OBJECT: 'OBJECT',\n  FIELD_DEFINITION: 'FIELD_DEFINITION',\n  ARGUMENT_DEFINITION: 'ARGUMENT_DEFINITION',\n  INTERFACE: 'INTERFACE',\n  UNION: 'UNION',\n  ENUM: 'ENUM',\n  ENUM_VALUE: 'ENUM_VALUE',\n  INPUT_OBJECT: 'INPUT_OBJECT',\n  INPUT_FIELD_DEFINITION: 'INPUT_FIELD_DEFINITION'\n});\n/**\n * The enum type representing the directive location values.\n */\n","/**\n * The set of allowed kind values for AST nodes.\n */\nexport var Kind = Object.freeze({\n  // Name\n  NAME: 'Name',\n  // Document\n  DOCUMENT: 'Document',\n  OPERATION_DEFINITION: 'OperationDefinition',\n  VARIABLE_DEFINITION: 'VariableDefinition',\n  SELECTION_SET: 'SelectionSet',\n  FIELD: 'Field',\n  ARGUMENT: 'Argument',\n  // Fragments\n  FRAGMENT_SPREAD: 'FragmentSpread',\n  INLINE_FRAGMENT: 'InlineFragment',\n  FRAGMENT_DEFINITION: 'FragmentDefinition',\n  // Values\n  VARIABLE: 'Variable',\n  INT: 'IntValue',\n  FLOAT: 'FloatValue',\n  STRING: 'StringValue',\n  BOOLEAN: 'BooleanValue',\n  NULL: 'NullValue',\n  ENUM: 'EnumValue',\n  LIST: 'ListValue',\n  OBJECT: 'ObjectValue',\n  OBJECT_FIELD: 'ObjectField',\n  // Directives\n  DIRECTIVE: 'Directive',\n  // Types\n  NAMED_TYPE: 'NamedType',\n  LIST_TYPE: 'ListType',\n  NON_NULL_TYPE: 'NonNullType',\n  // Type System Definitions\n  SCHEMA_DEFINITION: 'SchemaDefinition',\n  OPERATION_TYPE_DEFINITION: 'OperationTypeDefinition',\n  // Type Definitions\n  SCALAR_TYPE_DEFINITION: 'ScalarTypeDefinition',\n  OBJECT_TYPE_DEFINITION: 'ObjectTypeDefinition',\n  FIELD_DEFINITION: 'FieldDefinition',\n  INPUT_VALUE_DEFINITION: 'InputValueDefinition',\n  INTERFACE_TYPE_DEFINITION: 'InterfaceTypeDefinition',\n  UNION_TYPE_DEFINITION: 'UnionTypeDefinition',\n  ENUM_TYPE_DEFINITION: 'EnumTypeDefinition',\n  ENUM_VALUE_DEFINITION: 'EnumValueDefinition',\n  INPUT_OBJECT_TYPE_DEFINITION: 'InputObjectTypeDefinition',\n  // Directive Definitions\n  DIRECTIVE_DEFINITION: 'DirectiveDefinition',\n  // Type System Extensions\n  SCHEMA_EXTENSION: 'SchemaExtension',\n  // Type Extensions\n  SCALAR_TYPE_EXTENSION: 'ScalarTypeExtension',\n  OBJECT_TYPE_EXTENSION: 'ObjectTypeExtension',\n  INTERFACE_TYPE_EXTENSION: 'InterfaceTypeExtension',\n  UNION_TYPE_EXTENSION: 'UnionTypeExtension',\n  ENUM_TYPE_EXTENSION: 'EnumTypeExtension',\n  INPUT_OBJECT_TYPE_EXTENSION: 'InputObjectTypeExtension'\n});\n/**\n * The enum type representing the possible kind values of AST nodes.\n */\n","import { syntaxError } from \"../error/syntaxError.mjs\";\nimport { Token } from \"./ast.mjs\";\nimport { TokenKind } from \"./tokenKind.mjs\";\nimport { dedentBlockStringValue } from \"./blockString.mjs\";\n/**\n * Given a Source object, creates a Lexer for that source.\n * A Lexer is a stateful stream generator in that every time\n * it is advanced, it returns the next token in the Source. Assuming the\n * source lexes, the final Token emitted by the lexer will be of kind\n * EOF, after which the lexer will repeatedly return the same EOF token\n * whenever called.\n */\n\nexport var Lexer = /*#__PURE__*/function () {\n  /**\n   * The previously focused non-ignored token.\n   */\n\n  /**\n   * The currently focused non-ignored token.\n   */\n\n  /**\n   * The (1-indexed) line containing the current token.\n   */\n\n  /**\n   * The character offset at which the current line begins.\n   */\n  function Lexer(source) {\n    var startOfFileToken = new Token(TokenKind.SOF, 0, 0, 0, 0, null);\n    this.source = source;\n    this.lastToken = startOfFileToken;\n    this.token = startOfFileToken;\n    this.line = 1;\n    this.lineStart = 0;\n  }\n  /**\n   * Advances the token stream to the next non-ignored token.\n   */\n\n\n  var _proto = Lexer.prototype;\n\n  _proto.advance = function advance() {\n    this.lastToken = this.token;\n    var token = this.token = this.lookahead();\n    return token;\n  }\n  /**\n   * Looks ahead and returns the next non-ignored token, but does not change\n   * the state of Lexer.\n   */\n  ;\n\n  _proto.lookahead = function lookahead() {\n    var token = this.token;\n\n    if (token.kind !== TokenKind.EOF) {\n      do {\n        var _token$next;\n\n        // Note: next is only mutable during parsing, so we cast to allow this.\n        token = (_token$next = token.next) !== null && _token$next !== void 0 ? _token$next : token.next = readToken(this, token);\n      } while (token.kind === TokenKind.COMMENT);\n    }\n\n    return token;\n  };\n\n  return Lexer;\n}();\n/**\n * @internal\n */\n\nexport function isPunctuatorTokenKind(kind) {\n  return kind === TokenKind.BANG || kind === TokenKind.DOLLAR || kind === TokenKind.AMP || kind === TokenKind.PAREN_L || kind === TokenKind.PAREN_R || kind === TokenKind.SPREAD || kind === TokenKind.COLON || kind === TokenKind.EQUALS || kind === TokenKind.AT || kind === TokenKind.BRACKET_L || kind === TokenKind.BRACKET_R || kind === TokenKind.BRACE_L || kind === TokenKind.PIPE || kind === TokenKind.BRACE_R;\n}\n\nfunction printCharCode(code) {\n  return (// NaN/undefined represents access beyond the end of the file.\n    isNaN(code) ? TokenKind.EOF : // Trust JSON for ASCII.\n    code < 0x007f ? JSON.stringify(String.fromCharCode(code)) : // Otherwise print the escaped form.\n    \"\\\"\\\\u\".concat(('00' + code.toString(16).toUpperCase()).slice(-4), \"\\\"\")\n  );\n}\n/**\n * Gets the next token from the source starting at the given position.\n *\n * This skips over whitespace until it finds the next lexable token, then lexes\n * punctuators immediately or calls the appropriate helper function for more\n * complicated tokens.\n */\n\n\nfunction readToken(lexer, prev) {\n  var source = lexer.source;\n  var body = source.body;\n  var bodyLength = body.length;\n  var pos = prev.end;\n\n  while (pos < bodyLength) {\n    var code = body.charCodeAt(pos);\n    var _line = lexer.line;\n\n    var _col = 1 + pos - lexer.lineStart; // SourceCharacter\n\n\n    switch (code) {\n      case 0xfeff: // <BOM>\n\n      case 9: //   \\t\n\n      case 32: //  <space>\n\n      case 44:\n        //  ,\n        ++pos;\n        continue;\n\n      case 10:\n        //  \\n\n        ++pos;\n        ++lexer.line;\n        lexer.lineStart = pos;\n        continue;\n\n      case 13:\n        //  \\r\n        if (body.charCodeAt(pos + 1) === 10) {\n          pos += 2;\n        } else {\n          ++pos;\n        }\n\n        ++lexer.line;\n        lexer.lineStart = pos;\n        continue;\n\n      case 33:\n        //  !\n        return new Token(TokenKind.BANG, pos, pos + 1, _line, _col, prev);\n\n      case 35:\n        //  #\n        return readComment(source, pos, _line, _col, prev);\n\n      case 36:\n        //  $\n        return new Token(TokenKind.DOLLAR, pos, pos + 1, _line, _col, prev);\n\n      case 38:\n        //  &\n        return new Token(TokenKind.AMP, pos, pos + 1, _line, _col, prev);\n\n      case 40:\n        //  (\n        return new Token(TokenKind.PAREN_L, pos, pos + 1, _line, _col, prev);\n\n      case 41:\n        //  )\n        return new Token(TokenKind.PAREN_R, pos, pos + 1, _line, _col, prev);\n\n      case 46:\n        //  .\n        if (body.charCodeAt(pos + 1) === 46 && body.charCodeAt(pos + 2) === 46) {\n          return new Token(TokenKind.SPREAD, pos, pos + 3, _line, _col, prev);\n        }\n\n        break;\n\n      case 58:\n        //  :\n        return new Token(TokenKind.COLON, pos, pos + 1, _line, _col, prev);\n\n      case 61:\n        //  =\n        return new Token(TokenKind.EQUALS, pos, pos + 1, _line, _col, prev);\n\n      case 64:\n        //  @\n        return new Token(TokenKind.AT, pos, pos + 1, _line, _col, prev);\n\n      case 91:\n        //  [\n        return new Token(TokenKind.BRACKET_L, pos, pos + 1, _line, _col, prev);\n\n      case 93:\n        //  ]\n        return new Token(TokenKind.BRACKET_R, pos, pos + 1, _line, _col, prev);\n\n      case 123:\n        // {\n        return new Token(TokenKind.BRACE_L, pos, pos + 1, _line, _col, prev);\n\n      case 124:\n        // |\n        return new Token(TokenKind.PIPE, pos, pos + 1, _line, _col, prev);\n\n      case 125:\n        // }\n        return new Token(TokenKind.BRACE_R, pos, pos + 1, _line, _col, prev);\n\n      case 34:\n        //  \"\n        if (body.charCodeAt(pos + 1) === 34 && body.charCodeAt(pos + 2) === 34) {\n          return readBlockString(source, pos, _line, _col, prev, lexer);\n        }\n\n        return readString(source, pos, _line, _col, prev);\n\n      case 45: //  -\n\n      case 48: //  0\n\n      case 49: //  1\n\n      case 50: //  2\n\n      case 51: //  3\n\n      case 52: //  4\n\n      case 53: //  5\n\n      case 54: //  6\n\n      case 55: //  7\n\n      case 56: //  8\n\n      case 57:\n        //  9\n        return readNumber(source, pos, code, _line, _col, prev);\n\n      case 65: //  A\n\n      case 66: //  B\n\n      case 67: //  C\n\n      case 68: //  D\n\n      case 69: //  E\n\n      case 70: //  F\n\n      case 71: //  G\n\n      case 72: //  H\n\n      case 73: //  I\n\n      case 74: //  J\n\n      case 75: //  K\n\n      case 76: //  L\n\n      case 77: //  M\n\n      case 78: //  N\n\n      case 79: //  O\n\n      case 80: //  P\n\n      case 81: //  Q\n\n      case 82: //  R\n\n      case 83: //  S\n\n      case 84: //  T\n\n      case 85: //  U\n\n      case 86: //  V\n\n      case 87: //  W\n\n      case 88: //  X\n\n      case 89: //  Y\n\n      case 90: //  Z\n\n      case 95: //  _\n\n      case 97: //  a\n\n      case 98: //  b\n\n      case 99: //  c\n\n      case 100: // d\n\n      case 101: // e\n\n      case 102: // f\n\n      case 103: // g\n\n      case 104: // h\n\n      case 105: // i\n\n      case 106: // j\n\n      case 107: // k\n\n      case 108: // l\n\n      case 109: // m\n\n      case 110: // n\n\n      case 111: // o\n\n      case 112: // p\n\n      case 113: // q\n\n      case 114: // r\n\n      case 115: // s\n\n      case 116: // t\n\n      case 117: // u\n\n      case 118: // v\n\n      case 119: // w\n\n      case 120: // x\n\n      case 121: // y\n\n      case 122:\n        // z\n        return readName(source, pos, _line, _col, prev);\n    }\n\n    throw syntaxError(source, pos, unexpectedCharacterMessage(code));\n  }\n\n  var line = lexer.line;\n  var col = 1 + pos - lexer.lineStart;\n  return new Token(TokenKind.EOF, bodyLength, bodyLength, line, col, prev);\n}\n/**\n * Report a message that an unexpected character was encountered.\n */\n\n\nfunction unexpectedCharacterMessage(code) {\n  if (code < 0x0020 && code !== 0x0009 && code !== 0x000a && code !== 0x000d) {\n    return \"Cannot contain the invalid character \".concat(printCharCode(code), \".\");\n  }\n\n  if (code === 39) {\n    // '\n    return 'Unexpected single quote character (\\'), did you mean to use a double quote (\")?';\n  }\n\n  return \"Cannot parse the unexpected character \".concat(printCharCode(code), \".\");\n}\n/**\n * Reads a comment token from the source file.\n *\n * #[\\u0009\\u0020-\\uFFFF]*\n */\n\n\nfunction readComment(source, start, line, col, prev) {\n  var body = source.body;\n  var code;\n  var position = start;\n\n  do {\n    code = body.charCodeAt(++position);\n  } while (!isNaN(code) && ( // SourceCharacter but not LineTerminator\n  code > 0x001f || code === 0x0009));\n\n  return new Token(TokenKind.COMMENT, start, position, line, col, prev, body.slice(start + 1, position));\n}\n/**\n * Reads a number token from the source file, either a float\n * or an int depending on whether a decimal point appears.\n *\n * Int:   -?(0|[1-9][0-9]*)\n * Float: -?(0|[1-9][0-9]*)(\\.[0-9]+)?((E|e)(+|-)?[0-9]+)?\n */\n\n\nfunction readNumber(source, start, firstCode, line, col, prev) {\n  var body = source.body;\n  var code = firstCode;\n  var position = start;\n  var isFloat = false;\n\n  if (code === 45) {\n    // -\n    code = body.charCodeAt(++position);\n  }\n\n  if (code === 48) {\n    // 0\n    code = body.charCodeAt(++position);\n\n    if (code >= 48 && code <= 57) {\n      throw syntaxError(source, position, \"Invalid number, unexpected digit after 0: \".concat(printCharCode(code), \".\"));\n    }\n  } else {\n    position = readDigits(source, position, code);\n    code = body.charCodeAt(position);\n  }\n\n  if (code === 46) {\n    // .\n    isFloat = true;\n    code = body.charCodeAt(++position);\n    position = readDigits(source, position, code);\n    code = body.charCodeAt(position);\n  }\n\n  if (code === 69 || code === 101) {\n    // E e\n    isFloat = true;\n    code = body.charCodeAt(++position);\n\n    if (code === 43 || code === 45) {\n      // + -\n      code = body.charCodeAt(++position);\n    }\n\n    position = readDigits(source, position, code);\n    code = body.charCodeAt(position);\n  } // Numbers cannot be followed by . or NameStart\n\n\n  if (code === 46 || isNameStart(code)) {\n    throw syntaxError(source, position, \"Invalid number, expected digit but got: \".concat(printCharCode(code), \".\"));\n  }\n\n  return new Token(isFloat ? TokenKind.FLOAT : TokenKind.INT, start, position, line, col, prev, body.slice(start, position));\n}\n/**\n * Returns the new position in the source after reading digits.\n */\n\n\nfunction readDigits(source, start, firstCode) {\n  var body = source.body;\n  var position = start;\n  var code = firstCode;\n\n  if (code >= 48 && code <= 57) {\n    // 0 - 9\n    do {\n      code = body.charCodeAt(++position);\n    } while (code >= 48 && code <= 57); // 0 - 9\n\n\n    return position;\n  }\n\n  throw syntaxError(source, position, \"Invalid number, expected digit but got: \".concat(printCharCode(code), \".\"));\n}\n/**\n * Reads a string token from the source file.\n *\n * \"([^\"\\\\\\u000A\\u000D]|(\\\\(u[0-9a-fA-F]{4}|[\"\\\\/bfnrt])))*\"\n */\n\n\nfunction readString(source, start, line, col, prev) {\n  var body = source.body;\n  var position = start + 1;\n  var chunkStart = position;\n  var code = 0;\n  var value = '';\n\n  while (position < body.length && !isNaN(code = body.charCodeAt(position)) && // not LineTerminator\n  code !== 0x000a && code !== 0x000d) {\n    // Closing Quote (\")\n    if (code === 34) {\n      value += body.slice(chunkStart, position);\n      return new Token(TokenKind.STRING, start, position + 1, line, col, prev, value);\n    } // SourceCharacter\n\n\n    if (code < 0x0020 && code !== 0x0009) {\n      throw syntaxError(source, position, \"Invalid character within String: \".concat(printCharCode(code), \".\"));\n    }\n\n    ++position;\n\n    if (code === 92) {\n      // \\\n      value += body.slice(chunkStart, position - 1);\n      code = body.charCodeAt(position);\n\n      switch (code) {\n        case 34:\n          value += '\"';\n          break;\n\n        case 47:\n          value += '/';\n          break;\n\n        case 92:\n          value += '\\\\';\n          break;\n\n        case 98:\n          value += '\\b';\n          break;\n\n        case 102:\n          value += '\\f';\n          break;\n\n        case 110:\n          value += '\\n';\n          break;\n\n        case 114:\n          value += '\\r';\n          break;\n\n        case 116:\n          value += '\\t';\n          break;\n\n        case 117:\n          {\n            // uXXXX\n            var charCode = uniCharCode(body.charCodeAt(position + 1), body.charCodeAt(position + 2), body.charCodeAt(position + 3), body.charCodeAt(position + 4));\n\n            if (charCode < 0) {\n              var invalidSequence = body.slice(position + 1, position + 5);\n              throw syntaxError(source, position, \"Invalid character escape sequence: \\\\u\".concat(invalidSequence, \".\"));\n            }\n\n            value += String.fromCharCode(charCode);\n            position += 4;\n            break;\n          }\n\n        default:\n          throw syntaxError(source, position, \"Invalid character escape sequence: \\\\\".concat(String.fromCharCode(code), \".\"));\n      }\n\n      ++position;\n      chunkStart = position;\n    }\n  }\n\n  throw syntaxError(source, position, 'Unterminated string.');\n}\n/**\n * Reads a block string token from the source file.\n *\n * \"\"\"(\"?\"?(\\\\\"\"\"|\\\\(?!=\"\"\")|[^\"\\\\]))*\"\"\"\n */\n\n\nfunction readBlockString(source, start, line, col, prev, lexer) {\n  var body = source.body;\n  var position = start + 3;\n  var chunkStart = position;\n  var code = 0;\n  var rawValue = '';\n\n  while (position < body.length && !isNaN(code = body.charCodeAt(position))) {\n    // Closing Triple-Quote (\"\"\")\n    if (code === 34 && body.charCodeAt(position + 1) === 34 && body.charCodeAt(position + 2) === 34) {\n      rawValue += body.slice(chunkStart, position);\n      return new Token(TokenKind.BLOCK_STRING, start, position + 3, line, col, prev, dedentBlockStringValue(rawValue));\n    } // SourceCharacter\n\n\n    if (code < 0x0020 && code !== 0x0009 && code !== 0x000a && code !== 0x000d) {\n      throw syntaxError(source, position, \"Invalid character within String: \".concat(printCharCode(code), \".\"));\n    }\n\n    if (code === 10) {\n      // new line\n      ++position;\n      ++lexer.line;\n      lexer.lineStart = position;\n    } else if (code === 13) {\n      // carriage return\n      if (body.charCodeAt(position + 1) === 10) {\n        position += 2;\n      } else {\n        ++position;\n      }\n\n      ++lexer.line;\n      lexer.lineStart = position;\n    } else if ( // Escape Triple-Quote (\\\"\"\")\n    code === 92 && body.charCodeAt(position + 1) === 34 && body.charCodeAt(position + 2) === 34 && body.charCodeAt(position + 3) === 34) {\n      rawValue += body.slice(chunkStart, position) + '\"\"\"';\n      position += 4;\n      chunkStart = position;\n    } else {\n      ++position;\n    }\n  }\n\n  throw syntaxError(source, position, 'Unterminated string.');\n}\n/**\n * Converts four hexadecimal chars to the integer that the\n * string represents. For example, uniCharCode('0','0','0','f')\n * will return 15, and uniCharCode('0','0','f','f') returns 255.\n *\n * Returns a negative number on error, if a char was invalid.\n *\n * This is implemented by noting that char2hex() returns -1 on error,\n * which means the result of ORing the char2hex() will also be negative.\n */\n\n\nfunction uniCharCode(a, b, c, d) {\n  return char2hex(a) << 12 | char2hex(b) << 8 | char2hex(c) << 4 | char2hex(d);\n}\n/**\n * Converts a hex character to its integer value.\n * '0' becomes 0, '9' becomes 9\n * 'A' becomes 10, 'F' becomes 15\n * 'a' becomes 10, 'f' becomes 15\n *\n * Returns -1 on error.\n */\n\n\nfunction char2hex(a) {\n  return a >= 48 && a <= 57 ? a - 48 // 0-9\n  : a >= 65 && a <= 70 ? a - 55 // A-F\n  : a >= 97 && a <= 102 ? a - 87 // a-f\n  : -1;\n}\n/**\n * Reads an alphanumeric + underscore name from the source.\n *\n * [_A-Za-z][_0-9A-Za-z]*\n */\n\n\nfunction readName(source, start, line, col, prev) {\n  var body = source.body;\n  var bodyLength = body.length;\n  var position = start + 1;\n  var code = 0;\n\n  while (position !== bodyLength && !isNaN(code = body.charCodeAt(position)) && (code === 95 || // _\n  code >= 48 && code <= 57 || // 0-9\n  code >= 65 && code <= 90 || // A-Z\n  code >= 97 && code <= 122) // a-z\n  ) {\n    ++position;\n  }\n\n  return new Token(TokenKind.NAME, start, position, line, col, prev, body.slice(start, position));\n} // _ A-Z a-z\n\n\nfunction isNameStart(code) {\n  return code === 95 || code >= 65 && code <= 90 || code >= 97 && code <= 122;\n}\n","/**\n * Represents a location in a Source.\n */\n\n/**\n * Takes a Source and a UTF-8 character offset, and returns the corresponding\n * line and column as a SourceLocation.\n */\nexport function getLocation(source, position) {\n  var lineRegexp = /\\r\\n|[\\n\\r]/g;\n  var line = 1;\n  var column = position + 1;\n  var match;\n\n  while ((match = lineRegexp.exec(source.body)) && match.index < position) {\n    line += 1;\n    column = position + 1 - (match.index + match[0].length);\n  }\n\n  return {\n    line: line,\n    column: column\n  };\n}\n","import { syntaxError } from \"../error/syntaxError.mjs\";\nimport { Kind } from \"./kinds.mjs\";\nimport { Location } from \"./ast.mjs\";\nimport { TokenKind } from \"./tokenKind.mjs\";\nimport { Source, isSource } from \"./source.mjs\";\nimport { DirectiveLocation } from \"./directiveLocation.mjs\";\nimport { Lexer, isPunctuatorTokenKind } from \"./lexer.mjs\";\n/**\n * Configuration options to control parser behavior\n */\n\n/**\n * Given a GraphQL source, parses it into a Document.\n * Throws GraphQLError if a syntax error is encountered.\n */\nexport function parse(source, options) {\n  var parser = new Parser(source, options);\n  return parser.parseDocument();\n}\n/**\n * Given a string containing a GraphQL value (ex. `[42]`), parse the AST for\n * that value.\n * Throws GraphQLError if a syntax error is encountered.\n *\n * This is useful within tools that operate upon GraphQL Values directly and\n * in isolation of complete GraphQL documents.\n *\n * Consider providing the results to the utility function: valueFromAST().\n */\n\nexport function parseValue(source, options) {\n  var parser = new Parser(source, options);\n  parser.expectToken(TokenKind.SOF);\n  var value = parser.parseValueLiteral(false);\n  parser.expectToken(TokenKind.EOF);\n  return value;\n}\n/**\n * Given a string containing a GraphQL Type (ex. `[Int!]`), parse the AST for\n * that type.\n * Throws GraphQLError if a syntax error is encountered.\n *\n * This is useful within tools that operate upon GraphQL Types directly and\n * in isolation of complete GraphQL documents.\n *\n * Consider providing the results to the utility function: typeFromAST().\n */\n\nexport function parseType(source, options) {\n  var parser = new Parser(source, options);\n  parser.expectToken(TokenKind.SOF);\n  var type = parser.parseTypeReference();\n  parser.expectToken(TokenKind.EOF);\n  return type;\n}\n/**\n * This class is exported only to assist people in implementing their own parsers\n * without duplicating too much code and should be used only as last resort for cases\n * such as experimental syntax or if certain features could not be contributed upstream.\n *\n * It is still part of the internal API and is versioned, so any changes to it are never\n * considered breaking changes. If you still need to support multiple versions of the\n * library, please use the `versionInfo` variable for version detection.\n *\n * @internal\n */\n\nexport var Parser = /*#__PURE__*/function () {\n  function Parser(source, options) {\n    var sourceObj = isSource(source) ? source : new Source(source);\n    this._lexer = new Lexer(sourceObj);\n    this._options = options;\n  }\n  /**\n   * Converts a name lex token into a name parse node.\n   */\n\n\n  var _proto = Parser.prototype;\n\n  _proto.parseName = function parseName() {\n    var token = this.expectToken(TokenKind.NAME);\n    return {\n      kind: Kind.NAME,\n      value: token.value,\n      loc: this.loc(token)\n    };\n  } // Implements the parsing rules in the Document section.\n\n  /**\n   * Document : Definition+\n   */\n  ;\n\n  _proto.parseDocument = function parseDocument() {\n    var start = this._lexer.token;\n    return {\n      kind: Kind.DOCUMENT,\n      definitions: this.many(TokenKind.SOF, this.parseDefinition, TokenKind.EOF),\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * Definition :\n   *   - ExecutableDefinition\n   *   - TypeSystemDefinition\n   *   - TypeSystemExtension\n   *\n   * ExecutableDefinition :\n   *   - OperationDefinition\n   *   - FragmentDefinition\n   */\n  ;\n\n  _proto.parseDefinition = function parseDefinition() {\n    if (this.peek(TokenKind.NAME)) {\n      switch (this._lexer.token.value) {\n        case 'query':\n        case 'mutation':\n        case 'subscription':\n          return this.parseOperationDefinition();\n\n        case 'fragment':\n          return this.parseFragmentDefinition();\n\n        case 'schema':\n        case 'scalar':\n        case 'type':\n        case 'interface':\n        case 'union':\n        case 'enum':\n        case 'input':\n        case 'directive':\n          return this.parseTypeSystemDefinition();\n\n        case 'extend':\n          return this.parseTypeSystemExtension();\n      }\n    } else if (this.peek(TokenKind.BRACE_L)) {\n      return this.parseOperationDefinition();\n    } else if (this.peekDescription()) {\n      return this.parseTypeSystemDefinition();\n    }\n\n    throw this.unexpected();\n  } // Implements the parsing rules in the Operations section.\n\n  /**\n   * OperationDefinition :\n   *  - SelectionSet\n   *  - OperationType Name? VariableDefinitions? Directives? SelectionSet\n   */\n  ;\n\n  _proto.parseOperationDefinition = function parseOperationDefinition() {\n    var start = this._lexer.token;\n\n    if (this.peek(TokenKind.BRACE_L)) {\n      return {\n        kind: Kind.OPERATION_DEFINITION,\n        operation: 'query',\n        name: undefined,\n        variableDefinitions: [],\n        directives: [],\n        selectionSet: this.parseSelectionSet(),\n        loc: this.loc(start)\n      };\n    }\n\n    var operation = this.parseOperationType();\n    var name;\n\n    if (this.peek(TokenKind.NAME)) {\n      name = this.parseName();\n    }\n\n    return {\n      kind: Kind.OPERATION_DEFINITION,\n      operation: operation,\n      name: name,\n      variableDefinitions: this.parseVariableDefinitions(),\n      directives: this.parseDirectives(false),\n      selectionSet: this.parseSelectionSet(),\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * OperationType : one of query mutation subscription\n   */\n  ;\n\n  _proto.parseOperationType = function parseOperationType() {\n    var operationToken = this.expectToken(TokenKind.NAME);\n\n    switch (operationToken.value) {\n      case 'query':\n        return 'query';\n\n      case 'mutation':\n        return 'mutation';\n\n      case 'subscription':\n        return 'subscription';\n    }\n\n    throw this.unexpected(operationToken);\n  }\n  /**\n   * VariableDefinitions : ( VariableDefinition+ )\n   */\n  ;\n\n  _proto.parseVariableDefinitions = function parseVariableDefinitions() {\n    return this.optionalMany(TokenKind.PAREN_L, this.parseVariableDefinition, TokenKind.PAREN_R);\n  }\n  /**\n   * VariableDefinition : Variable : Type DefaultValue? Directives[Const]?\n   */\n  ;\n\n  _proto.parseVariableDefinition = function parseVariableDefinition() {\n    var start = this._lexer.token;\n    return {\n      kind: Kind.VARIABLE_DEFINITION,\n      variable: this.parseVariable(),\n      type: (this.expectToken(TokenKind.COLON), this.parseTypeReference()),\n      defaultValue: this.expectOptionalToken(TokenKind.EQUALS) ? this.parseValueLiteral(true) : undefined,\n      directives: this.parseDirectives(true),\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * Variable : $ Name\n   */\n  ;\n\n  _proto.parseVariable = function parseVariable() {\n    var start = this._lexer.token;\n    this.expectToken(TokenKind.DOLLAR);\n    return {\n      kind: Kind.VARIABLE,\n      name: this.parseName(),\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * SelectionSet : { Selection+ }\n   */\n  ;\n\n  _proto.parseSelectionSet = function parseSelectionSet() {\n    var start = this._lexer.token;\n    return {\n      kind: Kind.SELECTION_SET,\n      selections: this.many(TokenKind.BRACE_L, this.parseSelection, TokenKind.BRACE_R),\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * Selection :\n   *   - Field\n   *   - FragmentSpread\n   *   - InlineFragment\n   */\n  ;\n\n  _proto.parseSelection = function parseSelection() {\n    return this.peek(TokenKind.SPREAD) ? this.parseFragment() : this.parseField();\n  }\n  /**\n   * Field : Alias? Name Arguments? Directives? SelectionSet?\n   *\n   * Alias : Name :\n   */\n  ;\n\n  _proto.parseField = function parseField() {\n    var start = this._lexer.token;\n    var nameOrAlias = this.parseName();\n    var alias;\n    var name;\n\n    if (this.expectOptionalToken(TokenKind.COLON)) {\n      alias = nameOrAlias;\n      name = this.parseName();\n    } else {\n      name = nameOrAlias;\n    }\n\n    return {\n      kind: Kind.FIELD,\n      alias: alias,\n      name: name,\n      arguments: this.parseArguments(false),\n      directives: this.parseDirectives(false),\n      selectionSet: this.peek(TokenKind.BRACE_L) ? this.parseSelectionSet() : undefined,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * Arguments[Const] : ( Argument[?Const]+ )\n   */\n  ;\n\n  _proto.parseArguments = function parseArguments(isConst) {\n    var item = isConst ? this.parseConstArgument : this.parseArgument;\n    return this.optionalMany(TokenKind.PAREN_L, item, TokenKind.PAREN_R);\n  }\n  /**\n   * Argument[Const] : Name : Value[?Const]\n   */\n  ;\n\n  _proto.parseArgument = function parseArgument() {\n    var start = this._lexer.token;\n    var name = this.parseName();\n    this.expectToken(TokenKind.COLON);\n    return {\n      kind: Kind.ARGUMENT,\n      name: name,\n      value: this.parseValueLiteral(false),\n      loc: this.loc(start)\n    };\n  };\n\n  _proto.parseConstArgument = function parseConstArgument() {\n    var start = this._lexer.token;\n    return {\n      kind: Kind.ARGUMENT,\n      name: this.parseName(),\n      value: (this.expectToken(TokenKind.COLON), this.parseValueLiteral(true)),\n      loc: this.loc(start)\n    };\n  } // Implements the parsing rules in the Fragments section.\n\n  /**\n   * Corresponds to both FragmentSpread and InlineFragment in the spec.\n   *\n   * FragmentSpread : ... FragmentName Directives?\n   *\n   * InlineFragment : ... TypeCondition? Directives? SelectionSet\n   */\n  ;\n\n  _proto.parseFragment = function parseFragment() {\n    var start = this._lexer.token;\n    this.expectToken(TokenKind.SPREAD);\n    var hasTypeCondition = this.expectOptionalKeyword('on');\n\n    if (!hasTypeCondition && this.peek(TokenKind.NAME)) {\n      return {\n        kind: Kind.FRAGMENT_SPREAD,\n        name: this.parseFragmentName(),\n        directives: this.parseDirectives(false),\n        loc: this.loc(start)\n      };\n    }\n\n    return {\n      kind: Kind.INLINE_FRAGMENT,\n      typeCondition: hasTypeCondition ? this.parseNamedType() : undefined,\n      directives: this.parseDirectives(false),\n      selectionSet: this.parseSelectionSet(),\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * FragmentDefinition :\n   *   - fragment FragmentName on TypeCondition Directives? SelectionSet\n   *\n   * TypeCondition : NamedType\n   */\n  ;\n\n  _proto.parseFragmentDefinition = function parseFragmentDefinition() {\n    var _this$_options;\n\n    var start = this._lexer.token;\n    this.expectKeyword('fragment'); // Experimental support for defining variables within fragments changes\n    // the grammar of FragmentDefinition:\n    //   - fragment FragmentName VariableDefinitions? on TypeCondition Directives? SelectionSet\n\n    if (((_this$_options = this._options) === null || _this$_options === void 0 ? void 0 : _this$_options.experimentalFragmentVariables) === true) {\n      return {\n        kind: Kind.FRAGMENT_DEFINITION,\n        name: this.parseFragmentName(),\n        variableDefinitions: this.parseVariableDefinitions(),\n        typeCondition: (this.expectKeyword('on'), this.parseNamedType()),\n        directives: this.parseDirectives(false),\n        selectionSet: this.parseSelectionSet(),\n        loc: this.loc(start)\n      };\n    }\n\n    return {\n      kind: Kind.FRAGMENT_DEFINITION,\n      name: this.parseFragmentName(),\n      typeCondition: (this.expectKeyword('on'), this.parseNamedType()),\n      directives: this.parseDirectives(false),\n      selectionSet: this.parseSelectionSet(),\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * FragmentName : Name but not `on`\n   */\n  ;\n\n  _proto.parseFragmentName = function parseFragmentName() {\n    if (this._lexer.token.value === 'on') {\n      throw this.unexpected();\n    }\n\n    return this.parseName();\n  } // Implements the parsing rules in the Values section.\n\n  /**\n   * Value[Const] :\n   *   - [~Const] Variable\n   *   - IntValue\n   *   - FloatValue\n   *   - StringValue\n   *   - BooleanValue\n   *   - NullValue\n   *   - EnumValue\n   *   - ListValue[?Const]\n   *   - ObjectValue[?Const]\n   *\n   * BooleanValue : one of `true` `false`\n   *\n   * NullValue : `null`\n   *\n   * EnumValue : Name but not `true`, `false` or `null`\n   */\n  ;\n\n  _proto.parseValueLiteral = function parseValueLiteral(isConst) {\n    var token = this._lexer.token;\n\n    switch (token.kind) {\n      case TokenKind.BRACKET_L:\n        return this.parseList(isConst);\n\n      case TokenKind.BRACE_L:\n        return this.parseObject(isConst);\n\n      case TokenKind.INT:\n        this._lexer.advance();\n\n        return {\n          kind: Kind.INT,\n          value: token.value,\n          loc: this.loc(token)\n        };\n\n      case TokenKind.FLOAT:\n        this._lexer.advance();\n\n        return {\n          kind: Kind.FLOAT,\n          value: token.value,\n          loc: this.loc(token)\n        };\n\n      case TokenKind.STRING:\n      case TokenKind.BLOCK_STRING:\n        return this.parseStringLiteral();\n\n      case TokenKind.NAME:\n        this._lexer.advance();\n\n        switch (token.value) {\n          case 'true':\n            return {\n              kind: Kind.BOOLEAN,\n              value: true,\n              loc: this.loc(token)\n            };\n\n          case 'false':\n            return {\n              kind: Kind.BOOLEAN,\n              value: false,\n              loc: this.loc(token)\n            };\n\n          case 'null':\n            return {\n              kind: Kind.NULL,\n              loc: this.loc(token)\n            };\n\n          default:\n            return {\n              kind: Kind.ENUM,\n              value: token.value,\n              loc: this.loc(token)\n            };\n        }\n\n      case TokenKind.DOLLAR:\n        if (!isConst) {\n          return this.parseVariable();\n        }\n\n        break;\n    }\n\n    throw this.unexpected();\n  };\n\n  _proto.parseStringLiteral = function parseStringLiteral() {\n    var token = this._lexer.token;\n\n    this._lexer.advance();\n\n    return {\n      kind: Kind.STRING,\n      value: token.value,\n      block: token.kind === TokenKind.BLOCK_STRING,\n      loc: this.loc(token)\n    };\n  }\n  /**\n   * ListValue[Const] :\n   *   - [ ]\n   *   - [ Value[?Const]+ ]\n   */\n  ;\n\n  _proto.parseList = function parseList(isConst) {\n    var _this = this;\n\n    var start = this._lexer.token;\n\n    var item = function item() {\n      return _this.parseValueLiteral(isConst);\n    };\n\n    return {\n      kind: Kind.LIST,\n      values: this.any(TokenKind.BRACKET_L, item, TokenKind.BRACKET_R),\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * ObjectValue[Const] :\n   *   - { }\n   *   - { ObjectField[?Const]+ }\n   */\n  ;\n\n  _proto.parseObject = function parseObject(isConst) {\n    var _this2 = this;\n\n    var start = this._lexer.token;\n\n    var item = function item() {\n      return _this2.parseObjectField(isConst);\n    };\n\n    return {\n      kind: Kind.OBJECT,\n      fields: this.any(TokenKind.BRACE_L, item, TokenKind.BRACE_R),\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * ObjectField[Const] : Name : Value[?Const]\n   */\n  ;\n\n  _proto.parseObjectField = function parseObjectField(isConst) {\n    var start = this._lexer.token;\n    var name = this.parseName();\n    this.expectToken(TokenKind.COLON);\n    return {\n      kind: Kind.OBJECT_FIELD,\n      name: name,\n      value: this.parseValueLiteral(isConst),\n      loc: this.loc(start)\n    };\n  } // Implements the parsing rules in the Directives section.\n\n  /**\n   * Directives[Const] : Directive[?Const]+\n   */\n  ;\n\n  _proto.parseDirectives = function parseDirectives(isConst) {\n    var directives = [];\n\n    while (this.peek(TokenKind.AT)) {\n      directives.push(this.parseDirective(isConst));\n    }\n\n    return directives;\n  }\n  /**\n   * Directive[Const] : @ Name Arguments[?Const]?\n   */\n  ;\n\n  _proto.parseDirective = function parseDirective(isConst) {\n    var start = this._lexer.token;\n    this.expectToken(TokenKind.AT);\n    return {\n      kind: Kind.DIRECTIVE,\n      name: this.parseName(),\n      arguments: this.parseArguments(isConst),\n      loc: this.loc(start)\n    };\n  } // Implements the parsing rules in the Types section.\n\n  /**\n   * Type :\n   *   - NamedType\n   *   - ListType\n   *   - NonNullType\n   */\n  ;\n\n  _proto.parseTypeReference = function parseTypeReference() {\n    var start = this._lexer.token;\n    var type;\n\n    if (this.expectOptionalToken(TokenKind.BRACKET_L)) {\n      type = this.parseTypeReference();\n      this.expectToken(TokenKind.BRACKET_R);\n      type = {\n        kind: Kind.LIST_TYPE,\n        type: type,\n        loc: this.loc(start)\n      };\n    } else {\n      type = this.parseNamedType();\n    }\n\n    if (this.expectOptionalToken(TokenKind.BANG)) {\n      return {\n        kind: Kind.NON_NULL_TYPE,\n        type: type,\n        loc: this.loc(start)\n      };\n    }\n\n    return type;\n  }\n  /**\n   * NamedType : Name\n   */\n  ;\n\n  _proto.parseNamedType = function parseNamedType() {\n    var start = this._lexer.token;\n    return {\n      kind: Kind.NAMED_TYPE,\n      name: this.parseName(),\n      loc: this.loc(start)\n    };\n  } // Implements the parsing rules in the Type Definition section.\n\n  /**\n   * TypeSystemDefinition :\n   *   - SchemaDefinition\n   *   - TypeDefinition\n   *   - DirectiveDefinition\n   *\n   * TypeDefinition :\n   *   - ScalarTypeDefinition\n   *   - ObjectTypeDefinition\n   *   - InterfaceTypeDefinition\n   *   - UnionTypeDefinition\n   *   - EnumTypeDefinition\n   *   - InputObjectTypeDefinition\n   */\n  ;\n\n  _proto.parseTypeSystemDefinition = function parseTypeSystemDefinition() {\n    // Many definitions begin with a description and require a lookahead.\n    var keywordToken = this.peekDescription() ? this._lexer.lookahead() : this._lexer.token;\n\n    if (keywordToken.kind === TokenKind.NAME) {\n      switch (keywordToken.value) {\n        case 'schema':\n          return this.parseSchemaDefinition();\n\n        case 'scalar':\n          return this.parseScalarTypeDefinition();\n\n        case 'type':\n          return this.parseObjectTypeDefinition();\n\n        case 'interface':\n          return this.parseInterfaceTypeDefinition();\n\n        case 'union':\n          return this.parseUnionTypeDefinition();\n\n        case 'enum':\n          return this.parseEnumTypeDefinition();\n\n        case 'input':\n          return this.parseInputObjectTypeDefinition();\n\n        case 'directive':\n          return this.parseDirectiveDefinition();\n      }\n    }\n\n    throw this.unexpected(keywordToken);\n  };\n\n  _proto.peekDescription = function peekDescription() {\n    return this.peek(TokenKind.STRING) || this.peek(TokenKind.BLOCK_STRING);\n  }\n  /**\n   * Description : StringValue\n   */\n  ;\n\n  _proto.parseDescription = function parseDescription() {\n    if (this.peekDescription()) {\n      return this.parseStringLiteral();\n    }\n  }\n  /**\n   * SchemaDefinition : Description? schema Directives[Const]? { OperationTypeDefinition+ }\n   */\n  ;\n\n  _proto.parseSchemaDefinition = function parseSchemaDefinition() {\n    var start = this._lexer.token;\n    var description = this.parseDescription();\n    this.expectKeyword('schema');\n    var directives = this.parseDirectives(true);\n    var operationTypes = this.many(TokenKind.BRACE_L, this.parseOperationTypeDefinition, TokenKind.BRACE_R);\n    return {\n      kind: Kind.SCHEMA_DEFINITION,\n      description: description,\n      directives: directives,\n      operationTypes: operationTypes,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * OperationTypeDefinition : OperationType : NamedType\n   */\n  ;\n\n  _proto.parseOperationTypeDefinition = function parseOperationTypeDefinition() {\n    var start = this._lexer.token;\n    var operation = this.parseOperationType();\n    this.expectToken(TokenKind.COLON);\n    var type = this.parseNamedType();\n    return {\n      kind: Kind.OPERATION_TYPE_DEFINITION,\n      operation: operation,\n      type: type,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * ScalarTypeDefinition : Description? scalar Name Directives[Const]?\n   */\n  ;\n\n  _proto.parseScalarTypeDefinition = function parseScalarTypeDefinition() {\n    var start = this._lexer.token;\n    var description = this.parseDescription();\n    this.expectKeyword('scalar');\n    var name = this.parseName();\n    var directives = this.parseDirectives(true);\n    return {\n      kind: Kind.SCALAR_TYPE_DEFINITION,\n      description: description,\n      name: name,\n      directives: directives,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * ObjectTypeDefinition :\n   *   Description?\n   *   type Name ImplementsInterfaces? Directives[Const]? FieldsDefinition?\n   */\n  ;\n\n  _proto.parseObjectTypeDefinition = function parseObjectTypeDefinition() {\n    var start = this._lexer.token;\n    var description = this.parseDescription();\n    this.expectKeyword('type');\n    var name = this.parseName();\n    var interfaces = this.parseImplementsInterfaces();\n    var directives = this.parseDirectives(true);\n    var fields = this.parseFieldsDefinition();\n    return {\n      kind: Kind.OBJECT_TYPE_DEFINITION,\n      description: description,\n      name: name,\n      interfaces: interfaces,\n      directives: directives,\n      fields: fields,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * ImplementsInterfaces :\n   *   - implements `&`? NamedType\n   *   - ImplementsInterfaces & NamedType\n   */\n  ;\n\n  _proto.parseImplementsInterfaces = function parseImplementsInterfaces() {\n    var _this$_options2;\n\n    if (!this.expectOptionalKeyword('implements')) {\n      return [];\n    }\n\n    if (((_this$_options2 = this._options) === null || _this$_options2 === void 0 ? void 0 : _this$_options2.allowLegacySDLImplementsInterfaces) === true) {\n      var types = []; // Optional leading ampersand\n\n      this.expectOptionalToken(TokenKind.AMP);\n\n      do {\n        types.push(this.parseNamedType());\n      } while (this.expectOptionalToken(TokenKind.AMP) || this.peek(TokenKind.NAME));\n\n      return types;\n    }\n\n    return this.delimitedMany(TokenKind.AMP, this.parseNamedType);\n  }\n  /**\n   * FieldsDefinition : { FieldDefinition+ }\n   */\n  ;\n\n  _proto.parseFieldsDefinition = function parseFieldsDefinition() {\n    var _this$_options3;\n\n    // Legacy support for the SDL?\n    if (((_this$_options3 = this._options) === null || _this$_options3 === void 0 ? void 0 : _this$_options3.allowLegacySDLEmptyFields) === true && this.peek(TokenKind.BRACE_L) && this._lexer.lookahead().kind === TokenKind.BRACE_R) {\n      this._lexer.advance();\n\n      this._lexer.advance();\n\n      return [];\n    }\n\n    return this.optionalMany(TokenKind.BRACE_L, this.parseFieldDefinition, TokenKind.BRACE_R);\n  }\n  /**\n   * FieldDefinition :\n   *   - Description? Name ArgumentsDefinition? : Type Directives[Const]?\n   */\n  ;\n\n  _proto.parseFieldDefinition = function parseFieldDefinition() {\n    var start = this._lexer.token;\n    var description = this.parseDescription();\n    var name = this.parseName();\n    var args = this.parseArgumentDefs();\n    this.expectToken(TokenKind.COLON);\n    var type = this.parseTypeReference();\n    var directives = this.parseDirectives(true);\n    return {\n      kind: Kind.FIELD_DEFINITION,\n      description: description,\n      name: name,\n      arguments: args,\n      type: type,\n      directives: directives,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * ArgumentsDefinition : ( InputValueDefinition+ )\n   */\n  ;\n\n  _proto.parseArgumentDefs = function parseArgumentDefs() {\n    return this.optionalMany(TokenKind.PAREN_L, this.parseInputValueDef, TokenKind.PAREN_R);\n  }\n  /**\n   * InputValueDefinition :\n   *   - Description? Name : Type DefaultValue? Directives[Const]?\n   */\n  ;\n\n  _proto.parseInputValueDef = function parseInputValueDef() {\n    var start = this._lexer.token;\n    var description = this.parseDescription();\n    var name = this.parseName();\n    this.expectToken(TokenKind.COLON);\n    var type = this.parseTypeReference();\n    var defaultValue;\n\n    if (this.expectOptionalToken(TokenKind.EQUALS)) {\n      defaultValue = this.parseValueLiteral(true);\n    }\n\n    var directives = this.parseDirectives(true);\n    return {\n      kind: Kind.INPUT_VALUE_DEFINITION,\n      description: description,\n      name: name,\n      type: type,\n      defaultValue: defaultValue,\n      directives: directives,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * InterfaceTypeDefinition :\n   *   - Description? interface Name Directives[Const]? FieldsDefinition?\n   */\n  ;\n\n  _proto.parseInterfaceTypeDefinition = function parseInterfaceTypeDefinition() {\n    var start = this._lexer.token;\n    var description = this.parseDescription();\n    this.expectKeyword('interface');\n    var name = this.parseName();\n    var interfaces = this.parseImplementsInterfaces();\n    var directives = this.parseDirectives(true);\n    var fields = this.parseFieldsDefinition();\n    return {\n      kind: Kind.INTERFACE_TYPE_DEFINITION,\n      description: description,\n      name: name,\n      interfaces: interfaces,\n      directives: directives,\n      fields: fields,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * UnionTypeDefinition :\n   *   - Description? union Name Directives[Const]? UnionMemberTypes?\n   */\n  ;\n\n  _proto.parseUnionTypeDefinition = function parseUnionTypeDefinition() {\n    var start = this._lexer.token;\n    var description = this.parseDescription();\n    this.expectKeyword('union');\n    var name = this.parseName();\n    var directives = this.parseDirectives(true);\n    var types = this.parseUnionMemberTypes();\n    return {\n      kind: Kind.UNION_TYPE_DEFINITION,\n      description: description,\n      name: name,\n      directives: directives,\n      types: types,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * UnionMemberTypes :\n   *   - = `|`? NamedType\n   *   - UnionMemberTypes | NamedType\n   */\n  ;\n\n  _proto.parseUnionMemberTypes = function parseUnionMemberTypes() {\n    return this.expectOptionalToken(TokenKind.EQUALS) ? this.delimitedMany(TokenKind.PIPE, this.parseNamedType) : [];\n  }\n  /**\n   * EnumTypeDefinition :\n   *   - Description? enum Name Directives[Const]? EnumValuesDefinition?\n   */\n  ;\n\n  _proto.parseEnumTypeDefinition = function parseEnumTypeDefinition() {\n    var start = this._lexer.token;\n    var description = this.parseDescription();\n    this.expectKeyword('enum');\n    var name = this.parseName();\n    var directives = this.parseDirectives(true);\n    var values = this.parseEnumValuesDefinition();\n    return {\n      kind: Kind.ENUM_TYPE_DEFINITION,\n      description: description,\n      name: name,\n      directives: directives,\n      values: values,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * EnumValuesDefinition : { EnumValueDefinition+ }\n   */\n  ;\n\n  _proto.parseEnumValuesDefinition = function parseEnumValuesDefinition() {\n    return this.optionalMany(TokenKind.BRACE_L, this.parseEnumValueDefinition, TokenKind.BRACE_R);\n  }\n  /**\n   * EnumValueDefinition : Description? EnumValue Directives[Const]?\n   *\n   * EnumValue : Name\n   */\n  ;\n\n  _proto.parseEnumValueDefinition = function parseEnumValueDefinition() {\n    var start = this._lexer.token;\n    var description = this.parseDescription();\n    var name = this.parseName();\n    var directives = this.parseDirectives(true);\n    return {\n      kind: Kind.ENUM_VALUE_DEFINITION,\n      description: description,\n      name: name,\n      directives: directives,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * InputObjectTypeDefinition :\n   *   - Description? input Name Directives[Const]? InputFieldsDefinition?\n   */\n  ;\n\n  _proto.parseInputObjectTypeDefinition = function parseInputObjectTypeDefinition() {\n    var start = this._lexer.token;\n    var description = this.parseDescription();\n    this.expectKeyword('input');\n    var name = this.parseName();\n    var directives = this.parseDirectives(true);\n    var fields = this.parseInputFieldsDefinition();\n    return {\n      kind: Kind.INPUT_OBJECT_TYPE_DEFINITION,\n      description: description,\n      name: name,\n      directives: directives,\n      fields: fields,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * InputFieldsDefinition : { InputValueDefinition+ }\n   */\n  ;\n\n  _proto.parseInputFieldsDefinition = function parseInputFieldsDefinition() {\n    return this.optionalMany(TokenKind.BRACE_L, this.parseInputValueDef, TokenKind.BRACE_R);\n  }\n  /**\n   * TypeSystemExtension :\n   *   - SchemaExtension\n   *   - TypeExtension\n   *\n   * TypeExtension :\n   *   - ScalarTypeExtension\n   *   - ObjectTypeExtension\n   *   - InterfaceTypeExtension\n   *   - UnionTypeExtension\n   *   - EnumTypeExtension\n   *   - InputObjectTypeDefinition\n   */\n  ;\n\n  _proto.parseTypeSystemExtension = function parseTypeSystemExtension() {\n    var keywordToken = this._lexer.lookahead();\n\n    if (keywordToken.kind === TokenKind.NAME) {\n      switch (keywordToken.value) {\n        case 'schema':\n          return this.parseSchemaExtension();\n\n        case 'scalar':\n          return this.parseScalarTypeExtension();\n\n        case 'type':\n          return this.parseObjectTypeExtension();\n\n        case 'interface':\n          return this.parseInterfaceTypeExtension();\n\n        case 'union':\n          return this.parseUnionTypeExtension();\n\n        case 'enum':\n          return this.parseEnumTypeExtension();\n\n        case 'input':\n          return this.parseInputObjectTypeExtension();\n      }\n    }\n\n    throw this.unexpected(keywordToken);\n  }\n  /**\n   * SchemaExtension :\n   *  - extend schema Directives[Const]? { OperationTypeDefinition+ }\n   *  - extend schema Directives[Const]\n   */\n  ;\n\n  _proto.parseSchemaExtension = function parseSchemaExtension() {\n    var start = this._lexer.token;\n    this.expectKeyword('extend');\n    this.expectKeyword('schema');\n    var directives = this.parseDirectives(true);\n    var operationTypes = this.optionalMany(TokenKind.BRACE_L, this.parseOperationTypeDefinition, TokenKind.BRACE_R);\n\n    if (directives.length === 0 && operationTypes.length === 0) {\n      throw this.unexpected();\n    }\n\n    return {\n      kind: Kind.SCHEMA_EXTENSION,\n      directives: directives,\n      operationTypes: operationTypes,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * ScalarTypeExtension :\n   *   - extend scalar Name Directives[Const]\n   */\n  ;\n\n  _proto.parseScalarTypeExtension = function parseScalarTypeExtension() {\n    var start = this._lexer.token;\n    this.expectKeyword('extend');\n    this.expectKeyword('scalar');\n    var name = this.parseName();\n    var directives = this.parseDirectives(true);\n\n    if (directives.length === 0) {\n      throw this.unexpected();\n    }\n\n    return {\n      kind: Kind.SCALAR_TYPE_EXTENSION,\n      name: name,\n      directives: directives,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * ObjectTypeExtension :\n   *  - extend type Name ImplementsInterfaces? Directives[Const]? FieldsDefinition\n   *  - extend type Name ImplementsInterfaces? Directives[Const]\n   *  - extend type Name ImplementsInterfaces\n   */\n  ;\n\n  _proto.parseObjectTypeExtension = function parseObjectTypeExtension() {\n    var start = this._lexer.token;\n    this.expectKeyword('extend');\n    this.expectKeyword('type');\n    var name = this.parseName();\n    var interfaces = this.parseImplementsInterfaces();\n    var directives = this.parseDirectives(true);\n    var fields = this.parseFieldsDefinition();\n\n    if (interfaces.length === 0 && directives.length === 0 && fields.length === 0) {\n      throw this.unexpected();\n    }\n\n    return {\n      kind: Kind.OBJECT_TYPE_EXTENSION,\n      name: name,\n      interfaces: interfaces,\n      directives: directives,\n      fields: fields,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * InterfaceTypeExtension :\n   *  - extend interface Name ImplementsInterfaces? Directives[Const]? FieldsDefinition\n   *  - extend interface Name ImplementsInterfaces? Directives[Const]\n   *  - extend interface Name ImplementsInterfaces\n   */\n  ;\n\n  _proto.parseInterfaceTypeExtension = function parseInterfaceTypeExtension() {\n    var start = this._lexer.token;\n    this.expectKeyword('extend');\n    this.expectKeyword('interface');\n    var name = this.parseName();\n    var interfaces = this.parseImplementsInterfaces();\n    var directives = this.parseDirectives(true);\n    var fields = this.parseFieldsDefinition();\n\n    if (interfaces.length === 0 && directives.length === 0 && fields.length === 0) {\n      throw this.unexpected();\n    }\n\n    return {\n      kind: Kind.INTERFACE_TYPE_EXTENSION,\n      name: name,\n      interfaces: interfaces,\n      directives: directives,\n      fields: fields,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * UnionTypeExtension :\n   *   - extend union Name Directives[Const]? UnionMemberTypes\n   *   - extend union Name Directives[Const]\n   */\n  ;\n\n  _proto.parseUnionTypeExtension = function parseUnionTypeExtension() {\n    var start = this._lexer.token;\n    this.expectKeyword('extend');\n    this.expectKeyword('union');\n    var name = this.parseName();\n    var directives = this.parseDirectives(true);\n    var types = this.parseUnionMemberTypes();\n\n    if (directives.length === 0 && types.length === 0) {\n      throw this.unexpected();\n    }\n\n    return {\n      kind: Kind.UNION_TYPE_EXTENSION,\n      name: name,\n      directives: directives,\n      types: types,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * EnumTypeExtension :\n   *   - extend enum Name Directives[Const]? EnumValuesDefinition\n   *   - extend enum Name Directives[Const]\n   */\n  ;\n\n  _proto.parseEnumTypeExtension = function parseEnumTypeExtension() {\n    var start = this._lexer.token;\n    this.expectKeyword('extend');\n    this.expectKeyword('enum');\n    var name = this.parseName();\n    var directives = this.parseDirectives(true);\n    var values = this.parseEnumValuesDefinition();\n\n    if (directives.length === 0 && values.length === 0) {\n      throw this.unexpected();\n    }\n\n    return {\n      kind: Kind.ENUM_TYPE_EXTENSION,\n      name: name,\n      directives: directives,\n      values: values,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * InputObjectTypeExtension :\n   *   - extend input Name Directives[Const]? InputFieldsDefinition\n   *   - extend input Name Directives[Const]\n   */\n  ;\n\n  _proto.parseInputObjectTypeExtension = function parseInputObjectTypeExtension() {\n    var start = this._lexer.token;\n    this.expectKeyword('extend');\n    this.expectKeyword('input');\n    var name = this.parseName();\n    var directives = this.parseDirectives(true);\n    var fields = this.parseInputFieldsDefinition();\n\n    if (directives.length === 0 && fields.length === 0) {\n      throw this.unexpected();\n    }\n\n    return {\n      kind: Kind.INPUT_OBJECT_TYPE_EXTENSION,\n      name: name,\n      directives: directives,\n      fields: fields,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * DirectiveDefinition :\n   *   - Description? directive @ Name ArgumentsDefinition? `repeatable`? on DirectiveLocations\n   */\n  ;\n\n  _proto.parseDirectiveDefinition = function parseDirectiveDefinition() {\n    var start = this._lexer.token;\n    var description = this.parseDescription();\n    this.expectKeyword('directive');\n    this.expectToken(TokenKind.AT);\n    var name = this.parseName();\n    var args = this.parseArgumentDefs();\n    var repeatable = this.expectOptionalKeyword('repeatable');\n    this.expectKeyword('on');\n    var locations = this.parseDirectiveLocations();\n    return {\n      kind: Kind.DIRECTIVE_DEFINITION,\n      description: description,\n      name: name,\n      arguments: args,\n      repeatable: repeatable,\n      locations: locations,\n      loc: this.loc(start)\n    };\n  }\n  /**\n   * DirectiveLocations :\n   *   - `|`? DirectiveLocation\n   *   - DirectiveLocations | DirectiveLocation\n   */\n  ;\n\n  _proto.parseDirectiveLocations = function parseDirectiveLocations() {\n    return this.delimitedMany(TokenKind.PIPE, this.parseDirectiveLocation);\n  }\n  /*\n   * DirectiveLocation :\n   *   - ExecutableDirectiveLocation\n   *   - TypeSystemDirectiveLocation\n   *\n   * ExecutableDirectiveLocation : one of\n   *   `QUERY`\n   *   `MUTATION`\n   *   `SUBSCRIPTION`\n   *   `FIELD`\n   *   `FRAGMENT_DEFINITION`\n   *   `FRAGMENT_SPREAD`\n   *   `INLINE_FRAGMENT`\n   *\n   * TypeSystemDirectiveLocation : one of\n   *   `SCHEMA`\n   *   `SCALAR`\n   *   `OBJECT`\n   *   `FIELD_DEFINITION`\n   *   `ARGUMENT_DEFINITION`\n   *   `INTERFACE`\n   *   `UNION`\n   *   `ENUM`\n   *   `ENUM_VALUE`\n   *   `INPUT_OBJECT`\n   *   `INPUT_FIELD_DEFINITION`\n   */\n  ;\n\n  _proto.parseDirectiveLocation = function parseDirectiveLocation() {\n    var start = this._lexer.token;\n    var name = this.parseName();\n\n    if (DirectiveLocation[name.value] !== undefined) {\n      return name;\n    }\n\n    throw this.unexpected(start);\n  } // Core parsing utility functions\n\n  /**\n   * Returns a location object, used to identify the place in the source that created a given parsed object.\n   */\n  ;\n\n  _proto.loc = function loc(startToken) {\n    var _this$_options4;\n\n    if (((_this$_options4 = this._options) === null || _this$_options4 === void 0 ? void 0 : _this$_options4.noLocation) !== true) {\n      return new Location(startToken, this._lexer.lastToken, this._lexer.source);\n    }\n  }\n  /**\n   * Determines if the next token is of a given kind\n   */\n  ;\n\n  _proto.peek = function peek(kind) {\n    return this._lexer.token.kind === kind;\n  }\n  /**\n   * If the next token is of the given kind, return that token after advancing the lexer.\n   * Otherwise, do not change the parser state and throw an error.\n   */\n  ;\n\n  _proto.expectToken = function expectToken(kind) {\n    var token = this._lexer.token;\n\n    if (token.kind === kind) {\n      this._lexer.advance();\n\n      return token;\n    }\n\n    throw syntaxError(this._lexer.source, token.start, \"Expected \".concat(getTokenKindDesc(kind), \", found \").concat(getTokenDesc(token), \".\"));\n  }\n  /**\n   * If the next token is of the given kind, return that token after advancing the lexer.\n   * Otherwise, do not change the parser state and return undefined.\n   */\n  ;\n\n  _proto.expectOptionalToken = function expectOptionalToken(kind) {\n    var token = this._lexer.token;\n\n    if (token.kind === kind) {\n      this._lexer.advance();\n\n      return token;\n    }\n\n    return undefined;\n  }\n  /**\n   * If the next token is a given keyword, advance the lexer.\n   * Otherwise, do not change the parser state and throw an error.\n   */\n  ;\n\n  _proto.expectKeyword = function expectKeyword(value) {\n    var token = this._lexer.token;\n\n    if (token.kind === TokenKind.NAME && token.value === value) {\n      this._lexer.advance();\n    } else {\n      throw syntaxError(this._lexer.source, token.start, \"Expected \\\"\".concat(value, \"\\\", found \").concat(getTokenDesc(token), \".\"));\n    }\n  }\n  /**\n   * If the next token is a given keyword, return \"true\" after advancing the lexer.\n   * Otherwise, do not change the parser state and return \"false\".\n   */\n  ;\n\n  _proto.expectOptionalKeyword = function expectOptionalKeyword(value) {\n    var token = this._lexer.token;\n\n    if (token.kind === TokenKind.NAME && token.value === value) {\n      this._lexer.advance();\n\n      return true;\n    }\n\n    return false;\n  }\n  /**\n   * Helper function for creating an error when an unexpected lexed token is encountered.\n   */\n  ;\n\n  _proto.unexpected = function unexpected(atToken) {\n    var token = atToken !== null && atToken !== void 0 ? atToken : this._lexer.token;\n    return syntaxError(this._lexer.source, token.start, \"Unexpected \".concat(getTokenDesc(token), \".\"));\n  }\n  /**\n   * Returns a possibly empty list of parse nodes, determined by the parseFn.\n   * This list begins with a lex token of openKind and ends with a lex token of closeKind.\n   * Advances the parser to the next lex token after the closing token.\n   */\n  ;\n\n  _proto.any = function any(openKind, parseFn, closeKind) {\n    this.expectToken(openKind);\n    var nodes = [];\n\n    while (!this.expectOptionalToken(closeKind)) {\n      nodes.push(parseFn.call(this));\n    }\n\n    return nodes;\n  }\n  /**\n   * Returns a list of parse nodes, determined by the parseFn.\n   * It can be empty only if open token is missing otherwise it will always return non-empty list\n   * that begins with a lex token of openKind and ends with a lex token of closeKind.\n   * Advances the parser to the next lex token after the closing token.\n   */\n  ;\n\n  _proto.optionalMany = function optionalMany(openKind, parseFn, closeKind) {\n    if (this.expectOptionalToken(openKind)) {\n      var nodes = [];\n\n      do {\n        nodes.push(parseFn.call(this));\n      } while (!this.expectOptionalToken(closeKind));\n\n      return nodes;\n    }\n\n    return [];\n  }\n  /**\n   * Returns a non-empty list of parse nodes, determined by the parseFn.\n   * This list begins with a lex token of openKind and ends with a lex token of closeKind.\n   * Advances the parser to the next lex token after the closing token.\n   */\n  ;\n\n  _proto.many = function many(openKind, parseFn, closeKind) {\n    this.expectToken(openKind);\n    var nodes = [];\n\n    do {\n      nodes.push(parseFn.call(this));\n    } while (!this.expectOptionalToken(closeKind));\n\n    return nodes;\n  }\n  /**\n   * Returns a non-empty list of parse nodes, determined by the parseFn.\n   * This list may begin with a lex token of delimiterKind followed by items separated by lex tokens of tokenKind.\n   * Advances the parser to the next lex token after last item in the list.\n   */\n  ;\n\n  _proto.delimitedMany = function delimitedMany(delimiterKind, parseFn) {\n    this.expectOptionalToken(delimiterKind);\n    var nodes = [];\n\n    do {\n      nodes.push(parseFn.call(this));\n    } while (this.expectOptionalToken(delimiterKind));\n\n    return nodes;\n  };\n\n  return Parser;\n}();\n/**\n * A helper function to describe a token as a string for debugging.\n */\n\nfunction getTokenDesc(token) {\n  var value = token.value;\n  return getTokenKindDesc(token.kind) + (value != null ? \" \\\"\".concat(value, \"\\\"\") : '');\n}\n/**\n * A helper function to describe a token kind as a string for debugging.\n */\n\n\nfunction getTokenKindDesc(kind) {\n  return isPunctuatorTokenKind(kind) ? \"\\\"\".concat(kind, \"\\\"\") : kind;\n}\n","import { getLocation } from \"./location.mjs\";\n/**\n * Render a helpful description of the location in the GraphQL Source document.\n */\n\nexport function printLocation(location) {\n  return printSourceLocation(location.source, getLocation(location.source, location.start));\n}\n/**\n * Render a helpful description of the location in the GraphQL Source document.\n */\n\nexport function printSourceLocation(source, sourceLocation) {\n  var firstLineColumnOffset = source.locationOffset.column - 1;\n  var body = whitespace(firstLineColumnOffset) + source.body;\n  var lineIndex = sourceLocation.line - 1;\n  var lineOffset = source.locationOffset.line - 1;\n  var lineNum = sourceLocation.line + lineOffset;\n  var columnOffset = sourceLocation.line === 1 ? firstLineColumnOffset : 0;\n  var columnNum = sourceLocation.column + columnOffset;\n  var locationStr = \"\".concat(source.name, \":\").concat(lineNum, \":\").concat(columnNum, \"\\n\");\n  var lines = body.split(/\\r\\n|[\\n\\r]/g);\n  var locationLine = lines[lineIndex]; // Special case for minified documents\n\n  if (locationLine.length > 120) {\n    var subLineIndex = Math.floor(columnNum / 80);\n    var subLineColumnNum = columnNum % 80;\n    var subLines = [];\n\n    for (var i = 0; i < locationLine.length; i += 80) {\n      subLines.push(locationLine.slice(i, i + 80));\n    }\n\n    return locationStr + printPrefixedLines([[\"\".concat(lineNum), subLines[0]]].concat(subLines.slice(1, subLineIndex + 1).map(function (subLine) {\n      return ['', subLine];\n    }), [[' ', whitespace(subLineColumnNum - 1) + '^'], ['', subLines[subLineIndex + 1]]]));\n  }\n\n  return locationStr + printPrefixedLines([// Lines specified like this: [\"prefix\", \"string\"],\n  [\"\".concat(lineNum - 1), lines[lineIndex - 1]], [\"\".concat(lineNum), locationLine], ['', whitespace(columnNum - 1) + '^'], [\"\".concat(lineNum + 1), lines[lineIndex + 1]]]);\n}\n\nfunction printPrefixedLines(lines) {\n  var existingLines = lines.filter(function (_ref) {\n    var _ = _ref[0],\n        line = _ref[1];\n    return line !== undefined;\n  });\n  var padLen = Math.max.apply(Math, existingLines.map(function (_ref2) {\n    var prefix = _ref2[0];\n    return prefix.length;\n  }));\n  return existingLines.map(function (_ref3) {\n    var prefix = _ref3[0],\n        line = _ref3[1];\n    return leftPad(padLen, prefix) + (line ? ' | ' + line : ' |');\n  }).join('\\n');\n}\n\nfunction whitespace(len) {\n  return Array(len + 1).join(' ');\n}\n\nfunction leftPad(len, str) {\n  return whitespace(len - str.length) + str;\n}\n","import { visit } from \"./visitor.mjs\";\nimport { printBlockString } from \"./blockString.mjs\";\n/**\n * Converts an AST into a string, using one set of reasonable\n * formatting rules.\n */\n\nexport function print(ast) {\n  return visit(ast, {\n    leave: printDocASTReducer\n  });\n}\nvar MAX_LINE_LENGTH = 80; // TODO: provide better type coverage in future\n\nvar printDocASTReducer = {\n  Name: function Name(node) {\n    return node.value;\n  },\n  Variable: function Variable(node) {\n    return '$' + node.name;\n  },\n  // Document\n  Document: function Document(node) {\n    return join(node.definitions, '\\n\\n') + '\\n';\n  },\n  OperationDefinition: function OperationDefinition(node) {\n    var op = node.operation;\n    var name = node.name;\n    var varDefs = wrap('(', join(node.variableDefinitions, ', '), ')');\n    var directives = join(node.directives, ' ');\n    var selectionSet = node.selectionSet; // Anonymous queries with no directives or variable definitions can use\n    // the query short form.\n\n    return !name && !directives && !varDefs && op === 'query' ? selectionSet : join([op, join([name, varDefs]), directives, selectionSet], ' ');\n  },\n  VariableDefinition: function VariableDefinition(_ref) {\n    var variable = _ref.variable,\n        type = _ref.type,\n        defaultValue = _ref.defaultValue,\n        directives = _ref.directives;\n    return variable + ': ' + type + wrap(' = ', defaultValue) + wrap(' ', join(directives, ' '));\n  },\n  SelectionSet: function SelectionSet(_ref2) {\n    var selections = _ref2.selections;\n    return block(selections);\n  },\n  Field: function Field(_ref3) {\n    var alias = _ref3.alias,\n        name = _ref3.name,\n        args = _ref3.arguments,\n        directives = _ref3.directives,\n        selectionSet = _ref3.selectionSet;\n    var prefix = wrap('', alias, ': ') + name;\n    var argsLine = prefix + wrap('(', join(args, ', '), ')');\n\n    if (argsLine.length > MAX_LINE_LENGTH) {\n      argsLine = prefix + wrap('(\\n', indent(join(args, '\\n')), '\\n)');\n    }\n\n    return join([argsLine, join(directives, ' '), selectionSet], ' ');\n  },\n  Argument: function Argument(_ref4) {\n    var name = _ref4.name,\n        value = _ref4.value;\n    return name + ': ' + value;\n  },\n  // Fragments\n  FragmentSpread: function FragmentSpread(_ref5) {\n    var name = _ref5.name,\n        directives = _ref5.directives;\n    return '...' + name + wrap(' ', join(directives, ' '));\n  },\n  InlineFragment: function InlineFragment(_ref6) {\n    var typeCondition = _ref6.typeCondition,\n        directives = _ref6.directives,\n        selectionSet = _ref6.selectionSet;\n    return join(['...', wrap('on ', typeCondition), join(directives, ' '), selectionSet], ' ');\n  },\n  FragmentDefinition: function FragmentDefinition(_ref7) {\n    var name = _ref7.name,\n        typeCondition = _ref7.typeCondition,\n        variableDefinitions = _ref7.variableDefinitions,\n        directives = _ref7.directives,\n        selectionSet = _ref7.selectionSet;\n    return (// Note: fragment variable definitions are experimental and may be changed\n      // or removed in the future.\n      \"fragment \".concat(name).concat(wrap('(', join(variableDefinitions, ', '), ')'), \" \") + \"on \".concat(typeCondition, \" \").concat(wrap('', join(directives, ' '), ' ')) + selectionSet\n    );\n  },\n  // Value\n  IntValue: function IntValue(_ref8) {\n    var value = _ref8.value;\n    return value;\n  },\n  FloatValue: function FloatValue(_ref9) {\n    var value = _ref9.value;\n    return value;\n  },\n  StringValue: function StringValue(_ref10, key) {\n    var value = _ref10.value,\n        isBlockString = _ref10.block;\n    return isBlockString ? printBlockString(value, key === 'description' ? '' : '  ') : JSON.stringify(value);\n  },\n  BooleanValue: function BooleanValue(_ref11) {\n    var value = _ref11.value;\n    return value ? 'true' : 'false';\n  },\n  NullValue: function NullValue() {\n    return 'null';\n  },\n  EnumValue: function EnumValue(_ref12) {\n    var value = _ref12.value;\n    return value;\n  },\n  ListValue: function ListValue(_ref13) {\n    var values = _ref13.values;\n    return '[' + join(values, ', ') + ']';\n  },\n  ObjectValue: function ObjectValue(_ref14) {\n    var fields = _ref14.fields;\n    return '{' + join(fields, ', ') + '}';\n  },\n  ObjectField: function ObjectField(_ref15) {\n    var name = _ref15.name,\n        value = _ref15.value;\n    return name + ': ' + value;\n  },\n  // Directive\n  Directive: function Directive(_ref16) {\n    var name = _ref16.name,\n        args = _ref16.arguments;\n    return '@' + name + wrap('(', join(args, ', '), ')');\n  },\n  // Type\n  NamedType: function NamedType(_ref17) {\n    var name = _ref17.name;\n    return name;\n  },\n  ListType: function ListType(_ref18) {\n    var type = _ref18.type;\n    return '[' + type + ']';\n  },\n  NonNullType: function NonNullType(_ref19) {\n    var type = _ref19.type;\n    return type + '!';\n  },\n  // Type System Definitions\n  SchemaDefinition: addDescription(function (_ref20) {\n    var directives = _ref20.directives,\n        operationTypes = _ref20.operationTypes;\n    return join(['schema', join(directives, ' '), block(operationTypes)], ' ');\n  }),\n  OperationTypeDefinition: function OperationTypeDefinition(_ref21) {\n    var operation = _ref21.operation,\n        type = _ref21.type;\n    return operation + ': ' + type;\n  },\n  ScalarTypeDefinition: addDescription(function (_ref22) {\n    var name = _ref22.name,\n        directives = _ref22.directives;\n    return join(['scalar', name, join(directives, ' ')], ' ');\n  }),\n  ObjectTypeDefinition: addDescription(function (_ref23) {\n    var name = _ref23.name,\n        interfaces = _ref23.interfaces,\n        directives = _ref23.directives,\n        fields = _ref23.fields;\n    return join(['type', name, wrap('implements ', join(interfaces, ' & ')), join(directives, ' '), block(fields)], ' ');\n  }),\n  FieldDefinition: addDescription(function (_ref24) {\n    var name = _ref24.name,\n        args = _ref24.arguments,\n        type = _ref24.type,\n        directives = _ref24.directives;\n    return name + (hasMultilineItems(args) ? wrap('(\\n', indent(join(args, '\\n')), '\\n)') : wrap('(', join(args, ', '), ')')) + ': ' + type + wrap(' ', join(directives, ' '));\n  }),\n  InputValueDefinition: addDescription(function (_ref25) {\n    var name = _ref25.name,\n        type = _ref25.type,\n        defaultValue = _ref25.defaultValue,\n        directives = _ref25.directives;\n    return join([name + ': ' + type, wrap('= ', defaultValue), join(directives, ' ')], ' ');\n  }),\n  InterfaceTypeDefinition: addDescription(function (_ref26) {\n    var name = _ref26.name,\n        interfaces = _ref26.interfaces,\n        directives = _ref26.directives,\n        fields = _ref26.fields;\n    return join(['interface', name, wrap('implements ', join(interfaces, ' & ')), join(directives, ' '), block(fields)], ' ');\n  }),\n  UnionTypeDefinition: addDescription(function (_ref27) {\n    var name = _ref27.name,\n        directives = _ref27.directives,\n        types = _ref27.types;\n    return join(['union', name, join(directives, ' '), types && types.length !== 0 ? '= ' + join(types, ' | ') : ''], ' ');\n  }),\n  EnumTypeDefinition: addDescription(function (_ref28) {\n    var name = _ref28.name,\n        directives = _ref28.directives,\n        values = _ref28.values;\n    return join(['enum', name, join(directives, ' '), block(values)], ' ');\n  }),\n  EnumValueDefinition: addDescription(function (_ref29) {\n    var name = _ref29.name,\n        directives = _ref29.directives;\n    return join([name, join(directives, ' ')], ' ');\n  }),\n  InputObjectTypeDefinition: addDescription(function (_ref30) {\n    var name = _ref30.name,\n        directives = _ref30.directives,\n        fields = _ref30.fields;\n    return join(['input', name, join(directives, ' '), block(fields)], ' ');\n  }),\n  DirectiveDefinition: addDescription(function (_ref31) {\n    var name = _ref31.name,\n        args = _ref31.arguments,\n        repeatable = _ref31.repeatable,\n        locations = _ref31.locations;\n    return 'directive @' + name + (hasMultilineItems(args) ? wrap('(\\n', indent(join(args, '\\n')), '\\n)') : wrap('(', join(args, ', '), ')')) + (repeatable ? ' repeatable' : '') + ' on ' + join(locations, ' | ');\n  }),\n  SchemaExtension: function SchemaExtension(_ref32) {\n    var directives = _ref32.directives,\n        operationTypes = _ref32.operationTypes;\n    return join(['extend schema', join(directives, ' '), block(operationTypes)], ' ');\n  },\n  ScalarTypeExtension: function ScalarTypeExtension(_ref33) {\n    var name = _ref33.name,\n        directives = _ref33.directives;\n    return join(['extend scalar', name, join(directives, ' ')], ' ');\n  },\n  ObjectTypeExtension: function ObjectTypeExtension(_ref34) {\n    var name = _ref34.name,\n        interfaces = _ref34.interfaces,\n        directives = _ref34.directives,\n        fields = _ref34.fields;\n    return join(['extend type', name, wrap('implements ', join(interfaces, ' & ')), join(directives, ' '), block(fields)], ' ');\n  },\n  InterfaceTypeExtension: function InterfaceTypeExtension(_ref35) {\n    var name = _ref35.name,\n        interfaces = _ref35.interfaces,\n        directives = _ref35.directives,\n        fields = _ref35.fields;\n    return join(['extend interface', name, wrap('implements ', join(interfaces, ' & ')), join(directives, ' '), block(fields)], ' ');\n  },\n  UnionTypeExtension: function UnionTypeExtension(_ref36) {\n    var name = _ref36.name,\n        directives = _ref36.directives,\n        types = _ref36.types;\n    return join(['extend union', name, join(directives, ' '), types && types.length !== 0 ? '= ' + join(types, ' | ') : ''], ' ');\n  },\n  EnumTypeExtension: function EnumTypeExtension(_ref37) {\n    var name = _ref37.name,\n        directives = _ref37.directives,\n        values = _ref37.values;\n    return join(['extend enum', name, join(directives, ' '), block(values)], ' ');\n  },\n  InputObjectTypeExtension: function InputObjectTypeExtension(_ref38) {\n    var name = _ref38.name,\n        directives = _ref38.directives,\n        fields = _ref38.fields;\n    return join(['extend input', name, join(directives, ' '), block(fields)], ' ');\n  }\n};\n\nfunction addDescription(cb) {\n  return function (node) {\n    return join([node.description, cb(node)], '\\n');\n  };\n}\n/**\n * Given maybeArray, print an empty string if it is null or empty, otherwise\n * print all items together separated by separator if provided\n */\n\n\nfunction join(maybeArray) {\n  var _maybeArray$filter$jo;\n\n  var separator = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : '';\n  return (_maybeArray$filter$jo = maybeArray === null || maybeArray === void 0 ? void 0 : maybeArray.filter(function (x) {\n    return x;\n  }).join(separator)) !== null && _maybeArray$filter$jo !== void 0 ? _maybeArray$filter$jo : '';\n}\n/**\n * Given array, print each item on its own line, wrapped in an\n * indented \"{ }\" block.\n */\n\n\nfunction block(array) {\n  return wrap('{\\n', indent(join(array, '\\n')), '\\n}');\n}\n/**\n * If maybeString is not null or empty, then wrap with start and end, otherwise print an empty string.\n */\n\n\nfunction wrap(start, maybeString) {\n  var end = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : '';\n  return maybeString != null && maybeString !== '' ? start + maybeString + end : '';\n}\n\nfunction indent(str) {\n  return wrap('  ', str.replace(/\\n/g, '\\n  '));\n}\n\nfunction isMultiline(str) {\n  return str.indexOf('\\n') !== -1;\n}\n\nfunction hasMultilineItems(maybeArray) {\n  return maybeArray != null && maybeArray.some(isMultiline);\n}\n","function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\nimport { SYMBOL_TO_STRING_TAG } from \"../polyfills/symbols.mjs\";\nimport inspect from \"../jsutils/inspect.mjs\";\nimport devAssert from \"../jsutils/devAssert.mjs\";\nimport instanceOf from \"../jsutils/instanceOf.mjs\";\n\n/**\n * A representation of source input to GraphQL. The `name` and `locationOffset` parameters are\n * optional, but they are useful for clients who store GraphQL documents in source files.\n * For example, if the GraphQL input starts at line 40 in a file named `Foo.graphql`, it might\n * be useful for `name` to be `\"Foo.graphql\"` and location to be `{ line: 40, column: 1 }`.\n * The `line` and `column` properties in `locationOffset` are 1-indexed.\n */\nexport var Source = /*#__PURE__*/function () {\n  function Source(body) {\n    var name = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 'GraphQL request';\n    var locationOffset = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {\n      line: 1,\n      column: 1\n    };\n    typeof body === 'string' || devAssert(0, \"Body must be a string. Received: \".concat(inspect(body), \".\"));\n    this.body = body;\n    this.name = name;\n    this.locationOffset = locationOffset;\n    this.locationOffset.line > 0 || devAssert(0, 'line in locationOffset is 1-indexed and must be positive.');\n    this.locationOffset.column > 0 || devAssert(0, 'column in locationOffset is 1-indexed and must be positive.');\n  } // $FlowFixMe[unsupported-syntax] Flow doesn't support computed properties yet\n\n\n  _createClass(Source, [{\n    key: SYMBOL_TO_STRING_TAG,\n    get: function get() {\n      return 'Source';\n    }\n  }]);\n\n  return Source;\n}();\n/**\n * Test if the given value is a Source object.\n *\n * @internal\n */\n\n// eslint-disable-next-line no-redeclare\nexport function isSource(source) {\n  return instanceOf(source, Source);\n}\n","/**\n * An exported enum describing the different kinds of tokens that the\n * lexer emits.\n */\nexport var TokenKind = Object.freeze({\n  SOF: '<SOF>',\n  EOF: '<EOF>',\n  BANG: '!',\n  DOLLAR: '$',\n  AMP: '&',\n  PAREN_L: '(',\n  PAREN_R: ')',\n  SPREAD: '...',\n  COLON: ':',\n  EQUALS: '=',\n  AT: '@',\n  BRACKET_L: '[',\n  BRACKET_R: ']',\n  BRACE_L: '{',\n  PIPE: '|',\n  BRACE_R: '}',\n  NAME: 'Name',\n  INT: 'Int',\n  FLOAT: 'Float',\n  STRING: 'String',\n  BLOCK_STRING: 'BlockString',\n  COMMENT: 'Comment'\n});\n/**\n * The enum type representing the token kinds values.\n */\n","import inspect from \"../jsutils/inspect.mjs\";\nimport { isNode } from \"./ast.mjs\";\n/**\n * A visitor is provided to visit, it contains the collection of\n * relevant functions to be called during the visitor's traversal.\n */\n\nexport var QueryDocumentKeys = {\n  Name: [],\n  Document: ['definitions'],\n  OperationDefinition: ['name', 'variableDefinitions', 'directives', 'selectionSet'],\n  VariableDefinition: ['variable', 'type', 'defaultValue', 'directives'],\n  Variable: ['name'],\n  SelectionSet: ['selections'],\n  Field: ['alias', 'name', 'arguments', 'directives', 'selectionSet'],\n  Argument: ['name', 'value'],\n  FragmentSpread: ['name', 'directives'],\n  InlineFragment: ['typeCondition', 'directives', 'selectionSet'],\n  FragmentDefinition: ['name', // Note: fragment variable definitions are experimental and may be changed\n  // or removed in the future.\n  'variableDefinitions', 'typeCondition', 'directives', 'selectionSet'],\n  IntValue: [],\n  FloatValue: [],\n  StringValue: [],\n  BooleanValue: [],\n  NullValue: [],\n  EnumValue: [],\n  ListValue: ['values'],\n  ObjectValue: ['fields'],\n  ObjectField: ['name', 'value'],\n  Directive: ['name', 'arguments'],\n  NamedType: ['name'],\n  ListType: ['type'],\n  NonNullType: ['type'],\n  SchemaDefinition: ['description', 'directives', 'operationTypes'],\n  OperationTypeDefinition: ['type'],\n  ScalarTypeDefinition: ['description', 'name', 'directives'],\n  ObjectTypeDefinition: ['description', 'name', 'interfaces', 'directives', 'fields'],\n  FieldDefinition: ['description', 'name', 'arguments', 'type', 'directives'],\n  InputValueDefinition: ['description', 'name', 'type', 'defaultValue', 'directives'],\n  InterfaceTypeDefinition: ['description', 'name', 'interfaces', 'directives', 'fields'],\n  UnionTypeDefinition: ['description', 'name', 'directives', 'types'],\n  EnumTypeDefinition: ['description', 'name', 'directives', 'values'],\n  EnumValueDefinition: ['description', 'name', 'directives'],\n  InputObjectTypeDefinition: ['description', 'name', 'directives', 'fields'],\n  DirectiveDefinition: ['description', 'name', 'arguments', 'locations'],\n  SchemaExtension: ['directives', 'operationTypes'],\n  ScalarTypeExtension: ['name', 'directives'],\n  ObjectTypeExtension: ['name', 'interfaces', 'directives', 'fields'],\n  InterfaceTypeExtension: ['name', 'interfaces', 'directives', 'fields'],\n  UnionTypeExtension: ['name', 'directives', 'types'],\n  EnumTypeExtension: ['name', 'directives', 'values'],\n  InputObjectTypeExtension: ['name', 'directives', 'fields']\n};\nexport var BREAK = Object.freeze({});\n/**\n * visit() will walk through an AST using a depth-first traversal, calling\n * the visitor's enter function at each node in the traversal, and calling the\n * leave function after visiting that node and all of its child nodes.\n *\n * By returning different values from the enter and leave functions, the\n * behavior of the visitor can be altered, including skipping over a sub-tree of\n * the AST (by returning false), editing the AST by returning a value or null\n * to remove the value, or to stop the whole traversal by returning BREAK.\n *\n * When using visit() to edit an AST, the original AST will not be modified, and\n * a new version of the AST with the changes applied will be returned from the\n * visit function.\n *\n *     const editedAST = visit(ast, {\n *       enter(node, key, parent, path, ancestors) {\n *         // @return\n *         //   undefined: no action\n *         //   false: skip visiting this node\n *         //   visitor.BREAK: stop visiting altogether\n *         //   null: delete this node\n *         //   any value: replace this node with the returned value\n *       },\n *       leave(node, key, parent, path, ancestors) {\n *         // @return\n *         //   undefined: no action\n *         //   false: no action\n *         //   visitor.BREAK: stop visiting altogether\n *         //   null: delete this node\n *         //   any value: replace this node with the returned value\n *       }\n *     });\n *\n * Alternatively to providing enter() and leave() functions, a visitor can\n * instead provide functions named the same as the kinds of AST nodes, or\n * enter/leave visitors at a named key, leading to four permutations of the\n * visitor API:\n *\n * 1) Named visitors triggered when entering a node of a specific kind.\n *\n *     visit(ast, {\n *       Kind(node) {\n *         // enter the \"Kind\" node\n *       }\n *     })\n *\n * 2) Named visitors that trigger upon entering and leaving a node of\n *    a specific kind.\n *\n *     visit(ast, {\n *       Kind: {\n *         enter(node) {\n *           // enter the \"Kind\" node\n *         }\n *         leave(node) {\n *           // leave the \"Kind\" node\n *         }\n *       }\n *     })\n *\n * 3) Generic visitors that trigger upon entering and leaving any node.\n *\n *     visit(ast, {\n *       enter(node) {\n *         // enter any node\n *       },\n *       leave(node) {\n *         // leave any node\n *       }\n *     })\n *\n * 4) Parallel visitors for entering and leaving nodes of a specific kind.\n *\n *     visit(ast, {\n *       enter: {\n *         Kind(node) {\n *           // enter the \"Kind\" node\n *         }\n *       },\n *       leave: {\n *         Kind(node) {\n *           // leave the \"Kind\" node\n *         }\n *       }\n *     })\n */\n\nexport function visit(root, visitor) {\n  var visitorKeys = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : QueryDocumentKeys;\n\n  /* eslint-disable no-undef-init */\n  var stack = undefined;\n  var inArray = Array.isArray(root);\n  var keys = [root];\n  var index = -1;\n  var edits = [];\n  var node = undefined;\n  var key = undefined;\n  var parent = undefined;\n  var path = [];\n  var ancestors = [];\n  var newRoot = root;\n  /* eslint-enable no-undef-init */\n\n  do {\n    index++;\n    var isLeaving = index === keys.length;\n    var isEdited = isLeaving && edits.length !== 0;\n\n    if (isLeaving) {\n      key = ancestors.length === 0 ? undefined : path[path.length - 1];\n      node = parent;\n      parent = ancestors.pop();\n\n      if (isEdited) {\n        if (inArray) {\n          node = node.slice();\n        } else {\n          var clone = {};\n\n          for (var _i2 = 0, _Object$keys2 = Object.keys(node); _i2 < _Object$keys2.length; _i2++) {\n            var k = _Object$keys2[_i2];\n            clone[k] = node[k];\n          }\n\n          node = clone;\n        }\n\n        var editOffset = 0;\n\n        for (var ii = 0; ii < edits.length; ii++) {\n          var editKey = edits[ii][0];\n          var editValue = edits[ii][1];\n\n          if (inArray) {\n            editKey -= editOffset;\n          }\n\n          if (inArray && editValue === null) {\n            node.splice(editKey, 1);\n            editOffset++;\n          } else {\n            node[editKey] = editValue;\n          }\n        }\n      }\n\n      index = stack.index;\n      keys = stack.keys;\n      edits = stack.edits;\n      inArray = stack.inArray;\n      stack = stack.prev;\n    } else {\n      key = parent ? inArray ? index : keys[index] : undefined;\n      node = parent ? parent[key] : newRoot;\n\n      if (node === null || node === undefined) {\n        continue;\n      }\n\n      if (parent) {\n        path.push(key);\n      }\n    }\n\n    var result = void 0;\n\n    if (!Array.isArray(node)) {\n      if (!isNode(node)) {\n        throw new Error(\"Invalid AST Node: \".concat(inspect(node), \".\"));\n      }\n\n      var visitFn = getVisitFn(visitor, node.kind, isLeaving);\n\n      if (visitFn) {\n        result = visitFn.call(visitor, node, key, parent, path, ancestors);\n\n        if (result === BREAK) {\n          break;\n        }\n\n        if (result === false) {\n          if (!isLeaving) {\n            path.pop();\n            continue;\n          }\n        } else if (result !== undefined) {\n          edits.push([key, result]);\n\n          if (!isLeaving) {\n            if (isNode(result)) {\n              node = result;\n            } else {\n              path.pop();\n              continue;\n            }\n          }\n        }\n      }\n    }\n\n    if (result === undefined && isEdited) {\n      edits.push([key, node]);\n    }\n\n    if (isLeaving) {\n      path.pop();\n    } else {\n      var _visitorKeys$node$kin;\n\n      stack = {\n        inArray: inArray,\n        index: index,\n        keys: keys,\n        edits: edits,\n        prev: stack\n      };\n      inArray = Array.isArray(node);\n      keys = inArray ? node : (_visitorKeys$node$kin = visitorKeys[node.kind]) !== null && _visitorKeys$node$kin !== void 0 ? _visitorKeys$node$kin : [];\n      index = -1;\n      edits = [];\n\n      if (parent) {\n        ancestors.push(parent);\n      }\n\n      parent = node;\n    }\n  } while (stack !== undefined);\n\n  if (edits.length !== 0) {\n    newRoot = edits[edits.length - 1][1];\n  }\n\n  return newRoot;\n}\n/**\n * Creates a new visitor instance which delegates to many visitors to run in\n * parallel. Each visitor will be visited for each node before moving on.\n *\n * If a prior visitor edits a node, no following visitors will see that node.\n */\n\nexport function visitInParallel(visitors) {\n  var skipping = new Array(visitors.length);\n  return {\n    enter: function enter(node) {\n      for (var i = 0; i < visitors.length; i++) {\n        if (skipping[i] == null) {\n          var fn = getVisitFn(visitors[i], node.kind,\n          /* isLeaving */\n          false);\n\n          if (fn) {\n            var result = fn.apply(visitors[i], arguments);\n\n            if (result === false) {\n              skipping[i] = node;\n            } else if (result === BREAK) {\n              skipping[i] = BREAK;\n            } else if (result !== undefined) {\n              return result;\n            }\n          }\n        }\n      }\n    },\n    leave: function leave(node) {\n      for (var i = 0; i < visitors.length; i++) {\n        if (skipping[i] == null) {\n          var fn = getVisitFn(visitors[i], node.kind,\n          /* isLeaving */\n          true);\n\n          if (fn) {\n            var result = fn.apply(visitors[i], arguments);\n\n            if (result === BREAK) {\n              skipping[i] = BREAK;\n            } else if (result !== undefined && result !== false) {\n              return result;\n            }\n          }\n        } else if (skipping[i] === node) {\n          skipping[i] = null;\n        }\n      }\n    }\n  };\n}\n/**\n * Given a visitor instance, if it is leaving or not, and a node kind, return\n * the function the visitor runtime should call.\n */\n\nexport function getVisitFn(visitor, kind, isLeaving) {\n  var kindVisitor = visitor[kind];\n\n  if (kindVisitor) {\n    if (!isLeaving && typeof kindVisitor === 'function') {\n      // { Kind() {} }\n      return kindVisitor;\n    }\n\n    var kindSpecificVisitor = isLeaving ? kindVisitor.leave : kindVisitor.enter;\n\n    if (typeof kindSpecificVisitor === 'function') {\n      // { Kind: { enter() {}, leave() {} } }\n      return kindSpecificVisitor;\n    }\n  } else {\n    var specificVisitor = isLeaving ? visitor.leave : visitor.enter;\n\n    if (specificVisitor) {\n      if (typeof specificVisitor === 'function') {\n        // { enter() {}, leave() {} }\n        return specificVisitor;\n      }\n\n      var specificKindVisitor = specificVisitor[kind];\n\n      if (typeof specificKindVisitor === 'function') {\n        // { enter: { Kind() {} }, leave: { Kind() {} } }\n        return specificKindVisitor;\n      }\n    }\n  }\n}\n","// In ES2015 (or a polyfilled) environment, this will be Symbol.iterator\n// istanbul ignore next (See: 'https://github.com/graphql/graphql-js/issues/2317')\nexport var SYMBOL_ITERATOR = typeof Symbol === 'function' && Symbol.iterator != null ? Symbol.iterator : '@@iterator'; // In ES2017 (or a polyfilled) environment, this will be Symbol.asyncIterator\n// istanbul ignore next (See: 'https://github.com/graphql/graphql-js/issues/2317')\n\nexport var SYMBOL_ASYNC_ITERATOR = typeof Symbol === 'function' && Symbol.asyncIterator != null ? Symbol.asyncIterator : '@@asyncIterator'; // istanbul ignore next (See: 'https://github.com/graphql/graphql-js/issues/2317')\n\nexport var SYMBOL_TO_STRING_TAG = typeof Symbol === 'function' && Symbol.toStringTag != null ? Symbol.toStringTag : '@@toStringTag';\n","/******************************************************************************\nCopyright (c) Microsoft Corporation.\n\nPermission to use, copy, modify, and/or distribute this software for any\npurpose with or without fee is hereby granted.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\nPERFORMANCE OF THIS SOFTWARE.\n***************************************************************************** */\n/* global Reflect, Promise, SuppressedError, Symbol, Iterator */\n\nvar extendStatics = function(d, b) {\n  extendStatics = Object.setPrototypeOf ||\n      ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n      function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n  return extendStatics(d, b);\n};\n\nexport function __extends(d, b) {\n  if (typeof b !== \"function\" && b !== null)\n      throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n  extendStatics(d, b);\n  function __() { this.constructor = d; }\n  d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n}\n\nexport var __assign = function() {\n  __assign = Object.assign || function __assign(t) {\n      for (var s, i = 1, n = arguments.length; i < n; i++) {\n          s = arguments[i];\n          for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\n      }\n      return t;\n  }\n  return __assign.apply(this, arguments);\n}\n\nexport function __rest(s, e) {\n  var t = {};\n  for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n      t[p] = s[p];\n  if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n      for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n          if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n              t[p[i]] = s[p[i]];\n      }\n  return t;\n}\n\nexport function __decorate(decorators, target, key, desc) {\n  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n  if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n  return c > 3 && r && Object.defineProperty(target, key, r), r;\n}\n\nexport function __param(paramIndex, decorator) {\n  return function (target, key) { decorator(target, key, paramIndex); }\n}\n\nexport function __esDecorate(ctor, descriptorIn, decorators, contextIn, initializers, extraInitializers) {\n  function accept(f) { if (f !== void 0 && typeof f !== \"function\") throw new TypeError(\"Function expected\"); return f; }\n  var kind = contextIn.kind, key = kind === \"getter\" ? \"get\" : kind === \"setter\" ? \"set\" : \"value\";\n  var target = !descriptorIn && ctor ? contextIn[\"static\"] ? ctor : ctor.prototype : null;\n  var descriptor = descriptorIn || (target ? Object.getOwnPropertyDescriptor(target, contextIn.name) : {});\n  var _, done = false;\n  for (var i = decorators.length - 1; i >= 0; i--) {\n      var context = {};\n      for (var p in contextIn) context[p] = p === \"access\" ? {} : contextIn[p];\n      for (var p in contextIn.access) context.access[p] = contextIn.access[p];\n      context.addInitializer = function (f) { if (done) throw new TypeError(\"Cannot add initializers after decoration has completed\"); extraInitializers.push(accept(f || null)); };\n      var result = (0, decorators[i])(kind === \"accessor\" ? { get: descriptor.get, set: descriptor.set } : descriptor[key], context);\n      if (kind === \"accessor\") {\n          if (result === void 0) continue;\n          if (result === null || typeof result !== \"object\") throw new TypeError(\"Object expected\");\n          if (_ = accept(result.get)) descriptor.get = _;\n          if (_ = accept(result.set)) descriptor.set = _;\n          if (_ = accept(result.init)) initializers.unshift(_);\n      }\n      else if (_ = accept(result)) {\n          if (kind === \"field\") initializers.unshift(_);\n          else descriptor[key] = _;\n      }\n  }\n  if (target) Object.defineProperty(target, contextIn.name, descriptor);\n  done = true;\n};\n\nexport function __runInitializers(thisArg, initializers, value) {\n  var useValue = arguments.length > 2;\n  for (var i = 0; i < initializers.length; i++) {\n      value = useValue ? initializers[i].call(thisArg, value) : initializers[i].call(thisArg);\n  }\n  return useValue ? value : void 0;\n};\n\nexport function __propKey(x) {\n  return typeof x === \"symbol\" ? x : \"\".concat(x);\n};\n\nexport function __setFunctionName(f, name, prefix) {\n  if (typeof name === \"symbol\") name = name.description ? \"[\".concat(name.description, \"]\") : \"\";\n  return Object.defineProperty(f, \"name\", { configurable: true, value: prefix ? \"\".concat(prefix, \" \", name) : name });\n};\n\nexport function __metadata(metadataKey, metadataValue) {\n  if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(metadataKey, metadataValue);\n}\n\nexport function __awaiter(thisArg, _arguments, P, generator) {\n  function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n  return new (P || (P = Promise))(function (resolve, reject) {\n      function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n      function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n      function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n      step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n}\n\nexport function __generator(thisArg, body) {\n  var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g = Object.create((typeof Iterator === \"function\" ? Iterator : Object).prototype);\n  return g.next = verb(0), g[\"throw\"] = verb(1), g[\"return\"] = verb(2), typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n  function verb(n) { return function (v) { return step([n, v]); }; }\n  function step(op) {\n      if (f) throw new TypeError(\"Generator is already executing.\");\n      while (g && (g = 0, op[0] && (_ = 0)), _) try {\n          if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n          if (y = 0, t) op = [op[0] & 2, t.value];\n          switch (op[0]) {\n              case 0: case 1: t = op; break;\n              case 4: _.label++; return { value: op[1], done: false };\n              case 5: _.label++; y = op[1]; op = [0]; continue;\n              case 7: op = _.ops.pop(); _.trys.pop(); continue;\n              default:\n                  if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                  if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                  if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                  if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                  if (t[2]) _.ops.pop();\n                  _.trys.pop(); continue;\n          }\n          op = body.call(thisArg, _);\n      } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n      if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n  }\n}\n\nexport var __createBinding = Object.create ? (function(o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  var desc = Object.getOwnPropertyDescriptor(m, k);\n  if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n  }\n  Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  o[k2] = m[k];\n});\n\nexport function __exportStar(m, o) {\n  for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(o, p)) __createBinding(o, m, p);\n}\n\nexport function __values(o) {\n  var s = typeof Symbol === \"function\" && Symbol.iterator, m = s && o[s], i = 0;\n  if (m) return m.call(o);\n  if (o && typeof o.length === \"number\") return {\n      next: function () {\n          if (o && i >= o.length) o = void 0;\n          return { value: o && o[i++], done: !o };\n      }\n  };\n  throw new TypeError(s ? \"Object is not iterable.\" : \"Symbol.iterator is not defined.\");\n}\n\nexport function __read(o, n) {\n  var m = typeof Symbol === \"function\" && o[Symbol.iterator];\n  if (!m) return o;\n  var i = m.call(o), r, ar = [], e;\n  try {\n      while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);\n  }\n  catch (error) { e = { error: error }; }\n  finally {\n      try {\n          if (r && !r.done && (m = i[\"return\"])) m.call(i);\n      }\n      finally { if (e) throw e.error; }\n  }\n  return ar;\n}\n\n/** @deprecated */\nexport function __spread() {\n  for (var ar = [], i = 0; i < arguments.length; i++)\n      ar = ar.concat(__read(arguments[i]));\n  return ar;\n}\n\n/** @deprecated */\nexport function __spreadArrays() {\n  for (var s = 0, i = 0, il = arguments.length; i < il; i++) s += arguments[i].length;\n  for (var r = Array(s), k = 0, i = 0; i < il; i++)\n      for (var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)\n          r[k] = a[j];\n  return r;\n}\n\nexport function __spreadArray(to, from, pack) {\n  if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {\n      if (ar || !(i in from)) {\n          if (!ar) ar = Array.prototype.slice.call(from, 0, i);\n          ar[i] = from[i];\n      }\n  }\n  return to.concat(ar || Array.prototype.slice.call(from));\n}\n\nexport function __await(v) {\n  return this instanceof __await ? (this.v = v, this) : new __await(v);\n}\n\nexport function __asyncGenerator(thisArg, _arguments, generator) {\n  if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n  var g = generator.apply(thisArg, _arguments || []), i, q = [];\n  return i = Object.create((typeof AsyncIterator === \"function\" ? AsyncIterator : Object).prototype), verb(\"next\"), verb(\"throw\"), verb(\"return\", awaitReturn), i[Symbol.asyncIterator] = function () { return this; }, i;\n  function awaitReturn(f) { return function (v) { return Promise.resolve(v).then(f, reject); }; }\n  function verb(n, f) { if (g[n]) { i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; if (f) i[n] = f(i[n]); } }\n  function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\n  function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\n  function fulfill(value) { resume(\"next\", value); }\n  function reject(value) { resume(\"throw\", value); }\n  function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\n}\n\nexport function __asyncDelegator(o) {\n  var i, p;\n  return i = {}, verb(\"next\"), verb(\"throw\", function (e) { throw e; }), verb(\"return\"), i[Symbol.iterator] = function () { return this; }, i;\n  function verb(n, f) { i[n] = o[n] ? function (v) { return (p = !p) ? { value: __await(o[n](v)), done: false } : f ? f(v) : v; } : f; }\n}\n\nexport function __asyncValues(o) {\n  if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n  var m = o[Symbol.asyncIterator], i;\n  return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\n  function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\n  function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\n}\n\nexport function __makeTemplateObject(cooked, raw) {\n  if (Object.defineProperty) { Object.defineProperty(cooked, \"raw\", { value: raw }); } else { cooked.raw = raw; }\n  return cooked;\n};\n\nvar __setModuleDefault = Object.create ? (function(o, v) {\n  Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n  o[\"default\"] = v;\n};\n\nexport function __importStar(mod) {\n  if (mod && mod.__esModule) return mod;\n  var result = {};\n  if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n  __setModuleDefault(result, mod);\n  return result;\n}\n\nexport function __importDefault(mod) {\n  return (mod && mod.__esModule) ? mod : { default: mod };\n}\n\nexport function __classPrivateFieldGet(receiver, state, kind, f) {\n  if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n  if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n  return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n}\n\nexport function __classPrivateFieldSet(receiver, state, value, kind, f) {\n  if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\n  if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\n  if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n  return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\n}\n\nexport function __classPrivateFieldIn(state, receiver) {\n  if (receiver === null || (typeof receiver !== \"object\" && typeof receiver !== \"function\")) throw new TypeError(\"Cannot use 'in' operator on non-object\");\n  return typeof state === \"function\" ? receiver === state : state.has(receiver);\n}\n\nexport function __addDisposableResource(env, value, async) {\n  if (value !== null && value !== void 0) {\n    if (typeof value !== \"object\" && typeof value !== \"function\") throw new TypeError(\"Object expected.\");\n    var dispose, inner;\n    if (async) {\n      if (!Symbol.asyncDispose) throw new TypeError(\"Symbol.asyncDispose is not defined.\");\n      dispose = value[Symbol.asyncDispose];\n    }\n    if (dispose === void 0) {\n      if (!Symbol.dispose) throw new TypeError(\"Symbol.dispose is not defined.\");\n      dispose = value[Symbol.dispose];\n      if (async) inner = dispose;\n    }\n    if (typeof dispose !== \"function\") throw new TypeError(\"Object not disposable.\");\n    if (inner) dispose = function() { try { inner.call(this); } catch (e) { return Promise.reject(e); } };\n    env.stack.push({ value: value, dispose: dispose, async: async });\n  }\n  else if (async) {\n    env.stack.push({ async: true });\n  }\n  return value;\n}\n\nvar _SuppressedError = typeof SuppressedError === \"function\" ? SuppressedError : function (error, suppressed, message) {\n  var e = new Error(message);\n  return e.name = \"SuppressedError\", e.error = error, e.suppressed = suppressed, e;\n};\n\nexport function __disposeResources(env) {\n  function fail(e) {\n    env.error = env.hasError ? new _SuppressedError(e, env.error, \"An error was suppressed during disposal.\") : e;\n    env.hasError = true;\n  }\n  var r, s = 0;\n  function next() {\n    while (r = env.stack.pop()) {\n      try {\n        if (!r.async && s === 1) return s = 0, env.stack.push(r), Promise.resolve().then(next);\n        if (r.dispose) {\n          var result = r.dispose.call(r.value);\n          if (r.async) return s |= 2, Promise.resolve(result).then(next, function(e) { fail(e); return next(); });\n        }\n        else s |= 1;\n      }\n      catch (e) {\n        fail(e);\n      }\n    }\n    if (s === 1) return env.hasError ? Promise.reject(env.error) : Promise.resolve();\n    if (env.hasError) throw env.error;\n  }\n  return next();\n}\n\nexport default {\n  __extends,\n  __assign,\n  __rest,\n  __decorate,\n  __param,\n  __metadata,\n  __awaiter,\n  __generator,\n  __createBinding,\n  __exportStar,\n  __values,\n  __read,\n  __spread,\n  __spreadArrays,\n  __spreadArray,\n  __await,\n  __asyncGenerator,\n  __asyncDelegator,\n  __asyncValues,\n  __makeTemplateObject,\n  __importStar,\n  __importDefault,\n  __classPrivateFieldGet,\n  __classPrivateFieldSet,\n  __classPrivateFieldIn,\n  __addDisposableResource,\n  __disposeResources,\n};\n","import { USER_AGENT_HEADER, getAmplifyUserAgent } from '@aws-amplify/core/internals/utils';\nimport { MESSAGE_TYPES, DEFAULT_KEEP_ALIVE_TIMEOUT } from '../constants.mjs';\nimport { AWSWebSocketProvider } from '../AWSWebSocketProvider/index.mjs';\nimport { awsRealTimeHeaderBasedAuth } from '../AWSWebSocketProvider/authHeaders.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst PROVIDER_NAME = 'AWSAppSyncRealTimeProvider';\nconst WS_PROTOCOL_NAME = 'graphql-ws';\nconst CONNECT_URI = '/connect';\nclass AWSAppSyncRealTimeProvider extends AWSWebSocketProvider {\n    constructor() {\n        super({\n            providerName: PROVIDER_NAME,\n            wsProtocolName: WS_PROTOCOL_NAME,\n            connectUri: CONNECT_URI,\n        });\n    }\n    getProviderName() {\n        return PROVIDER_NAME;\n    }\n    subscribe(options, customUserAgentDetails) {\n        return super.subscribe(options, customUserAgentDetails);\n    }\n    async _prepareSubscriptionPayload({ options, subscriptionId, customUserAgentDetails, additionalCustomHeaders, libraryConfigHeaders, }) {\n        const { appSyncGraphqlEndpoint, authenticationType, query, variables, apiKey, region, } = options;\n        const data = {\n            query,\n            variables,\n        };\n        const serializedData = JSON.stringify(data);\n        const headers = {\n            ...(await awsRealTimeHeaderBasedAuth({\n                apiKey,\n                appSyncGraphqlEndpoint,\n                authenticationType,\n                payload: serializedData,\n                canonicalUri: '',\n                region,\n                additionalCustomHeaders,\n            })),\n            ...libraryConfigHeaders,\n            ...additionalCustomHeaders,\n            [USER_AGENT_HEADER]: getAmplifyUserAgent(customUserAgentDetails),\n        };\n        const subscriptionMessage = {\n            id: subscriptionId,\n            payload: {\n                data: serializedData,\n                extensions: {\n                    authorization: {\n                        ...headers,\n                    },\n                },\n            },\n            type: MESSAGE_TYPES.GQL_START,\n        };\n        const serializedSubscriptionMessage = JSON.stringify(subscriptionMessage);\n        return serializedSubscriptionMessage;\n    }\n    _handleSubscriptionData(message) {\n        this.logger.debug(`subscription message from AWS AppSync RealTime: ${message.data}`);\n        const { id = '', payload, type } = JSON.parse(String(message.data));\n        const { observer = null, query = '', variables = {}, } = this.subscriptionObserverMap.get(id) || {};\n        this.logger.debug({ id, observer, query, variables });\n        if (type === MESSAGE_TYPES.DATA && payload && payload.data) {\n            if (observer) {\n                observer.next(payload);\n            }\n            else {\n                this.logger.debug(`observer not found for id: ${id}`);\n            }\n            return [true, { id, type, payload }];\n        }\n        return [false, { id, type, payload }];\n    }\n    _unsubscribeMessage(subscriptionId) {\n        return {\n            id: subscriptionId,\n            type: MESSAGE_TYPES.GQL_STOP,\n        };\n    }\n    _extractConnectionTimeout(data) {\n        const { payload: { connectionTimeoutMs = DEFAULT_KEEP_ALIVE_TIMEOUT } = {}, } = data;\n        return connectionTimeoutMs;\n    }\n    _extractErrorCodeAndType(data) {\n        const { payload: { errors: [{ errorType = '', errorCode = 0 } = {}] = [] } = {}, } = data;\n        return { errorCode, errorType };\n    }\n}\n\nexport { AWSAppSyncRealTimeProvider };\n//# sourceMappingURL=index.mjs.map\n","import { AmplifyUrl, AmplifyUrlSearchParams } from '@aws-amplify/core/internals/utils';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst protocol = 'wss://';\nconst standardDomainPattern = /^https:\\/\\/\\w{26}\\.appsync-api\\.\\w{2}(?:(?:-\\w{2,})+)-\\d\\.amazonaws.com(?:\\.cn)?\\/graphql$/i;\nconst eventDomainPattern = /^https:\\/\\/\\w{26}\\.\\w+-api\\.\\w{2}(?:(?:-\\w{2,})+)-\\d\\.amazonaws.com(?:\\.cn)?\\/event$/i;\nconst customDomainPath = '/realtime';\nconst isCustomDomain = (url) => {\n    return url.match(standardDomainPattern) === null;\n};\nconst isEventDomain = (url) => url.match(eventDomainPattern) !== null;\nconst getRealtimeEndpointUrl = (appSyncGraphqlEndpoint) => {\n    let realtimeEndpoint = appSyncGraphqlEndpoint ?? '';\n    if (isEventDomain(realtimeEndpoint)) {\n        realtimeEndpoint = realtimeEndpoint\n            .concat(customDomainPath)\n            .replace('ddpg-api', 'grt-gamma')\n            .replace('appsync-api', 'appsync-realtime-api');\n    }\n    else if (isCustomDomain(realtimeEndpoint)) {\n        realtimeEndpoint = realtimeEndpoint.concat(customDomainPath);\n    }\n    else {\n        realtimeEndpoint = realtimeEndpoint\n            .replace('appsync-api', 'appsync-realtime-api')\n            .replace('gogi-beta', 'grt-beta')\n            .replace('ddpg-api', 'grt-gamma');\n    }\n    realtimeEndpoint = realtimeEndpoint\n        .replace('https://', protocol)\n        .replace('http://', 'ws://');\n    return new AmplifyUrl(realtimeEndpoint);\n};\n/**\n * Strips out `Authorization` header if present\n */\nconst extractNonAuthHeaders = (headers) => {\n    if (!headers) {\n        return {};\n    }\n    if ('Authorization' in headers) {\n        const { Authorization: _, ...nonAuthHeaders } = headers;\n        return nonAuthHeaders;\n    }\n    return headers;\n};\n/**\n *\n * @param headers - http headers\n * @returns uri-encoded query parameters derived from custom headers\n */\nconst queryParamsFromCustomHeaders = (headers) => {\n    const nonAuthHeaders = extractNonAuthHeaders(headers);\n    const params = new AmplifyUrlSearchParams();\n    Object.entries(nonAuthHeaders).forEach(([k, v]) => {\n        params.append(k, v);\n    });\n    return params;\n};\n/**\n * Normalizes AppSync realtime endpoint URL\n *\n * @param appSyncGraphqlEndpoint - AppSync endpointUri from config\n * @param urlParams - URLSearchParams\n * @returns fully resolved string realtime endpoint URL\n */\nconst realtimeUrlWithQueryString = (appSyncGraphqlEndpoint, urlParams) => {\n    const realtimeEndpointUrl = getRealtimeEndpointUrl(appSyncGraphqlEndpoint);\n    // preserves any query params a customer might manually set in the configuration\n    const existingParams = new AmplifyUrlSearchParams(realtimeEndpointUrl.search);\n    for (const [k, v] of urlParams.entries()) {\n        existingParams.append(k, v);\n    }\n    realtimeEndpointUrl.search = existingParams.toString();\n    return realtimeEndpointUrl.toString();\n};\n// TODO: move to separate file?\nconst additionalHeadersFromOptions = async (options) => {\n    const { appSyncGraphqlEndpoint, query, libraryConfigHeaders = () => ({}), additionalHeaders = {}, authToken, } = options;\n    let additionalCustomHeaders = {};\n    const _libraryConfigHeaders = await libraryConfigHeaders();\n    if (typeof additionalHeaders === 'function') {\n        const requestOptions = {\n            url: appSyncGraphqlEndpoint || '',\n            queryString: query || '',\n        };\n        additionalCustomHeaders = await additionalHeaders(requestOptions);\n    }\n    else {\n        additionalCustomHeaders = additionalHeaders;\n    }\n    // if an authorization header is set, have the explicit, operation-level authToken take precedence\n    if (authToken) {\n        additionalCustomHeaders = {\n            ...additionalCustomHeaders,\n            Authorization: authToken,\n        };\n    }\n    return {\n        additionalCustomHeaders,\n        libraryConfigHeaders: _libraryConfigHeaders,\n    };\n};\n\nexport { additionalHeadersFromOptions, getRealtimeEndpointUrl, isCustomDomain, queryParamsFromCustomHeaders, realtimeUrlWithQueryString };\n//# sourceMappingURL=appsyncUrl.mjs.map\n","import { ConsoleLogger, fetchAuthSession } from '@aws-amplify/core';\nimport { signRequest } from '@aws-amplify/core/internals/aws-client-utils';\nimport { AmplifyUrl } from '@aws-amplify/core/internals/utils';\nimport { AWS_APPSYNC_REALTIME_HEADERS } from '../constants.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst logger = new ConsoleLogger('AWSAppSyncRealTimeProvider Auth');\nconst awsAuthTokenHeader = async ({ host }) => {\n    const session = await fetchAuthSession();\n    return {\n        Authorization: session?.tokens?.accessToken?.toString(),\n        host,\n    };\n};\nconst awsRealTimeApiKeyHeader = async ({ apiKey, host, }) => {\n    const dt = new Date();\n    const dtStr = dt.toISOString().replace(/[:-]|\\.\\d{3}/g, '');\n    return {\n        host,\n        'x-amz-date': dtStr,\n        'x-api-key': apiKey,\n    };\n};\nconst awsRealTimeIAMHeader = async ({ payload, canonicalUri, appSyncGraphqlEndpoint, region, }) => {\n    const endpointInfo = {\n        region,\n        service: 'appsync',\n    };\n    const creds = (await fetchAuthSession()).credentials;\n    const request = {\n        url: `${appSyncGraphqlEndpoint}${canonicalUri}`,\n        data: payload,\n        method: 'POST',\n        headers: { ...AWS_APPSYNC_REALTIME_HEADERS },\n    };\n    const signedParams = signRequest({\n        headers: request.headers,\n        method: request.method,\n        url: new AmplifyUrl(request.url),\n        body: request.data,\n    }, {\n        credentials: creds,\n        signingRegion: endpointInfo.region,\n        signingService: endpointInfo.service,\n    });\n    return signedParams.headers;\n};\nconst customAuthHeader = async ({ host, additionalCustomHeaders, }) => {\n    /**\n     * If `additionalHeaders` was provided to the subscription as a function,\n     * the headers that are returned by that function will already have been\n     * provided before this function is called.\n     */\n    if (!additionalCustomHeaders?.Authorization) {\n        throw new Error('No auth token specified');\n    }\n    return {\n        Authorization: additionalCustomHeaders.Authorization,\n        host,\n    };\n};\nconst awsRealTimeHeaderBasedAuth = async ({ apiKey, authenticationType, canonicalUri, appSyncGraphqlEndpoint, region, additionalCustomHeaders, payload, }) => {\n    const headerHandler = {\n        apiKey: awsRealTimeApiKeyHeader,\n        iam: awsRealTimeIAMHeader,\n        oidc: awsAuthTokenHeader,\n        userPool: awsAuthTokenHeader,\n        lambda: customAuthHeader,\n        none: customAuthHeader,\n    };\n    if (!authenticationType || !headerHandler[authenticationType]) {\n        logger.debug(`Authentication type ${authenticationType} not supported`);\n        return undefined;\n    }\n    else {\n        const handler = headerHandler[authenticationType];\n        const host = appSyncGraphqlEndpoint\n            ? new AmplifyUrl(appSyncGraphqlEndpoint).host\n            : undefined;\n        const resolvedApiKey = authenticationType === 'apiKey' ? apiKey : undefined;\n        logger.debug(`Authenticating with ${JSON.stringify(authenticationType)}`);\n        const result = await handler({\n            payload,\n            canonicalUri,\n            appSyncGraphqlEndpoint,\n            apiKey: resolvedApiKey,\n            region,\n            host,\n            additionalCustomHeaders,\n        });\n        return result;\n    }\n};\n\nexport { awsRealTimeHeaderBasedAuth };\n//# sourceMappingURL=authHeaders.mjs.map\n","import { Observable } from 'rxjs';\nimport { GraphQLError } from 'graphql';\nimport { ConsoleLogger, Hub } from '@aws-amplify/core';\nimport { NonRetryableError, amplifyUuid, isNonRetryableError, base64Encoder, jitteredExponentialRetry, AMPLIFY_SYMBOL } from '@aws-amplify/core/internals/utils';\nimport { ConnectionState, CONTROL_MSG } from '../../types/PubSub.mjs';\nimport { SOCKET_STATUS, DEFAULT_KEEP_ALIVE_TIMEOUT, NON_RETRYABLE_CODES, NON_RETRYABLE_ERROR_TYPES, SUBSCRIPTION_STATUS, START_ACK_TIMEOUT, MESSAGE_TYPES, DEFAULT_KEEP_ALIVE_ALERT_TIMEOUT, MAX_DELAY_MS, CONNECTION_INIT_TIMEOUT, CONNECTION_STATE_CHANGE } from '../constants.mjs';\nimport { ConnectionStateMonitor, CONNECTION_CHANGE } from '../../utils/ConnectionStateMonitor.mjs';\nimport { ReconnectionMonitor, ReconnectEvent } from '../../utils/ReconnectionMonitor.mjs';\nimport { additionalHeadersFromOptions, queryParamsFromCustomHeaders, realtimeUrlWithQueryString } from './appsyncUrl.mjs';\nimport { awsRealTimeHeaderBasedAuth } from './authHeaders.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst dispatchApiEvent = (payload) => {\n    Hub.dispatch('api', payload, 'PubSub', AMPLIFY_SYMBOL);\n};\nclass AWSWebSocketProvider {\n    constructor(args) {\n        this.subscriptionObserverMap = new Map();\n        this.socketStatus = SOCKET_STATUS.CLOSED;\n        this.keepAliveTimeout = DEFAULT_KEEP_ALIVE_TIMEOUT;\n        this.promiseArray = [];\n        this.connectionStateMonitor = new ConnectionStateMonitor();\n        this.reconnectionMonitor = new ReconnectionMonitor();\n        /**\n         * Open WebSocket connection & perform handshake\n         * Ref: https://docs.aws.amazon.com/appsync/latest/devguide/real-time-websocket-client.html#appsynclong-real-time-websocket-client-implementation-guide-for-graphql-subscriptions\n         *\n         * @param subprotocol -\n         */\n        this._establishConnection = async (awsRealTimeUrl, subprotocol) => {\n            this.logger.debug(`Establishing WebSocket connection to ${awsRealTimeUrl}`);\n            try {\n                await this._openConnection(awsRealTimeUrl, subprotocol);\n                await this._initiateHandshake();\n            }\n            catch (err) {\n                const { errorType, errorCode } = err;\n                if (NON_RETRYABLE_CODES.includes(errorCode) ||\n                    // Event API does not currently return `errorCode`. This may change in the future.\n                    // For now fall back to also checking known non-retryable error types\n                    NON_RETRYABLE_ERROR_TYPES.includes(errorType)) {\n                    throw new NonRetryableError(errorType);\n                }\n                else if (errorType) {\n                    throw new Error(errorType);\n                }\n                else {\n                    throw err;\n                }\n            }\n        };\n        this.logger = new ConsoleLogger(args.providerName);\n        this.wsProtocolName = args.wsProtocolName;\n        this.wsConnectUri = args.connectUri;\n        this.connectionStateMonitorSubscription =\n            this._startConnectionStateMonitoring();\n    }\n    /**\n     * Mark the socket closed and release all active listeners\n     */\n    close() {\n        // Mark the socket closed both in status and the connection monitor\n        this.socketStatus = SOCKET_STATUS.CLOSED;\n        this.connectionStateMonitor.record(CONNECTION_CHANGE.CONNECTION_FAILED);\n        // Turn off the subscription monitor Hub publishing\n        this.connectionStateMonitorSubscription.unsubscribe();\n        // Complete all reconnect observers\n        this.reconnectionMonitor.close();\n        return new Promise((resolve, reject) => {\n            if (this.awsRealTimeSocket) {\n                this.awsRealTimeSocket.onclose = (_) => {\n                    this.subscriptionObserverMap = new Map();\n                    this.awsRealTimeSocket = undefined;\n                    resolve();\n                };\n                this.awsRealTimeSocket.onerror = (err) => {\n                    reject(err);\n                };\n                this.awsRealTimeSocket.close();\n            }\n            else {\n                resolve();\n            }\n        });\n    }\n    subscribe(options, customUserAgentDetails) {\n        return new Observable(observer => {\n            if (!options?.appSyncGraphqlEndpoint) {\n                // \tobserver.error({\n                // \t\terrors: [\n                // \t\t\t{\n                // \t\t\t\t...new GraphQLError(\n                // \t\t\t\t\t`Subscribe only available for AWS AppSync endpoint`,\n                // \t\t\t\t),\n                // \t\t\t},\n                // \t\t],\n                // \t});\n                // \tobserver.complete();\n                return;\n            }\n            let subscriptionStartInProgress = false;\n            const subscriptionId = amplifyUuid();\n            const startSubscription = () => {\n                if (!subscriptionStartInProgress) {\n                    subscriptionStartInProgress = true;\n                    this._startSubscriptionWithAWSAppSyncRealTime({\n                        options,\n                        observer,\n                        subscriptionId,\n                        customUserAgentDetails,\n                    })\n                        .catch(err => {\n                        this.logger.debug(`${CONTROL_MSG.REALTIME_SUBSCRIPTION_INIT_ERROR}: ${err}`);\n                        this.connectionStateMonitor.record(CONNECTION_CHANGE.CLOSED);\n                    })\n                        .finally(() => {\n                        subscriptionStartInProgress = false;\n                    });\n                }\n            };\n            // Add an observable to the reconnection list to manage reconnection for this subscription\n            const reconnectSubscription = new Observable(reconnectSubscriptionObserver => {\n                this.reconnectionMonitor.addObserver(reconnectSubscriptionObserver);\n            }).subscribe(() => {\n                startSubscription();\n            });\n            startSubscription();\n            return async () => {\n                await this._cleanupSubscription(subscriptionId, reconnectSubscription);\n            };\n        });\n    }\n    async connect(options) {\n        if (this.socketStatus === SOCKET_STATUS.READY) {\n            return;\n        }\n        await this._connectWebSocket(options);\n    }\n    async publish(options, customUserAgentDetails) {\n        if (this.socketStatus !== SOCKET_STATUS.READY) {\n            throw new Error('Subscription has not been initialized');\n        }\n        return this._publishMessage(options, customUserAgentDetails);\n    }\n    async _connectWebSocket(options) {\n        const { apiKey, appSyncGraphqlEndpoint, authenticationType, region } = options;\n        const { additionalCustomHeaders } = await additionalHeadersFromOptions(options);\n        this.connectionStateMonitor.record(CONNECTION_CHANGE.OPENING_CONNECTION);\n        await this._initializeWebSocketConnection({\n            apiKey,\n            appSyncGraphqlEndpoint,\n            authenticationType,\n            region,\n            additionalCustomHeaders,\n        });\n    }\n    async _publishMessage(options, customUserAgentDetails) {\n        const subscriptionId = amplifyUuid();\n        const { additionalCustomHeaders, libraryConfigHeaders } = await additionalHeadersFromOptions(options);\n        const serializedSubscriptionMessage = await this._prepareSubscriptionPayload({\n            options,\n            subscriptionId,\n            customUserAgentDetails,\n            additionalCustomHeaders,\n            libraryConfigHeaders,\n            publish: true,\n        });\n        return new Promise((resolve, reject) => {\n            if (this.awsRealTimeSocket) {\n                const publishListener = (event) => {\n                    const data = JSON.parse(event.data);\n                    if (data.id === subscriptionId && data.type === 'publish_success') {\n                        this.awsRealTimeSocket &&\n                            this.awsRealTimeSocket.removeEventListener('message', publishListener);\n                        resolve();\n                    }\n                    if (data.erroredEvents && data.erroredEvents.length > 0) ;\n                };\n                this.awsRealTimeSocket.addEventListener('message', publishListener);\n                this.awsRealTimeSocket.addEventListener('close', () => {\n                    reject(new Error('WebSocket is closed'));\n                });\n                //\n                // this.awsRealTimeSocket.addEventListener('error', publishListener);\n                this.awsRealTimeSocket.send(serializedSubscriptionMessage);\n            }\n        });\n    }\n    async _cleanupSubscription(subscriptionId, reconnectSubscription) {\n        // Cleanup reconnection subscription\n        reconnectSubscription?.unsubscribe();\n        // Cleanup after unsubscribing or observer.complete was called after _startSubscriptionWithAWSAppSyncRealTime\n        try {\n            // Waiting that subscription has been connected before trying to unsubscribe\n            await this._waitForSubscriptionToBeConnected(subscriptionId);\n            const { subscriptionState } = this.subscriptionObserverMap.get(subscriptionId) || {};\n            if (!subscriptionState) {\n                // subscription already unsubscribed\n                return;\n            }\n            if (subscriptionState === SUBSCRIPTION_STATUS.CONNECTED) {\n                this._sendUnsubscriptionMessage(subscriptionId);\n            }\n            else {\n                throw new Error('Subscription never connected');\n            }\n        }\n        catch (err) {\n            this.logger.debug(`Error while unsubscribing ${err}`);\n        }\n        finally {\n            this._removeSubscriptionObserver(subscriptionId);\n        }\n    }\n    // Monitor the connection state and pass changes along to Hub\n    _startConnectionStateMonitoring() {\n        return this.connectionStateMonitor.connectionStateObservable.subscribe(connectionState => {\n            dispatchApiEvent({\n                event: CONNECTION_STATE_CHANGE,\n                data: {\n                    provider: this,\n                    connectionState,\n                },\n                message: `Connection state is ${connectionState}`,\n            });\n            this.connectionState = connectionState;\n            // Trigger START_RECONNECT when the connection is disrupted\n            if (connectionState === ConnectionState.ConnectionDisrupted) {\n                this.reconnectionMonitor.record(ReconnectEvent.START_RECONNECT);\n            }\n            // Trigger HALT_RECONNECT to halt reconnection attempts when the state is anything other than\n            // ConnectionDisrupted or Connecting\n            if ([\n                ConnectionState.Connected,\n                ConnectionState.ConnectedPendingDisconnect,\n                ConnectionState.ConnectedPendingKeepAlive,\n                ConnectionState.ConnectedPendingNetwork,\n                ConnectionState.ConnectionDisruptedPendingNetwork,\n                ConnectionState.Disconnected,\n            ].includes(connectionState)) {\n                this.reconnectionMonitor.record(ReconnectEvent.HALT_RECONNECT);\n            }\n        });\n    }\n    async _startSubscriptionWithAWSAppSyncRealTime({ options, observer, subscriptionId, customUserAgentDetails, }) {\n        const { query, variables } = options;\n        const { additionalCustomHeaders, libraryConfigHeaders } = await additionalHeadersFromOptions(options);\n        this.subscriptionObserverMap.set(subscriptionId, {\n            observer,\n            query: query ?? '',\n            variables: variables ?? {},\n            subscriptionState: SUBSCRIPTION_STATUS.PENDING,\n            startAckTimeoutId: undefined,\n        });\n        const serializedSubscriptionMessage = await this._prepareSubscriptionPayload({\n            options,\n            subscriptionId,\n            customUserAgentDetails,\n            additionalCustomHeaders,\n            libraryConfigHeaders,\n        });\n        try {\n            await this._connectWebSocket(options);\n        }\n        catch (err) {\n            this._logStartSubscriptionError(subscriptionId, observer, err);\n            return;\n        }\n        // Potential race condition can occur when unsubscribe is called during _initializeWebSocketConnection.\n        // E.g.unsubscribe gets invoked prior to finishing WebSocket handshake or START_ACK.\n        // Both subscriptionFailedCallback and subscriptionReadyCallback are used to synchronized this.\n        const { subscriptionFailedCallback, subscriptionReadyCallback } = this.subscriptionObserverMap.get(subscriptionId) ?? {};\n        // This must be done before sending the message in order to be listening immediately\n        this.subscriptionObserverMap.set(subscriptionId, {\n            observer,\n            subscriptionState: SUBSCRIPTION_STATUS.PENDING,\n            query: query ?? '',\n            variables: variables ?? {},\n            subscriptionReadyCallback,\n            subscriptionFailedCallback,\n            startAckTimeoutId: setTimeout(() => {\n                this._timeoutStartSubscriptionAck(subscriptionId);\n            }, START_ACK_TIMEOUT),\n        });\n        if (this.awsRealTimeSocket) {\n            this.awsRealTimeSocket.send(serializedSubscriptionMessage);\n        }\n    }\n    // Log logic for start subscription failures\n    _logStartSubscriptionError(subscriptionId, observer, err) {\n        this.logger.debug({ err });\n        const message = String(err.message ?? '');\n        // Resolving to give the state observer time to propogate the update\n        this.connectionStateMonitor.record(CONNECTION_CHANGE.CLOSED);\n        // Capture the error only when the network didn't cause disruption\n        if (this.connectionState !== ConnectionState.ConnectionDisruptedPendingNetwork) {\n            // When the error is non-retriable, error out the observable\n            if (isNonRetryableError(err)) {\n                observer.error({\n                    errors: [\n                        {\n                            ...new GraphQLError(`${CONTROL_MSG.CONNECTION_FAILED}: ${message}`),\n                        },\n                    ],\n                });\n            }\n            else {\n                this.logger.debug(`${CONTROL_MSG.CONNECTION_FAILED}: ${message}`);\n            }\n            const { subscriptionFailedCallback } = this.subscriptionObserverMap.get(subscriptionId) || {};\n            // Notify concurrent unsubscription\n            if (typeof subscriptionFailedCallback === 'function') {\n                subscriptionFailedCallback();\n            }\n        }\n    }\n    // Waiting that subscription has been connected before trying to unsubscribe\n    async _waitForSubscriptionToBeConnected(subscriptionId) {\n        const subscriptionObserver = this.subscriptionObserverMap.get(subscriptionId);\n        if (subscriptionObserver) {\n            const { subscriptionState } = subscriptionObserver;\n            // This in case unsubscribe is invoked before sending start subscription message\n            if (subscriptionState === SUBSCRIPTION_STATUS.PENDING) {\n                return new Promise((resolve, reject) => {\n                    const { observer, subscriptionState: observedSubscriptionState, variables, query, } = subscriptionObserver;\n                    this.subscriptionObserverMap.set(subscriptionId, {\n                        observer,\n                        subscriptionState: observedSubscriptionState,\n                        variables,\n                        query,\n                        subscriptionReadyCallback: resolve,\n                        subscriptionFailedCallback: reject,\n                    });\n                });\n            }\n        }\n    }\n    _sendUnsubscriptionMessage(subscriptionId) {\n        try {\n            if (this.awsRealTimeSocket &&\n                this.awsRealTimeSocket.readyState === WebSocket.OPEN &&\n                this.socketStatus === SOCKET_STATUS.READY) {\n                // Preparing unsubscribe message to stop receiving messages for that subscription\n                const unsubscribeMessage = this._unsubscribeMessage(subscriptionId);\n                const stringToAWSRealTime = JSON.stringify(unsubscribeMessage);\n                this.awsRealTimeSocket.send(stringToAWSRealTime);\n            }\n        }\n        catch (err) {\n            // If GQL_STOP is not sent because of disconnection issue, then there is nothing the client can do\n            this.logger.debug({ err });\n        }\n    }\n    _removeSubscriptionObserver(subscriptionId) {\n        this.subscriptionObserverMap.delete(subscriptionId);\n        // Verifying 1000ms after removing subscription in case there are new subscription unmount/mount\n        setTimeout(this._closeSocketIfRequired.bind(this), 1000);\n    }\n    _closeSocketIfRequired() {\n        if (this.subscriptionObserverMap.size > 0) {\n            // Active subscriptions on the WebSocket\n            return;\n        }\n        if (!this.awsRealTimeSocket) {\n            this.socketStatus = SOCKET_STATUS.CLOSED;\n            return;\n        }\n        this.connectionStateMonitor.record(CONNECTION_CHANGE.CLOSING_CONNECTION);\n        if (this.awsRealTimeSocket.bufferedAmount > 0) {\n            // Still data on the WebSocket\n            setTimeout(this._closeSocketIfRequired.bind(this), 1000);\n        }\n        else {\n            this.logger.debug('closing WebSocket...');\n            if (this.keepAliveTimeoutId) {\n                clearTimeout(this.keepAliveTimeoutId);\n            }\n            if (this.keepAliveAlertTimeoutId) {\n                clearTimeout(this.keepAliveAlertTimeoutId);\n            }\n            const tempSocket = this.awsRealTimeSocket;\n            // Cleaning callbacks to avoid race condition, socket still exists\n            tempSocket.onclose = null;\n            tempSocket.onerror = null;\n            tempSocket.close(1000);\n            this.awsRealTimeSocket = undefined;\n            this.socketStatus = SOCKET_STATUS.CLOSED;\n            this.connectionStateMonitor.record(CONNECTION_CHANGE.CLOSED);\n        }\n    }\n    _handleIncomingSubscriptionMessage(message) {\n        if (typeof message.data !== 'string') {\n            return;\n        }\n        const [isData, data] = this._handleSubscriptionData(message);\n        if (isData)\n            return;\n        const { type, id, payload } = data;\n        const { observer = null, query = '', variables = {}, startAckTimeoutId, subscriptionReadyCallback, subscriptionFailedCallback, } = this.subscriptionObserverMap.get(id) || {};\n        if (type === MESSAGE_TYPES.GQL_START_ACK ||\n            type === MESSAGE_TYPES.EVENT_SUBSCRIBE_ACK) {\n            this.logger.debug(`subscription ready for ${JSON.stringify({ query, variables })}`);\n            if (typeof subscriptionReadyCallback === 'function') {\n                subscriptionReadyCallback();\n            }\n            if (startAckTimeoutId)\n                clearTimeout(startAckTimeoutId);\n            dispatchApiEvent({\n                event: CONTROL_MSG.SUBSCRIPTION_ACK,\n                data: { query, variables },\n                message: 'Connection established for subscription',\n            });\n            const subscriptionState = SUBSCRIPTION_STATUS.CONNECTED;\n            if (observer) {\n                this.subscriptionObserverMap.set(id, {\n                    observer,\n                    query,\n                    variables,\n                    startAckTimeoutId: undefined,\n                    subscriptionState,\n                    subscriptionReadyCallback,\n                    subscriptionFailedCallback,\n                });\n            }\n            this.connectionStateMonitor.record(CONNECTION_CHANGE.CONNECTION_ESTABLISHED);\n            return;\n        }\n        if (type === MESSAGE_TYPES.GQL_CONNECTION_KEEP_ALIVE) {\n            if (this.keepAliveTimeoutId)\n                clearTimeout(this.keepAliveTimeoutId);\n            if (this.keepAliveAlertTimeoutId)\n                clearTimeout(this.keepAliveAlertTimeoutId);\n            this.keepAliveTimeoutId = setTimeout(() => {\n                this._errorDisconnect(CONTROL_MSG.TIMEOUT_DISCONNECT);\n            }, this.keepAliveTimeout);\n            this.keepAliveAlertTimeoutId = setTimeout(() => {\n                this.connectionStateMonitor.record(CONNECTION_CHANGE.KEEP_ALIVE_MISSED);\n            }, DEFAULT_KEEP_ALIVE_ALERT_TIMEOUT);\n            this.connectionStateMonitor.record(CONNECTION_CHANGE.KEEP_ALIVE);\n            return;\n        }\n        if (type === MESSAGE_TYPES.GQL_ERROR) {\n            const subscriptionState = SUBSCRIPTION_STATUS.FAILED;\n            if (observer) {\n                this.subscriptionObserverMap.set(id, {\n                    observer,\n                    query,\n                    variables,\n                    startAckTimeoutId,\n                    subscriptionReadyCallback,\n                    subscriptionFailedCallback,\n                    subscriptionState,\n                });\n                this.logger.debug(`${CONTROL_MSG.CONNECTION_FAILED}: ${JSON.stringify(payload ?? data)}`);\n                observer.error({\n                    errors: [\n                        {\n                            ...new GraphQLError(`${CONTROL_MSG.CONNECTION_FAILED}: ${JSON.stringify(payload ?? data)}`),\n                        },\n                    ],\n                });\n                if (startAckTimeoutId)\n                    clearTimeout(startAckTimeoutId);\n                if (typeof subscriptionFailedCallback === 'function') {\n                    subscriptionFailedCallback();\n                }\n            }\n        }\n    }\n    _errorDisconnect(msg) {\n        this.logger.debug(`Disconnect error: ${msg}`);\n        if (this.awsRealTimeSocket) {\n            this.connectionStateMonitor.record(CONNECTION_CHANGE.CLOSED);\n            this.awsRealTimeSocket.close();\n        }\n        this.socketStatus = SOCKET_STATUS.CLOSED;\n    }\n    _timeoutStartSubscriptionAck(subscriptionId) {\n        const subscriptionObserver = this.subscriptionObserverMap.get(subscriptionId);\n        if (subscriptionObserver) {\n            const { observer, query, variables } = subscriptionObserver;\n            if (!observer) {\n                return;\n            }\n            this.subscriptionObserverMap.set(subscriptionId, {\n                observer,\n                query,\n                variables,\n                subscriptionState: SUBSCRIPTION_STATUS.FAILED,\n            });\n            this.connectionStateMonitor.record(CONNECTION_CHANGE.CLOSED);\n            this.logger.debug('timeoutStartSubscription', JSON.stringify({ query, variables }));\n        }\n    }\n    _initializeWebSocketConnection({ appSyncGraphqlEndpoint, authenticationType, apiKey, region, additionalCustomHeaders, }) {\n        if (this.socketStatus === SOCKET_STATUS.READY) {\n            return;\n        }\n        // TODO(Eslint): refactor to now use async function as the promise executor\n        // eslint-disable-next-line no-async-promise-executor\n        return new Promise(async (resolve, reject) => {\n            this.promiseArray.push({ res: resolve, rej: reject });\n            if (this.socketStatus === SOCKET_STATUS.CLOSED) {\n                try {\n                    this.socketStatus = SOCKET_STATUS.CONNECTING;\n                    // Empty payload on connect\n                    const payloadString = '{}';\n                    const authHeader = await awsRealTimeHeaderBasedAuth({\n                        authenticationType,\n                        payload: payloadString,\n                        canonicalUri: this.wsConnectUri,\n                        apiKey,\n                        appSyncGraphqlEndpoint,\n                        region,\n                        additionalCustomHeaders,\n                    });\n                    const headerString = authHeader ? JSON.stringify(authHeader) : '';\n                    // base64url-encoded string\n                    const encodedHeader = base64Encoder.convert(headerString, {\n                        urlSafe: true,\n                        skipPadding: true,\n                    });\n                    const authTokenSubprotocol = `header-${encodedHeader}`;\n                    const queryParams = queryParamsFromCustomHeaders(additionalCustomHeaders);\n                    const awsRealTimeUrl = realtimeUrlWithQueryString(appSyncGraphqlEndpoint, queryParams);\n                    await this._establishRetryableConnection(awsRealTimeUrl, authTokenSubprotocol);\n                    this.promiseArray.forEach(({ res }) => {\n                        this.logger.debug('Notifying connection successful');\n                        res();\n                    });\n                    this.socketStatus = SOCKET_STATUS.READY;\n                    this.promiseArray = [];\n                }\n                catch (err) {\n                    this.logger.debug('Connection exited with', err);\n                    this.promiseArray.forEach(({ rej }) => {\n                        rej(err);\n                    });\n                    this.promiseArray = [];\n                    if (this.awsRealTimeSocket &&\n                        this.awsRealTimeSocket.readyState === WebSocket.OPEN) {\n                        this.awsRealTimeSocket.close(3001);\n                    }\n                    this.awsRealTimeSocket = undefined;\n                    this.socketStatus = SOCKET_STATUS.CLOSED;\n                }\n            }\n        });\n    }\n    async _establishRetryableConnection(awsRealTimeUrl, subprotocol) {\n        this.logger.debug(`Establishing retryable connection`);\n        await jitteredExponentialRetry(this._establishConnection.bind(this), [awsRealTimeUrl, subprotocol], MAX_DELAY_MS);\n    }\n    async _openConnection(awsRealTimeUrl, subprotocol) {\n        return new Promise((resolve, reject) => {\n            const newSocket = this._getNewWebSocket(awsRealTimeUrl, [\n                this.wsProtocolName,\n                subprotocol,\n            ]);\n            newSocket.onerror = () => {\n                this.logger.debug(`WebSocket connection error`);\n            };\n            newSocket.onclose = () => {\n                reject(new Error('Connection handshake error'));\n            };\n            newSocket.onopen = () => {\n                this.awsRealTimeSocket = newSocket;\n                resolve();\n            };\n        });\n    }\n    _getNewWebSocket(url, protocol) {\n        return new WebSocket(url, protocol);\n    }\n    async _initiateHandshake() {\n        return new Promise((resolve, reject) => {\n            if (!this.awsRealTimeSocket) {\n                reject(new Error('awsRealTimeSocket undefined'));\n                return;\n            }\n            let ackOk = false;\n            this.awsRealTimeSocket.onerror = error => {\n                this.logger.debug(`WebSocket error ${JSON.stringify(error)}`);\n            };\n            this.awsRealTimeSocket.onclose = event => {\n                this.logger.debug(`WebSocket closed ${event.reason}`);\n                reject(new Error(JSON.stringify(event)));\n            };\n            this.awsRealTimeSocket.onmessage = (message) => {\n                if (typeof message.data !== 'string') {\n                    return;\n                }\n                this.logger.debug(`subscription message from AWS AppSyncRealTime: ${message.data} `);\n                const data = JSON.parse(message.data);\n                const { type } = data;\n                const connectionTimeoutMs = this._extractConnectionTimeout(data);\n                if (type === MESSAGE_TYPES.GQL_CONNECTION_ACK) {\n                    ackOk = true;\n                    this._registerWebsocketHandlers(connectionTimeoutMs);\n                    resolve('Connected to AWS AppSyncRealTime');\n                    return;\n                }\n                if (type === MESSAGE_TYPES.GQL_CONNECTION_ERROR) {\n                    const { errorType, errorCode } = this._extractErrorCodeAndType(data);\n                    // TODO(Eslint): refactor to reject an Error object instead of a plain object\n                    // eslint-disable-next-line prefer-promise-reject-errors\n                    reject({ errorType, errorCode });\n                }\n            };\n            const gqlInit = {\n                type: MESSAGE_TYPES.GQL_CONNECTION_INIT,\n            };\n            this.awsRealTimeSocket.send(JSON.stringify(gqlInit));\n            const checkAckOk = (targetAckOk) => {\n                if (!targetAckOk) {\n                    this.connectionStateMonitor.record(CONNECTION_CHANGE.CONNECTION_FAILED);\n                    reject(new Error(`Connection timeout: ack from AWSAppSyncRealTime was not received after ${CONNECTION_INIT_TIMEOUT} ms`));\n                }\n            };\n            setTimeout(() => {\n                checkAckOk(ackOk);\n            }, CONNECTION_INIT_TIMEOUT);\n        });\n    }\n    _registerWebsocketHandlers(connectionTimeoutMs) {\n        if (!this.awsRealTimeSocket) {\n            return;\n        }\n        this.keepAliveTimeout = connectionTimeoutMs;\n        this.awsRealTimeSocket.onmessage =\n            this._handleIncomingSubscriptionMessage.bind(this);\n        this.awsRealTimeSocket.onerror = err => {\n            this.logger.debug(err);\n            this._errorDisconnect(CONTROL_MSG.CONNECTION_CLOSED);\n        };\n        this.awsRealTimeSocket.onclose = event => {\n            this.logger.debug(`WebSocket closed ${event.reason}`);\n            this._errorDisconnect(CONTROL_MSG.CONNECTION_CLOSED);\n        };\n    }\n}\n\nexport { AWSWebSocketProvider };\n//# sourceMappingURL=index.mjs.map\n","export { AMPLIFY_SYMBOL } from '@aws-amplify/core/internals/utils';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst MAX_DELAY_MS = 5000;\nconst NON_RETRYABLE_CODES = [400, 401, 403];\nconst NON_RETRYABLE_ERROR_TYPES = [\n    'BadRequestException',\n    'UnauthorizedException',\n];\nconst CONNECTION_STATE_CHANGE = 'ConnectionStateChange';\nvar MESSAGE_TYPES;\n(function (MESSAGE_TYPES) {\n    /**\n     * Client -> Server message.\n     * This message type is the first message after handshake and this will initialize AWS AppSync RealTime communication\n     */\n    MESSAGE_TYPES[\"GQL_CONNECTION_INIT\"] = \"connection_init\";\n    /**\n     * Server -> Client message\n     * This message type is in case there is an issue with AWS AppSync RealTime when establishing connection\n     */\n    MESSAGE_TYPES[\"GQL_CONNECTION_ERROR\"] = \"connection_error\";\n    /**\n     * Server -> Client message.\n     * This message type is for the ack response from AWS AppSync RealTime for GQL_CONNECTION_INIT message\n     */\n    MESSAGE_TYPES[\"GQL_CONNECTION_ACK\"] = \"connection_ack\";\n    /**\n     * Client -> Server message.\n     * This message type is for register subscriptions with AWS AppSync RealTime\n     */\n    MESSAGE_TYPES[\"GQL_START\"] = \"start\";\n    /**\n     * Server -> Client message.\n     * This message type is for the ack response from AWS AppSync RealTime for GQL_START message\n     */\n    MESSAGE_TYPES[\"GQL_START_ACK\"] = \"start_ack\";\n    /**\n     * Server -> Client message.\n     * This message type is for subscription message from AWS AppSync RealTime or Events\n     */\n    MESSAGE_TYPES[\"DATA\"] = \"data\";\n    /**\n     * Server -> Client message.\n     * This message type helps the client to know is still receiving messages from AWS AppSync RealTime\n     */\n    MESSAGE_TYPES[\"GQL_CONNECTION_KEEP_ALIVE\"] = \"ka\";\n    /**\n     * Client -> Server message.\n     * This message type is for unregister subscriptions with AWS AppSync RealTime\n     */\n    MESSAGE_TYPES[\"GQL_STOP\"] = \"stop\";\n    /**\n     * Server -> Client message.\n     * This message type is for the ack response from AWS AppSync RealTime for GQL_STOP message\n     */\n    MESSAGE_TYPES[\"GQL_COMPLETE\"] = \"complete\";\n    /**\n     * Server -> Client message.\n     * This message type is for sending error messages from AWS AppSync RealTime to the client\n     */\n    MESSAGE_TYPES[\"GQL_ERROR\"] = \"error\";\n    /**\n     * Client -> Server message.\n     * This message type is for registering subscriptions with Events\n     */\n    MESSAGE_TYPES[\"EVENT_SUBSCRIBE\"] = \"subscribe\";\n    /**\n     * Client -> Server message.\n     * This message type is for publishing a message with Events\n     */\n    MESSAGE_TYPES[\"EVENT_PUBLISH\"] = \"publish\";\n    /**\n     * Server -> Client message.\n     * Server acknowledges successful subscription\n     */\n    MESSAGE_TYPES[\"EVENT_SUBSCRIBE_ACK\"] = \"subscribe_success\";\n    /**\n     * Server -> Client message.\n     * Server acknowledges successful publish\n     */\n    MESSAGE_TYPES[\"EVENT_PUBLISH_ACK\"] = \"publish_success\";\n    /**\n     * Client -> Server message.\n     * This message type is for unregister subscriptions with AWS AppSync RealTime\n     */\n    MESSAGE_TYPES[\"EVENT_STOP\"] = \"unsubscribe\";\n    /**\n     * Server -> Client message.\n     * This is the ack response from AWS AppSync Events to EVENT_STOP message\n     */\n    MESSAGE_TYPES[\"EVENT_COMPLETE\"] = \"unsubscribe_success\";\n})(MESSAGE_TYPES || (MESSAGE_TYPES = {}));\nvar SUBSCRIPTION_STATUS;\n(function (SUBSCRIPTION_STATUS) {\n    SUBSCRIPTION_STATUS[SUBSCRIPTION_STATUS[\"PENDING\"] = 0] = \"PENDING\";\n    SUBSCRIPTION_STATUS[SUBSCRIPTION_STATUS[\"CONNECTED\"] = 1] = \"CONNECTED\";\n    SUBSCRIPTION_STATUS[SUBSCRIPTION_STATUS[\"FAILED\"] = 2] = \"FAILED\";\n})(SUBSCRIPTION_STATUS || (SUBSCRIPTION_STATUS = {}));\nvar SOCKET_STATUS;\n(function (SOCKET_STATUS) {\n    SOCKET_STATUS[SOCKET_STATUS[\"CLOSED\"] = 0] = \"CLOSED\";\n    SOCKET_STATUS[SOCKET_STATUS[\"READY\"] = 1] = \"READY\";\n    SOCKET_STATUS[SOCKET_STATUS[\"CONNECTING\"] = 2] = \"CONNECTING\";\n})(SOCKET_STATUS || (SOCKET_STATUS = {}));\nconst AWS_APPSYNC_REALTIME_HEADERS = {\n    accept: 'application/json, text/javascript',\n    'content-encoding': 'amz-1.0',\n    'content-type': 'application/json; charset=UTF-8',\n};\n/**\n * Time in milleseconds to wait for GQL_CONNECTION_INIT message\n */\nconst CONNECTION_INIT_TIMEOUT = 15000;\n/**\n * Time in milleseconds to wait for GQL_START_ACK message\n */\nconst START_ACK_TIMEOUT = 15000;\n/**\n * Default Time in milleseconds to wait for GQL_CONNECTION_KEEP_ALIVE message\n */\nconst DEFAULT_KEEP_ALIVE_TIMEOUT = 5 * 60 * 1000;\n/**\n * Default Time in milleseconds to alert for missed GQL_CONNECTION_KEEP_ALIVE message\n */\nconst DEFAULT_KEEP_ALIVE_ALERT_TIMEOUT = 65 * 1000;\n/**\n * Default delay time in milleseconds between when reconnect is triggered vs when it is attempted\n */\nconst RECONNECT_DELAY = 5 * 1000;\n/**\n * Default interval time in milleseconds between when reconnect is re-attempted\n */\nconst RECONNECT_INTERVAL = 60 * 1000;\n\nexport { AWS_APPSYNC_REALTIME_HEADERS, CONNECTION_INIT_TIMEOUT, CONNECTION_STATE_CHANGE, DEFAULT_KEEP_ALIVE_ALERT_TIMEOUT, DEFAULT_KEEP_ALIVE_TIMEOUT, MAX_DELAY_MS, MESSAGE_TYPES, NON_RETRYABLE_CODES, NON_RETRYABLE_ERROR_TYPES, RECONNECT_DELAY, RECONNECT_INTERVAL, SOCKET_STATUS, START_ACK_TIMEOUT, SUBSCRIPTION_STATUS };\n//# sourceMappingURL=constants.mjs.map\n","import { parse, print } from 'graphql';\nimport { catchError } from 'rxjs';\nimport { AmplifyUrl, getAmplifyUserAgent } from '@aws-amplify/core/internals/utils';\nimport { isCancelError } from '@aws-amplify/api-rest';\nimport { post, cancel, updateRequestToBeCancellable } from '@aws-amplify/api-rest/internals';\nimport { AWSAppSyncRealTimeProvider } from '../Providers/AWSAppSyncRealTimeProvider/index.mjs';\nimport { resolveConfig } from '../utils/resolveConfig.mjs';\nimport { resolveLibraryOptions } from '../utils/resolveLibraryOptions.mjs';\nimport { repackageUnauthorizedError } from '../utils/errors/repackageAuthError.mjs';\nimport { NO_ENDPOINT } from '../utils/errors/constants.mjs';\nimport { GraphQLApiError } from '../utils/errors/GraphQLApiError.mjs';\nimport '../utils/errors/validation.mjs';\nimport { createGraphQLResultWithError } from '../utils/errors/createGraphQLResultWithError.mjs';\nimport { isGraphQLResponseWithErrors } from './utils/runtimeTypeGuards/isGraphQLResponseWithErrors.mjs';\nimport { headerBasedAuth } from './graphqlAuth.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst USER_AGENT_HEADER = 'x-amz-user-agent';\nconst isAmplifyInstance = (amplify) => {\n    return typeof amplify !== 'function';\n};\n/**\n * Export Cloud Logic APIs\n */\nclass InternalGraphQLAPIClass {\n    constructor() {\n        /**\n         * @private\n         */\n        this.appSyncRealTime = new AWSAppSyncRealTimeProvider();\n        this._api = {\n            post,\n            cancelREST: cancel,\n            isCancelErrorREST: isCancelError,\n            updateRequestToBeCancellable,\n        };\n    }\n    getModuleName() {\n        return 'InternalGraphQLAPI';\n    }\n    /**\n     * to get the operation type\n     * @param operation\n     */\n    getGraphqlOperationType(operation) {\n        const doc = parse(operation);\n        const definitions = doc.definitions;\n        const [{ operation: operationType }] = definitions;\n        return operationType;\n    }\n    /**\n     * Executes a GraphQL operation\n     *\n     * @param options - GraphQL Options\n     * @param [additionalHeaders] - headers to merge in after any `libraryConfigHeaders` set in the config\n     * @returns An Observable if the query is a subscription query, else a promise of the graphql result.\n     */\n    graphql(amplify, { query: paramQuery, variables = {}, authMode, authToken }, additionalHeaders, customUserAgentDetails) {\n        const query = typeof paramQuery === 'string'\n            ? parse(paramQuery)\n            : parse(print(paramQuery));\n        const [operationDef = {}] = query.definitions.filter(def => def.kind === 'OperationDefinition');\n        const { operation: operationType } = operationDef;\n        const headers = additionalHeaders || {};\n        switch (operationType) {\n            case 'query':\n            case 'mutation': {\n                const abortController = new AbortController();\n                let responsePromise;\n                if (isAmplifyInstance(amplify)) {\n                    responsePromise = this._graphql(amplify, { query, variables, authMode }, headers, abortController, customUserAgentDetails, authToken);\n                }\n                else {\n                    // NOTE: this wrapper function must be await-able so the Amplify server context manager can\n                    // destroy the context only after it completes\n                    const wrapper = async (amplifyInstance) => {\n                        const result = await this._graphql(amplifyInstance, { query, variables, authMode }, headers, abortController, customUserAgentDetails, authToken);\n                        return result;\n                    };\n                    responsePromise = amplify(wrapper);\n                }\n                this._api.updateRequestToBeCancellable(responsePromise, abortController);\n                return responsePromise;\n            }\n            case 'subscription':\n                return this._graphqlSubscribe(amplify, { query, variables, authMode }, headers, customUserAgentDetails, authToken);\n            default:\n                throw new Error(`invalid operation type: ${operationType}`);\n        }\n    }\n    async _graphql(amplify, { query, variables, authMode: explicitAuthMode }, additionalHeaders = {}, abortController, customUserAgentDetails, authToken) {\n        const { apiKey, region, endpoint: appSyncGraphqlEndpoint, customEndpoint, customEndpointRegion, defaultAuthMode, } = resolveConfig(amplify);\n        const initialAuthMode = explicitAuthMode || defaultAuthMode || 'iam';\n        // identityPool is an alias for iam. TODO: remove 'iam' in v7\n        const authMode = initialAuthMode === 'identityPool' ? 'iam' : initialAuthMode;\n        /**\n         * Retrieve library options from Amplify configuration.\n         * `customHeaders` here are from the Amplify configuration options,\n         * and are for non-AppSync endpoints only. These are *not* the same as\n         * `additionalHeaders`, which are custom headers that are either 1)\n         * included when configuring the API client or 2) passed along with\n         * individual requests.\n         */\n        const { headers: customHeaders, withCredentials } = resolveLibraryOptions(amplify);\n        /**\n         * Client or request-specific custom headers that may or may not be\n         * returned by a function:\n         */\n        let additionalCustomHeaders;\n        if (typeof additionalHeaders === 'function') {\n            const requestOptions = {\n                method: 'POST',\n                url: new AmplifyUrl(customEndpoint || appSyncGraphqlEndpoint || '').toString(),\n                queryString: print(query),\n            };\n            additionalCustomHeaders = await additionalHeaders(requestOptions);\n        }\n        else {\n            additionalCustomHeaders = additionalHeaders;\n        }\n        // if an authorization header is set, have the explicit authToken take precedence\n        if (authToken) {\n            additionalCustomHeaders = {\n                ...additionalCustomHeaders,\n                Authorization: authToken,\n            };\n        }\n        const authHeaders = await headerBasedAuth(amplify, authMode, apiKey, additionalCustomHeaders);\n        const headers = {\n            ...(!customEndpoint && authHeaders),\n            /**\n             * Custom endpoint headers.\n             * If there is both a custom endpoint and custom region present, we get the headers.\n             * If there is a custom endpoint but no region, we return an empty object.\n             * If neither are present, we return an empty object.\n             */\n            ...((customEndpoint && (customEndpointRegion ? authHeaders : {})) || {}),\n            // Custom headers included in Amplify configuration options:\n            ...(customHeaders &&\n                (await customHeaders({\n                    query: print(query),\n                    variables,\n                }))),\n            // Custom headers from individual requests or API client configuration:\n            ...additionalCustomHeaders,\n            // User agent headers:\n            ...(!customEndpoint && {\n                [USER_AGENT_HEADER]: getAmplifyUserAgent(customUserAgentDetails),\n            }),\n        };\n        const body = {\n            query: print(query),\n            variables: variables || null,\n        };\n        let signingServiceInfo;\n        /**\n         * We do not send the signing service info to the REST API under the\n         * following conditions (i.e. it will not sign the request):\n         *   - there is a custom endpoint but no region\n         *   - the auth mode is `none`, or `apiKey`\n         *   - the auth mode is a type other than the types listed below\n         */\n        if ((customEndpoint && !customEndpointRegion) ||\n            (authMode !== 'oidc' &&\n                authMode !== 'userPool' &&\n                authMode !== 'iam' &&\n                authMode !== 'lambda')) {\n            signingServiceInfo = undefined;\n        }\n        else {\n            signingServiceInfo = {\n                service: !customEndpointRegion ? 'appsync' : 'execute-api',\n                region: !customEndpointRegion ? region : customEndpointRegion,\n            };\n        }\n        const endpoint = customEndpoint || appSyncGraphqlEndpoint;\n        if (!endpoint) {\n            throw createGraphQLResultWithError(new GraphQLApiError(NO_ENDPOINT));\n        }\n        let response;\n        try {\n            // \t// // See the inline doc of the REST `post()` API for possible errors to be thrown.\n            // \t// // As these errors are catastrophic they should be caught and handled by GraphQL\n            // \t// // API consumers.\n            const { body: responseBody } = await this._api.post(amplify, {\n                url: new AmplifyUrl(endpoint),\n                options: {\n                    headers,\n                    body,\n                    signingServiceInfo,\n                    withCredentials,\n                },\n                abortController,\n            });\n            response = await responseBody.json();\n        }\n        catch (error) {\n            if (this.isCancelError(error)) {\n                throw error;\n            }\n            response = createGraphQLResultWithError(error);\n        }\n        if (isGraphQLResponseWithErrors(response)) {\n            throw repackageUnauthorizedError(response);\n        }\n        return response;\n    }\n    /**\n     * Checks to see if an error thrown is from an api request cancellation\n     * @param {any} error - Any error\n     * @return {boolean} - A boolean indicating if the error was from an api request cancellation\n     */\n    isCancelError(error) {\n        return this._api.isCancelErrorREST(error);\n    }\n    /**\n     * Cancels an inflight request. Only applicable for graphql queries and mutations\n     * @param {any} request - request to cancel\n     * @returns - A boolean indicating if the request was cancelled\n     */\n    cancel(request, message) {\n        return this._api.cancelREST(request, message);\n    }\n    _graphqlSubscribe(amplify, { query, variables, authMode: explicitAuthMode }, additionalHeaders = {}, customUserAgentDetails, authToken) {\n        const config = resolveConfig(amplify);\n        const initialAuthMode = explicitAuthMode || config?.defaultAuthMode || 'iam';\n        // identityPool is an alias for iam. TODO: remove 'iam' in v7\n        const authMode = initialAuthMode === 'identityPool' ? 'iam' : initialAuthMode;\n        /**\n         * Retrieve library options from Amplify configuration.\n         * `libraryConfigHeaders` are from the Amplify configuration options,\n         * and will not be overwritten by other custom headers. These are *not*\n         * the same as `additionalHeaders`, which are custom headers that are\n         * either 1)included when configuring the API client or 2) passed along\n         * with individual requests.\n         */\n        const { headers: libraryConfigHeaders } = resolveLibraryOptions(amplify);\n        return this.appSyncRealTime\n            .subscribe({\n            query: print(query),\n            variables,\n            appSyncGraphqlEndpoint: config?.endpoint,\n            region: config?.region,\n            authenticationType: authMode,\n            apiKey: config?.apiKey,\n            additionalHeaders,\n            authToken,\n            libraryConfigHeaders,\n        }, customUserAgentDetails)\n            .pipe(catchError(e => {\n            if (e.errors) {\n                throw repackageUnauthorizedError(e);\n            }\n            throw e;\n        }));\n    }\n}\nconst InternalGraphQLAPI = new InternalGraphQLAPIClass();\n\nexport { InternalGraphQLAPI, InternalGraphQLAPIClass };\n//# sourceMappingURL=InternalGraphQLAPI.mjs.map\n","import { GraphQLApiError } from '../utils/errors/GraphQLApiError.mjs';\nimport '../utils/errors/validation.mjs';\nimport 'graphql';\nimport { NO_AUTH_TOKEN_HEADER, NO_SIGNED_IN_USER, NO_VALID_AUTH_TOKEN, NO_VALID_CREDENTIALS, NO_API_KEY } from '../utils/errors/constants.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nasync function headerBasedAuth(amplify, authMode, apiKey, additionalHeaders = {}) {\n    let headers = {};\n    switch (authMode) {\n        case 'apiKey':\n            if (!apiKey) {\n                throw new GraphQLApiError(NO_API_KEY);\n            }\n            headers = {\n                'X-Api-Key': apiKey,\n            };\n            break;\n        case 'iam': {\n            const session = await amplify.Auth.fetchAuthSession();\n            if (session.credentials === undefined) {\n                throw new GraphQLApiError(NO_VALID_CREDENTIALS);\n            }\n            break;\n        }\n        case 'oidc':\n        case 'userPool': {\n            let token;\n            try {\n                token = (await amplify.Auth.fetchAuthSession()).tokens?.accessToken.toString();\n            }\n            catch (e) {\n                // fetchAuthSession failed\n                throw new GraphQLApiError({\n                    ...NO_SIGNED_IN_USER,\n                    underlyingError: e,\n                });\n            }\n            // `fetchAuthSession()` succeeded but didn't return `tokens`.\n            // This may happen when unauthenticated access is enabled and there is\n            // no user signed in.\n            if (!token) {\n                throw new GraphQLApiError(NO_VALID_AUTH_TOKEN);\n            }\n            headers = {\n                Authorization: token,\n            };\n            break;\n        }\n        case 'lambda':\n            if (typeof additionalHeaders === 'object' &&\n                !additionalHeaders.Authorization) {\n                throw new GraphQLApiError(NO_AUTH_TOKEN_HEADER);\n            }\n            headers = {\n                Authorization: additionalHeaders.Authorization,\n            };\n            break;\n    }\n    return headers;\n}\n\nexport { headerBasedAuth };\n//# sourceMappingURL=graphqlAuth.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nfunction isGraphQLResponseWithErrors(response) {\n    if (!response) {\n        return false;\n    }\n    const r = response;\n    return Array.isArray(r.errors) && r.errors.length > 0;\n}\n\nexport { isGraphQLResponseWithErrors };\n//# sourceMappingURL=isGraphQLResponseWithErrors.mjs.map\n","var CONTROL_MSG;\n(function (CONTROL_MSG) {\n    CONTROL_MSG[\"CONNECTION_CLOSED\"] = \"Connection closed\";\n    CONTROL_MSG[\"CONNECTION_FAILED\"] = \"Connection failed\";\n    CONTROL_MSG[\"REALTIME_SUBSCRIPTION_INIT_ERROR\"] = \"AppSync Realtime subscription init error\";\n    CONTROL_MSG[\"SUBSCRIPTION_ACK\"] = \"Subscription ack\";\n    CONTROL_MSG[\"TIMEOUT_DISCONNECT\"] = \"Timeout disconnect\";\n})(CONTROL_MSG || (CONTROL_MSG = {}));\n/** @enum {string} */\nvar ConnectionState;\n(function (ConnectionState) {\n    /*\n     * The connection is alive and healthy\n     */\n    ConnectionState[\"Connected\"] = \"Connected\";\n    /*\n     * The connection is alive, but the connection is offline\n     */\n    ConnectionState[\"ConnectedPendingNetwork\"] = \"ConnectedPendingNetwork\";\n    /*\n     * The connection has been disconnected while in use\n     */\n    ConnectionState[\"ConnectionDisrupted\"] = \"ConnectionDisrupted\";\n    /*\n     * The connection has been disconnected and the network is offline\n     */\n    ConnectionState[\"ConnectionDisruptedPendingNetwork\"] = \"ConnectionDisruptedPendingNetwork\";\n    /*\n     * The connection is in the process of connecting\n     */\n    ConnectionState[\"Connecting\"] = \"Connecting\";\n    /*\n     * The connection is not in use and is being disconnected\n     */\n    ConnectionState[\"ConnectedPendingDisconnect\"] = \"ConnectedPendingDisconnect\";\n    /*\n     * The connection is not in use and has been disconnected\n     */\n    ConnectionState[\"Disconnected\"] = \"Disconnected\";\n    /*\n     * The connection is alive, but a keep alive message has been missed\n     */\n    ConnectionState[\"ConnectedPendingKeepAlive\"] = \"ConnectedPendingKeepAlive\";\n})(ConnectionState || (ConnectionState = {}));\n\nexport { CONTROL_MSG, ConnectionState };\n//# sourceMappingURL=PubSub.mjs.map\n","export { CONTROL_MSG, ConnectionState } from './PubSub.mjs';\n\nvar GraphQLAuthError;\n(function (GraphQLAuthError) {\n    GraphQLAuthError[\"NO_API_KEY\"] = \"No api-key configured\";\n    GraphQLAuthError[\"NO_CURRENT_USER\"] = \"No current user\";\n    GraphQLAuthError[\"NO_CREDENTIALS\"] = \"No credentials\";\n    GraphQLAuthError[\"NO_FEDERATED_JWT\"] = \"No federated jwt\";\n    GraphQLAuthError[\"NO_AUTH_TOKEN\"] = \"No auth token specified\";\n})(GraphQLAuthError || (GraphQLAuthError = {}));\nconst __amplify = Symbol('amplify');\nconst __authMode = Symbol('authMode');\nconst __authToken = Symbol('authToken');\nconst __headers = Symbol('headers');\nfunction getInternals(client) {\n    const c = client;\n    return {\n        amplify: c[__amplify],\n        authMode: c[__authMode],\n        authToken: c[__authToken],\n        headers: c[__headers],\n    };\n}\n\nexport { GraphQLAuthError, __amplify, __authMode, __authToken, __headers, getInternals };\n//# sourceMappingURL=index.mjs.map\n","import { Observable, map, filter } from 'rxjs';\nimport { ConnectionState } from '../types/PubSub.mjs';\nimport { ReachabilityMonitor } from './ReachabilityMonitor/index.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst CONNECTION_CHANGE = {\n    KEEP_ALIVE_MISSED: { keepAliveState: 'unhealthy' },\n    KEEP_ALIVE: { keepAliveState: 'healthy' },\n    CONNECTION_ESTABLISHED: { connectionState: 'connected' },\n    CONNECTION_FAILED: {\n        intendedConnectionState: 'disconnected',\n        connectionState: 'disconnected',\n    },\n    CLOSING_CONNECTION: { intendedConnectionState: 'disconnected' },\n    OPENING_CONNECTION: {\n        intendedConnectionState: 'connected',\n        connectionState: 'connecting',\n    },\n    CLOSED: { connectionState: 'disconnected' },\n    ONLINE: { networkState: 'connected' },\n    OFFLINE: { networkState: 'disconnected' },\n};\nclass ConnectionStateMonitor {\n    constructor() {\n        this._networkMonitoringSubscription = undefined;\n        this._linkedConnectionState = {\n            networkState: 'connected',\n            connectionState: 'disconnected',\n            intendedConnectionState: 'disconnected',\n            keepAliveState: 'healthy',\n        };\n        // Attempt to update the state with the current actual network state\n        this._initialNetworkStateSubscription = ReachabilityMonitor().subscribe(({ online }) => {\n            this.record(online ? CONNECTION_CHANGE.ONLINE : CONNECTION_CHANGE.OFFLINE);\n            this._initialNetworkStateSubscription?.unsubscribe();\n        });\n        this._linkedConnectionStateObservable =\n            new Observable(connectionStateObserver => {\n                connectionStateObserver.next(this._linkedConnectionState);\n                this._linkedConnectionStateObserver = connectionStateObserver;\n            });\n    }\n    /**\n     * Turn network state monitoring on if it isn't on already\n     */\n    enableNetworkMonitoring() {\n        // If no initial network state was discovered, stop trying\n        this._initialNetworkStateSubscription?.unsubscribe();\n        // Maintain the network state based on the reachability monitor\n        if (this._networkMonitoringSubscription === undefined) {\n            this._networkMonitoringSubscription = ReachabilityMonitor().subscribe(({ online }) => {\n                this.record(online ? CONNECTION_CHANGE.ONLINE : CONNECTION_CHANGE.OFFLINE);\n            });\n        }\n    }\n    /**\n     * Turn network state monitoring off if it isn't off already\n     */\n    disableNetworkMonitoring() {\n        this._networkMonitoringSubscription?.unsubscribe();\n        this._networkMonitoringSubscription = undefined;\n    }\n    /**\n     * Get the observable that allows us to monitor the connection state\n     *\n     * @returns {Observable<ConnectionState>} - The observable that emits ConnectionState updates\n     */\n    get connectionStateObservable() {\n        let previous;\n        // The linked state aggregates state changes to any of the network, connection,\n        // intendedConnection and keepAliveHealth. Some states will change these independent\n        // states without changing the overall connection state.\n        // After translating from linked states to ConnectionState, then remove any duplicates\n        return this._linkedConnectionStateObservable\n            .pipe(map(value => {\n            return this.connectionStatesTranslator(value);\n        }))\n            .pipe(filter(current => {\n            const toInclude = current !== previous;\n            previous = current;\n            return toInclude;\n        }));\n    }\n    /*\n     * Updates local connection state and emits the full state to the observer.\n     */\n    record(statusUpdates) {\n        // Maintain the network monitor\n        if (statusUpdates.intendedConnectionState === 'connected') {\n            this.enableNetworkMonitoring();\n        }\n        else if (statusUpdates.intendedConnectionState === 'disconnected') {\n            this.disableNetworkMonitoring();\n        }\n        // Maintain the socket state\n        const newSocketStatus = {\n            ...this._linkedConnectionState,\n            ...statusUpdates,\n        };\n        this._linkedConnectionState = { ...newSocketStatus };\n        this._linkedConnectionStateObserver?.next(this._linkedConnectionState);\n    }\n    /*\n     * Translate the ConnectionState structure into a specific ConnectionState string literal union\n     */\n    connectionStatesTranslator({ connectionState, networkState, intendedConnectionState, keepAliveState, }) {\n        if (connectionState === 'connected' && networkState === 'disconnected')\n            return ConnectionState.ConnectedPendingNetwork;\n        if (connectionState === 'connected' &&\n            intendedConnectionState === 'disconnected')\n            return ConnectionState.ConnectedPendingDisconnect;\n        if (connectionState === 'disconnected' &&\n            intendedConnectionState === 'connected' &&\n            networkState === 'disconnected')\n            return ConnectionState.ConnectionDisruptedPendingNetwork;\n        if (connectionState === 'disconnected' &&\n            intendedConnectionState === 'connected')\n            return ConnectionState.ConnectionDisrupted;\n        if (connectionState === 'connected' && keepAliveState === 'unhealthy')\n            return ConnectionState.ConnectedPendingKeepAlive;\n        // All remaining states directly correspond to the connection state\n        if (connectionState === 'connecting')\n            return ConnectionState.Connecting;\n        if (connectionState === 'disconnected')\n            return ConnectionState.Disconnected;\n        return ConnectionState.Connected;\n    }\n}\n\nexport { CONNECTION_CHANGE, ConnectionStateMonitor };\n//# sourceMappingURL=ConnectionStateMonitor.mjs.map\n","import { Reachability } from '@aws-amplify/core/internals/utils';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst ReachabilityMonitor = () => new Reachability().networkMonitor();\n\nexport { ReachabilityMonitor };\n//# sourceMappingURL=index.mjs.map\n","import { RECONNECT_INTERVAL, RECONNECT_DELAY } from '../Providers/constants.mjs';\n\nvar ReconnectEvent;\n(function (ReconnectEvent) {\n    ReconnectEvent[\"START_RECONNECT\"] = \"START_RECONNECT\";\n    ReconnectEvent[\"HALT_RECONNECT\"] = \"HALT_RECONNECT\";\n})(ReconnectEvent || (ReconnectEvent = {}));\n/**\n * Captures the reconnect event logic used to determine when to reconnect to PubSub providers.\n *   Reconnect attempts are delayed by 5 seconds to let the interface settle.\n *   Attempting to reconnect only once creates unrecoverable states when the network state isn't\n *   supported by the browser, so this keeps retrying every minute until halted.\n */\nclass ReconnectionMonitor {\n    constructor() {\n        this.reconnectObservers = [];\n    }\n    /**\n     * Add reconnect observer to the list of observers to alert on reconnect\n     */\n    addObserver(reconnectObserver) {\n        this.reconnectObservers.push(reconnectObserver);\n    }\n    /**\n     * Given a reconnect event, start the appropriate behavior\n     */\n    record(event) {\n        if (event === ReconnectEvent.START_RECONNECT) {\n            // If the reconnection hasn't been started\n            if (this.reconnectSetTimeoutId === undefined &&\n                this.reconnectIntervalId === undefined) {\n                this.reconnectSetTimeoutId = setTimeout(() => {\n                    // Reconnect now\n                    this._triggerReconnect();\n                    // Retry reconnect every periodically until it works\n                    this.reconnectIntervalId = setInterval(() => {\n                        this._triggerReconnect();\n                    }, RECONNECT_INTERVAL);\n                }, RECONNECT_DELAY);\n            }\n        }\n        if (event === ReconnectEvent.HALT_RECONNECT) {\n            if (this.reconnectIntervalId) {\n                clearInterval(this.reconnectIntervalId);\n                this.reconnectIntervalId = undefined;\n            }\n            if (this.reconnectSetTimeoutId) {\n                clearTimeout(this.reconnectSetTimeoutId);\n                this.reconnectSetTimeoutId = undefined;\n            }\n        }\n    }\n    /**\n     * Complete all reconnect observers\n     */\n    close() {\n        this.reconnectObservers.forEach(reconnectObserver => {\n            reconnectObserver.complete?.();\n        });\n    }\n    _triggerReconnect() {\n        this.reconnectObservers.forEach(reconnectObserver => {\n            reconnectObserver.next?.();\n        });\n    }\n}\n\nexport { ReconnectEvent, ReconnectionMonitor };\n//# sourceMappingURL=ReconnectionMonitor.mjs.map\n","import { AmplifyError } from '@aws-amplify/core/internals/utils';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * @internal\n */\nclass GraphQLApiError extends AmplifyError {\n    constructor(params) {\n        super(params);\n        // Hack for making the custom error class work when transpiled to es5\n        // TODO: Delete the following 2 lines after we change the build target to >= es2015\n        this.constructor = GraphQLApiError;\n        Object.setPrototypeOf(this, GraphQLApiError.prototype);\n    }\n}\n\nexport { GraphQLApiError };\n//# sourceMappingURL=GraphQLApiError.mjs.map\n","import { GraphQLApiError } from './GraphQLApiError.mjs';\nimport { validationErrorMap } from './validation.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * @internal\n */\nfunction assertValidationError(assertion, name) {\n    const { message, recoverySuggestion } = validationErrorMap[name];\n    if (!assertion) {\n        throw new GraphQLApiError({ name, message, recoverySuggestion });\n    }\n}\n\nexport { assertValidationError };\n//# sourceMappingURL=assertValidationError.mjs.map\n","import { GraphQLAuthError } from '../../types/index.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst NO_API_KEY = {\n    name: 'NoApiKey',\n    // ideal: No API key configured.\n    message: GraphQLAuthError.NO_API_KEY,\n    recoverySuggestion: 'The API request was made with `authMode: \"apiKey\"` but no API Key was passed into `Amplify.configure()`. Review if your API key is passed into the `Amplify.configure()` function.',\n};\nconst NO_VALID_CREDENTIALS = {\n    name: 'NoCredentials',\n    // ideal: No auth credentials available.\n    message: GraphQLAuthError.NO_CREDENTIALS,\n    recoverySuggestion: `The API request was made with \\`authMode: \"iam\"\\` but no authentication credentials are available.\n\nIf you intended to make a request using an authenticated role, review if your user is signed in before making the request.\n\nIf you intend to make a request using an unauthenticated role or also known as \"guest access\", verify if \"Auth.Cognito.allowGuestAccess\" is set to \"true\" in the \\`Amplify.configure()\\` function.`,\n};\nconst NO_VALID_AUTH_TOKEN = {\n    name: 'NoValidAuthTokens',\n    // ideal: No valid JWT auth token provided to make the API request..\n    message: GraphQLAuthError.NO_FEDERATED_JWT,\n    recoverySuggestion: 'If you intended to make an authenticated API request, review if the current user is signed in.',\n};\nconst NO_SIGNED_IN_USER = {\n    name: 'NoSignedUser',\n    // ideal: Couldn't retrieve authentication credentials to make the API request.\n    message: GraphQLAuthError.NO_CURRENT_USER,\n    recoverySuggestion: 'Review the underlying exception field for more details. If you intended to make an authenticated API request, review if the current user is signed in.',\n};\nconst NO_AUTH_TOKEN_HEADER = {\n    name: 'NoAuthorizationHeader',\n    // ideal: Authorization header not specified.\n    message: GraphQLAuthError.NO_AUTH_TOKEN,\n    recoverySuggestion: 'The API request was made with `authMode: \"lambda\"` but no `authToken` is set. Review if a valid authToken is passed into the request options or in the `Amplify.configure()` function.',\n};\nconst NO_ENDPOINT = {\n    name: 'NoEndpoint',\n    message: 'No GraphQL endpoint configured in `Amplify.configure()`.',\n    recoverySuggestion: 'Review if the GraphQL API endpoint is set in the `Amplify.configure()` function.',\n};\n\nexport { NO_API_KEY, NO_AUTH_TOKEN_HEADER, NO_ENDPOINT, NO_SIGNED_IN_USER, NO_VALID_AUTH_TOKEN, NO_VALID_CREDENTIALS };\n//# sourceMappingURL=constants.mjs.map\n","import { GraphQLError } from 'graphql';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst createGraphQLResultWithError = (error) => {\n    return {\n        data: {},\n        errors: [new GraphQLError(error.message, null, null, null, null, error)],\n    };\n};\n\nexport { createGraphQLResultWithError };\n//# sourceMappingURL=createGraphQLResultWithError.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Checks to see if the given response or subscription message contains an\n * Unauthorized error. If it does, it changes the error message to include instructions\n * for the app developer.\n */\nfunction repackageUnauthorizedError(content) {\n    if (content.errors && Array.isArray(content.errors)) {\n        content.errors.forEach(e => {\n            if (isUnauthorizedError(e)) {\n                e.message = 'Unauthorized';\n                e.recoverySuggestion =\n                    `If you're calling an Amplify-generated API, make sure ` +\n                        `to set the \"authMode\" in generateClient({ authMode: '...' }) to the backend authorization ` +\n                        `rule's auth provider ('apiKey', 'userPool', 'iam', 'oidc', 'lambda')`;\n            }\n        });\n    }\n    return content;\n}\nfunction isUnauthorizedError(error) {\n    // Error pattern corresponding to appsync calls\n    if (error?.originalError?.name?.startsWith('UnauthorizedException')) {\n        return true;\n    }\n    // Error pattern corresponding to appsync subscriptions\n    if (error.message?.startsWith('Connection failed:') &&\n        error.message?.includes('Permission denied')) {\n        return true;\n    }\n    return false;\n}\n\nexport { repackageUnauthorizedError };\n//# sourceMappingURL=repackageAuthError.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nvar APIValidationErrorCode;\n(function (APIValidationErrorCode) {\n    APIValidationErrorCode[\"NoAuthSession\"] = \"NoAuthSession\";\n    APIValidationErrorCode[\"NoRegion\"] = \"NoRegion\";\n    APIValidationErrorCode[\"NoCustomEndpoint\"] = \"NoCustomEndpoint\";\n})(APIValidationErrorCode || (APIValidationErrorCode = {}));\nconst validationErrorMap = {\n    [APIValidationErrorCode.NoAuthSession]: {\n        message: 'Auth session should not be empty.',\n    },\n    // TODO: re-enable when working in all test environments:\n    // [APIValidationErrorCode.NoEndpoint]: {\n    // \tmessage: 'Missing endpoint',\n    // },\n    [APIValidationErrorCode.NoRegion]: {\n        message: 'Missing region.',\n    },\n    [APIValidationErrorCode.NoCustomEndpoint]: {\n        message: 'Custom endpoint region is present without custom endpoint.',\n    },\n};\n\nexport { APIValidationErrorCode, validationErrorMap };\n//# sourceMappingURL=validation.mjs.map\n","import { ConsoleLogger } from '@aws-amplify/core';\nimport '@aws-amplify/core/internals/utils';\nimport { assertValidationError } from './errors/assertValidationError.mjs';\nimport { APIValidationErrorCode } from './errors/validation.mjs';\nimport 'graphql';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst logger = new ConsoleLogger('GraphQLAPI resolveConfig');\n/**\n * @internal\n */\nconst resolveConfig = (amplify) => {\n    const config = amplify.getConfig();\n    if (!config.API?.GraphQL) {\n        logger.warn('The API configuration is missing. This is likely due to Amplify.configure() not being called prior to generateClient().');\n    }\n    const { apiKey, customEndpoint, customEndpointRegion, defaultAuthMode, endpoint, region, } = config.API?.GraphQL ?? {};\n    // TODO: re-enable when working in all test environments:\n    // assertValidationError(!!endpoint, APIValidationErrorCode.NoEndpoint);\n    assertValidationError(!(!customEndpoint && customEndpointRegion), APIValidationErrorCode.NoCustomEndpoint);\n    return {\n        apiKey,\n        customEndpoint,\n        customEndpointRegion,\n        defaultAuthMode,\n        endpoint,\n        region,\n    };\n};\n\nexport { resolveConfig };\n//# sourceMappingURL=resolveConfig.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * @internal\n */\nconst resolveLibraryOptions = (amplify) => {\n    const headers = amplify.libraryOptions?.API?.GraphQL?.headers;\n    const withCredentials = amplify.libraryOptions?.API?.GraphQL?.withCredentials;\n    return { headers, withCredentials };\n};\n\nexport { resolveLibraryOptions };\n//# sourceMappingURL=resolveLibraryOptions.mjs.map\n","import { getRetryDecider, jitteredBackoff, authenticatedHandler, unauthenticatedHandler } from '@aws-amplify/core/internals/aws-client-utils';\nimport '@aws-amplify/core/internals/utils';\nimport '../../errors/validation.mjs';\nimport { parseRestApiServiceError } from '../../utils/serviceError.mjs';\nimport { logger } from '../../utils/logger.mjs';\nimport { parseSigningInfo } from '../../utils/parseSigningInfo.mjs';\nimport { resolveHeaders } from '../../utils/resolveHeaders.mjs';\n\n/**\n * Make REST API call with best-effort IAM auth.\n * @param amplify Amplify instance to to resolve credentials and tokens. Should use different instance in client-side\n *   and SSR\n * @param options Options accepted from public API options when calling the handlers.\n * @param signingServiceInfo Internal-only options enable IAM auth as well as to to overwrite the IAM signing service\n *   and region. If specified, and NONE of API Key header or Auth header is present, IAM auth will be used.\n * @param iamAuthApplicable Callback function that is used to determine if IAM Auth should be used or not.\n *\n * @internal\n */\nconst transferHandler = async (amplify, options, iamAuthApplicable, signingServiceInfo) => {\n    const { url, method, headers, body, withCredentials, abortSignal } = options;\n    const resolvedBody = body\n        ? body instanceof FormData\n            ? body\n            : JSON.stringify(body ?? '')\n        : undefined;\n    const resolvedHeaders = resolveHeaders(headers, body);\n    const request = {\n        url,\n        headers: resolvedHeaders,\n        method,\n        body: resolvedBody,\n    };\n    const baseOptions = {\n        retryDecider: getRetryDecider(parseRestApiServiceError),\n        computeDelay: jitteredBackoff,\n        withCrossDomainCredentials: withCredentials,\n        abortSignal,\n    };\n    const isIamAuthApplicable = iamAuthApplicable(request, signingServiceInfo);\n    let response;\n    const credentials = await resolveCredentials(amplify);\n    if (isIamAuthApplicable && credentials) {\n        const signingInfoFromUrl = parseSigningInfo(url);\n        const signingService = signingServiceInfo?.service ?? signingInfoFromUrl.service;\n        const signingRegion = signingServiceInfo?.region ?? signingInfoFromUrl.region;\n        response = await authenticatedHandler(request, {\n            ...baseOptions,\n            credentials,\n            region: signingRegion,\n            service: signingService,\n        });\n    }\n    else {\n        response = await unauthenticatedHandler(request, {\n            ...baseOptions,\n        });\n    }\n    // Clean-up un-modeled properties from response.\n    return {\n        statusCode: response.statusCode,\n        headers: response.headers,\n        body: response.body,\n    };\n};\nconst resolveCredentials = async (amplify) => {\n    try {\n        const { credentials } = await amplify.Auth.fetchAuthSession();\n        if (credentials) {\n            return credentials;\n        }\n    }\n    catch (e) {\n        logger.debug('No credentials available, the request will be unsigned.');\n    }\n    return null;\n};\n\nexport { transferHandler };\n//# sourceMappingURL=handler.mjs.map\n","import { createCancellableOperation } from '../../utils/createCancellableOperation.mjs';\nimport '@aws-amplify/core/internals/aws-client-utils';\nimport '@aws-amplify/core/internals/utils';\nimport '../../errors/validation.mjs';\nimport '../../utils/logger.mjs';\nimport { isIamAuthApplicableForGraphQL } from '../../utils/isIamAuthApplicable.mjs';\nimport { transferHandler } from './handler.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * This weak map provides functionality to cancel a request given the promise containing the `post` request.\n *\n * 1. For every GraphQL POST request, an abort controller is created and supplied to the request.\n * 2. The promise fulfilled by GraphGL POST request is then mapped to that abort controller.\n * 3. The promise is returned to the external caller.\n * 4. The caller can either wait for the promise to fulfill or call `cancel(promise)` to cancel the request.\n * 5. If `cancel(promise)` is called, then the corresponding abort controller is retrieved from the map below.\n * 6. GraphQL POST request will be rejected with the error message provided during cancel.\n * 7. Caller can check if the error is because of cancelling by calling `isCancelError(error)`.\n */\nconst cancelTokenMap = new WeakMap();\n/**\n * @internal\n *\n * REST POST handler to send GraphQL request to given endpoint. By default, it will use IAM to authorize\n * the request. In some auth modes, the IAM auth has to be disabled. Here's how to set up the request auth correctly:\n * * If auth mode is 'iam', you MUST NOT set 'authorization' header and 'x-api-key' header, since it would disable IAM\n *   auth. You MUST also set 'input.options.signingServiceInfo' option.\n *   * The including 'input.options.signingServiceInfo.service' and 'input.options.signingServiceInfo.region' are\n *     optional. If omitted, the signing service and region will be inferred from url.\n * * If auth mode is 'none', you MUST NOT set 'options.signingServiceInfo' option.\n * * If auth mode is 'apiKey', you MUST set 'x-api-key' custom header.\n * * If auth mode is 'oidc' or 'lambda' or 'userPool', you MUST set 'authorization' header.\n *\n * To make the internal post cancellable, you must also call `updateRequestToBeCancellable()` with the promise from\n * internal post call and the abort controller supplied to the internal post call.\n *\n * @param amplify the AmplifyClassV6 instance - it may be the singleton used on Web, or an instance created within\n * a context created by `runWithAmplifyServerContext`\n * @param postInput an object of {@link InternalPostInput}\n * @param postInput.url The URL that the POST request sends to\n * @param postInput.options Options of the POST request\n * @param postInput.abortController The abort controller used to cancel the POST request\n * @returns a {@link RestApiResponse}\n *\n * @throws an {@link AmplifyError} with `Network Error` as the `message` when the external resource is unreachable due to one\n * of the following reasons:\n *   1. no network connection\n *   2. CORS error\n * @throws a {@link CanceledError} when the ongoing POST request get cancelled\n */\nconst post = (amplify, { url, options, abortController }) => {\n    const controller = abortController ?? new AbortController();\n    const responsePromise = createCancellableOperation(async () => {\n        const response = transferHandler(amplify, {\n            url,\n            method: 'POST',\n            ...options,\n            abortSignal: controller.signal,\n        }, isIamAuthApplicableForGraphQL, options?.signingServiceInfo);\n        return response;\n    }, controller);\n    const responseWithCleanUp = responsePromise.finally(() => {\n        cancelTokenMap.delete(responseWithCleanUp);\n    });\n    return responseWithCleanUp;\n};\n/**\n * Cancels a request given the promise returned by `post`.\n * If the request is already completed, this function does nothing.\n * It MUST be used after `updateRequestToBeCancellable` is called.\n */\nconst cancel = (promise, message) => {\n    const controller = cancelTokenMap.get(promise);\n    if (controller) {\n        controller.abort(message);\n        if (message && controller.signal.reason !== message) {\n            // In runtimes where `AbortSignal.reason` is not supported, we track the reason ourselves.\n            // @ts-expect-error reason is read-only property.\n            controller.signal.reason = message;\n        }\n        return true;\n    }\n    return false;\n};\n/**\n * MUST be used to make a promise including internal `post` API call cancellable.\n */\nconst updateRequestToBeCancellable = (promise, controller) => {\n    cancelTokenMap.set(promise, controller);\n};\n\nexport { cancel, post, updateRequestToBeCancellable };\n//# sourceMappingURL=internalPost.mjs.map\n","import { createCancellableOperation } from '../../utils/createCancellableOperation.mjs';\nimport { parseSigningInfo } from '../../utils/parseSigningInfo.mjs';\nimport '@aws-amplify/core/internals/aws-client-utils';\nimport '@aws-amplify/core/internals/utils';\nimport '../../errors/validation.mjs';\nimport { resolveApiUrl } from '../../utils/resolveApiUrl.mjs';\nimport { logger } from '../../utils/logger.mjs';\nimport { isIamAuthApplicableForRest } from '../../utils/isIamAuthApplicable.mjs';\nimport { transferHandler } from './handler.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst publicHandler = (amplify, options, method) => createCancellableOperation(async (abortSignal) => {\n    const { apiName, options: apiOptions = {}, path: apiPath } = options;\n    const url = resolveApiUrl(amplify, apiName, apiPath, apiOptions?.queryParams);\n    const libraryConfigHeaders = await amplify.libraryOptions?.API?.REST?.headers?.({\n        apiName,\n    });\n    const { headers: invocationHeaders = {} } = apiOptions;\n    const headers = {\n        // custom headers from invocation options should precede library options\n        ...libraryConfigHeaders,\n        ...invocationHeaders,\n    };\n    const signingServiceInfo = parseSigningInfo(url, {\n        amplify,\n        apiName,\n    });\n    logger.debug(method, url, headers, `IAM signing options: ${JSON.stringify(signingServiceInfo)}`);\n    return transferHandler(amplify, {\n        ...apiOptions,\n        url,\n        method,\n        headers,\n        abortSignal,\n    }, isIamAuthApplicableForRest, signingServiceInfo);\n});\nconst get = (amplify, input) => publicHandler(amplify, input, 'GET');\nconst post = (amplify, input) => publicHandler(amplify, input, 'POST');\nconst put = (amplify, input) => publicHandler(amplify, input, 'PUT');\nconst del = (amplify, input) => publicHandler(amplify, input, 'DELETE');\nconst head = (amplify, input) => publicHandler(amplify, input, 'HEAD');\nconst patch = (amplify, input) => publicHandler(amplify, input, 'PATCH');\n\nexport { del, get, head, patch, post, put };\n//# sourceMappingURL=publicApis.mjs.map\n","import { Amplify } from '@aws-amplify/core';\nimport { get as get$1, post as post$1, put as put$1, del as del$1, head as head$1, patch as patch$1 } from './common/publicApis.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * GET HTTP request\n * @param {GetInput} input - Input for GET operation\n * @returns {GetOperation} Operation for GET request\n * @throws - {@link RestApiError}\n * @example\n * Send a GET request\n * ```js\n * import { get, isCancelError } from '@aws-amplify/api';\n *\n * const { body } = await get({\n *   apiName,\n *   path,\n *   options: {\n *     headers, // Optional, A map of custom header key/values\n *     body, // Optional, JSON object or FormData\n *     queryParams, // Optional, A map of query strings\n *   }\n * }).response;\n * const data = await body.json();\n * ```\n * @example\n * Cancel a GET request\n *\n * ```js\n * import { get, isCancelError } from '@aws-amplify/api';\n *\n * const { response, cancel } = get({apiName, path, options});\n * cancel(message);\n * try {\n *   await response;\n * } catch (e) {\n *   if (isCancelError(e)) {\n *    // handle request cancellation\n *   }\n *   //...\n * }\n * ```\n */\nconst get = (input) => get$1(Amplify, input);\n/**\n * POST HTTP request\n * @param {PostInput} input - Input for POST operation\n * @returns {PostOperation} Operation for POST request\n * @throws - {@link RestApiError}\n * @example\n * Send a POST request\n * ```js\n * import { post, isCancelError } from '@aws-amplify/api';\n *\n * const { body } = await post({\n *   apiName,\n *   path,\n *   options: {\n *     headers, // Optional, A map of custom header key/values\n *     body, // Optional, JSON object or FormData\n *     queryParams, // Optional, A map of query strings\n *   }\n * }).response;\n * const data = await body.json();\n * ```\n * @example\n * Cancel a POST request\n *\n * ```js\n * import { post, isCancelError } from '@aws-amplify/api';\n *\n * const { response, cancel } = post({apiName, path, options});\n * cancel(message);\n * try {\n *   await response;\n * } catch (e) {\n *   if (isCancelError(e)) {\n *    // handle request cancellation\n *   }\n *   //...\n * }\n * ```\n */\nconst post = (input) => post$1(Amplify, input);\n/**\n * PUT HTTP request\n * @param {PutInput} input - Input for PUT operation\n * @returns {PutOperation} Operation for PUT request\n * @throws - {@link RestApiError}\n * @example\n * Send a PUT request\n * ```js\n * import { put, isCancelError } from '@aws-amplify/api';\n *\n * const { body } = await put({\n *   apiName,\n *   path,\n *   options: {\n *     headers, // Optional, A map of custom header key/values\n *     body, // Optional, JSON object or FormData\n *     queryParams, // Optional, A map of query strings\n *   }\n * }).response;\n * const data = await body.json();\n * ```\n * @example\n * Cancel a PUT request\n * ```js\n * import { put, isCancelError } from '@aws-amplify/api';\n *\n * const { response, cancel } = put({apiName, path, options});\n * cancel(message);\n * try {\n *  await response;\n * } catch (e) {\n *   if (isCancelError(e)) {\n *     // handle request cancellation\n *   }\n * //...\n * }\n * ```\n */\nconst put = (input) => put$1(Amplify, input);\n/**\n * DELETE HTTP request\n * @param {DeleteInput} input - Input for DELETE operation\n * @returns {DeleteOperation} Operation for DELETE request\n * @throws - {@link RestApiError}\n * @example\n * Send a DELETE request\n * ```js\n * import { del } from '@aws-amplify/api';\n *\n * const { statusCode } = await del({\n *   apiName,\n *   path,\n *   options: {\n *     headers, // Optional, A map of custom header key/values\n *     queryParams, // Optional, A map of query strings\n *   }\n * }).response;\n * ```\n */\nconst del = (input) => del$1(Amplify, input);\n/**\n * HEAD HTTP request\n * @param {HeadInput} input - Input for HEAD operation\n * @returns {HeadOperation} Operation for HEAD request\n * @throws - {@link RestApiError}\n * @example\n * Send a HEAD request\n * ```js\n * import { head, isCancelError } from '@aws-amplify/api';\n *\n * const { headers, statusCode } = await head({\n *   apiName,\n *   path,\n *   options: {\n *     headers, // Optional, A map of custom header key/values\n *     queryParams, // Optional, A map of query strings\n *   }\n * }),response;\n * ```\n *\n */\nconst head = (input) => head$1(Amplify, input);\n/**\n * PATCH HTTP request\n * @param {PatchInput} input - Input for PATCH operation\n * @returns {PatchOperation} Operation for PATCH request\n * @throws - {@link RestApiError}\n * @example\n * Send a PATCH request\n * ```js\n * import { patch } from '@aws-amplify/api';\n *\n * const { body } = await patch({\n *   apiName,\n *   path,\n *   options: {\n *     headers, // Optional, A map of custom header key/values\n *     body, // Optional, JSON object or FormData\n *     queryParams, // Optional, A map of query strings\n *   }\n * }).response;\n * const data = await body.json();\n * ```\n *\n * @example\n * Cancel a PATCH request\n * ```js\n * import { patch, isCancelError } from '@aws-amplify/api';\n *\n * const { response, cancel } = patch({apiName, path, options});\n * cancel(message);\n * try {\n *  await response;\n * } catch (e) {\n *  if (isCancelError(e)) {\n *   // handle request cancellation\n *  }\n * //...\n * }\n * ```\n */\nconst patch = (input) => patch$1(Amplify, input);\n\nexport { del, get, head, patch, post, put };\n//# sourceMappingURL=index.mjs.map\n","import { RestApiError } from './RestApiError.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Internal-only class for CanceledError.\n *\n * @internal\n */\nclass CanceledError extends RestApiError {\n    constructor(params = {}) {\n        super({\n            name: 'CanceledError',\n            message: 'Request is canceled by user',\n            ...params,\n        });\n        // TODO: Delete the following 2 lines after we change the build target to >= es2015\n        this.constructor = CanceledError;\n        Object.setPrototypeOf(this, CanceledError.prototype);\n    }\n}\n/**\n * Check if an error is caused by user calling `cancel()` in REST API.\n *\n * @note This function works **ONLY** for errors thrown by REST API. For GraphQL APIs, use `client.isCancelError(error)`\n *   instead. `client` is generated from  `generateClient()` API from `aws-amplify/api`.\n *\n * @param {unknown} error The unknown exception to be checked.\n * @returns - A boolean indicating if the error was from an upload cancellation\n */\nconst isCancelError = (error) => !!error && error instanceof CanceledError;\n\nexport { CanceledError, isCancelError };\n//# sourceMappingURL=CanceledError.mjs.map\n","import { ApiError } from '@aws-amplify/core/internals/utils';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nclass RestApiError extends ApiError {\n    constructor(params) {\n        super(params);\n        // TODO: Delete the following 2 lines after we change the build target to >= es2015\n        this.constructor = RestApiError;\n        Object.setPrototypeOf(this, RestApiError.prototype);\n    }\n}\n\nexport { RestApiError };\n//# sourceMappingURL=RestApiError.mjs.map\n","import { RestApiError } from './RestApiError.mjs';\nimport { validationErrorMap } from './validation.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * @internal\n */\nfunction assertValidationError(assertion, name) {\n    const { message, recoverySuggestion } = validationErrorMap[name];\n    if (!assertion) {\n        throw new RestApiError({ name, message, recoverySuggestion });\n    }\n}\n\nexport { assertValidationError };\n//# sourceMappingURL=assertValidatonError.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nvar RestApiValidationErrorCode;\n(function (RestApiValidationErrorCode) {\n    RestApiValidationErrorCode[\"InvalidApiName\"] = \"InvalidApiName\";\n})(RestApiValidationErrorCode || (RestApiValidationErrorCode = {}));\nconst validationErrorMap = {\n    [RestApiValidationErrorCode.InvalidApiName]: {\n        message: 'API name is invalid.',\n        recoverySuggestion: 'Check if the API name matches the one in your configuration or `aws-exports.js`',\n    },\n};\n\nexport { RestApiValidationErrorCode, validationErrorMap };\n//# sourceMappingURL=validation.mjs.map\n","export { isCancelError } from './errors/CanceledError.mjs';\nexport { del, get, head, patch, post, put } from './apis/index.mjs';\n//# sourceMappingURL=index.mjs.map\n","export { cancel, post, updateRequestToBeCancellable } from '../apis/common/internalPost.mjs';\n//# sourceMappingURL=index.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst DEFAULT_REST_IAM_SIGNING_SERVICE = 'execute-api';\nconst DEFAULT_APPSYNC_API_SERVICE = 'appsync-api';\nconst DEFAULT_IAM_SIGNING_REGION = 'us-east-1';\n/**\n * The REST endpoints generated by API Gateway\n * @see {@link https://docs.aws.amazon.com/general/latest/gr/apigateway.html#apigateway_region_data_plane}\n */\nconst APIG_HOSTNAME_PATTERN = /^.+\\.([a-z0-9-]+)\\.([a-z0-9-]+)\\.amazonaws\\.com/;\n\nexport { APIG_HOSTNAME_PATTERN, DEFAULT_APPSYNC_API_SERVICE, DEFAULT_IAM_SIGNING_REGION, DEFAULT_REST_IAM_SIGNING_SERVICE };\n//# sourceMappingURL=constants.mjs.map\n","import { CanceledError } from '../errors/CanceledError.mjs';\nimport '@aws-amplify/core/internals/utils';\nimport '../errors/validation.mjs';\nimport { parseRestApiServiceError } from './serviceError.mjs';\nimport { logger } from './logger.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * @internal\n */\nfunction createCancellableOperation(handler, abortController) {\n    const isInternalPost = (targetHandler) => !!abortController;\n    // For creating a cancellable operation for public REST APIs, we need to create an AbortController\n    // internally. Whereas for internal POST APIs, we need to accept in the AbortController from the\n    // callers.\n    const publicApisAbortController = new AbortController();\n    const publicApisAbortSignal = publicApisAbortController.signal;\n    const internalPostAbortSignal = abortController?.signal;\n    let abortReason;\n    const job = async () => {\n        try {\n            const response = await (isInternalPost(handler)\n                ? handler()\n                : handler(publicApisAbortSignal));\n            if (response.statusCode >= 300) {\n                throw await parseRestApiServiceError(response);\n            }\n            return response;\n        }\n        catch (error) {\n            const abortSignal = internalPostAbortSignal ?? publicApisAbortSignal;\n            const message = abortReason ?? abortSignal.reason;\n            if (error.name === 'AbortError' || abortSignal?.aborted === true) {\n                const canceledError = new CanceledError({\n                    ...(message && { message }),\n                    underlyingError: error,\n                    recoverySuggestion: 'The API request was explicitly canceled. If this is not intended, validate if you called the `cancel()` function on the API request erroneously.',\n                });\n                logger.debug(error);\n                throw canceledError;\n            }\n            logger.debug(error);\n            throw error;\n        }\n    };\n    if (isInternalPost()) {\n        return job();\n    }\n    else {\n        const cancel = (abortMessage) => {\n            if (publicApisAbortSignal.aborted === true) {\n                return;\n            }\n            publicApisAbortController.abort(abortMessage);\n            // If abort reason is not supported, set a scoped reasons instead. The reason property inside an\n            // AbortSignal is a readonly property and trying to set it would throw an error.\n            if (abortMessage && publicApisAbortSignal.reason !== abortMessage) {\n                abortReason = abortMessage;\n            }\n        };\n        return { response: job(), cancel };\n    }\n}\n\nexport { createCancellableOperation };\n//# sourceMappingURL=createCancellableOperation.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Determines if IAM authentication should be applied for a GraphQL request.\n *\n * This function checks the `headers` of the HTTP request to determine if IAM authentication\n * is applicable. IAM authentication is considered applicable if there is no `authorization`\n * header, no `x-api-key` header, and `signingServiceInfo` is provided.\n *\n * @param request - The HTTP request object containing headers.\n * @param signingServiceInfo - Optional signing service information,\n * including service and region.\n * @returns A boolean `true` if IAM authentication should be applied.\n *\n * @internal\n */\nconst isIamAuthApplicableForGraphQL = ({ headers }, signingServiceInfo) => !headers.authorization && !headers['x-api-key'] && !!signingServiceInfo;\n/**\n * Determines if IAM authentication should be applied for a REST request.\n *\n * This function checks the `headers` of the HTTP request to determine if IAM authentication\n * is applicable. IAM authentication is considered applicable if there is no `authorization`\n * header and `signingServiceInfo` is provided.\n *\n * @param request - The HTTP request object containing headers.\n * @param signingServiceInfo - Optional signing service information,\n * including service and region.\n * @returns A boolean `true` if IAM authentication should be applied.\n *\n * @internal\n */\nconst isIamAuthApplicableForRest = ({ headers }, signingServiceInfo) => !headers.authorization && !!signingServiceInfo;\n\nexport { isIamAuthApplicableForGraphQL, isIamAuthApplicableForRest };\n//# sourceMappingURL=isIamAuthApplicable.mjs.map\n","import { ConsoleLogger } from '@aws-amplify/core';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst logger = new ConsoleLogger('RestApis');\n\nexport { logger };\n//# sourceMappingURL=logger.mjs.map\n","import { DEFAULT_REST_IAM_SIGNING_SERVICE, DEFAULT_IAM_SIGNING_REGION, APIG_HOSTNAME_PATTERN } from './constants.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Infer the signing service and region from the given URL, and for REST API only, from the Amplify configuration.\n * It supports raw API Gateway endpoint and AppSync endpoint.\n *\n * @internal\n */\nconst parseSigningInfo = (url, restApiOptions) => {\n    const { service: signingService = DEFAULT_REST_IAM_SIGNING_SERVICE, region: signingRegion = DEFAULT_IAM_SIGNING_REGION, } = restApiOptions?.amplify.getConfig()?.API?.REST?.[restApiOptions?.apiName] ??\n        {};\n    const { hostname } = url;\n    const [, service, region] = APIG_HOSTNAME_PATTERN.exec(hostname) ?? [];\n    if (service === DEFAULT_REST_IAM_SIGNING_SERVICE) {\n        // The configured endpoint is an API Gateway endpoint\n        // @see: https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-call-api.html\n        return {\n            service,\n            region: region ?? signingRegion,\n        };\n    }\n    else if (service === 'appsync-api') {\n        // AppSync endpoint is internally supported because GraphQL operation will send request using POST handler.\n        // example: https://xxxx.appsync-api.us-east-1.amazonaws.com/graphql\n        return {\n            service: 'appsync',\n            region: region ?? signingRegion,\n        };\n    }\n    else {\n        return {\n            service: signingService,\n            region: signingRegion,\n        };\n    }\n};\n\nexport { parseSigningInfo };\n//# sourceMappingURL=parseSigningInfo.mjs.map\n","import { AmplifyUrl, AmplifyUrlSearchParams } from '@aws-amplify/core/internals/utils';\nimport { RestApiError } from '../errors/RestApiError.mjs';\nimport { assertValidationError } from '../errors/assertValidatonError.mjs';\nimport { RestApiValidationErrorCode, validationErrorMap } from '../errors/validation.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Resolve the REST API request URL by:\n * 1. Loading the REST API endpoint from the Amplify configuration with corresponding API name.\n * 2. Appending the path to the endpoint.\n * 3. Merge the query parameters from path and the queryParameter argument which is taken from the public REST API\n *   options.\n * 4. Validating the resulting URL string.\n *\n * @internal\n */\nconst resolveApiUrl = (amplify, apiName, path, queryParams) => {\n    const urlStr = amplify.getConfig()?.API?.REST?.[apiName]?.endpoint;\n    assertValidationError(!!urlStr, RestApiValidationErrorCode.InvalidApiName);\n    try {\n        const url = new AmplifyUrl(urlStr + path);\n        if (queryParams) {\n            const mergedQueryParams = new AmplifyUrlSearchParams(url.searchParams);\n            Object.entries(queryParams).forEach(([key, value]) => {\n                mergedQueryParams.set(key, value);\n            });\n            url.search = new AmplifyUrlSearchParams(mergedQueryParams).toString();\n        }\n        return url;\n    }\n    catch (error) {\n        throw new RestApiError({\n            name: RestApiValidationErrorCode.InvalidApiName,\n            ...validationErrorMap[RestApiValidationErrorCode.InvalidApiName],\n            recoverySuggestion: `Please make sure the REST endpoint URL is a valid URL string. Got ${urlStr}`,\n        });\n    }\n};\n\nexport { resolveApiUrl };\n//# sourceMappingURL=resolveApiUrl.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst resolveHeaders = (headers, body) => {\n    const normalizedHeaders = {};\n    for (const key in headers) {\n        normalizedHeaders[key.toLowerCase()] = headers[key];\n    }\n    if (body) {\n        normalizedHeaders['content-type'] = 'application/json; charset=UTF-8';\n        if (body instanceof FormData) {\n            /**\n             * If body is a FormData we should not allow setting content-type.\n             * It's because runtime HTTP handlers(xhr, fetch, undici, node-fetch,\n             * etc.) will modify the content-type value when setting multipart\n             * boundary.\n             */\n            delete normalizedHeaders['content-type'];\n        }\n    }\n    return normalizedHeaders;\n};\n\nexport { resolveHeaders };\n//# sourceMappingURL=resolveHeaders.mjs.map\n","import { parseJsonError } from '@aws-amplify/core/internals/aws-client-utils';\nimport { RestApiError } from '../errors/RestApiError.mjs';\nimport '../errors/validation.mjs';\n\n/**\n * Parses both AWS and non-AWS error responses coming from the users' backend code.\n * * AWS errors generated by the AWS services(e.g. API Gateway, Bedrock). They can be Signature errors,\n *   ClockSkew errors, etc. These responses will be parsed to errors with proper name and message from the AWS\n *   services.\n * * non-AWS errors thrown by the user code. They can contain any headers or body. Users need to access the\n *   error.response to get the headers and body and parse them accordingly. The JS error name and message will\n *   be `UnknownError` and `Unknown error` respectively.\n */\nconst parseRestApiServiceError = async (response) => {\n    if (!response) {\n        // Response is not considered an error.\n        return;\n    }\n    const parsedAwsError = await parseJsonError(stubErrorResponse(response));\n    if (!parsedAwsError) ;\n    else {\n        const bodyText = await response.body?.text();\n        return buildRestApiError(parsedAwsError, {\n            statusCode: response.statusCode,\n            headers: response.headers,\n            body: bodyText,\n        });\n    }\n};\n/**\n * The response object needs to be stub here because the parseAwsJsonError assumes the response body to be valid JSON.\n * Although this is true for AWS services, it is not true for responses from user's code. Once the response body is\n * unwrapped as JSON(and fail), it cannot be read as text again. Therefore, we need to stub the response body here to\n * make sure we can read the error response body as a JSON, and may fall back to read as text if it is not a valid JSON.\n */\nconst stubErrorResponse = (response) => {\n    let bodyTextPromise;\n    const bodyProxy = new Proxy(response.body, {\n        get(target, prop, receiver) {\n            if (prop === 'json') {\n                // For potential AWS errors, error parser will try to parse the body as JSON first.\n                return async () => {\n                    if (!bodyTextPromise) {\n                        bodyTextPromise = target.text();\n                    }\n                    try {\n                        return JSON.parse(await bodyTextPromise);\n                    }\n                    catch (error) {\n                        // If response body is not a valid JSON, we stub it to be an empty object and eventually parsed\n                        // as an unknown error\n                        return {};\n                    }\n                };\n            }\n            else if (prop === 'text') {\n                // For non-AWS errors, users can access the body as a string as a fallback.\n                return async () => {\n                    if (!bodyTextPromise) {\n                        bodyTextPromise = target.text();\n                    }\n                    return bodyTextPromise;\n                };\n            }\n            else {\n                return Reflect.get(target, prop, receiver);\n            }\n        },\n    });\n    const responseProxy = new Proxy(response, {\n        get(target, prop, receiver) {\n            if (prop === 'body') {\n                return bodyProxy;\n            }\n            else {\n                return Reflect.get(target, prop, receiver);\n            }\n        },\n    });\n    return responseProxy;\n};\n/**\n * Utility to create a new RestApiError from a service error.\n */\nconst buildRestApiError = (error, response) => {\n    const restApiError = new RestApiError({\n        name: error?.name,\n        message: error.message,\n        underlyingError: error,\n        response,\n    });\n    // $metadata is only required for backwards compatibility.\n    return Object.assign(restApiError, { $metadata: error.$metadata });\n};\n\nexport { parseRestApiServiceError };\n//# sourceMappingURL=serviceError.mjs.map\n","import { InternalGraphQLAPIClass } from '@aws-amplify/api-graphql/internals';\nimport { Cache, Amplify } from '@aws-amplify/core';\nimport { Category, ApiAction } from '@aws-amplify/core/internals/utils';\n\n/**\n * NOTE!\n *\n * This is used only by DataStore.\n *\n * This can probably be pruned and/or removed. Just leaving it as much of the same\n * state as possible for V6 to reduce number of potentially impactful changes to DataStore.\n */\n/**\n * @deprecated\n * Use RestApi or GraphQLAPI to reduce your application bundle size\n * Export Cloud Logic APIs\n */\nclass InternalAPIClass {\n    /**\n     * Initialize API\n     */\n    constructor() {\n        this.Cache = Cache;\n        this._graphqlApi = new InternalGraphQLAPIClass();\n    }\n    getModuleName() {\n        return 'InternalAPI';\n    }\n    /**\n     * to get the operation type\n     * @param operation\n     */\n    getGraphqlOperationType(operation) {\n        return this._graphqlApi.getGraphqlOperationType(operation);\n    }\n    graphql(options, additionalHeaders, customUserAgentDetails) {\n        const apiUserAgentDetails = {\n            category: Category.API,\n            action: ApiAction.GraphQl,\n            ...customUserAgentDetails,\n        };\n        return this._graphqlApi.graphql(Amplify, options, additionalHeaders, apiUserAgentDetails);\n    }\n}\nconst InternalAPI = new InternalAPIClass();\n\nexport { InternalAPI, InternalAPIClass };\n//# sourceMappingURL=InternalAPI.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nclass BackgroundManagerNotOpenError extends Error {\n    constructor(message) {\n        super(`BackgroundManagerNotOpenError: ${message}`);\n    }\n}\n\nexport { BackgroundManagerNotOpenError };\n//# sourceMappingURL=BackgroundManagerNotOpenError.mjs.map\n","import { BackgroundManagerNotOpenError } from './BackgroundManagerNotOpenError.mjs';\nimport { BackgroundProcessManagerState } from './types.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * @private For internal Amplify use.\n *\n * Creates a new scope for promises, observables, and other types of work or\n * processes that may be running in the background. This manager provides\n * an singular entrypoint to request termination and await completion.\n *\n * As work completes on its own prior to close, the manager removes them\n * from the registry to avoid holding references to completed jobs.\n */\nclass BackgroundProcessManager {\n    constructor() {\n        /**\n         * A string indicating whether the manager is accepting new work (\"Open\"),\n         * waiting for work to complete (\"Closing\"), or fully done with all\n         * submitted work and *not* accepting new jobs (\"Closed\").\n         */\n        this._state = BackgroundProcessManagerState.Open;\n        /**\n         * The list of outstanding jobs we'll need to wait for upon `close()`\n         */\n        this.jobs = new Set();\n    }\n    add(jobOrDescription, optionalDescription) {\n        let job;\n        let description;\n        if (typeof jobOrDescription === 'string') {\n            job = undefined;\n            description = jobOrDescription;\n        }\n        else {\n            job = jobOrDescription;\n            description = optionalDescription;\n        }\n        const error = this.closedFailure(description);\n        if (error)\n            return error;\n        if (job === undefined) {\n            return this.addHook(description);\n        }\n        else if (typeof job === 'function') {\n            return this.addFunction(job, description);\n        }\n        else if (job instanceof BackgroundProcessManager) {\n            this.addManager(job, description);\n        }\n        else {\n            throw new Error('If `job` is provided, it must be an Observable, Function, or BackgroundProcessManager.');\n        }\n    }\n    /**\n     * Adds a **cleaner** function that doesn't immediately get executed.\n     * Instead, the caller gets a **terminate** function back. The *cleaner* is\n     * invoked only once the mananger *closes* or the returned **terminate**\n     * function is called.\n     *\n     * @param clean The cleanup function.\n     * @param description Optional description to help identify pending jobs.\n     * @returns A terminate function.\n     */\n    addCleaner(clean, description) {\n        const { resolve, onTerminate } = this.addHook(description);\n        const proxy = async () => {\n            await clean();\n            resolve();\n        };\n        onTerminate.then(proxy);\n        return proxy;\n    }\n    addFunction(job, description) {\n        // the function we call when we want to try to terminate this job.\n        let terminate;\n        // the promise the job can opt into listening to for termination.\n        const onTerminate = new Promise(resolve => {\n            terminate = resolve;\n        });\n        // finally! start the job.\n        const jobResult = job(onTerminate);\n        // depending on what the job gives back, register the result\n        // so we can monitor for completion.\n        if (typeof jobResult?.then === 'function') {\n            this.registerPromise(jobResult, terminate, description);\n        }\n        // At the end of the day, or you know, method call, it doesn't matter\n        // what the return value is at all; we just pass it through to the\n        // caller.\n        return jobResult;\n    }\n    addManager(manager, description) {\n        this.addCleaner(async () => manager.close(), description);\n    }\n    /**\n     * Creates and registers a fabricated job for processes that need to operate\n     * with callbacks/hooks. The returned `resolve` and `reject`\n     * functions can be used to signal the job is done successfully or not.\n     * The returned `onTerminate` is a promise that will resolve when the\n     * manager is requesting the termination of the job.\n     *\n     * @param description Optional description to help identify pending jobs.\n     * @returns `{ resolve, reject, onTerminate }`\n     */\n    addHook(description) {\n        // the resolve/reject functions we'll provide to the caller to signal\n        // the state of the job.\n        let promiseResolve;\n        let promiseReject;\n        // the underlying promise we'll use to manage it, pretty much like\n        // any other promise.\n        const promise = new Promise((resolve, reject) => {\n            promiseResolve = resolve;\n            promiseReject = reject;\n        });\n        // the function we call when we want to try to terminate this job.\n        let terminate;\n        // the promise the job can opt into listening to for termination.\n        const onTerminate = new Promise(resolve => {\n            terminate = resolve;\n        });\n        this.registerPromise(promise, terminate, description);\n        return {\n            resolve: promiseResolve,\n            reject: promiseReject,\n            onTerminate,\n        };\n    }\n    /**\n     * Adds a Promise based job to the list of jobs for monitoring and listens\n     * for either a success or failure, upon which the job is considered \"done\"\n     * and removed from the registry.\n     *\n     * @param promise A promise that is on its way to being returned to a\n     * caller, which needs to be tracked as a background job.\n     * @param terminate The termination function to register, which can be\n     * invoked to request the job stop.\n     * @param description Optional description to help identify pending jobs.\n     */\n    registerPromise(promise, terminate, description) {\n        const jobEntry = { promise, terminate, description };\n        this.jobs.add(jobEntry);\n        // in all of my testing, it is safe to multi-subscribe to a promise.\n        // so, rather than create another layer of promising, we're just going\n        // to hook into the promise we already have, and when it's done\n        // (successfully or not), we no longer need to wait for it upon close.\n        //\n        // sorry this is a bit hand-wavy:\n        //\n        // i believe we use `.then` and `.catch` instead of `.finally` because\n        // `.finally` is invoked in a different order in the sequence, and this\n        // breaks assumptions throughout and causes failures.\n        promise\n            .then(() => {\n            this.jobs.delete(jobEntry);\n        })\n            .catch(() => {\n            this.jobs.delete(jobEntry);\n        });\n    }\n    /**\n     * The number of jobs being waited on.\n     *\n     * We don't use this for anything. It's just informational for the caller,\n     * and can be used in logging and testing.\n     *\n     * @returns the number of jobs.\n     */\n    get length() {\n        return this.jobs.size;\n    }\n    /**\n     * The execution state of the manager. One of:\n     *\n     * 1. \"Open\" -> Accepting new jobs\n     * 1. \"Closing\" -> Not accepting new work. Waiting for jobs to complete.\n     * 1. \"Closed\" -> Not accepting new work. All submitted jobs are complete.\n     */\n    get state() {\n        return this._state;\n    }\n    /**\n     * The registered `description` of all still-pending jobs.\n     *\n     * @returns descriptions as an array.\n     */\n    get pending() {\n        return Array.from(this.jobs).map(job => job.description);\n    }\n    /**\n     * Whether the manager is accepting new jobs.\n     */\n    get isOpen() {\n        return this._state === BackgroundProcessManagerState.Open;\n    }\n    /**\n     * Whether the manager is rejecting new work, but still waiting for\n     * submitted work to complete.\n     */\n    get isClosing() {\n        return this._state === BackgroundProcessManagerState.Closing;\n    }\n    /**\n     * Whether the manager is rejecting work and done waiting for submitted\n     * work to complete.\n     */\n    get isClosed() {\n        return this._state === BackgroundProcessManagerState.Closed;\n    }\n    closedFailure(description) {\n        if (!this.isOpen) {\n            return Promise.reject(new BackgroundManagerNotOpenError([\n                `The manager is ${this.state}.`,\n                `You tried to add \"${description}\".`,\n                `Pending jobs: [\\n${this.pending\n                    .map(t => '    ' + t)\n                    .join(',\\n')}\\n]`,\n            ].join('\\n')));\n        }\n    }\n    /**\n     * Signals jobs to stop (for those that accept interruptions) and waits\n     * for confirmation that jobs have stopped.\n     *\n     * This immediately puts the manager into a closing state and just begins\n     * to reject new work. After all work in the manager is complete, the\n     * manager goes into a `Completed` state and `close()` returns.\n     *\n     * This call is idempotent.\n     *\n     * If the manager is already closing or closed, `finalCleaup` is not executed.\n     *\n     * @param onClosed\n     * @returns The settled results of each still-running job's promise. If the\n     * manager is already closed, this will contain the results as of when the\n     * manager's `close()` was called in an `Open` state.\n     */\n    async close() {\n        if (this.isOpen) {\n            this._state = BackgroundProcessManagerState.Closing;\n            for (const job of Array.from(this.jobs)) {\n                try {\n                    job.terminate();\n                }\n                catch (error) {\n                    // Due to potential races with a job's natural completion, it's\n                    // reasonable to expect the termination call to fail. Hence,\n                    // not logging as an error.\n                    console.warn(`Failed to send termination signal to job. Error: ${error.message}`, job);\n                }\n            }\n            // Use `allSettled()` because we want to wait for all to finish. We do\n            // not want to stop waiting if there is a failure.\n            this._closingPromise = Promise.allSettled(Array.from(this.jobs).map(j => j.promise));\n            await this._closingPromise;\n            this._state = BackgroundProcessManagerState.Closed;\n        }\n        return this._closingPromise;\n    }\n    /**\n     * Signals the manager to start accepting work (again) and returns once\n     * the manager is ready to do so.\n     *\n     * If the state is already `Open`, this call is a no-op.\n     *\n     * If the state is `Closed`, this call simply updates state and returns.\n     *\n     * If the state is `Closing`, this call waits for completion before it\n     * updates the state and returns.\n     */\n    async open() {\n        if (this.isClosing) {\n            await this.close();\n        }\n        this._state = BackgroundProcessManagerState.Open;\n    }\n}\n\nexport { BackgroundProcessManager };\n//# sourceMappingURL=BackgroundProcessManager.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * All possible states a `BackgroundProcessManager` instance can be in.\n */\nvar BackgroundProcessManagerState;\n(function (BackgroundProcessManagerState) {\n    /**\n     * Accepting new jobs.\n     */\n    BackgroundProcessManagerState[\"Open\"] = \"Open\";\n    /**\n     * Not accepting new jobs. Waiting for submitted jobs to complete.\n     */\n    BackgroundProcessManagerState[\"Closing\"] = \"Closing\";\n    /**\n     * Not accepting new jobs. All submitted jobs are complete.\n     */\n    BackgroundProcessManagerState[\"Closed\"] = \"Closed\";\n})(BackgroundProcessManagerState || (BackgroundProcessManagerState = {}));\n\nexport { BackgroundProcessManagerState };\n//# sourceMappingURL=types.mjs.map\n","import { ConsoleLogger } from '../Logger/ConsoleLogger.mjs';\nimport { KeyValueStorage } from '../storage/KeyValueStorage.mjs';\nimport { getLocalStorageWithFallback } from '../storage/utils.mjs';\nimport { defaultConfig } from './constants.mjs';\nimport { StorageCacheCommon } from './StorageCacheCommon.mjs';\nimport { getCurrentSizeKey, getCurrentTime } from './utils/cacheHelpers.mjs';\nimport './utils/errorHelpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst logger = new ConsoleLogger('StorageCache');\n/**\n * Customized storage based on the SessionStorage or LocalStorage with LRU implemented\n */\nclass StorageCache extends StorageCacheCommon {\n    /**\n     * initialize the cache\n     * @param config - the configuration of the cache\n     */\n    constructor(config) {\n        const storage = getLocalStorageWithFallback();\n        super({ config, keyValueStorage: new KeyValueStorage(storage) });\n        this.storage = storage;\n        this.getItem = this.getItem.bind(this);\n        this.setItem = this.setItem.bind(this);\n        this.removeItem = this.removeItem.bind(this);\n    }\n    async getAllCacheKeys(options) {\n        const { omitSizeKey } = options ?? {};\n        const keys = [];\n        for (let i = 0; i < this.storage.length; i++) {\n            const key = this.storage.key(i);\n            if (omitSizeKey && key === getCurrentSizeKey(this.config.keyPrefix)) {\n                continue;\n            }\n            if (key?.startsWith(this.config.keyPrefix)) {\n                keys.push(key.substring(this.config.keyPrefix.length));\n            }\n        }\n        return keys;\n    }\n    /**\n     * Return a new instance of cache with customized configuration.\n     * @param {Object} config - the customized configuration\n     * @return {Object} - the new instance of Cache\n     */\n    createInstance(config) {\n        if (!config.keyPrefix || config.keyPrefix === defaultConfig.keyPrefix) {\n            logger.error('invalid keyPrefix, setting keyPrefix with timeStamp');\n            config.keyPrefix = getCurrentTime.toString();\n        }\n        return new StorageCache(config);\n    }\n}\n\nexport { StorageCache };\n//# sourceMappingURL=StorageCache.mjs.map\n","import { ConsoleLogger } from '../Logger/ConsoleLogger.mjs';\nimport { defaultConfig, currentSizeKey } from './constants.mjs';\nimport { getCurrentSizeKey, getCurrentTime, getByteLength } from './utils/cacheHelpers.mjs';\nimport { assert, CacheErrorCode } from './utils/errorHelpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst logger = new ConsoleLogger('StorageCache');\n/**\n * Initialization of the cache\n *\n */\nclass StorageCacheCommon {\n    /**\n     * Initialize the cache\n     *\n     * @param config - Custom configuration for this instance.\n     */\n    constructor({ config, keyValueStorage, }) {\n        this.config = {\n            ...defaultConfig,\n            ...config,\n        };\n        this.keyValueStorage = keyValueStorage;\n        this.sanitizeConfig();\n    }\n    getModuleName() {\n        return 'Cache';\n    }\n    /**\n     * Set custom configuration for the cache instance.\n     *\n     * @param config - customized configuration (without keyPrefix, which can't be changed)\n     *\n     * @return - the current configuration\n     */\n    configure(config) {\n        if (config) {\n            if (config.keyPrefix) {\n                logger.warn('keyPrefix can not be re-configured on an existing Cache instance.');\n            }\n            this.config = {\n                ...this.config,\n                ...config,\n            };\n        }\n        this.sanitizeConfig();\n        return this.config;\n    }\n    /**\n     * return the current size of the cache\n     * @return {Promise}\n     */\n    async getCurrentCacheSize() {\n        let size = await this.getStorage().getItem(getCurrentSizeKey(this.config.keyPrefix));\n        if (!size) {\n            await this.getStorage().setItem(getCurrentSizeKey(this.config.keyPrefix), '0');\n            size = '0';\n        }\n        return Number(size);\n    }\n    /**\n     * Set item into cache. You can put number, string, boolean or object.\n     * The cache will first check whether has the same key.\n     * If it has, it will delete the old item and then put the new item in\n     * The cache will pop out items if it is full\n     * You can specify the cache item options. The cache will abort and output a warning:\n     * If the key is invalid\n     * If the size of the item exceeds itemMaxSize.\n     * If the value is undefined\n     * If incorrect cache item configuration\n     * If error happened with browser storage\n     *\n     * @param {String} key - the key of the item\n     * @param {Object} value - the value of the item\n     * @param {Object} [options] - optional, the specified meta-data\n     *\n     * @return {Promise}\n     */\n    async setItem(key, value, options) {\n        logger.debug(`Set item: key is ${key}, value is ${value} with options: ${options}`);\n        if (!key || key === currentSizeKey) {\n            logger.warn(`Invalid key: should not be empty or reserved key: '${currentSizeKey}'`);\n            return;\n        }\n        if (typeof value === 'undefined') {\n            logger.warn(`The value of item should not be undefined!`);\n            return;\n        }\n        const cacheItemOptions = {\n            priority: options?.priority !== undefined\n                ? options.priority\n                : this.config.defaultPriority,\n            expires: options?.expires !== undefined\n                ? options.expires\n                : this.config.defaultTTL + getCurrentTime(),\n        };\n        if (cacheItemOptions.priority < 1 || cacheItemOptions.priority > 5) {\n            logger.warn(`Invalid parameter: priority due to out or range. It should be within 1 and 5.`);\n            return;\n        }\n        const prefixedKey = `${this.config.keyPrefix}${key}`;\n        const item = this.fillCacheItem(prefixedKey, value, cacheItemOptions);\n        // check whether this item is too big;\n        if (item.byteSize > this.config.itemMaxSize) {\n            logger.warn(`Item with key: ${key} you are trying to put into is too big!`);\n            return;\n        }\n        try {\n            // first look into the storage, if it exists, delete it.\n            const val = await this.getStorage().getItem(prefixedKey);\n            if (val) {\n                await this.removeCacheItem(prefixedKey, JSON.parse(val).byteSize);\n            }\n            // check whether the cache is full\n            if (await this.isCacheFull(item.byteSize)) {\n                const validKeys = await this.clearInvalidAndGetRemainingKeys();\n                if (await this.isCacheFull(item.byteSize)) {\n                    const sizeToPop = await this.sizeToPop(item.byteSize);\n                    await this.popOutItems(validKeys, sizeToPop);\n                }\n            }\n            // put item in the cache\n            return this.setCacheItem(prefixedKey, item);\n        }\n        catch (e) {\n            logger.warn(`setItem failed! ${e}`);\n        }\n    }\n    /**\n     * Get item from cache. It will return null if item doesn’t exist or it has been expired.\n     * If you specified callback function in the options,\n     * then the function will be executed if no such item in the cache\n     * and finally put the return value into cache.\n     * Please make sure the callback function will return the value you want to put into the cache.\n     * The cache will abort output a warning:\n     * If the key is invalid\n     * If error happened with AsyncStorage\n     *\n     * @param {String} key - the key of the item\n     * @param {Object} [options] - the options of callback function\n     *\n     * @return {Promise} - return a promise resolves to be the value of the item\n     */\n    async getItem(key, options) {\n        logger.debug(`Get item: key is ${key} with options ${options}`);\n        let cached;\n        if (!key || key === currentSizeKey) {\n            logger.warn(`Invalid key: should not be empty or reserved key: '${currentSizeKey}'`);\n            return null;\n        }\n        const prefixedKey = `${this.config.keyPrefix}${key}`;\n        try {\n            cached = await this.getStorage().getItem(prefixedKey);\n            if (cached != null) {\n                if (await this.isExpired(prefixedKey)) {\n                    // if expired, remove that item and return null\n                    await this.removeCacheItem(prefixedKey, JSON.parse(cached).byteSize);\n                }\n                else {\n                    // if not expired, update its visitedTime and return the value\n                    const item = await this.updateVisitedTime(JSON.parse(cached), prefixedKey);\n                    return item.data;\n                }\n            }\n            if (options?.callback) {\n                const val = options.callback();\n                if (val !== null) {\n                    await this.setItem(key, val, options);\n                }\n                return val;\n            }\n            return null;\n        }\n        catch (e) {\n            logger.warn(`getItem failed! ${e}`);\n            return null;\n        }\n    }\n    /**\n     * remove item from the cache\n     * The cache will abort output a warning:\n     * If error happened with AsyncStorage\n     * @param {String} key - the key of the item\n     * @return {Promise}\n     */\n    async removeItem(key) {\n        logger.debug(`Remove item: key is ${key}`);\n        if (!key || key === currentSizeKey) {\n            logger.warn(`Invalid key: should not be empty or reserved key: '${currentSizeKey}'`);\n            return;\n        }\n        const prefixedKey = `${this.config.keyPrefix}${key}`;\n        try {\n            const val = await this.getStorage().getItem(prefixedKey);\n            if (val) {\n                await this.removeCacheItem(prefixedKey, JSON.parse(val).byteSize);\n            }\n        }\n        catch (e) {\n            logger.warn(`removeItem failed! ${e}`);\n        }\n    }\n    /**\n     * Return all the keys owned by this cache.\n     * Will return an empty array if error occurred.\n     *\n     * @return {Promise}\n     */\n    async getAllKeys() {\n        try {\n            return await this.getAllCacheKeys();\n        }\n        catch (e) {\n            logger.warn(`getAllkeys failed! ${e}`);\n            return [];\n        }\n    }\n    getStorage() {\n        return this.keyValueStorage;\n    }\n    /**\n     * check whether item is expired\n     *\n     * @param key - the key of the item\n     *\n     * @return true if the item is expired.\n     */\n    async isExpired(key) {\n        const text = await this.getStorage().getItem(key);\n        assert(text !== null, CacheErrorCode.NoCacheItem, `Key: ${key}`);\n        const item = JSON.parse(text);\n        if (getCurrentTime() >= item.expires) {\n            return true;\n        }\n        return false;\n    }\n    /**\n     * delete item from cache\n     *\n     * @param prefixedKey - the key of the item\n     * @param size - optional, the byte size of the item\n     */\n    async removeCacheItem(prefixedKey, size) {\n        const item = await this.getStorage().getItem(prefixedKey);\n        assert(item !== null, CacheErrorCode.NoCacheItem, `Key: ${prefixedKey}`);\n        const itemSize = size ?? JSON.parse(item).byteSize;\n        // first try to update the current size of the cache\n        await this.decreaseCurrentSizeInBytes(itemSize);\n        // try to remove the item from cache\n        try {\n            await this.getStorage().removeItem(prefixedKey);\n        }\n        catch (removeItemError) {\n            // if some error happened, we need to rollback the current size\n            await this.increaseCurrentSizeInBytes(itemSize);\n            logger.error(`Failed to remove item: ${removeItemError}`);\n        }\n    }\n    /**\n     * produce a JSON object with meta-data and data value\n     * @param value - the value of the item\n     * @param options - optional, the specified meta-data\n     *\n     * @return - the item which has the meta-data and the value\n     */\n    fillCacheItem(key, value, options) {\n        const item = {\n            key,\n            data: value,\n            timestamp: getCurrentTime(),\n            visitedTime: getCurrentTime(),\n            priority: options.priority ?? 0,\n            expires: options.expires ?? 0,\n            type: typeof value,\n            byteSize: 0,\n        };\n        // calculate byte size\n        item.byteSize = getByteLength(JSON.stringify(item));\n        // re-calculate using cache item with updated byteSize property\n        item.byteSize = getByteLength(JSON.stringify(item));\n        return item;\n    }\n    sanitizeConfig() {\n        if (this.config.itemMaxSize > this.config.capacityInBytes) {\n            logger.error('Invalid parameter: itemMaxSize. It should be smaller than capacityInBytes. Setting back to default.');\n            this.config.itemMaxSize = defaultConfig.itemMaxSize;\n        }\n        if (this.config.defaultPriority > 5 || this.config.defaultPriority < 1) {\n            logger.error('Invalid parameter: defaultPriority. It should be between 1 and 5. Setting back to default.');\n            this.config.defaultPriority = defaultConfig.defaultPriority;\n        }\n        if (Number(this.config.warningThreshold) > 1 ||\n            Number(this.config.warningThreshold) < 0) {\n            logger.error('Invalid parameter: warningThreshold. It should be between 0 and 1. Setting back to default.');\n            this.config.warningThreshold = defaultConfig.warningThreshold;\n        }\n        // Set 5MB limit\n        const cacheLimit = 5 * 1024 * 1024;\n        if (this.config.capacityInBytes > cacheLimit) {\n            logger.error('Cache Capacity should be less than 5MB. Setting back to default. Setting back to default.');\n            this.config.capacityInBytes = defaultConfig.capacityInBytes;\n        }\n    }\n    /**\n     * increase current size of the cache\n     *\n     * @param amount - the amount of the cache szie which need to be increased\n     */\n    async increaseCurrentSizeInBytes(amount) {\n        const size = await this.getCurrentCacheSize();\n        await this.getStorage().setItem(getCurrentSizeKey(this.config.keyPrefix), (size + amount).toString());\n    }\n    /**\n     * decrease current size of the cache\n     *\n     * @param amount - the amount of the cache size which needs to be decreased\n     */\n    async decreaseCurrentSizeInBytes(amount) {\n        const size = await this.getCurrentCacheSize();\n        await this.getStorage().setItem(getCurrentSizeKey(this.config.keyPrefix), (size - amount).toString());\n    }\n    /**\n     * update the visited time if item has been visited\n     *\n     * @param item - the item which need to be updated\n     * @param prefixedKey - the key of the item\n     *\n     * @return the updated item\n     */\n    async updateVisitedTime(item, prefixedKey) {\n        item.visitedTime = getCurrentTime();\n        await this.getStorage().setItem(prefixedKey, JSON.stringify(item));\n        return item;\n    }\n    /**\n     * put item into cache\n     *\n     * @param prefixedKey - the key of the item\n     * @param itemData - the value of the item\n     * @param itemSizeInBytes - the byte size of the item\n     */\n    async setCacheItem(prefixedKey, item) {\n        // first try to update the current size of the cache.\n        await this.increaseCurrentSizeInBytes(item.byteSize);\n        // try to add the item into cache\n        try {\n            await this.getStorage().setItem(prefixedKey, JSON.stringify(item));\n        }\n        catch (setItemErr) {\n            // if some error happened, we need to rollback the current size\n            await this.decreaseCurrentSizeInBytes(item.byteSize);\n            logger.error(`Failed to set item ${setItemErr}`);\n        }\n    }\n    /**\n     * total space needed when poping out items\n     *\n     * @param itemSize\n     *\n     * @return total space needed\n     */\n    async sizeToPop(itemSize) {\n        const cur = await this.getCurrentCacheSize();\n        const spaceItemNeed = cur + itemSize - this.config.capacityInBytes;\n        const cacheThresholdSpace = (1 - this.config.warningThreshold) * this.config.capacityInBytes;\n        return spaceItemNeed > cacheThresholdSpace\n            ? spaceItemNeed\n            : cacheThresholdSpace;\n    }\n    /**\n     * see whether cache is full\n     *\n     * @param itemSize\n     *\n     * @return true if cache is full\n     */\n    async isCacheFull(itemSize) {\n        const cur = await this.getCurrentCacheSize();\n        return itemSize + cur > this.config.capacityInBytes;\n    }\n    /**\n     * get all the items we have, sort them by their priority,\n     * if priority is same, sort them by their last visited time\n     * pop out items from the low priority (5 is the lowest)\n     * @private\n     * @param keys - all the keys in this cache\n     * @param sizeToPop - the total size of the items which needed to be poped out\n     */\n    async popOutItems(keys, sizeToPop) {\n        const items = [];\n        let remainedSize = sizeToPop;\n        for (const key of keys) {\n            const val = await this.getStorage().getItem(key);\n            if (val != null) {\n                const item = JSON.parse(val);\n                items.push(item);\n            }\n        }\n        // first compare priority\n        // then compare visited time\n        items.sort((a, b) => {\n            if (a.priority > b.priority) {\n                return -1;\n            }\n            else if (a.priority < b.priority) {\n                return 1;\n            }\n            else {\n                if (a.visitedTime < b.visitedTime) {\n                    return -1;\n                }\n                else\n                    return 1;\n            }\n        });\n        for (const item of items) {\n            // pop out items until we have enough room for new item\n            await this.removeCacheItem(item.key, item.byteSize);\n            remainedSize -= item.byteSize;\n            if (remainedSize <= 0) {\n                return;\n            }\n        }\n    }\n    /**\n     * Scan the storage and combine the following operations for efficiency\n     *   1. Clear out all expired keys owned by this cache, not including the size key.\n     *   2. Return the remaining keys.\n     *\n     * @return The remaining valid keys\n     */\n    async clearInvalidAndGetRemainingKeys() {\n        const remainingKeys = [];\n        const keys = await this.getAllCacheKeys({\n            omitSizeKey: true,\n        });\n        for (const key of keys) {\n            if (await this.isExpired(key)) {\n                await this.removeCacheItem(key);\n            }\n            else {\n                remainingKeys.push(key);\n            }\n        }\n        return remainingKeys;\n    }\n    /**\n     * clear the entire cache\n     * The cache will abort and output a warning if error occurs\n     * @return {Promise}\n     */\n    async clear() {\n        logger.debug(`Clear Cache`);\n        try {\n            const keys = await this.getAllKeys();\n            for (const key of keys) {\n                const prefixedKey = `${this.config.keyPrefix}${key}`;\n                await this.getStorage().removeItem(prefixedKey);\n            }\n        }\n        catch (e) {\n            logger.warn(`clear failed! ${e}`);\n        }\n    }\n}\n\nexport { StorageCacheCommon };\n//# sourceMappingURL=StorageCacheCommon.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Default cache config\n */\nconst defaultConfig = {\n    keyPrefix: 'aws-amplify-cache',\n    capacityInBytes: 1048576,\n    itemMaxSize: 210000,\n    defaultTTL: 259200000,\n    defaultPriority: 5,\n    warningThreshold: 0.8,\n};\nconst currentSizeKey = 'CurSize';\n\nexport { currentSizeKey, defaultConfig };\n//# sourceMappingURL=constants.mjs.map\n","import { StorageCache } from './StorageCache.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst Cache = new StorageCache();\n\nexport { Cache };\n//# sourceMappingURL=index.mjs.map\n","import { currentSizeKey } from '../constants.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * return the byte size of the string\n * @param str\n */\nfunction getByteLength(str) {\n    let ret = 0;\n    ret = str.length;\n    for (let i = str.length; i >= 0; i -= 1) {\n        const charCode = str.charCodeAt(i);\n        if (charCode > 0x7f && charCode <= 0x7ff) {\n            ret += 1;\n        }\n        else if (charCode > 0x7ff && charCode <= 0xffff) {\n            ret += 2;\n        }\n        // trail surrogate\n        if (charCode >= 0xdc00 && charCode <= 0xdfff) {\n            i -= 1;\n        }\n    }\n    return ret;\n}\n/**\n * get current time\n */\nfunction getCurrentTime() {\n    const currentTime = new Date();\n    return currentTime.getTime();\n}\n/**\n * check if passed value is an integer\n */\nfunction isInteger(value) {\n    if (Number.isInteger) {\n        return Number.isInteger(value);\n    }\n    return (typeof value === 'number' && isFinite(value) && Math.floor(value) === value);\n}\nconst getCurrentSizeKey = (keyPrefix) => `${keyPrefix}${currentSizeKey}`;\n\nexport { getByteLength, getCurrentSizeKey, getCurrentTime, isInteger };\n//# sourceMappingURL=cacheHelpers.mjs.map\n","import { createAssertionFunction } from '../../errors/createAssertionFunction.mjs';\nimport '../../types/errors.mjs';\nimport '../../errors/errorHelpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nvar CacheErrorCode;\n(function (CacheErrorCode) {\n    CacheErrorCode[\"NoCacheItem\"] = \"NoCacheItem\";\n    CacheErrorCode[\"NullNextNode\"] = \"NullNextNode\";\n    CacheErrorCode[\"NullPreviousNode\"] = \"NullPreviousNode\";\n})(CacheErrorCode || (CacheErrorCode = {}));\nconst cacheErrorMap = {\n    [CacheErrorCode.NoCacheItem]: {\n        message: 'Item not found in the cache storage.',\n    },\n    [CacheErrorCode.NullNextNode]: {\n        message: 'Next node is null.',\n    },\n    [CacheErrorCode.NullPreviousNode]: {\n        message: 'Previous node is null.',\n    },\n};\nconst assert = createAssertionFunction(cacheErrorMap);\n\nexport { CacheErrorCode, assert };\n//# sourceMappingURL=errorHelpers.mjs.map\n","import { ConsoleLogger } from '../Logger/ConsoleLogger.mjs';\nimport { NO_HUBCALLBACK_PROVIDED_EXCEPTION } from '../constants.mjs';\nimport { AmplifyError } from '../errors/AmplifyError.mjs';\nimport '../types/errors.mjs';\nimport '../errors/errorHelpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst AMPLIFY_SYMBOL = (typeof Symbol !== 'undefined'\n    ? Symbol('amplify_default')\n    : '@@amplify_default');\nconst logger = new ConsoleLogger('Hub');\nclass HubClass {\n    constructor(name) {\n        this.listeners = new Map();\n        this.protectedChannels = [\n            'core',\n            'auth',\n            'api',\n            'analytics',\n            'interactions',\n            'pubsub',\n            'storage',\n            'ui',\n            'xr',\n        ];\n        this.name = name;\n    }\n    /**\n     * Used internally to remove a Hub listener.\n     *\n     * @remarks\n     * This private method is for internal use only. Instead of calling Hub.remove, call the result of Hub.listen.\n     */\n    _remove(channel, listener) {\n        const holder = this.listeners.get(channel);\n        if (!holder) {\n            logger.warn(`No listeners for ${channel}`);\n            return;\n        }\n        this.listeners.set(channel, [\n            ...holder.filter(({ callback }) => callback !== listener),\n        ]);\n    }\n    dispatch(channel, payload, source, ampSymbol) {\n        if (typeof channel === 'string' &&\n            this.protectedChannels.indexOf(channel) > -1) {\n            const hasAccess = ampSymbol === AMPLIFY_SYMBOL;\n            if (!hasAccess) {\n                logger.warn(`WARNING: ${channel} is protected and dispatching on it can have unintended consequences`);\n            }\n        }\n        const capsule = {\n            channel,\n            payload: { ...payload },\n            source,\n            patternInfo: [],\n        };\n        try {\n            this._toListeners(capsule);\n        }\n        catch (e) {\n            logger.error(e);\n        }\n    }\n    listen(channel, callback, listenerName = 'noname') {\n        let cb;\n        if (typeof callback !== 'function') {\n            throw new AmplifyError({\n                name: NO_HUBCALLBACK_PROVIDED_EXCEPTION,\n                message: 'No callback supplied to Hub',\n            });\n        }\n        else {\n            // Needs to be casted as a more generic type\n            cb = callback;\n        }\n        let holder = this.listeners.get(channel);\n        if (!holder) {\n            holder = [];\n            this.listeners.set(channel, holder);\n        }\n        holder.push({\n            name: listenerName,\n            callback: cb,\n        });\n        return () => {\n            this._remove(channel, cb);\n        };\n    }\n    _toListeners(capsule) {\n        const { channel, payload } = capsule;\n        const holder = this.listeners.get(channel);\n        if (holder) {\n            holder.forEach(listener => {\n                logger.debug(`Dispatching to ${channel} with `, payload);\n                try {\n                    listener.callback(capsule);\n                }\n                catch (e) {\n                    logger.error(e);\n                }\n            });\n        }\n    }\n}\n/* We export a __default__ instance of HubClass to use it as a\npseudo Singleton for the main messaging bus, however you can still create\nyour own instance of HubClass() for a separate \"private bus\" of events. */\nconst Hub = new HubClass('__default__');\n/**\n * @internal\n *\n * Internal hub used for core Amplify functionality. Not intended for use outside of Amplify.\n *\n */\nconst HubInternal = new HubClass('internal-hub');\n\nexport { AMPLIFY_SYMBOL, Hub, HubClass, HubInternal };\n//# sourceMappingURL=index.mjs.map\n","import { AWS_CLOUDWATCH_CATEGORY } from '../constants.mjs';\nimport { LogType } from './types.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst LOG_LEVELS = {\n    VERBOSE: 1,\n    DEBUG: 2,\n    INFO: 3,\n    WARN: 4,\n    ERROR: 5,\n    NONE: 6,\n};\n/**\n * Write logs\n * @class Logger\n */\nclass ConsoleLogger {\n    /**\n     * @constructor\n     * @param {string} name - Name of the logger\n     */\n    constructor(name, level = LogType.WARN) {\n        this.name = name;\n        this.level = level;\n        this._pluggables = [];\n    }\n    _padding(n) {\n        return n < 10 ? '0' + n : '' + n;\n    }\n    _ts() {\n        const dt = new Date();\n        return ([this._padding(dt.getMinutes()), this._padding(dt.getSeconds())].join(':') +\n            '.' +\n            dt.getMilliseconds());\n    }\n    configure(config) {\n        if (!config)\n            return this._config;\n        this._config = config;\n        return this._config;\n    }\n    /**\n     * Write log\n     * @method\n     * @memeberof Logger\n     * @param {LogType|string} type - log type, default INFO\n     * @param {string|object} msg - Logging message or object\n     */\n    _log(type, ...msg) {\n        let loggerLevelName = this.level;\n        if (ConsoleLogger.LOG_LEVEL) {\n            loggerLevelName = ConsoleLogger.LOG_LEVEL;\n        }\n        if (typeof window !== 'undefined' && window.LOG_LEVEL) {\n            loggerLevelName = window.LOG_LEVEL;\n        }\n        const loggerLevel = LOG_LEVELS[loggerLevelName];\n        const typeLevel = LOG_LEVELS[type];\n        if (!(typeLevel >= loggerLevel)) {\n            // Do nothing if type is not greater than or equal to logger level (handle undefined)\n            return;\n        }\n        let log = console.log.bind(console);\n        if (type === LogType.ERROR && console.error) {\n            log = console.error.bind(console);\n        }\n        if (type === LogType.WARN && console.warn) {\n            log = console.warn.bind(console);\n        }\n        if (ConsoleLogger.BIND_ALL_LOG_LEVELS) {\n            if (type === LogType.INFO && console.info) {\n                log = console.info.bind(console);\n            }\n            if (type === LogType.DEBUG && console.debug) {\n                log = console.debug.bind(console);\n            }\n        }\n        const prefix = `[${type}] ${this._ts()} ${this.name}`;\n        let message = '';\n        if (msg.length === 1 && typeof msg[0] === 'string') {\n            message = `${prefix} - ${msg[0]}`;\n            log(message);\n        }\n        else if (msg.length === 1) {\n            message = `${prefix} ${msg[0]}`;\n            log(prefix, msg[0]);\n        }\n        else if (typeof msg[0] === 'string') {\n            let obj = msg.slice(1);\n            if (obj.length === 1) {\n                obj = obj[0];\n            }\n            message = `${prefix} - ${msg[0]} ${obj}`;\n            log(`${prefix} - ${msg[0]}`, obj);\n        }\n        else {\n            message = `${prefix} ${msg}`;\n            log(prefix, msg);\n        }\n        for (const plugin of this._pluggables) {\n            const logEvent = { message, timestamp: Date.now() };\n            plugin.pushLogs([logEvent]);\n        }\n    }\n    /**\n     * Write General log. Default to INFO\n     * @method\n     * @memeberof Logger\n     * @param {string|object} msg - Logging message or object\n     */\n    log(...msg) {\n        this._log(LogType.INFO, ...msg);\n    }\n    /**\n     * Write INFO log\n     * @method\n     * @memeberof Logger\n     * @param {string|object} msg - Logging message or object\n     */\n    info(...msg) {\n        this._log(LogType.INFO, ...msg);\n    }\n    /**\n     * Write WARN log\n     * @method\n     * @memeberof Logger\n     * @param {string|object} msg - Logging message or object\n     */\n    warn(...msg) {\n        this._log(LogType.WARN, ...msg);\n    }\n    /**\n     * Write ERROR log\n     * @method\n     * @memeberof Logger\n     * @param {string|object} msg - Logging message or object\n     */\n    error(...msg) {\n        this._log(LogType.ERROR, ...msg);\n    }\n    /**\n     * Write DEBUG log\n     * @method\n     * @memeberof Logger\n     * @param {string|object} msg - Logging message or object\n     */\n    debug(...msg) {\n        this._log(LogType.DEBUG, ...msg);\n    }\n    /**\n     * Write VERBOSE log\n     * @method\n     * @memeberof Logger\n     * @param {string|object} msg - Logging message or object\n     */\n    verbose(...msg) {\n        this._log(LogType.VERBOSE, ...msg);\n    }\n    addPluggable(pluggable) {\n        if (pluggable && pluggable.getCategoryName() === AWS_CLOUDWATCH_CATEGORY) {\n            this._pluggables.push(pluggable);\n            pluggable.configure(this._config);\n        }\n    }\n    listPluggables() {\n        return this._pluggables;\n    }\n}\nConsoleLogger.LOG_LEVEL = null;\nConsoleLogger.BIND_ALL_LOG_LEVELS = false;\n\nexport { ConsoleLogger };\n//# sourceMappingURL=ConsoleLogger.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nvar LogType;\n(function (LogType) {\n    LogType[\"DEBUG\"] = \"DEBUG\";\n    LogType[\"ERROR\"] = \"ERROR\";\n    LogType[\"INFO\"] = \"INFO\";\n    LogType[\"WARN\"] = \"WARN\";\n    LogType[\"VERBOSE\"] = \"VERBOSE\";\n    LogType[\"NONE\"] = \"NONE\";\n})(LogType || (LogType = {}));\n\nexport { LogType };\n//# sourceMappingURL=types.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/*!\n * The MIT License (MIT)\n *\n * Copyright (c) 2016 Christian Speckner <cnspeckn@googlemail.com>\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the \"Software\"), to deal\n * in the Software without restriction, including without limitation the rights\n * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n * copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n * THE SOFTWARE.\n */\nclass Mutex {\n    constructor() {\n        this._queue = [];\n        this._pending = false;\n    }\n    isLocked() {\n        return this._pending;\n    }\n    acquire() {\n        const ticket = new Promise(resolve => this._queue.push(resolve));\n        if (!this._pending) {\n            this._dispatchNext();\n        }\n        return ticket;\n    }\n    runExclusive(callback) {\n        return this.acquire().then(release => {\n            let result;\n            try {\n                result = callback();\n            }\n            catch (e) {\n                release();\n                throw e;\n            }\n            return Promise.resolve(result).then((x) => {\n                release();\n                return x;\n            }, e => {\n                release();\n                throw e;\n            });\n        });\n    }\n    _dispatchNext() {\n        if (this._queue.length > 0) {\n            this._pending = true;\n            this._queue.shift()(this._dispatchNext.bind(this));\n        }\n        else {\n            this._pending = false;\n        }\n    }\n}\n\nexport { Mutex };\n//# sourceMappingURL=Mutex.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// Maintains custom user-agent state set by external consumers.\nconst customUserAgentState = {};\n/**\n * Sets custom user agent state which will be appended to applicable requests. Returns a function that can be used to\n * clean up any custom state set with this API.\n *\n * @note\n * This API operates globally. Calling this API multiple times will result in the most recently set values for a\n * particular API being used.\n *\n * @note\n * This utility IS NOT compatible with SSR.\n *\n * @param input - SetCustomUserAgentInput that defines custom state to apply to the specified APIs.\n */\nconst setCustomUserAgent = (input) => {\n    // Save custom user-agent state & increment reference counter\n    // TODO Remove `any` when we upgrade to TypeScript 5.2, see: https://github.com/microsoft/TypeScript/issues/44373\n    customUserAgentState[input.category] = input.apis.reduce((acc, api) => ({\n        ...acc,\n        [api]: {\n            refCount: acc[api]?.refCount ? acc[api].refCount + 1 : 1,\n            additionalDetails: input.additionalDetails,\n        },\n    }), customUserAgentState[input.category] ?? {});\n    // Callback that cleans up state for APIs recorded by this call\n    let cleanUpCallbackCalled = false;\n    const cleanUpCallback = () => {\n        // Only allow the cleanup callback to be called once\n        if (cleanUpCallbackCalled) {\n            return;\n        }\n        cleanUpCallbackCalled = true;\n        input.apis.forEach(api => {\n            const apiRefCount = customUserAgentState[input.category][api].refCount;\n            if (apiRefCount > 1) {\n                customUserAgentState[input.category][api].refCount = apiRefCount - 1;\n            }\n            else {\n                delete customUserAgentState[input.category][api];\n                // Clean up category if no more APIs set\n                if (!Object.keys(customUserAgentState[input.category]).length) {\n                    delete customUserAgentState[input.category];\n                }\n            }\n        });\n    };\n    return cleanUpCallback;\n};\nconst getCustomUserAgent = (category, api) => customUserAgentState[category]?.[api]?.additionalDetails;\n\nexport { getCustomUserAgent, setCustomUserAgent };\n//# sourceMappingURL=customUserAgent.mjs.map\n","import { Framework } from './types.mjs';\nimport { detect } from './detection/index.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// We want to cache detection since the framework won't change\nlet frameworkCache;\nconst frameworkChangeObservers = [];\n// Setup the detection reset tracking / timeout delays\nlet resetTriggered = false;\nconst SSR_RESET_TIMEOUT = 10; // ms\nconst WEB_RESET_TIMEOUT = 10; // ms\nconst PRIME_FRAMEWORK_DELAY = 1000; // ms\nconst detectFramework = () => {\n    if (!frameworkCache) {\n        frameworkCache = detect();\n        if (resetTriggered) {\n            // The final run of detectFramework:\n            // Starting from this point, the `frameworkCache` becomes \"final\".\n            // So we don't need to notify the observers again so the observer\n            // can be removed after the final notice.\n            while (frameworkChangeObservers.length) {\n                frameworkChangeObservers.pop()?.();\n            }\n        }\n        else {\n            // The first run of detectFramework:\n            // Every time we update the cache, call each observer function\n            frameworkChangeObservers.forEach(fcn => {\n                fcn();\n            });\n        }\n        // Retry once for either Unknown type after a delay (explained below)\n        resetTimeout(Framework.ServerSideUnknown, SSR_RESET_TIMEOUT);\n        resetTimeout(Framework.WebUnknown, WEB_RESET_TIMEOUT);\n    }\n    return frameworkCache;\n};\n/**\n * @internal Setup observer callback that will be called everytime the framework changes\n */\nconst observeFrameworkChanges = (fcn) => {\n    // When the `frameworkCache` won't be updated again, we ignore all incoming\n    // observers.\n    if (resetTriggered) {\n        return;\n    }\n    frameworkChangeObservers.push(fcn);\n};\nfunction clearCache() {\n    frameworkCache = undefined;\n}\n// For a framework type and a delay amount, setup the event to re-detect\n//   During the runtime boot, it is possible that framework detection will\n//   be triggered before the framework has made modifications to the\n//   global/window/etc needed for detection. When no framework is detected\n//   we will reset and try again to ensure we don't use a cached\n//   non-framework detection result for all requests.\nfunction resetTimeout(framework, delay) {\n    if (frameworkCache === framework && !resetTriggered) {\n        setTimeout(() => {\n            clearCache();\n            resetTriggered = true;\n            setTimeout(detectFramework, PRIME_FRAMEWORK_DELAY);\n        }, delay);\n    }\n}\n\nexport { clearCache, detectFramework, frameworkChangeObservers, observeFrameworkChanges };\n//# sourceMappingURL=detectFramework.mjs.map\n","import { documentExists, processExists, windowExists } from './helpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// Tested with @angular/core 16.0.0\nfunction angularWebDetect() {\n    const angularVersionSetInDocument = Boolean(documentExists() && document.querySelector('[ng-version]'));\n    const angularContentSetInWindow = Boolean(windowExists() && typeof window.ng !== 'undefined');\n    return angularVersionSetInDocument || angularContentSetInWindow;\n}\nfunction angularSSRDetect() {\n    return ((processExists() &&\n        typeof process.env === 'object' &&\n        process.env.npm_lifecycle_script?.startsWith('ng ')) ||\n        false);\n}\n\nexport { angularSSRDetect, angularWebDetect };\n//# sourceMappingURL=Angular.mjs.map\n","import { globalExists } from './helpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// Tested with expo 48 / react-native 0.71.3\nfunction expoDetect() {\n    return globalExists() && typeof global.expo !== 'undefined';\n}\n\nexport { expoDetect };\n//# sourceMappingURL=Expo.mjs.map\n","import { windowExists, globalExists, keyPrefixMatch } from './helpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// Tested with next 13.4 / react 18.2\nfunction nextWebDetect() {\n    return (windowExists() &&\n        window.next &&\n        typeof window.next === 'object');\n}\nfunction nextSSRDetect() {\n    return (globalExists() &&\n        (keyPrefixMatch(global, '__next') || keyPrefixMatch(global, '__NEXT')));\n}\n\nexport { nextSSRDetect, nextWebDetect };\n//# sourceMappingURL=Next.mjs.map\n","import { windowExists, globalExists } from './helpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// Tested with nuxt 2.15 / vue 2.7\nfunction nuxtWebDetect() {\n    return (windowExists() &&\n        (window.__NUXT__ !== undefined ||\n            window.$nuxt !== undefined));\n}\nfunction nuxtSSRDetect() {\n    return (globalExists() && typeof global.__NUXT_PATHS__ !== 'undefined');\n}\n\nexport { nuxtSSRDetect, nuxtWebDetect };\n//# sourceMappingURL=Nuxt.mjs.map\n","import { documentExists, processExists } from './helpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// Tested with react 18.2 - built using Vite\nfunction reactWebDetect() {\n    const elementKeyPrefixedWithReact = (key) => {\n        return key.startsWith('_react') || key.startsWith('__react');\n    };\n    const elementIsReactEnabled = (element) => {\n        return Object.keys(element).find(elementKeyPrefixedWithReact);\n    };\n    const allElementsWithId = () => Array.from(document.querySelectorAll('[id]'));\n    return documentExists() && allElementsWithId().some(elementIsReactEnabled);\n}\nfunction reactSSRDetect() {\n    return (processExists() &&\n        typeof process.env !== 'undefined' &&\n        !!Object.keys(process.env).find(key => key.includes('react')));\n}\n// use the some\n\nexport { reactSSRDetect, reactWebDetect };\n//# sourceMappingURL=React.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// Tested with react-native 0.17.7\nfunction reactNativeDetect() {\n    return (typeof navigator !== 'undefined' &&\n        typeof navigator.product !== 'undefined' &&\n        navigator.product === 'ReactNative');\n}\n\nexport { reactNativeDetect };\n//# sourceMappingURL=ReactNative.mjs.map\n","import { windowExists, keyPrefixMatch, processExists } from './helpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// Tested with svelte 3.59\nfunction svelteWebDetect() {\n    return windowExists() && keyPrefixMatch(window, '__SVELTE');\n}\nfunction svelteSSRDetect() {\n    return (processExists() &&\n        typeof process.env !== 'undefined' &&\n        !!Object.keys(process.env).find(key => key.includes('svelte')));\n}\n\nexport { svelteSSRDetect, svelteWebDetect };\n//# sourceMappingURL=Svelte.mjs.map\n","import { windowExists, keyPrefixMatch, globalExists } from './helpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// Tested with vue 3.3.2\nfunction vueWebDetect() {\n    return windowExists() && keyPrefixMatch(window, '__VUE');\n}\nfunction vueSSRDetect() {\n    return globalExists() && keyPrefixMatch(global, '__VUE');\n}\n\nexport { vueSSRDetect, vueWebDetect };\n//# sourceMappingURL=Vue.mjs.map\n","import { windowExists } from './helpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nfunction webDetect() {\n    return windowExists();\n}\n\nexport { webDetect };\n//# sourceMappingURL=Web.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst globalExists = () => {\n    return typeof global !== 'undefined';\n};\nconst globalThisExists = () => {\n    return typeof globalThis !== 'undefined';\n};\nconst windowExists = () => {\n    return typeof window !== 'undefined';\n};\nconst documentExists = () => {\n    return typeof document !== 'undefined';\n};\nconst processExists = () => {\n    return typeof process !== 'undefined';\n};\nconst keyPrefixMatch = (object, prefix) => {\n    return !!Object.keys(object).find(key => key.startsWith(prefix));\n};\n\nexport { documentExists, globalExists, globalThisExists, keyPrefixMatch, processExists, windowExists };\n//# sourceMappingURL=helpers.mjs.map\n","import { Framework } from '../types.mjs';\nimport { reactWebDetect, reactSSRDetect } from './React.mjs';\nimport { vueWebDetect, vueSSRDetect } from './Vue.mjs';\nimport { svelteWebDetect, svelteSSRDetect } from './Svelte.mjs';\nimport { nextWebDetect, nextSSRDetect } from './Next.mjs';\nimport { nuxtWebDetect, nuxtSSRDetect } from './Nuxt.mjs';\nimport { angularWebDetect, angularSSRDetect } from './Angular.mjs';\nimport { reactNativeDetect } from './ReactNative.mjs';\nimport { expoDetect } from './Expo.mjs';\nimport { webDetect } from './Web.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// These are in the order of detection where when both are detectable, the early Framework will be reported\nconst detectionMap = [\n    // First, detect mobile\n    { platform: Framework.Expo, detectionMethod: expoDetect },\n    { platform: Framework.ReactNative, detectionMethod: reactNativeDetect },\n    // Next, detect web frameworks\n    { platform: Framework.NextJs, detectionMethod: nextWebDetect },\n    { platform: Framework.Nuxt, detectionMethod: nuxtWebDetect },\n    { platform: Framework.Angular, detectionMethod: angularWebDetect },\n    { platform: Framework.React, detectionMethod: reactWebDetect },\n    { platform: Framework.VueJs, detectionMethod: vueWebDetect },\n    { platform: Framework.Svelte, detectionMethod: svelteWebDetect },\n    { platform: Framework.WebUnknown, detectionMethod: webDetect },\n    // Last, detect ssr frameworks\n    { platform: Framework.NextJsSSR, detectionMethod: nextSSRDetect },\n    { platform: Framework.NuxtSSR, detectionMethod: nuxtSSRDetect },\n    { platform: Framework.ReactSSR, detectionMethod: reactSSRDetect },\n    { platform: Framework.VueJsSSR, detectionMethod: vueSSRDetect },\n    { platform: Framework.AngularSSR, detectionMethod: angularSSRDetect },\n    { platform: Framework.SvelteSSR, detectionMethod: svelteSSRDetect },\n];\nfunction detect() {\n    return (detectionMap.find(detectionEntry => detectionEntry.detectionMethod())\n        ?.platform || Framework.ServerSideUnknown);\n}\n\nexport { detect };\n//# sourceMappingURL=index.mjs.map\n","import { Framework } from './types.mjs';\nimport { version } from './version.mjs';\nimport { detectFramework, observeFrameworkChanges } from './detectFramework.mjs';\nimport { getCustomUserAgent } from './customUserAgent.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst BASE_USER_AGENT = `aws-amplify`;\n/** Sanitize Amplify version string be removing special character + and character post the special character  */\nconst sanitizeAmplifyVersion = (amplifyVersion) => amplifyVersion.replace(/\\+.*/, '');\nclass PlatformBuilder {\n    constructor() {\n        this.userAgent = `${BASE_USER_AGENT}/${sanitizeAmplifyVersion(version)}`;\n    }\n    get framework() {\n        return detectFramework();\n    }\n    get isReactNative() {\n        return (this.framework === Framework.ReactNative ||\n            this.framework === Framework.Expo);\n    }\n    observeFrameworkChanges(fcn) {\n        observeFrameworkChanges(fcn);\n    }\n}\nconst Platform = new PlatformBuilder();\nconst getAmplifyUserAgentObject = ({ category, action, } = {}) => {\n    const userAgent = [\n        [BASE_USER_AGENT, sanitizeAmplifyVersion(version)],\n    ];\n    if (category) {\n        userAgent.push([category, action]);\n    }\n    userAgent.push(['framework', detectFramework()]);\n    if (category && action) {\n        const customState = getCustomUserAgent(category, action);\n        if (customState) {\n            customState.forEach(state => {\n                userAgent.push(state);\n            });\n        }\n    }\n    return userAgent;\n};\nconst getAmplifyUserAgent = (customUserAgentDetails) => {\n    const userAgent = getAmplifyUserAgentObject(customUserAgentDetails);\n    const userAgentString = userAgent\n        .map(([agentKey, agentValue]) => agentKey && agentValue ? `${agentKey}/${agentValue}` : agentKey)\n        .join(' ');\n    return userAgentString;\n};\n\nexport { Platform, getAmplifyUserAgent, getAmplifyUserAgentObject, sanitizeAmplifyVersion };\n//# sourceMappingURL=index.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nvar Framework;\n(function (Framework) {\n    // < 100 - Web frameworks\n    Framework[\"WebUnknown\"] = \"0\";\n    Framework[\"React\"] = \"1\";\n    Framework[\"NextJs\"] = \"2\";\n    Framework[\"Angular\"] = \"3\";\n    Framework[\"VueJs\"] = \"4\";\n    Framework[\"Nuxt\"] = \"5\";\n    Framework[\"Svelte\"] = \"6\";\n    // 100s - Server side frameworks\n    Framework[\"ServerSideUnknown\"] = \"100\";\n    Framework[\"ReactSSR\"] = \"101\";\n    Framework[\"NextJsSSR\"] = \"102\";\n    Framework[\"AngularSSR\"] = \"103\";\n    Framework[\"VueJsSSR\"] = \"104\";\n    Framework[\"NuxtSSR\"] = \"105\";\n    Framework[\"SvelteSSR\"] = \"106\";\n    // 200s - Mobile framework\n    Framework[\"ReactNative\"] = \"201\";\n    Framework[\"Expo\"] = \"202\";\n})(Framework || (Framework = {}));\nvar Category;\n(function (Category) {\n    Category[\"AI\"] = \"ai\";\n    Category[\"API\"] = \"api\";\n    Category[\"Auth\"] = \"auth\";\n    Category[\"Analytics\"] = \"analytics\";\n    Category[\"DataStore\"] = \"datastore\";\n    Category[\"Geo\"] = \"geo\";\n    Category[\"InAppMessaging\"] = \"inappmessaging\";\n    Category[\"Interactions\"] = \"interactions\";\n    Category[\"Predictions\"] = \"predictions\";\n    Category[\"PubSub\"] = \"pubsub\";\n    Category[\"PushNotification\"] = \"pushnotification\";\n    Category[\"Storage\"] = \"storage\";\n})(Category || (Category = {}));\nvar AiAction;\n(function (AiAction) {\n    AiAction[\"CreateConversation\"] = \"1\";\n    AiAction[\"GetConversation\"] = \"2\";\n    AiAction[\"ListConversations\"] = \"3\";\n    AiAction[\"DeleteConversation\"] = \"4\";\n    AiAction[\"SendMessage\"] = \"5\";\n    AiAction[\"ListMessages\"] = \"6\";\n    AiAction[\"OnMessage\"] = \"7\";\n    AiAction[\"Generation\"] = \"8\";\n    AiAction[\"UpdateConversation\"] = \"9\";\n})(AiAction || (AiAction = {}));\nvar AnalyticsAction;\n(function (AnalyticsAction) {\n    AnalyticsAction[\"Record\"] = \"1\";\n    AnalyticsAction[\"IdentifyUser\"] = \"2\";\n})(AnalyticsAction || (AnalyticsAction = {}));\nvar ApiAction;\n(function (ApiAction) {\n    ApiAction[\"GraphQl\"] = \"1\";\n    ApiAction[\"Get\"] = \"2\";\n    ApiAction[\"Post\"] = \"3\";\n    ApiAction[\"Put\"] = \"4\";\n    ApiAction[\"Patch\"] = \"5\";\n    ApiAction[\"Del\"] = \"6\";\n    ApiAction[\"Head\"] = \"7\";\n})(ApiAction || (ApiAction = {}));\nvar AuthAction;\n(function (AuthAction) {\n    AuthAction[\"SignUp\"] = \"1\";\n    AuthAction[\"ConfirmSignUp\"] = \"2\";\n    AuthAction[\"ResendSignUpCode\"] = \"3\";\n    AuthAction[\"SignIn\"] = \"4\";\n    AuthAction[\"FetchMFAPreference\"] = \"6\";\n    AuthAction[\"UpdateMFAPreference\"] = \"7\";\n    AuthAction[\"SetUpTOTP\"] = \"10\";\n    AuthAction[\"VerifyTOTPSetup\"] = \"11\";\n    AuthAction[\"ConfirmSignIn\"] = \"12\";\n    AuthAction[\"DeleteUserAttributes\"] = \"15\";\n    AuthAction[\"DeleteUser\"] = \"16\";\n    AuthAction[\"UpdateUserAttributes\"] = \"17\";\n    AuthAction[\"FetchUserAttributes\"] = \"18\";\n    AuthAction[\"ConfirmUserAttribute\"] = \"22\";\n    AuthAction[\"SignOut\"] = \"26\";\n    AuthAction[\"UpdatePassword\"] = \"27\";\n    AuthAction[\"ResetPassword\"] = \"28\";\n    AuthAction[\"ConfirmResetPassword\"] = \"29\";\n    AuthAction[\"FederatedSignIn\"] = \"30\";\n    AuthAction[\"RememberDevice\"] = \"32\";\n    AuthAction[\"ForgetDevice\"] = \"33\";\n    AuthAction[\"FetchDevices\"] = \"34\";\n    AuthAction[\"SendUserAttributeVerificationCode\"] = \"35\";\n    AuthAction[\"SignInWithRedirect\"] = \"36\";\n    AuthAction[\"StartWebAuthnRegistration\"] = \"37\";\n    AuthAction[\"CompleteWebAuthnRegistration\"] = \"38\";\n    AuthAction[\"ListWebAuthnCredentials\"] = \"39\";\n    AuthAction[\"DeleteWebAuthnCredential\"] = \"40\";\n})(AuthAction || (AuthAction = {}));\nvar DataStoreAction;\n(function (DataStoreAction) {\n    DataStoreAction[\"Subscribe\"] = \"1\";\n    DataStoreAction[\"GraphQl\"] = \"2\";\n})(DataStoreAction || (DataStoreAction = {}));\nvar GeoAction;\n(function (GeoAction) {\n    GeoAction[\"SearchByText\"] = \"0\";\n    GeoAction[\"SearchByCoordinates\"] = \"1\";\n    GeoAction[\"SearchForSuggestions\"] = \"2\";\n    GeoAction[\"SearchByPlaceId\"] = \"3\";\n    GeoAction[\"SaveGeofences\"] = \"4\";\n    GeoAction[\"GetGeofence\"] = \"5\";\n    GeoAction[\"ListGeofences\"] = \"6\";\n    GeoAction[\"DeleteGeofences\"] = \"7\";\n})(GeoAction || (GeoAction = {}));\nvar InAppMessagingAction;\n(function (InAppMessagingAction) {\n    InAppMessagingAction[\"SyncMessages\"] = \"1\";\n    InAppMessagingAction[\"IdentifyUser\"] = \"2\";\n    InAppMessagingAction[\"NotifyMessageInteraction\"] = \"3\";\n})(InAppMessagingAction || (InAppMessagingAction = {}));\nvar InteractionsAction;\n(function (InteractionsAction) {\n    InteractionsAction[\"None\"] = \"0\";\n})(InteractionsAction || (InteractionsAction = {}));\nvar PredictionsAction;\n(function (PredictionsAction) {\n    PredictionsAction[\"Convert\"] = \"1\";\n    PredictionsAction[\"Identify\"] = \"2\";\n    PredictionsAction[\"Interpret\"] = \"3\";\n})(PredictionsAction || (PredictionsAction = {}));\nvar PubSubAction;\n(function (PubSubAction) {\n    PubSubAction[\"Subscribe\"] = \"1\";\n})(PubSubAction || (PubSubAction = {}));\nvar PushNotificationAction;\n(function (PushNotificationAction) {\n    PushNotificationAction[\"InitializePushNotifications\"] = \"1\";\n    PushNotificationAction[\"IdentifyUser\"] = \"2\";\n})(PushNotificationAction || (PushNotificationAction = {}));\nvar StorageAction;\n(function (StorageAction) {\n    StorageAction[\"UploadData\"] = \"1\";\n    StorageAction[\"DownloadData\"] = \"2\";\n    StorageAction[\"List\"] = \"3\";\n    StorageAction[\"Copy\"] = \"4\";\n    StorageAction[\"Remove\"] = \"5\";\n    StorageAction[\"GetProperties\"] = \"6\";\n    StorageAction[\"GetUrl\"] = \"7\";\n    StorageAction[\"GetDataAccess\"] = \"8\";\n    StorageAction[\"ListCallerAccessGrants\"] = \"9\";\n})(StorageAction || (StorageAction = {}));\n\nexport { AiAction, AnalyticsAction, ApiAction, AuthAction, Category, DataStoreAction, Framework, GeoAction, InAppMessagingAction, InteractionsAction, PredictionsAction, PubSubAction, PushNotificationAction, StorageAction };\n//# sourceMappingURL=types.mjs.map\n","// generated by genversion\nconst version = '6.10.2';\n\nexport { version };\n//# sourceMappingURL=version.mjs.map\n","import { from, Observable } from 'rxjs';\nimport '../utils/getClientInfo/getClientInfo.mjs';\nimport { isWebWorker } from '../utils/isWebWorker.mjs';\nimport '../utils/retry/retry.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nclass Reachability {\n    networkMonitor(_) {\n        const globalObj = isWebWorker()\n            ? self\n            : typeof window !== 'undefined' && window;\n        if (!globalObj) {\n            return from([{ online: true }]);\n        }\n        return new Observable(observer => {\n            observer.next({ online: globalObj.navigator.onLine });\n            const notifyOnline = () => {\n                observer.next({ online: true });\n            };\n            const notifyOffline = () => {\n                observer.next({ online: false });\n            };\n            globalObj.addEventListener('online', notifyOnline);\n            globalObj.addEventListener('offline', notifyOffline);\n            Reachability._observers.push(observer);\n            return () => {\n                globalObj.removeEventListener('online', notifyOnline);\n                globalObj.removeEventListener('offline', notifyOffline);\n                Reachability._observers = Reachability._observers.filter(_observer => _observer !== observer);\n            };\n        });\n    }\n    // expose observers to simulate offline mode for integration testing\n    static _observerOverride(status) {\n        for (const observer of this._observers) {\n            if (observer.closed) {\n                this._observers = this._observers.filter(_observer => _observer !== observer);\n                continue;\n            }\n            observer?.next && observer.next(status);\n        }\n    }\n}\nReachability._observers = [];\n\nexport { Reachability };\n//# sourceMappingURL=Reachability.mjs.map\n","import { retryMiddlewareFactory } from '../middleware/retry/middleware.mjs';\nimport '../../utils/getClientInfo/getClientInfo.mjs';\nimport '../../utils/retry/retry.mjs';\nimport '../../types/errors.mjs';\nimport { signingMiddlewareFactory } from '../middleware/signing/middleware.mjs';\nimport { userAgentMiddlewareFactory } from '../middleware/userAgent/middleware.mjs';\nimport { composeTransferHandler } from '../internal/composeTransferHandler.mjs';\nimport { fetchTransferHandler } from './fetch.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst authenticatedHandler = composeTransferHandler(fetchTransferHandler, [\n    userAgentMiddlewareFactory,\n    retryMiddlewareFactory,\n    signingMiddlewareFactory,\n]);\n\nexport { authenticatedHandler };\n//# sourceMappingURL=authenticated.mjs.map\n","import { AmplifyError } from '../../errors/AmplifyError.mjs';\nimport { AmplifyErrorCode } from '../../types/errors.mjs';\nimport '../../errors/errorHelpers.mjs';\nimport { withMemoization } from '../utils/memoization.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst shouldSendBody = (method) => !['HEAD', 'GET', 'DELETE'].includes(method.toUpperCase());\n// TODO[AllanZhengYP]: we need to provide isCanceledError utility\nconst fetchTransferHandler = async ({ url, method, headers, body }, { abortSignal, cache, withCrossDomainCredentials }) => {\n    let resp;\n    try {\n        resp = await fetch(url, {\n            method,\n            headers,\n            body: shouldSendBody(method) ? body : undefined,\n            signal: abortSignal,\n            cache,\n            credentials: withCrossDomainCredentials ? 'include' : 'same-origin',\n        });\n    }\n    catch (e) {\n        if (e instanceof TypeError) {\n            throw new AmplifyError({\n                name: AmplifyErrorCode.NetworkError,\n                message: 'A network error has occurred.',\n                underlyingError: e,\n            });\n        }\n        throw e;\n    }\n    const responseHeaders = {};\n    resp.headers?.forEach((value, key) => {\n        responseHeaders[key.toLowerCase()] = value;\n    });\n    const httpResponse = {\n        statusCode: resp.status,\n        headers: responseHeaders,\n        body: null,\n    };\n    // resp.body is a ReadableStream according to Fetch API spec, but React Native\n    // does not implement it.\n    const bodyWithMixin = Object.assign(resp.body ?? {}, {\n        text: withMemoization(() => resp.text()),\n        blob: withMemoization(() => resp.blob()),\n        json: withMemoization(() => resp.json()),\n    });\n    return {\n        ...httpResponse,\n        body: bodyWithMixin,\n    };\n};\n\nexport { fetchTransferHandler };\n//# sourceMappingURL=fetch.mjs.map\n","import { retryMiddlewareFactory } from '../middleware/retry/middleware.mjs';\nimport '../../utils/getClientInfo/getClientInfo.mjs';\nimport '../../utils/retry/retry.mjs';\nimport '../../types/errors.mjs';\nimport { userAgentMiddlewareFactory } from '../middleware/userAgent/middleware.mjs';\nimport { composeTransferHandler } from '../internal/composeTransferHandler.mjs';\nimport { fetchTransferHandler } from './fetch.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst unauthenticatedHandler = composeTransferHandler(fetchTransferHandler, [userAgentMiddlewareFactory, retryMiddlewareFactory]);\n\nexport { unauthenticatedHandler };\n//# sourceMappingURL=unauthenticated.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Compose a transfer handler with a core transfer handler and a list of middleware.\n * @param coreHandler Core transfer handler\n * @param middleware\tList of middleware\n * @returns A transfer handler whose option type is the union of the core\n * \ttransfer handler's option type and the middleware's option type.\n * @internal\n */\nconst composeTransferHandler = (coreHandler, middleware) => (request, options) => {\n    const context = {};\n    let composedHandler = (composeHandlerRequest) => coreHandler(composeHandlerRequest, options);\n    for (let i = middleware.length - 1; i >= 0; i--) {\n        const m = middleware[i];\n        const resolvedMiddleware = m(options);\n        composedHandler = resolvedMiddleware(composedHandler, context);\n    }\n    return composedHandler(request);\n};\n\nexport { composeTransferHandler };\n//# sourceMappingURL=composeTransferHandler.mjs.map\n","import { AmplifyErrorCode } from '../../../types/errors.mjs';\nimport { isClockSkewError } from './isClockSkewError.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Get retry decider function\n * @param errorParser Function to load JavaScript error from HTTP response\n */\nconst getRetryDecider = (errorParser) => async (response, error) => {\n    const parsedError = error ??\n        (await errorParser(response)) ??\n        undefined;\n    const errorCode = parsedError?.code || parsedError?.name;\n    const statusCode = response?.statusCode;\n    const isRetryable = isConnectionError(error) ||\n        isThrottlingError(statusCode, errorCode) ||\n        isClockSkewError(errorCode) ||\n        isServerSideError(statusCode, errorCode);\n    return {\n        retryable: isRetryable,\n    };\n};\n// reference: https://github.com/aws/aws-sdk-js-v3/blob/ab0e7be36e7e7f8a0c04834357aaad643c7912c3/packages/service-error-classification/src/constants.ts#L22-L37\nconst THROTTLING_ERROR_CODES = [\n    'BandwidthLimitExceeded',\n    'EC2ThrottledException',\n    'LimitExceededException',\n    'PriorRequestNotComplete',\n    'ProvisionedThroughputExceededException',\n    'RequestLimitExceeded',\n    'RequestThrottled',\n    'RequestThrottledException',\n    'SlowDown',\n    'ThrottledException',\n    'Throttling',\n    'ThrottlingException',\n    'TooManyRequestsException',\n];\nconst TIMEOUT_ERROR_CODES = [\n    'TimeoutError',\n    'RequestTimeout',\n    'RequestTimeoutException',\n];\nconst isThrottlingError = (statusCode, errorCode) => statusCode === 429 ||\n    (!!errorCode && THROTTLING_ERROR_CODES.includes(errorCode));\nconst isConnectionError = (error) => [\n    AmplifyErrorCode.NetworkError,\n    // TODO(vNext): unify the error code `ERR_NETWORK` used by the Storage XHR handler\n    'ERR_NETWORK',\n].includes(error?.name);\nconst isServerSideError = (statusCode, errorCode) => (!!statusCode && [500, 502, 503, 504].includes(statusCode)) ||\n    (!!errorCode && TIMEOUT_ERROR_CODES.includes(errorCode));\n\nexport { getRetryDecider };\n//# sourceMappingURL=defaultRetryDecider.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// via https://github.com/aws/aws-sdk-js-v3/blob/ab0e7be36e7e7f8a0c04834357aaad643c7912c3/packages/service-error-classification/src/constants.ts#L8\nconst CLOCK_SKEW_ERROR_CODES = [\n    'AuthFailure',\n    'InvalidSignatureException',\n    'RequestExpired',\n    'RequestInTheFuture',\n    'RequestTimeTooSkewed',\n    'SignatureDoesNotMatch',\n    'BadRequestException', // API Gateway\n];\n/**\n * Given an error code, returns true if it is related to a clock skew error.\n *\n * @param errorCode String representation of some error.\n * @returns True if given error is present in `CLOCK_SKEW_ERROR_CODES`, false otherwise.\n *\n * @internal\n */\nconst isClockSkewError = (errorCode) => !!errorCode && CLOCK_SKEW_ERROR_CODES.includes(errorCode);\n\nexport { isClockSkewError };\n//# sourceMappingURL=isClockSkewError.mjs.map\n","import '../../../utils/getClientInfo/getClientInfo.mjs';\nimport { jitteredBackoff as jitteredBackoff$1 } from '../../../utils/retry/jitteredBackoff.mjs';\nimport '../../../utils/retry/retry.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// TODO: [v6] The separate retry utility is used by Data packages now and will replaced by retry middleware.\nconst DEFAULT_MAX_DELAY_MS = 5 * 60 * 1000;\nconst jitteredBackoff = attempt => {\n    const delayFunction = jitteredBackoff$1(DEFAULT_MAX_DELAY_MS);\n    const delay = delayFunction(attempt);\n    // The delayFunction returns false when the delay is greater than the max delay(5 mins).\n    // In this case, the retry middleware will delay 5 mins instead, as a ceiling of the delay.\n    return delay === false ? DEFAULT_MAX_DELAY_MS : delay;\n};\n\nexport { jitteredBackoff };\n//# sourceMappingURL=jitteredBackoff.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst DEFAULT_RETRY_ATTEMPTS = 3;\n/**\n * Retry middleware\n */\nconst retryMiddlewareFactory = ({ maxAttempts = DEFAULT_RETRY_ATTEMPTS, retryDecider, computeDelay, abortSignal, }) => {\n    if (maxAttempts < 1) {\n        throw new Error('maxAttempts must be greater than 0');\n    }\n    return (next, context) => async function retryMiddleware(request) {\n        let error;\n        let attemptsCount = context.attemptsCount ?? 0;\n        let response;\n        // When retry is not needed or max attempts is reached, either error or response will be set. This function handles either cases.\n        const handleTerminalErrorOrResponse = () => {\n            if (response) {\n                addOrIncrementMetadataAttempts(response, attemptsCount);\n                return response;\n            }\n            else {\n                addOrIncrementMetadataAttempts(error, attemptsCount);\n                throw error;\n            }\n        };\n        while (!abortSignal?.aborted && attemptsCount < maxAttempts) {\n            try {\n                response = await next(request);\n                error = undefined;\n            }\n            catch (e) {\n                error = e;\n                response = undefined;\n            }\n            // context.attemptsCount may be updated after calling next handler which may retry the request by itself.\n            attemptsCount =\n                (context.attemptsCount ?? 0) > attemptsCount\n                    ? (context.attemptsCount ?? 0)\n                    : attemptsCount + 1;\n            context.attemptsCount = attemptsCount;\n            const { isCredentialsExpiredError, retryable } = await retryDecider(response, error, context);\n            if (retryable) {\n                // Setting isCredentialsInvalid flag to notify signing middleware to forceRefresh credentials provider.\n                context.isCredentialsExpired = !!isCredentialsExpiredError;\n                if (!abortSignal?.aborted && attemptsCount < maxAttempts) {\n                    // prevent sleep for last attempt or cancelled request;\n                    const delay = computeDelay(attemptsCount);\n                    await cancellableSleep(delay, abortSignal);\n                }\n                continue;\n            }\n            else {\n                return handleTerminalErrorOrResponse();\n            }\n        }\n        if (abortSignal?.aborted) {\n            throw new Error('Request aborted.');\n        }\n        else {\n            return handleTerminalErrorOrResponse();\n        }\n    };\n};\nconst cancellableSleep = (timeoutMs, abortSignal) => {\n    if (abortSignal?.aborted) {\n        return Promise.resolve();\n    }\n    let timeoutId;\n    let sleepPromiseResolveFn;\n    const sleepPromise = new Promise(resolve => {\n        sleepPromiseResolveFn = resolve;\n        timeoutId = setTimeout(resolve, timeoutMs);\n    });\n    abortSignal?.addEventListener('abort', function cancelSleep(_) {\n        clearTimeout(timeoutId);\n        abortSignal?.removeEventListener('abort', cancelSleep);\n        sleepPromiseResolveFn();\n    });\n    return sleepPromise;\n};\nconst addOrIncrementMetadataAttempts = (nextHandlerOutput, attempts) => {\n    if (Object.prototype.toString.call(nextHandlerOutput) !== '[object Object]') {\n        return;\n    }\n    nextHandlerOutput.$metadata = {\n        ...(nextHandlerOutput.$metadata ?? {}),\n        attempts,\n    };\n};\n\nexport { retryMiddlewareFactory };\n//# sourceMappingURL=middleware.mjs.map\n","import { signRequest } from './signer/signatureV4/signRequest.mjs';\nimport '@aws-crypto/sha256-js';\nimport '@smithy/util-hex-encoding';\nimport { getSkewCorrectedDate } from './utils/getSkewCorrectedDate.mjs';\nimport { getUpdatedSystemClockOffset } from './utils/getUpdatedSystemClockOffset.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Middleware that SigV4 signs request with AWS credentials, and correct system clock offset.\n * This middleware is expected to be placed after retry middleware.\n */\nconst signingMiddlewareFactory = ({ credentials, region, service, uriEscapePath = true, }) => {\n    let currentSystemClockOffset;\n    return (next, context) => async function signingMiddleware(request) {\n        currentSystemClockOffset = currentSystemClockOffset ?? 0;\n        const signRequestOptions = {\n            credentials: typeof credentials === 'function'\n                ? await credentials({\n                    forceRefresh: !!context?.isCredentialsExpired,\n                })\n                : credentials,\n            signingDate: getSkewCorrectedDate(currentSystemClockOffset),\n            signingRegion: region,\n            signingService: service,\n            uriEscapePath,\n        };\n        const signedRequest = await signRequest(request, signRequestOptions);\n        const response = await next(signedRequest);\n        // Update system clock offset if response contains date header, regardless of the status code.\n        // non-2xx response will still be returned from next handler instead of thrown, because it's\n        // only thrown by the retry middleware.\n        const dateString = getDateHeader(response);\n        if (dateString) {\n            currentSystemClockOffset = getUpdatedSystemClockOffset(Date.parse(dateString), currentSystemClockOffset);\n        }\n        return response;\n    };\n};\nconst getDateHeader = ({ headers } = {}) => headers?.date ?? headers?.Date ?? headers?.['x-amz-date'];\n\nexport { signingMiddlewareFactory };\n//# sourceMappingURL=middleware.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// query params\nconst ALGORITHM_QUERY_PARAM = 'X-Amz-Algorithm';\nconst AMZ_DATE_QUERY_PARAM = 'X-Amz-Date';\nconst CREDENTIAL_QUERY_PARAM = 'X-Amz-Credential';\nconst EXPIRES_QUERY_PARAM = 'X-Amz-Expires';\nconst REGION_SET_PARAM = 'X-Amz-Region-Set';\nconst SIGNATURE_QUERY_PARAM = 'X-Amz-Signature';\nconst SIGNED_HEADERS_QUERY_PARAM = 'X-Amz-SignedHeaders';\nconst TOKEN_QUERY_PARAM = 'X-Amz-Security-Token';\n// headers\nconst AUTH_HEADER = 'authorization';\nconst HOST_HEADER = 'host';\nconst AMZ_DATE_HEADER = AMZ_DATE_QUERY_PARAM.toLowerCase();\nconst TOKEN_HEADER = TOKEN_QUERY_PARAM.toLowerCase();\n// identifiers\nconst KEY_TYPE_IDENTIFIER = 'aws4_request';\nconst SHA256_ALGORITHM_IDENTIFIER = 'AWS4-HMAC-SHA256';\nconst SIGNATURE_IDENTIFIER = 'AWS4';\n// preset values\nconst EMPTY_HASH = 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855';\nconst UNSIGNED_PAYLOAD = 'UNSIGNED-PAYLOAD';\n\nexport { ALGORITHM_QUERY_PARAM, AMZ_DATE_HEADER, AMZ_DATE_QUERY_PARAM, AUTH_HEADER, CREDENTIAL_QUERY_PARAM, EMPTY_HASH, EXPIRES_QUERY_PARAM, HOST_HEADER, KEY_TYPE_IDENTIFIER, REGION_SET_PARAM, SHA256_ALGORITHM_IDENTIFIER, SIGNATURE_IDENTIFIER, SIGNATURE_QUERY_PARAM, SIGNED_HEADERS_QUERY_PARAM, TOKEN_HEADER, TOKEN_QUERY_PARAM, UNSIGNED_PAYLOAD };\n//# sourceMappingURL=constants.mjs.map\n","import { getSignedHeaders } from './utils/getSignedHeaders.mjs';\nimport { getSigningValues } from './utils/getSigningValues.mjs';\nimport { HOST_HEADER, AMZ_DATE_HEADER, TOKEN_HEADER, AUTH_HEADER, SHA256_ALGORITHM_IDENTIFIER } from './constants.mjs';\nimport { getSignature } from './utils/getSignature.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Given a `HttpRequest`, returns a Signature Version 4 signed `HttpRequest`.\n *\n * @param request `HttpRequest` to be signed.\n * @param signRequestOptions `SignRequestOptions` object containing values used to construct the signature.\n * @returns A `HttpRequest` with authentication headers which can grant temporary access to AWS resources.\n */\nconst signRequest = (request, options) => {\n    const signingValues = getSigningValues(options);\n    const { accessKeyId, credentialScope, longDate, sessionToken } = signingValues;\n    // create the request to sign\n    const headers = { ...request.headers };\n    headers[HOST_HEADER] = request.url.host;\n    headers[AMZ_DATE_HEADER] = longDate;\n    if (sessionToken) {\n        headers[TOKEN_HEADER] = sessionToken;\n    }\n    const requestToSign = { ...request, headers };\n    // calculate and add the signature to the request\n    const signature = getSignature(requestToSign, signingValues);\n    const credentialEntry = `Credential=${accessKeyId}/${credentialScope}`;\n    const signedHeadersEntry = `SignedHeaders=${getSignedHeaders(headers)}`;\n    const signatureEntry = `Signature=${signature}`;\n    headers[AUTH_HEADER] =\n        `${SHA256_ALGORITHM_IDENTIFIER} ${credentialEntry}, ${signedHeadersEntry}, ${signatureEntry}`;\n    return requestToSign;\n};\n\nexport { signRequest };\n//# sourceMappingURL=signRequest.mjs.map\n","import { Sha256 } from '@aws-crypto/sha256-js';\nimport { toHex } from '@smithy/util-hex-encoding';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// TODO: V6 update to different crypto dependency?\n/**\n * Returns the hashed data a `Uint8Array`.\n *\n * @param key `SourceData` to be used as hashing key.\n * @param data Hashable `SourceData`.\n * @returns `Uint8Array` created from the data as input to a hash function.\n */\nconst getHashedData = (key, data) => {\n    const sha256 = new Sha256(key ?? undefined);\n    sha256.update(data);\n    // TODO: V6 flip to async digest\n    const hashedData = sha256.digestSync();\n    return hashedData;\n};\n/**\n * Returns the hashed data as a hex string.\n *\n * @param key `SourceData` to be used as hashing key.\n * @param data Hashable `SourceData`.\n * @returns String using lowercase hexadecimal characters created from the data as input to a hash function.\n *\n * @internal\n */\nconst getHashedDataAsHex = (key, data) => {\n    const hashedData = getHashedData(key, data);\n    return toHex(hashedData);\n};\n\nexport { getHashedData, getHashedDataAsHex };\n//# sourceMappingURL=dataHashHelpers.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Returns canonical headers.\n *\n * @param headers Headers from the request.\n * @returns Request headers that will be signed, and their values, separated by newline characters. Header names must\n * use lowercase characters, must appear in alphabetical order, and must be followed by a colon (:). For the values,\n * trim any leading or trailing spaces, convert sequential spaces to a single space, and separate the values\n * for a multi-value header using commas.\n *\n * @internal\n */\nconst getCanonicalHeaders = (headers) => Object.entries(headers)\n    .map(([key, value]) => ({\n    key: key.toLowerCase(),\n    value: value?.trim().replace(/\\s+/g, ' ') ?? '',\n}))\n    .sort((a, b) => (a.key < b.key ? -1 : 1))\n    .map(entry => `${entry.key}:${entry.value}\\n`)\n    .join('');\n\nexport { getCanonicalHeaders };\n//# sourceMappingURL=getCanonicalHeaders.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Returns a canonical query string.\n *\n * @param searchParams `searchParams` from the request url.\n * @returns URL-encoded query string parameters, separated by ampersands (&). Percent-encode reserved characters,\n * including the space character. Encode names and values separately. If there are empty parameters, append the equals\n * sign to the parameter name before encoding. After encoding, sort the parameters alphabetically by key name. If there\n * is no query string, use an empty string (\"\").\n *\n * @internal\n */\nconst getCanonicalQueryString = (searchParams) => Array.from(searchParams)\n    .sort(([keyA, valA], [keyB, valB]) => {\n    if (keyA === keyB) {\n        return valA < valB ? -1 : 1;\n    }\n    return keyA < keyB ? -1 : 1;\n})\n    .map(([key, val]) => `${escapeUri(key)}=${escapeUri(val)}`)\n    .join('&');\nconst escapeUri = (uri) => encodeURIComponent(uri).replace(/[!'()*]/g, hexEncode);\nconst hexEncode = (c) => `%${c.charCodeAt(0).toString(16).toUpperCase()}`;\n\nexport { getCanonicalQueryString };\n//# sourceMappingURL=getCanonicalQueryString.mjs.map\n","import { getCanonicalHeaders } from './getCanonicalHeaders.mjs';\nimport { getCanonicalQueryString } from './getCanonicalQueryString.mjs';\nimport { getCanonicalUri } from './getCanonicalUri.mjs';\nimport { getHashedPayload } from './getHashedPayload.mjs';\nimport { getSignedHeaders } from './getSignedHeaders.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Returns a canonical request.\n *\n * @param request `HttpRequest` from which to create the canonical request from.\n * @param uriEscapePath Whether to uri encode the path as part of canonical uri. It's used for S3 only where the\n *   pathname is already uri encoded, and the signing process is not expected to uri encode it again. Defaults to true.\n * @returns String created by by concatenating the following strings, separated by newline characters:\n * - HTTPMethod\n * - CanonicalUri\n * - CanonicalQueryString\n * - CanonicalHeaders\n * - SignedHeaders\n * - HashedPayload\n *\n * @internal\n */\nconst getCanonicalRequest = ({ body, headers, method, url }, uriEscapePath = true) => [\n    method,\n    getCanonicalUri(url.pathname, uriEscapePath),\n    getCanonicalQueryString(url.searchParams),\n    getCanonicalHeaders(headers),\n    getSignedHeaders(headers),\n    getHashedPayload(body),\n].join('\\n');\n\nexport { getCanonicalRequest };\n//# sourceMappingURL=getCanonicalRequest.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Returns a canonical uri.\n *\n * @param pathname `pathname` from request url.\n * @param uriEscapePath Whether to uri encode the path as part of canonical uri. It's used for S3 only where the\n *   pathname is already uri encoded, and the signing process is not expected to uri encode it again. Defaults to true.\n * @returns URI-encoded version of the absolute path component URL (everything between the host and the question mark\n * character (?) that starts the query string parameters). If the absolute path is empty, a forward slash character (/).\n *\n * @internal\n */\nconst getCanonicalUri = (pathname, uriEscapePath = true) => pathname\n    ? uriEscapePath\n        ? encodeURIComponent(pathname).replace(/%2F/g, '/')\n        : pathname\n    : '/';\n\nexport { getCanonicalUri };\n//# sourceMappingURL=getCanonicalUri.mjs.map\n","import { KEY_TYPE_IDENTIFIER } from '../constants.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Returns the credential scope which restricts the resulting signature to the specified region and service.\n *\n * @param date Current date in the format 'YYYYMMDD'.\n * @param region AWS region in which the service resides.\n * @param service Service to which the signed request is being sent.\n *\n * @returns  A string representing the credential scope with format 'YYYYMMDD/region/service/aws4_request'.\n *\n * @internal\n */\nconst getCredentialScope = (date, region, service) => `${date}/${region}/${service}/${KEY_TYPE_IDENTIFIER}`;\n\nexport { getCredentialScope };\n//# sourceMappingURL=getCredentialScope.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Returns expected date strings to be used in signing.\n *\n * @param date JavaScript `Date` object.\n * @returns `FormattedDates` object containing the following:\n * - longDate: A date string in 'YYYYMMDDThhmmssZ' format\n * - shortDate: A date string in 'YYYYMMDD' format\n *\n * @internal\n */\nconst getFormattedDates = (date) => {\n    const longDate = date.toISOString().replace(/[:-]|\\.\\d{3}/g, '');\n    return {\n        longDate,\n        shortDate: longDate.slice(0, 8),\n    };\n};\n\nexport { getFormattedDates };\n//# sourceMappingURL=getFormattedDates.mjs.map\n","import { EMPTY_HASH, UNSIGNED_PAYLOAD } from '../constants.mjs';\nimport { getHashedDataAsHex } from './dataHashHelpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Returns the hashed payload.\n *\n * @param body `body` (payload) from the request.\n * @returns String created using the payload in the body of the HTTP request as input to a hash function. This string\n * uses lowercase hexadecimal characters. If the payload is empty, return precalculated result of an empty hash.\n *\n * @internal\n */\nconst getHashedPayload = (body) => {\n    // return precalculated empty hash if body is undefined or null\n    if (body == null) {\n        return EMPTY_HASH;\n    }\n    if (isSourceData(body)) {\n        const hashedData = getHashedDataAsHex(null, body);\n        return hashedData;\n    }\n    // Defined body is not signable. Return unsigned payload which may or may not be accepted by the service.\n    return UNSIGNED_PAYLOAD;\n};\nconst isSourceData = (body) => typeof body === 'string' || ArrayBuffer.isView(body) || isArrayBuffer(body);\nconst isArrayBuffer = (arg) => (typeof ArrayBuffer === 'function' && arg instanceof ArrayBuffer) ||\n    Object.prototype.toString.call(arg) === '[object ArrayBuffer]';\n\nexport { getHashedPayload };\n//# sourceMappingURL=getHashedPayload.mjs.map\n","import { getHashedDataAsHex } from './dataHashHelpers.mjs';\nimport { getCanonicalRequest } from './getCanonicalRequest.mjs';\nimport { getSigningKey } from './getSigningKey.mjs';\nimport { getStringToSign } from './getStringToSign.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Calculates and returns an AWS API Signature.\n * https://docs.aws.amazon.com/IAM/latest/UserGuide/create-signed-request.html\n *\n * @param request `HttpRequest` to be signed.\n * @param signRequestOptions `SignRequestOptions` object containing values used to construct the signature.\n * @returns AWS API Signature to sign a request or url with.\n *\n * @internal\n */\nconst getSignature = (request, { credentialScope, longDate, secretAccessKey, shortDate, signingRegion, signingService, uriEscapePath, }) => {\n    // step 1: create a canonical request\n    const canonicalRequest = getCanonicalRequest(request, uriEscapePath);\n    // step 2: create a hash of the canonical request\n    const hashedRequest = getHashedDataAsHex(null, canonicalRequest);\n    // step 3: create a string to sign\n    const stringToSign = getStringToSign(longDate, credentialScope, hashedRequest);\n    // step 4: calculate the signature\n    const signature = getHashedDataAsHex(getSigningKey(secretAccessKey, shortDate, signingRegion, signingService), stringToSign);\n    return signature;\n};\n\nexport { getSignature };\n//# sourceMappingURL=getSignature.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Returns signed headers.\n *\n * @param headers `headers` from the request.\n * @returns List of headers included in canonical headers, separated by semicolons (;). This indicates which headers\n * are part of the signing process. Header names must use lowercase characters and must appear in alphabetical order.\n *\n * @internal\n */\nconst getSignedHeaders = (headers) => Object.keys(headers)\n    .map(key => key.toLowerCase())\n    .sort()\n    .join(';');\n\nexport { getSignedHeaders };\n//# sourceMappingURL=getSignedHeaders.mjs.map\n","import { KEY_TYPE_IDENTIFIER, SIGNATURE_IDENTIFIER } from '../constants.mjs';\nimport { getHashedData } from './dataHashHelpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Returns a signing key to be used for signing requests.\n *\n * @param secretAccessKey AWS secret access key from credentials.\n * @param date Current date in the format 'YYYYMMDD'.\n * @param region AWS region in which the service resides.\n * @param service Service to which the signed request is being sent.\n *\n * @returns `Uint8Array` calculated from its composite parts.\n *\n * @internal\n */\nconst getSigningKey = (secretAccessKey, date, region, service) => {\n    const key = `${SIGNATURE_IDENTIFIER}${secretAccessKey}`;\n    const dateKey = getHashedData(key, date);\n    const regionKey = getHashedData(dateKey, region);\n    const serviceKey = getHashedData(regionKey, service);\n    const signingKey = getHashedData(serviceKey, KEY_TYPE_IDENTIFIER);\n    return signingKey;\n};\n\nexport { getSigningKey };\n//# sourceMappingURL=getSigningKey.mjs.map\n","import { getCredentialScope } from './getCredentialScope.mjs';\nimport { getFormattedDates } from './getFormattedDates.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Extracts common values used for signing both requests and urls.\n *\n * @param options `SignRequestOptions` object containing values used to construct the signature.\n * @returns Common `SigningValues` used for signing.\n *\n * @internal\n */\nconst getSigningValues = ({ credentials, signingDate = new Date(), signingRegion, signingService, uriEscapePath = true, }) => {\n    // get properties from credentials\n    const { accessKeyId, secretAccessKey, sessionToken } = credentials;\n    // get formatted dates for signing\n    const { longDate, shortDate } = getFormattedDates(signingDate);\n    // copy header and set signing properties\n    const credentialScope = getCredentialScope(shortDate, signingRegion, signingService);\n    return {\n        accessKeyId,\n        credentialScope,\n        longDate,\n        secretAccessKey,\n        sessionToken,\n        shortDate,\n        signingRegion,\n        signingService,\n        uriEscapePath,\n    };\n};\n\nexport { getSigningValues };\n//# sourceMappingURL=getSigningValues.mjs.map\n","import { SHA256_ALGORITHM_IDENTIFIER } from '../constants.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Returns a string to be signed.\n *\n * @param date Current date in the format 'YYYYMMDDThhmmssZ'.\n * @param credentialScope String representing the credential scope with format 'YYYYMMDD/region/service/aws4_request'.\n * @param hashedRequest Hashed canonical request.\n *\n * @returns A string created by by concatenating the following strings, separated by newline characters:\n * - Algorithm\n * - RequestDateTime\n * - CredentialScope\n * - HashedCanonicalRequest\n *\n * @internal\n */\nconst getStringToSign = (date, credentialScope, hashedRequest) => [SHA256_ALGORITHM_IDENTIFIER, date, credentialScope, hashedRequest].join('\\n');\n\nexport { getStringToSign };\n//# sourceMappingURL=getStringToSign.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Returns a `Date` that is corrected for clock skew.\n *\n * @param systemClockOffset The offset of the system clock in milliseconds.\n *\n * @returns `Date` representing the current time adjusted by the system clock offset.\n *\n * @internal\n */\nconst getSkewCorrectedDate = (systemClockOffset) => new Date(Date.now() + systemClockOffset);\n\nexport { getSkewCorrectedDate };\n//# sourceMappingURL=getSkewCorrectedDate.mjs.map\n","import { isClockSkewed } from './isClockSkewed.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Returns the difference between clock time and the current system time if clock is skewed.\n *\n * @param clockTimeInMilliseconds Clock time in milliseconds.\n * @param currentSystemClockOffset Current system clock offset in milliseconds.\n *\n * @internal\n */\nconst getUpdatedSystemClockOffset = (clockTimeInMilliseconds, currentSystemClockOffset) => {\n    if (isClockSkewed(clockTimeInMilliseconds, currentSystemClockOffset)) {\n        return clockTimeInMilliseconds - Date.now();\n    }\n    return currentSystemClockOffset;\n};\n\nexport { getUpdatedSystemClockOffset };\n//# sourceMappingURL=getUpdatedSystemClockOffset.mjs.map\n","import { getSkewCorrectedDate } from './getSkewCorrectedDate.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// 5 mins in milliseconds. Ref: https://github.com/aws/aws-sdk-js-v3/blob/6c0f44fab30a1bb2134af47362a31332abc3666b/packages/middleware-signing/src/utils/isClockSkewed.ts#L10\nconst SKEW_WINDOW = 5 * 60 * 1000;\n/**\n * Checks if the provided date is within the skew window of 5 minutes.\n *\n * @param clockTimeInMilliseconds Time to check for skew in milliseconds.\n * @param clockOffsetInMilliseconds Offset to check clock against in milliseconds.\n *\n * @returns True if skewed. False otherwise.\n *\n * @internal\n */\nconst isClockSkewed = (clockTimeInMilliseconds, clockOffsetInMilliseconds) => Math.abs(getSkewCorrectedDate(clockOffsetInMilliseconds).getTime() -\n    clockTimeInMilliseconds) >= SKEW_WINDOW;\n\nexport { isClockSkewed };\n//# sourceMappingURL=isClockSkewed.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Middleware injects user agent string to specified header(default to 'x-amz-user-agent'),\n * if the header is not set already.\n *\n * TODO: incorporate new user agent design\n */\nconst userAgentMiddlewareFactory = ({ userAgentHeader = 'x-amz-user-agent', userAgentValue = '', }) => next => {\n    return async function userAgentMiddleware(request) {\n        if (userAgentValue.trim().length === 0) {\n            const result = await next(request);\n            return result;\n        }\n        else {\n            const headerName = userAgentHeader.toLowerCase();\n            request.headers[headerName] = request.headers[headerName]\n                ? `${request.headers[headerName]} ${userAgentValue}`\n                : userAgentValue;\n            const response = await next(request);\n            return response;\n        }\n    };\n};\n\nexport { userAgentMiddlewareFactory };\n//# sourceMappingURL=middleware.mjs.map\n","import { parseMetadata } from './responseInfo.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Utility functions for serializing and deserializing of JSON protocol in general(including: REST-JSON, JSON-RPC, etc.)\n */\n/**\n * Error parser for AWS JSON protocol.\n */\nconst parseJsonError = async (response) => {\n    if (!response || response.statusCode < 300) {\n        return;\n    }\n    const body = await parseJsonBody(response);\n    const sanitizeErrorCode = (rawValue) => {\n        const [cleanValue] = rawValue.toString().split(/[,:]+/);\n        if (cleanValue.includes('#')) {\n            return cleanValue.split('#')[1];\n        }\n        return cleanValue;\n    };\n    const code = sanitizeErrorCode(response.headers['x-amzn-errortype'] ??\n        body.code ??\n        body.__type ??\n        'UnknownError');\n    const message = body.message ?? body.Message ?? 'Unknown error';\n    const error = new Error(message);\n    return Object.assign(error, {\n        name: code,\n        $metadata: parseMetadata(response),\n    });\n};\n/**\n * Parse JSON response body to JavaScript object.\n */\nconst parseJsonBody = async (response) => {\n    if (!response.body) {\n        throw new Error('Missing response payload');\n    }\n    const output = await response.body.json();\n    return Object.assign(output, {\n        $metadata: parseMetadata(response),\n    });\n};\n\nexport { parseJsonBody, parseJsonError };\n//# sourceMappingURL=json.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst parseMetadata = (response) => {\n    const { headers, statusCode } = response;\n    return {\n        ...(isMetadataBearer(response) ? response.$metadata : {}),\n        httpStatusCode: statusCode,\n        requestId: headers['x-amzn-requestid'] ??\n            headers['x-amzn-request-id'] ??\n            headers['x-amz-request-id'],\n        extendedRequestId: headers['x-amz-id-2'],\n        cfId: headers['x-amz-cf-id'],\n    };\n};\nconst isMetadataBearer = (response) => typeof response?.$metadata === 'object';\n\nexport { parseMetadata };\n//# sourceMappingURL=responseInfo.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Cache the payload of a response body. It allows multiple calls to the body,\n * for example, when reading the body in both retry decider and error deserializer.\n * Caching body is allowed here because we call the body accessor(blob(), json(),\n * etc.) when body is small or streaming implementation is not available(RN).\n *\n * @internal\n */\nconst withMemoization = (payloadAccessor) => {\n    let cached;\n    return () => {\n        if (!cached) {\n            // Explicitly not awaiting. Intermediate await would add overhead and\n            // introduce a possible race in the event that this wrapper is called\n            // again before the first `payloadAccessor` call resolves.\n            cached = payloadAccessor();\n        }\n        return cached;\n    };\n};\n\nexport { withMemoization };\n//# sourceMappingURL=memoization.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// Logging constants\nconst AWS_CLOUDWATCH_CATEGORY = 'Logging';\nconst USER_AGENT_HEADER = 'x-amz-user-agent';\n// Error exception code constants\nconst NO_HUBCALLBACK_PROVIDED_EXCEPTION = 'NoHubcallbackProvidedException';\n\nexport { AWS_CLOUDWATCH_CATEGORY, NO_HUBCALLBACK_PROVIDED_EXCEPTION, USER_AGENT_HEADER };\n//# sourceMappingURL=constants.mjs.map\n","import { AmplifyError } from './AmplifyError.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Error class for errors that associated with unsuccessful HTTP responses.\n * It's throw by API category REST API handlers and GraphQL query handlers for now.\n */\nclass ApiError extends AmplifyError {\n    /**\n     * The unwrapped HTTP response causing the given API error.\n     */\n    get response() {\n        return this._response\n            ? replicateApiErrorResponse(this._response)\n            : undefined;\n    }\n    constructor(params) {\n        super(params);\n        // TODO: Delete the following 2 lines after we change the build target to >= es2015\n        this.constructor = ApiError;\n        Object.setPrototypeOf(this, ApiError.prototype);\n        if (params.response) {\n            this._response = params.response;\n        }\n    }\n}\nconst replicateApiErrorResponse = (response) => ({\n    ...response,\n    headers: { ...response.headers },\n});\n\nexport { ApiError };\n//# sourceMappingURL=APIError.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nclass AmplifyError extends Error {\n    /**\n     *  Constructs an AmplifyError.\n     *\n     * @param message text that describes the main problem.\n     * @param underlyingError the underlying cause of the error.\n     * @param recoverySuggestion suggestion to recover from the error.\n     *\n     */\n    constructor({ message, name, recoverySuggestion, underlyingError, }) {\n        super(message);\n        this.name = name;\n        this.underlyingError = underlyingError;\n        this.recoverySuggestion = recoverySuggestion;\n        // Hack for making the custom error class work when transpiled to es5\n        // TODO: Delete the following 2 lines after we change the build target to >= es2015\n        this.constructor = AmplifyError;\n        Object.setPrototypeOf(this, AmplifyError.prototype);\n    }\n}\n\nexport { AmplifyError };\n//# sourceMappingURL=AmplifyError.mjs.map\n","import { AmplifyErrorCode } from '../types/errors.mjs';\nimport { AmplifyError } from './AmplifyError.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nclass PlatformNotSupportedError extends AmplifyError {\n    constructor() {\n        super({\n            name: AmplifyErrorCode.PlatformNotSupported,\n            message: 'Function not supported on current platform',\n        });\n    }\n}\n\nexport { PlatformNotSupportedError };\n//# sourceMappingURL=PlatformNotSupportedError.mjs.map\n","import { AmplifyError } from './AmplifyError.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst createAssertionFunction = (errorMap, AssertionError = AmplifyError) => (assertion, name, additionalContext) => {\n    const { message, recoverySuggestion } = errorMap[name];\n    if (!assertion) {\n        throw new AssertionError({\n            name,\n            message: additionalContext\n                ? `${message} ${additionalContext}`\n                : message,\n            recoverySuggestion,\n        });\n    }\n};\n\nexport { createAssertionFunction };\n//# sourceMappingURL=createAssertionFunction.mjs.map\n","import { ConsoleLogger } from './Logger/ConsoleLogger.mjs';\nimport { AmplifyError } from './errors/AmplifyError.mjs';\nimport './types/errors.mjs';\nimport './errors/errorHelpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst logger = new ConsoleLogger('parseAWSExports');\nconst authTypeMapping = {\n    API_KEY: 'apiKey',\n    AWS_IAM: 'iam',\n    AMAZON_COGNITO_USER_POOLS: 'userPool',\n    OPENID_CONNECT: 'oidc',\n    NONE: 'none',\n    AWS_LAMBDA: 'lambda',\n    // `LAMBDA` is an incorrect value that was added during the v6 rewrite.\n    // Keeping it as a valid value until v7 to prevent breaking customers who might\n    // be relying on it as a workaround.\n    // ref: https://github.com/aws-amplify/amplify-js/pull/12922\n    // TODO: @v7 remove next line\n    LAMBDA: 'lambda',\n};\n/**\n * Converts the object imported from `aws-exports.js` or `amplifyconfiguration.json` files generated by\n * the Amplify CLI into an object that conforms to the {@link ResourcesConfig}.\n *\n * @param config A configuration object imported  from `aws-exports.js` or `amplifyconfiguration.json`.\n *\n * @returns An object that conforms to the {@link ResourcesConfig} .\n */\nconst parseAWSExports = (config = {}) => {\n    if (!Object.prototype.hasOwnProperty.call(config, 'aws_project_region')) {\n        throw new AmplifyError({\n            name: 'InvalidParameterException',\n            message: 'Invalid config parameter.',\n            recoverySuggestion: 'Ensure passing the config object imported from  `amplifyconfiguration.json`.',\n        });\n    }\n    const { aws_appsync_apiKey, aws_appsync_authenticationType, aws_appsync_graphqlEndpoint, aws_appsync_region, aws_bots_config, aws_cognito_identity_pool_id, aws_cognito_sign_up_verification_method, aws_cognito_mfa_configuration, aws_cognito_mfa_types, aws_cognito_password_protection_settings, aws_cognito_verification_mechanisms, aws_cognito_signup_attributes, aws_cognito_social_providers, aws_cognito_username_attributes, aws_mandatory_sign_in, aws_mobile_analytics_app_id, aws_mobile_analytics_app_region, aws_user_files_s3_bucket, aws_user_files_s3_bucket_region, aws_user_files_s3_dangerously_connect_to_http_endpoint_for_testing, aws_user_pools_id, aws_user_pools_web_client_id, geo, oauth, predictions, aws_cloud_logic_custom, Notifications, modelIntrospection, } = config;\n    const amplifyConfig = {};\n    // Analytics\n    if (aws_mobile_analytics_app_id) {\n        amplifyConfig.Analytics = {\n            Pinpoint: {\n                appId: aws_mobile_analytics_app_id,\n                region: aws_mobile_analytics_app_region,\n            },\n        };\n    }\n    // Notifications\n    const { InAppMessaging, Push } = Notifications ?? {};\n    if (InAppMessaging?.AWSPinpoint || Push?.AWSPinpoint) {\n        if (InAppMessaging?.AWSPinpoint) {\n            const { appId, region } = InAppMessaging.AWSPinpoint;\n            amplifyConfig.Notifications = {\n                InAppMessaging: {\n                    Pinpoint: {\n                        appId,\n                        region,\n                    },\n                },\n            };\n        }\n        if (Push?.AWSPinpoint) {\n            const { appId, region } = Push.AWSPinpoint;\n            amplifyConfig.Notifications = {\n                ...amplifyConfig.Notifications,\n                PushNotification: {\n                    Pinpoint: {\n                        appId,\n                        region,\n                    },\n                },\n            };\n        }\n    }\n    // Interactions\n    if (Array.isArray(aws_bots_config)) {\n        amplifyConfig.Interactions = {\n            LexV1: Object.fromEntries(aws_bots_config.map(bot => [bot.name, bot])),\n        };\n    }\n    // API\n    if (aws_appsync_graphqlEndpoint) {\n        const defaultAuthMode = authTypeMapping[aws_appsync_authenticationType];\n        if (!defaultAuthMode) {\n            logger.debug(`Invalid authentication type ${aws_appsync_authenticationType}. Falling back to IAM.`);\n        }\n        amplifyConfig.API = {\n            GraphQL: {\n                endpoint: aws_appsync_graphqlEndpoint,\n                apiKey: aws_appsync_apiKey,\n                region: aws_appsync_region,\n                defaultAuthMode: defaultAuthMode ?? 'iam',\n            },\n        };\n        if (modelIntrospection) {\n            amplifyConfig.API.GraphQL.modelIntrospection = modelIntrospection;\n        }\n    }\n    // Auth\n    const mfaConfig = aws_cognito_mfa_configuration\n        ? {\n            status: aws_cognito_mfa_configuration &&\n                aws_cognito_mfa_configuration.toLowerCase(),\n            totpEnabled: aws_cognito_mfa_types?.includes('TOTP') ?? false,\n            smsEnabled: aws_cognito_mfa_types?.includes('SMS') ?? false,\n        }\n        : undefined;\n    const passwordFormatConfig = aws_cognito_password_protection_settings\n        ? {\n            minLength: aws_cognito_password_protection_settings.passwordPolicyMinLength,\n            requireLowercase: aws_cognito_password_protection_settings.passwordPolicyCharacters?.includes('REQUIRES_LOWERCASE') ?? false,\n            requireUppercase: aws_cognito_password_protection_settings.passwordPolicyCharacters?.includes('REQUIRES_UPPERCASE') ?? false,\n            requireNumbers: aws_cognito_password_protection_settings.passwordPolicyCharacters?.includes('REQUIRES_NUMBERS') ?? false,\n            requireSpecialCharacters: aws_cognito_password_protection_settings.passwordPolicyCharacters?.includes('REQUIRES_SYMBOLS') ?? false,\n        }\n        : undefined;\n    const mergedUserAttributes = Array.from(new Set([\n        ...(aws_cognito_verification_mechanisms ?? []),\n        ...(aws_cognito_signup_attributes ?? []),\n    ]));\n    const userAttributes = mergedUserAttributes.reduce((attributes, key) => ({\n        ...attributes,\n        // All user attributes generated by the CLI are required\n        [key.toLowerCase()]: { required: true },\n    }), {});\n    const loginWithEmailEnabled = aws_cognito_username_attributes?.includes('EMAIL') ?? false;\n    const loginWithPhoneEnabled = aws_cognito_username_attributes?.includes('PHONE_NUMBER') ?? false;\n    if (aws_cognito_identity_pool_id || aws_user_pools_id) {\n        amplifyConfig.Auth = {\n            Cognito: {\n                identityPoolId: aws_cognito_identity_pool_id,\n                allowGuestAccess: aws_mandatory_sign_in !== 'enable',\n                signUpVerificationMethod: aws_cognito_sign_up_verification_method,\n                userAttributes,\n                userPoolClientId: aws_user_pools_web_client_id,\n                userPoolId: aws_user_pools_id,\n                mfa: mfaConfig,\n                passwordFormat: passwordFormatConfig,\n                loginWith: {\n                    username: !(loginWithEmailEnabled || loginWithPhoneEnabled),\n                    email: loginWithEmailEnabled,\n                    phone: loginWithPhoneEnabled,\n                },\n            },\n        };\n    }\n    const hasOAuthConfig = oauth ? Object.keys(oauth).length > 0 : false;\n    const hasSocialProviderConfig = aws_cognito_social_providers\n        ? aws_cognito_social_providers.length > 0\n        : false;\n    if (amplifyConfig.Auth && hasOAuthConfig) {\n        amplifyConfig.Auth.Cognito.loginWith = {\n            ...amplifyConfig.Auth.Cognito.loginWith,\n            oauth: {\n                ...getOAuthConfig(oauth),\n                ...(hasSocialProviderConfig && {\n                    providers: parseSocialProviders(aws_cognito_social_providers),\n                }),\n            },\n        };\n    }\n    // Storage\n    if (aws_user_files_s3_bucket) {\n        amplifyConfig.Storage = {\n            S3: {\n                bucket: aws_user_files_s3_bucket,\n                region: aws_user_files_s3_bucket_region,\n                dangerouslyConnectToHttpEndpointForTesting: aws_user_files_s3_dangerously_connect_to_http_endpoint_for_testing,\n            },\n        };\n    }\n    // Geo\n    if (geo) {\n        const { amazon_location_service } = geo;\n        amplifyConfig.Geo = {\n            LocationService: {\n                maps: amazon_location_service.maps,\n                geofenceCollections: amazon_location_service.geofenceCollections,\n                searchIndices: amazon_location_service.search_indices,\n                region: amazon_location_service.region,\n            },\n        };\n    }\n    // REST API\n    if (aws_cloud_logic_custom) {\n        amplifyConfig.API = {\n            ...amplifyConfig.API,\n            REST: aws_cloud_logic_custom.reduce((acc, api) => {\n                const { name, endpoint, region, service } = api;\n                return {\n                    ...acc,\n                    [name]: {\n                        endpoint,\n                        ...(service ? { service } : undefined),\n                        ...(region ? { region } : undefined),\n                    },\n                };\n            }, {}),\n        };\n    }\n    // Predictions\n    if (predictions) {\n        // map VoiceId from speechGenerator defaults to voiceId\n        const { VoiceId: voiceId } = predictions?.convert?.speechGenerator?.defaults ?? {};\n        amplifyConfig.Predictions = voiceId\n            ? {\n                ...predictions,\n                convert: {\n                    ...predictions.convert,\n                    speechGenerator: {\n                        ...predictions.convert.speechGenerator,\n                        defaults: { voiceId },\n                    },\n                },\n            }\n            : predictions;\n    }\n    return amplifyConfig;\n};\nconst getRedirectUrl = (redirectStr) => redirectStr?.split(',') ?? [];\nconst getOAuthConfig = ({ domain, scope, redirectSignIn, redirectSignOut, responseType, }) => ({\n    domain,\n    scopes: scope,\n    redirectSignIn: getRedirectUrl(redirectSignIn),\n    redirectSignOut: getRedirectUrl(redirectSignOut),\n    responseType,\n});\nconst parseSocialProviders = (aws_cognito_social_providers) => {\n    return aws_cognito_social_providers.map((provider) => {\n        const updatedProvider = provider.toLowerCase();\n        return updatedProvider.charAt(0).toUpperCase() + updatedProvider.slice(1);\n    });\n};\n\nexport { parseAWSExports };\n//# sourceMappingURL=parseAWSExports.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nfunction isAmplifyOutputs(config) {\n    // version format initially will be '1' but is expected to be something like x.y where x is major and y minor version\n    const { version } = config;\n    if (!version) {\n        return false;\n    }\n    return version.startsWith('1');\n}\nfunction parseStorage(amplifyOutputsStorageProperties) {\n    if (!amplifyOutputsStorageProperties) {\n        return undefined;\n    }\n    const { bucket_name, aws_region, buckets } = amplifyOutputsStorageProperties;\n    return {\n        S3: {\n            bucket: bucket_name,\n            region: aws_region,\n            buckets: buckets && createBucketInfoMap(buckets),\n        },\n    };\n}\nfunction parseAuth(amplifyOutputsAuthProperties) {\n    if (!amplifyOutputsAuthProperties) {\n        return undefined;\n    }\n    const { user_pool_id, user_pool_client_id, identity_pool_id, password_policy, mfa_configuration, mfa_methods, unauthenticated_identities_enabled, oauth, username_attributes, standard_required_attributes, groups, } = amplifyOutputsAuthProperties;\n    const authConfig = {\n        Cognito: {\n            userPoolId: user_pool_id,\n            userPoolClientId: user_pool_client_id,\n            groups,\n        },\n    };\n    if (identity_pool_id) {\n        authConfig.Cognito = {\n            ...authConfig.Cognito,\n            identityPoolId: identity_pool_id,\n        };\n    }\n    if (password_policy) {\n        authConfig.Cognito.passwordFormat = {\n            requireLowercase: password_policy.require_lowercase,\n            requireNumbers: password_policy.require_numbers,\n            requireUppercase: password_policy.require_uppercase,\n            requireSpecialCharacters: password_policy.require_symbols,\n            minLength: password_policy.min_length ?? 6,\n        };\n    }\n    if (mfa_configuration) {\n        authConfig.Cognito.mfa = {\n            status: getMfaStatus(mfa_configuration),\n            smsEnabled: mfa_methods?.includes('SMS'),\n            totpEnabled: mfa_methods?.includes('TOTP'),\n        };\n    }\n    if (unauthenticated_identities_enabled) {\n        authConfig.Cognito.allowGuestAccess = unauthenticated_identities_enabled;\n    }\n    if (oauth) {\n        authConfig.Cognito.loginWith = {\n            oauth: {\n                domain: oauth.domain,\n                redirectSignIn: oauth.redirect_sign_in_uri,\n                redirectSignOut: oauth.redirect_sign_out_uri,\n                responseType: oauth.response_type === 'token' ? 'token' : 'code',\n                scopes: oauth.scopes,\n                providers: getOAuthProviders(oauth.identity_providers),\n            },\n        };\n    }\n    if (username_attributes) {\n        authConfig.Cognito.loginWith = {\n            ...authConfig.Cognito.loginWith,\n            email: username_attributes.includes('email'),\n            phone: username_attributes.includes('phone_number'),\n            // Signing in with a username is not currently supported in Gen2, this should always evaluate to false\n            username: username_attributes.includes('username'),\n        };\n    }\n    if (standard_required_attributes) {\n        authConfig.Cognito.userAttributes = standard_required_attributes.reduce((acc, curr) => ({ ...acc, [curr]: { required: true } }), {});\n    }\n    return authConfig;\n}\nfunction parseAnalytics(amplifyOutputsAnalyticsProperties) {\n    if (!amplifyOutputsAnalyticsProperties?.amazon_pinpoint) {\n        return undefined;\n    }\n    const { amazon_pinpoint } = amplifyOutputsAnalyticsProperties;\n    return {\n        Pinpoint: {\n            appId: amazon_pinpoint.app_id,\n            region: amazon_pinpoint.aws_region,\n        },\n    };\n}\nfunction parseGeo(amplifyOutputsAnalyticsProperties) {\n    if (!amplifyOutputsAnalyticsProperties) {\n        return undefined;\n    }\n    const { aws_region, geofence_collections, maps, search_indices } = amplifyOutputsAnalyticsProperties;\n    return {\n        LocationService: {\n            region: aws_region,\n            searchIndices: search_indices,\n            geofenceCollections: geofence_collections,\n            maps,\n        },\n    };\n}\nfunction parseData(amplifyOutputsDataProperties) {\n    if (!amplifyOutputsDataProperties) {\n        return undefined;\n    }\n    const { aws_region, default_authorization_type, url, api_key, model_introspection, } = amplifyOutputsDataProperties;\n    const GraphQL = {\n        endpoint: url,\n        defaultAuthMode: getGraphQLAuthMode(default_authorization_type),\n        region: aws_region,\n        apiKey: api_key,\n        modelIntrospection: model_introspection,\n    };\n    return {\n        GraphQL,\n    };\n}\nfunction parseCustom(amplifyOutputsCustomProperties) {\n    if (!amplifyOutputsCustomProperties?.events) {\n        return undefined;\n    }\n    const { url, aws_region, api_key, default_authorization_type } = amplifyOutputsCustomProperties.events;\n    const Events = {\n        endpoint: url,\n        defaultAuthMode: getGraphQLAuthMode(default_authorization_type),\n        region: aws_region,\n        apiKey: api_key,\n    };\n    return {\n        Events,\n    };\n}\nfunction parseNotifications(amplifyOutputsNotificationsProperties) {\n    if (!amplifyOutputsNotificationsProperties) {\n        return undefined;\n    }\n    const { aws_region, channels, amazon_pinpoint_app_id } = amplifyOutputsNotificationsProperties;\n    const hasInAppMessaging = channels.includes('IN_APP_MESSAGING');\n    const hasPushNotification = channels.includes('APNS') || channels.includes('FCM');\n    if (!(hasInAppMessaging || hasPushNotification)) {\n        return undefined;\n    }\n    // At this point, we know the Amplify outputs contains at least one supported channel\n    const notificationsConfig = {};\n    if (hasInAppMessaging) {\n        notificationsConfig.InAppMessaging = {\n            Pinpoint: {\n                appId: amazon_pinpoint_app_id,\n                region: aws_region,\n            },\n        };\n    }\n    if (hasPushNotification) {\n        notificationsConfig.PushNotification = {\n            Pinpoint: {\n                appId: amazon_pinpoint_app_id,\n                region: aws_region,\n            },\n        };\n    }\n    return notificationsConfig;\n}\nfunction parseAmplifyOutputs(amplifyOutputs) {\n    const resourcesConfig = {};\n    if (amplifyOutputs.storage) {\n        resourcesConfig.Storage = parseStorage(amplifyOutputs.storage);\n    }\n    if (amplifyOutputs.auth) {\n        resourcesConfig.Auth = parseAuth(amplifyOutputs.auth);\n    }\n    if (amplifyOutputs.analytics) {\n        resourcesConfig.Analytics = parseAnalytics(amplifyOutputs.analytics);\n    }\n    if (amplifyOutputs.geo) {\n        resourcesConfig.Geo = parseGeo(amplifyOutputs.geo);\n    }\n    if (amplifyOutputs.data) {\n        resourcesConfig.API = parseData(amplifyOutputs.data);\n    }\n    if (amplifyOutputs.custom) {\n        const customConfig = parseCustom(amplifyOutputs.custom);\n        if (customConfig && 'Events' in customConfig) {\n            resourcesConfig.API = { ...resourcesConfig.API, ...customConfig };\n        }\n    }\n    if (amplifyOutputs.notifications) {\n        resourcesConfig.Notifications = parseNotifications(amplifyOutputs.notifications);\n    }\n    return resourcesConfig;\n}\nconst authModeNames = {\n    AMAZON_COGNITO_USER_POOLS: 'userPool',\n    API_KEY: 'apiKey',\n    AWS_IAM: 'iam',\n    AWS_LAMBDA: 'lambda',\n    OPENID_CONNECT: 'oidc',\n};\nfunction getGraphQLAuthMode(authType) {\n    return authModeNames[authType];\n}\nconst providerNames = {\n    GOOGLE: 'Google',\n    LOGIN_WITH_AMAZON: 'Amazon',\n    FACEBOOK: 'Facebook',\n    SIGN_IN_WITH_APPLE: 'Apple',\n};\nfunction getOAuthProviders(providers = []) {\n    return providers.reduce((oAuthProviders, provider) => {\n        if (providerNames[provider] !== undefined) {\n            oAuthProviders.push(providerNames[provider]);\n        }\n        return oAuthProviders;\n    }, []);\n}\nfunction getMfaStatus(mfaConfiguration) {\n    if (mfaConfiguration === 'OPTIONAL')\n        return 'optional';\n    if (mfaConfiguration === 'REQUIRED')\n        return 'on';\n    return 'off';\n}\nfunction createBucketInfoMap(buckets) {\n    const mappedBuckets = {};\n    buckets.forEach(({ name, bucket_name: bucketName, aws_region: region, paths }) => {\n        if (name in mappedBuckets) {\n            throw new Error(`Duplicate friendly name found: ${name}. Name must be unique.`);\n        }\n        mappedBuckets[name] = {\n            bucketName,\n            region,\n            paths,\n        };\n    });\n    return mappedBuckets;\n}\n\nexport { isAmplifyOutputs, parseAmplifyOutputs, parseAnalytics };\n//# sourceMappingURL=parseAmplifyOutputs.mjs.map\n","import { Hub, AMPLIFY_SYMBOL } from '../Hub/index.mjs';\nimport '../utils/getClientInfo/getClientInfo.mjs';\nimport '../utils/retry/retry.mjs';\nimport { deepFreeze } from '../utils/deepFreeze.mjs';\nimport '../parseAWSExports.mjs';\nimport { ADD_OAUTH_LISTENER } from './constants.mjs';\nimport 'uuid';\nimport { parseAmplifyConfig } from '../utils/parseAmplifyConfig.mjs';\nimport '../types/errors.mjs';\nimport '../errors/errorHelpers.mjs';\nimport './Auth/utils/errorHelpers.mjs';\nimport { AuthClass } from './Auth/index.mjs';\nimport '@aws-crypto/sha256-js';\nimport '@smithy/util-hex-encoding';\nimport '../Platform/index.mjs';\nimport '../Platform/types.mjs';\nimport '../BackgroundProcessManager/types.mjs';\nimport '../Reachability/Reachability.mjs';\nimport '../utils/sessionListener/index.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nclass AmplifyClass {\n    constructor() {\n        this.oAuthListener = undefined;\n        this.resourcesConfig = {};\n        this.libraryOptions = {};\n        this.Auth = new AuthClass();\n    }\n    /**\n     * Configures Amplify for use with your back-end resources.\n     *\n     * @remarks\n     * This API does not perform any merging of either `resourcesConfig` or `libraryOptions`. The most recently\n     * provided values will be used after configuration.\n     *\n     * @remarks\n     * `configure` can be used to specify additional library options where available for supported categories.\n     *\n     * @param resourceConfig - Back-end resource configuration. Typically provided via the `aws-exports.js` file.\n     * @param libraryOptions - Additional options for customizing the behavior of the library.\n     */\n    configure(resourcesConfig, libraryOptions) {\n        const resolvedResourceConfig = parseAmplifyConfig(resourcesConfig);\n        this.resourcesConfig = resolvedResourceConfig;\n        if (libraryOptions) {\n            this.libraryOptions = libraryOptions;\n        }\n        // Make resource config immutable\n        this.resourcesConfig = deepFreeze(this.resourcesConfig);\n        this.Auth.configure(this.resourcesConfig.Auth, this.libraryOptions.Auth);\n        Hub.dispatch('core', {\n            event: 'configure',\n            data: this.resourcesConfig,\n        }, 'Configure', AMPLIFY_SYMBOL);\n        this.notifyOAuthListener();\n    }\n    /**\n     * Provides access to the current back-end resource configuration for the Library.\n     *\n     * @returns Returns the immutable back-end resource configuration.\n     */\n    getConfig() {\n        return this.resourcesConfig;\n    }\n    /** @internal */\n    [ADD_OAUTH_LISTENER](listener) {\n        if (this.resourcesConfig.Auth?.Cognito.loginWith?.oauth) {\n            // when Amplify has been configured with a valid OAuth config while adding the listener, run it directly\n            listener(this.resourcesConfig.Auth?.Cognito);\n        }\n        else {\n            // otherwise register the listener and run it later when Amplify gets configured with a valid oauth config\n            this.oAuthListener = listener;\n        }\n    }\n    notifyOAuthListener() {\n        if (!this.resourcesConfig.Auth?.Cognito.loginWith?.oauth ||\n            !this.oAuthListener) {\n            return;\n        }\n        this.oAuthListener(this.resourcesConfig.Auth?.Cognito);\n        // the listener should only be notified once with a valid oauth config\n        this.oAuthListener = undefined;\n    }\n}\n/**\n * The `Amplify` utility is used to configure the library.\n *\n * @remarks\n * `Amplify` orchestrates cross-category communication within the library.\n */\nconst Amplify = new AmplifyClass();\n\nexport { Amplify, AmplifyClass };\n//# sourceMappingURL=Amplify.mjs.map\n","import { ConsoleLogger } from '../../Logger/ConsoleLogger.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst logger = new ConsoleLogger('Auth');\nfunction isTokenExpired({ expiresAt, clockDrift, }) {\n    const currentTime = Date.now();\n    return currentTime + clockDrift > expiresAt;\n}\nclass AuthClass {\n    /**\n     * Configure Auth category\n     *\n     * @internal\n     *\n     * @param authResourcesConfig - Resources configurations required by Auth providers.\n     * @param authOptions - Client options used by library\n     *\n     * @returns void\n     */\n    configure(authResourcesConfig, authOptions) {\n        this.authConfig = authResourcesConfig;\n        this.authOptions = authOptions;\n        if (authResourcesConfig.Cognito.userPoolEndpoint) {\n            logger.warn(getCustomEndpointWarningMessage('Amazon Cognito User Pool'));\n        }\n        if (authResourcesConfig.Cognito.identityPoolEndpoint) {\n            logger.warn(getCustomEndpointWarningMessage('Amazon Cognito Identity Pool'));\n        }\n    }\n    /**\n     * Fetch the auth tokens, and the temporary AWS credentials and identity if they are configured. By default it\n     * does not refresh the auth tokens or credentials if they are loaded in storage already. You can force a refresh\n     * with `{ forceRefresh: true }` input.\n     *\n     * @param options - Options configuring the fetch behavior.\n     *\n     * @returns Promise of current auth session {@link AuthSession}.\n     */\n    async fetchAuthSession(options = {}) {\n        let credentialsAndIdentityId;\n        let userSub;\n        // Get tokens will throw if session cannot be refreshed (network or service error) or return null if not available\n        const tokens = await this.getTokens(options);\n        if (tokens) {\n            userSub = tokens.accessToken?.payload?.sub;\n            // getCredentialsAndIdentityId will throw if cannot get credentials (network or service error)\n            credentialsAndIdentityId =\n                await this.authOptions?.credentialsProvider?.getCredentialsAndIdentityId({\n                    authConfig: this.authConfig,\n                    tokens,\n                    authenticated: true,\n                    forceRefresh: options.forceRefresh,\n                });\n        }\n        else {\n            // getCredentialsAndIdentityId will throw if cannot get credentials (network or service error)\n            credentialsAndIdentityId =\n                await this.authOptions?.credentialsProvider?.getCredentialsAndIdentityId({\n                    authConfig: this.authConfig,\n                    authenticated: false,\n                    forceRefresh: options.forceRefresh,\n                });\n        }\n        return {\n            tokens,\n            credentials: credentialsAndIdentityId?.credentials,\n            identityId: credentialsAndIdentityId?.identityId,\n            userSub,\n        };\n    }\n    async clearCredentials() {\n        await this.authOptions?.credentialsProvider?.clearCredentialsAndIdentityId();\n    }\n    async getTokens(options) {\n        return ((await this.authOptions?.tokenProvider?.getTokens(options)) ?? undefined);\n    }\n}\nconst getCustomEndpointWarningMessage = (target) => `You are using a custom Amazon ${target} endpoint, ensure the endpoint is correct.`;\n\nexport { AuthClass, isTokenExpired };\n//# sourceMappingURL=index.mjs.map\n","import { Amplify } from '../Amplify.mjs';\nimport { fetchAuthSession as fetchAuthSession$1 } from './internal/fetchAuthSession.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Fetch the auth session including the tokens and credentials if they are available. By default it\n * does not refresh the auth tokens or credentials if they are loaded in storage already. You can force a refresh\n * with `{ forceRefresh: true }` input.\n *\n * @param options - Options configuring the fetch behavior.\n * @throws {@link AuthError} - Throws error when session information cannot be refreshed.\n * @returns Promise<AuthSession>\n */\nconst fetchAuthSession = (options) => {\n    return fetchAuthSession$1(Amplify, options);\n};\n\nexport { fetchAuthSession };\n//# sourceMappingURL=fetchAuthSession.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst fetchAuthSession = (amplify, options) => {\n    return amplify.Auth.fetchAuthSession(options);\n};\n\nexport { fetchAuthSession };\n//# sourceMappingURL=fetchAuthSession.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst ADD_OAUTH_LISTENER = Symbol('oauth-listener');\n\nexport { ADD_OAUTH_LISTENER };\n//# sourceMappingURL=constants.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * @internal\n */\nclass InMemoryStorage {\n    constructor() {\n        this.storage = new Map();\n    }\n    get length() {\n        return this.storage.size;\n    }\n    key(index) {\n        if (index > this.length - 1) {\n            return null;\n        }\n        return Array.from(this.storage.keys())[index];\n    }\n    setItem(key, value) {\n        this.storage.set(key, value);\n    }\n    getItem(key) {\n        return this.storage.get(key) ?? null;\n    }\n    removeItem(key) {\n        this.storage.delete(key);\n    }\n    clear() {\n        this.storage.clear();\n    }\n}\n\nexport { InMemoryStorage };\n//# sourceMappingURL=InMemoryStorage.mjs.map\n","import { PlatformNotSupportedError } from '../errors/PlatformNotSupportedError.mjs';\nimport '../errors/errorHelpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * @internal\n */\nclass KeyValueStorage {\n    constructor(storage) {\n        this.storage = storage;\n    }\n    /**\n     * This is used to set a specific item in storage\n     * @param {string} key - the key for the item\n     * @param {object} value - the value\n     * @returns {string} value that was set\n     */\n    async setItem(key, value) {\n        if (!this.storage)\n            throw new PlatformNotSupportedError();\n        this.storage.setItem(key, value);\n    }\n    /**\n     * This is used to get a specific key from storage\n     * @param {string} key - the key for the item\n     * This is used to clear the storage\n     * @returns {string} the data item\n     */\n    async getItem(key) {\n        if (!this.storage)\n            throw new PlatformNotSupportedError();\n        return this.storage.getItem(key);\n    }\n    /**\n     * This is used to remove an item from storage\n     * @param {string} key - the key being set\n     * @returns {string} value - value that was deleted\n     */\n    async removeItem(key) {\n        if (!this.storage)\n            throw new PlatformNotSupportedError();\n        this.storage.removeItem(key);\n    }\n    /**\n     * This is used to clear the storage\n     * @returns {string} nothing\n     */\n    async clear() {\n        if (!this.storage)\n            throw new PlatformNotSupportedError();\n        this.storage.clear();\n    }\n}\n\nexport { KeyValueStorage };\n//# sourceMappingURL=KeyValueStorage.mjs.map\n","import { ConsoleLogger } from '../Logger/ConsoleLogger.mjs';\nimport { InMemoryStorage } from './InMemoryStorage.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * @internal\n * @returns Either a reference to window.localStorage or an in-memory storage as fallback\n */\nconst logger = new ConsoleLogger('CoreStorageUtils');\nconst getLocalStorageWithFallback = () => {\n    try {\n        // Attempt to use localStorage directly\n        if (typeof window !== 'undefined' && window.localStorage) {\n            return window.localStorage;\n        }\n    }\n    catch (e) {\n        // Handle any errors related to localStorage access\n        logger.info('localStorage not found. InMemoryStorage is used as a fallback.');\n    }\n    // Return in-memory storage as a fallback if localStorage is not accessible\n    return new InMemoryStorage();\n};\n/**\n * @internal\n * @returns Either a reference to window.sessionStorage or an in-memory storage as fallback\n */\nconst getSessionStorageWithFallback = () => {\n    try {\n        // Attempt to use sessionStorage directly\n        if (typeof window !== 'undefined' && window.sessionStorage) {\n            // Verify we can actually use it by testing access\n            window.sessionStorage.getItem('test');\n            return window.sessionStorage;\n        }\n        throw new Error('sessionStorage is not defined');\n    }\n    catch (e) {\n        // Handle any errors related to sessionStorage access\n        logger.info('sessionStorage not found. InMemoryStorage is used as a fallback.');\n        return new InMemoryStorage();\n    }\n};\n\nexport { getLocalStorageWithFallback, getSessionStorageWithFallback };\n//# sourceMappingURL=utils.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nvar AmplifyErrorCode;\n(function (AmplifyErrorCode) {\n    AmplifyErrorCode[\"NoEndpointId\"] = \"NoEndpointId\";\n    AmplifyErrorCode[\"PlatformNotSupported\"] = \"PlatformNotSupported\";\n    AmplifyErrorCode[\"Unknown\"] = \"Unknown\";\n    AmplifyErrorCode[\"NetworkError\"] = \"NetworkError\";\n})(AmplifyErrorCode || (AmplifyErrorCode = {}));\n\nexport { AmplifyErrorCode };\n//# sourceMappingURL=errors.mjs.map\n","import { cryptoSecureRandomInt } from './cryptoSecureRandomInt.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Hex encoding strategy.\n * Converts a word array to a hex string.\n * @param {WordArray} wordArray The word array.\n * @return {string} The hex string.\n * @static\n */\nfunction hexStringify(wordArray) {\n    // Shortcuts\n    const { words } = wordArray;\n    const { sigBytes } = wordArray;\n    // Convert\n    const hexChars = [];\n    for (let i = 0; i < sigBytes; i++) {\n        const bite = (words[i >>> 2] >>> (24 - (i % 4) * 8)) & 0xff;\n        hexChars.push((bite >>> 4).toString(16));\n        hexChars.push((bite & 0x0f).toString(16));\n    }\n    return hexChars.join('');\n}\nclass WordArray {\n    constructor(words, sigBytes) {\n        this.words = [];\n        let Words = words;\n        Words = this.words = Words || [];\n        if (sigBytes !== undefined) {\n            this.sigBytes = sigBytes;\n        }\n        else {\n            this.sigBytes = Words.length * 4;\n        }\n    }\n    random(nBytes) {\n        const words = [];\n        for (let i = 0; i < nBytes; i += 4) {\n            words.push(cryptoSecureRandomInt());\n        }\n        return new WordArray(words, nBytes);\n    }\n    toString() {\n        return hexStringify(this);\n    }\n}\n\nexport { WordArray };\n//# sourceMappingURL=WordArray.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst AmplifyUrl = URL;\nconst AmplifyUrlSearchParams = URLSearchParams;\n\nexport { AmplifyUrl, AmplifyUrlSearchParams };\n//# sourceMappingURL=index.mjs.map\n","import { v4 } from 'uuid';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst amplifyUuid = v4;\n\nexport { amplifyUuid };\n//# sourceMappingURL=index.mjs.map\n","import { getBtoa } from '../../globalHelpers/index.mjs';\nimport { bytesToString } from './bytesToString.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst base64Encoder = {\n    /**\n     * Convert input to base64-encoded string\n     * @param input - string to convert to base64\n     * @param options - encoding options that can optionally produce a base64url string\n     * @returns base64-encoded string\n     */\n    convert(input, options = {\n        urlSafe: false,\n        skipPadding: false,\n    }) {\n        const inputStr = typeof input === 'string' ? input : bytesToString(input);\n        let encodedStr = getBtoa()(inputStr);\n        // urlSafe char replacement and skipPadding options conform to the base64url spec\n        // https://datatracker.ietf.org/doc/html/rfc4648#section-5\n        if (options.urlSafe) {\n            encodedStr = encodedStr.replace(/\\+/g, '-').replace(/\\//g, '_');\n        }\n        if (options.skipPadding) {\n            encodedStr = encodedStr.replace(/=/g, '');\n        }\n        return encodedStr;\n    },\n};\n\nexport { base64Encoder };\n//# sourceMappingURL=base64Encoder.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nfunction bytesToString(input) {\n    return Array.from(input, byte => String.fromCodePoint(byte)).join('');\n}\n\nexport { bytesToString };\n//# sourceMappingURL=bytesToString.mjs.map\n","import { getCrypto } from './globalHelpers/index.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/*\n * Cryptographically secure pseudorandom number generator\n * As Math.random() is cryptographically not safe to use\n */\nfunction cryptoSecureRandomInt() {\n    const crypto = getCrypto();\n    const randomResult = crypto.getRandomValues(new Uint32Array(1))[0];\n    return randomResult;\n}\n\nexport { cryptoSecureRandomInt };\n//# sourceMappingURL=cryptoSecureRandomInt.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst deepFreeze = (object) => {\n    const propNames = Reflect.ownKeys(object);\n    for (const name of propNames) {\n        const value = object[name];\n        if ((value && typeof value === 'object') || typeof value === 'function') {\n            deepFreeze(value);\n        }\n    }\n    return Object.freeze(object);\n};\n\nexport { deepFreeze };\n//# sourceMappingURL=deepFreeze.mjs.map\n","import { AmplifyError } from '../../errors/AmplifyError.mjs';\nimport '../../types/errors.mjs';\nimport '../../errors/errorHelpers.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst getCrypto = () => {\n    if (typeof window === 'object' && typeof window.crypto === 'object') {\n        return window.crypto;\n    }\n    // Next.js global polyfill\n    if (typeof crypto === 'object') {\n        return crypto;\n    }\n    throw new AmplifyError({\n        name: 'MissingPolyfill',\n        message: 'Cannot resolve the `crypto` function from the environment.',\n    });\n};\nconst getBtoa = () => {\n    // browser\n    if (typeof window !== 'undefined' && typeof window.btoa === 'function') {\n        return window.btoa;\n    }\n    // Next.js global polyfill\n    if (typeof btoa === 'function') {\n        return btoa;\n    }\n    throw new AmplifyError({\n        name: 'Base64EncoderError',\n        message: 'Cannot resolve the `btoa` function from the environment.',\n    });\n};\nconst getAtob = () => {\n    // browser\n    if (typeof window !== 'undefined' && typeof window.atob === 'function') {\n        return window.atob;\n    }\n    // Next.js global polyfill\n    if (typeof atob === 'function') {\n        return atob;\n    }\n    throw new AmplifyError({\n        name: 'Base64EncoderError',\n        message: 'Cannot resolve the `atob` function from the environment.',\n    });\n};\n\nexport { getAtob, getBtoa, getCrypto };\n//# sourceMappingURL=index.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst isBrowser = () => typeof window !== 'undefined' && typeof window.document !== 'undefined';\n\nexport { isBrowser };\n//# sourceMappingURL=isBrowser.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst isWebWorker = () => {\n    if (typeof self === 'undefined') {\n        return false;\n    }\n    const selfContext = self;\n    return (typeof selfContext.WorkerGlobalScope !== 'undefined' &&\n        self instanceof selfContext.WorkerGlobalScope);\n};\n\nexport { isWebWorker };\n//# sourceMappingURL=isWebWorker.mjs.map\n","import { parseAWSExports } from '../parseAWSExports.mjs';\nimport { isAmplifyOutputs, parseAmplifyOutputs } from '../parseAmplifyOutputs.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Parses the variety of configuration shapes that Amplify can accept into a ResourcesConfig.\n *\n * @param amplifyConfig An Amplify configuration object conforming to one of the supported schemas.\n * @return A ResourcesConfig for the provided configuration object.\n */\nconst parseAmplifyConfig = (amplifyConfig) => {\n    if (Object.keys(amplifyConfig).some(key => key.startsWith('aws_'))) {\n        return parseAWSExports(amplifyConfig);\n    }\n    else if (isAmplifyOutputs(amplifyConfig)) {\n        return parseAmplifyOutputs(amplifyConfig);\n    }\n    else {\n        return amplifyConfig;\n    }\n};\n\nexport { parseAmplifyConfig };\n//# sourceMappingURL=parseAmplifyConfig.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nclass NonRetryableError extends Error {\n    constructor() {\n        super(...arguments);\n        this.nonRetryable = true;\n    }\n}\n\nexport { NonRetryableError };\n//# sourceMappingURL=NonRetryableError.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst MAX_DELAY_MS = 5 * 60 * 1000;\n\nexport { MAX_DELAY_MS };\n//# sourceMappingURL=constants.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst isNonRetryableError = (obj) => {\n    const key = 'nonRetryable';\n    return obj && obj[key];\n};\n\nexport { isNonRetryableError };\n//# sourceMappingURL=isNonRetryableError.mjs.map\n","import { MAX_DELAY_MS } from './constants.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * @private\n * Internal use of Amplify only\n */\nfunction jitteredBackoff(maxDelayMs = MAX_DELAY_MS) {\n    const BASE_TIME_MS = 100;\n    const JITTER_FACTOR = 100;\n    return attempt => {\n        const delay = 2 ** attempt * BASE_TIME_MS + JITTER_FACTOR * Math.random();\n        return delay > maxDelayMs ? false : delay;\n    };\n}\n\nexport { jitteredBackoff };\n//# sourceMappingURL=jitteredBackoff.mjs.map\n","import { MAX_DELAY_MS } from './constants.mjs';\nimport { jitteredBackoff } from './jitteredBackoff.mjs';\nimport { retry } from './retry.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * @private\n * Internal use of Amplify only\n */\nconst jitteredExponentialRetry = (functionToRetry, args, maxDelayMs = MAX_DELAY_MS, onTerminate) => retry(functionToRetry, args, jitteredBackoff(maxDelayMs), onTerminate);\n\nexport { jitteredExponentialRetry };\n//# sourceMappingURL=jitteredExponentialRetry.mjs.map\n","import { ConsoleLogger } from '../../Logger/ConsoleLogger.mjs';\nimport { isNonRetryableError } from './isNonRetryableError.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst logger = new ConsoleLogger('retryUtil');\n/**\n * @private\n * Internal use of Amplify only\n */\nasync function retry(functionToRetry, args, delayFn, onTerminate) {\n    if (typeof functionToRetry !== 'function') {\n        throw Error('functionToRetry must be a function');\n    }\n    // TODO(eslint): remove this linter suppression with refactoring.\n    // eslint-disable-next-line no-async-promise-executor\n    return new Promise(async (resolve, reject) => {\n        let attempt = 0;\n        let terminated = false;\n        let timeout;\n        let wakeUp = () => {\n            // no-op\n        }; // will be replaced with a resolver()\n        // used after the loop if terminated while waiting for a timer.\n        let lastError;\n        onTerminate &&\n            onTerminate.then(() => {\n                // signal not to try anymore.\n                terminated = true;\n                // stop sleeping if we're sleeping.\n                clearTimeout(timeout);\n                wakeUp();\n            });\n        // TODO(eslint): remove this linter suppression with refactoring.\n        // eslint-disable-next-line no-unmodified-loop-condition\n        while (!terminated) {\n            attempt++;\n            logger.debug(`${functionToRetry.name} attempt #${attempt} with this vars: ${JSON.stringify(args)}`);\n            try {\n                resolve(await functionToRetry(...args));\n                return;\n            }\n            catch (err) {\n                lastError = err;\n                logger.debug(`error on ${functionToRetry.name}`, err);\n                if (isNonRetryableError(err)) {\n                    logger.debug(`${functionToRetry.name} non retryable error`, err);\n                    reject(err);\n                    return;\n                }\n                const retryIn = delayFn(attempt, args, err);\n                logger.debug(`${functionToRetry.name} retrying in ${retryIn} ms`);\n                // we check `terminated` again here because it could have flipped\n                // in the time it took `functionToRetry` to return.\n                if (retryIn === false || terminated) {\n                    reject(err);\n                    return;\n                }\n                else {\n                    await new Promise(_resolve => {\n                        wakeUp = _resolve; // export wakeUp for onTerminate handling\n                        timeout = setTimeout(wakeUp, retryIn);\n                    });\n                }\n            }\n        }\n        // reached if terminated while waiting for a timer.\n        reject(lastError);\n    });\n}\n\nexport { retry };\n//# sourceMappingURL=retry.mjs.map\n","// Default behavior is to use the primary auth mode for an API,\n// so we are returning an empty array so that DataStore will default\n// to using the primary auth mode.\nconst defaultAuthStrategy = () => [];\n\nexport { defaultAuthStrategy };\n//# sourceMappingURL=defaultAuthStrategy.mjs.map\n","import { fetchAuthSession } from '@aws-amplify/core';\nimport { ModelAttributeAuthAllow, ModelAttributeAuthProvider } from '../types.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nfunction getProviderFromRule(rule) {\n    // private with no provider means userPools\n    if (rule.allow === 'private' && !rule.provider) {\n        return ModelAttributeAuthProvider.USER_POOLS;\n    }\n    // public with no provider means apiKey\n    if (rule.allow === 'public' && !rule.provider) {\n        return ModelAttributeAuthProvider.API_KEY;\n    }\n    return rule.provider;\n}\nfunction sortAuthRulesWithPriority(rules) {\n    const allowSortPriority = [\n        ModelAttributeAuthAllow.CUSTOM,\n        ModelAttributeAuthAllow.OWNER,\n        ModelAttributeAuthAllow.GROUPS,\n        ModelAttributeAuthAllow.PRIVATE,\n        ModelAttributeAuthAllow.PUBLIC,\n    ];\n    const providerSortPriority = [\n        ModelAttributeAuthProvider.FUNCTION,\n        ModelAttributeAuthProvider.USER_POOLS,\n        ModelAttributeAuthProvider.OIDC,\n        ModelAttributeAuthProvider.IAM,\n        ModelAttributeAuthProvider.API_KEY,\n    ];\n    return [...rules].sort((a, b) => {\n        if (a.allow === b.allow) {\n            return (providerSortPriority.indexOf(getProviderFromRule(a)) -\n                providerSortPriority.indexOf(getProviderFromRule(b)));\n        }\n        return (allowSortPriority.indexOf(a.allow) - allowSortPriority.indexOf(b.allow));\n    });\n}\nfunction getAuthRules({ rules, currentUser, }) {\n    // Using Set to ensure uniqueness\n    const authModes = new Set();\n    rules.forEach(rule => {\n        switch (rule.allow) {\n            case ModelAttributeAuthAllow.CUSTOM:\n                // custom with no provider -> function\n                if (!rule.provider ||\n                    rule.provider === ModelAttributeAuthProvider.FUNCTION) {\n                    authModes.add('lambda');\n                }\n                break;\n            case ModelAttributeAuthAllow.GROUPS:\n            case ModelAttributeAuthAllow.OWNER: {\n                // We shouldn't attempt User Pool or OIDC if there isn't an authenticated user\n                if (currentUser) {\n                    if (rule.provider === ModelAttributeAuthProvider.USER_POOLS) {\n                        authModes.add('userPool');\n                    }\n                    else if (rule.provider === ModelAttributeAuthProvider.OIDC) {\n                        authModes.add('oidc');\n                    }\n                }\n                break;\n            }\n            case ModelAttributeAuthAllow.PRIVATE: {\n                // We shouldn't attempt private if there isn't an authenticated user\n                if (currentUser) {\n                    // private with no provider means userPools\n                    if (!rule.provider ||\n                        rule.provider === ModelAttributeAuthProvider.USER_POOLS) {\n                        authModes.add('userPool');\n                    }\n                    else if (rule.provider === ModelAttributeAuthProvider.IAM) {\n                        authModes.add('iam');\n                    }\n                }\n                break;\n            }\n            case ModelAttributeAuthAllow.PUBLIC: {\n                if (rule.provider === ModelAttributeAuthProvider.IAM) {\n                    authModes.add('iam');\n                }\n                else if (!rule.provider ||\n                    rule.provider === ModelAttributeAuthProvider.API_KEY) {\n                    // public with no provider means apiKey\n                    authModes.add('apiKey');\n                }\n                break;\n            }\n        }\n    });\n    return Array.from(authModes);\n}\n/**\n * Returns an array of auth modes to try based on the schema, model, and\n * authenticated user (or lack thereof). Rules are sourced from `getAuthRules`\n * and returned in the order they ought to be attempted.\n *\n * @see sortAuthRulesWithPriority\n * @see getAuthRules\n *\n * @param param0 The `{schema, modelName}` to inspect.\n * @returns A sorted array of auth modes to attempt.\n */\nconst multiAuthStrategy = () => async ({ schema, modelName }) => {\n    let currentUser;\n    try {\n        const authSession = await fetchAuthSession();\n        if (authSession.tokens.accessToken) {\n            // the user is authenticated\n            currentUser = authSession;\n        }\n    }\n    catch (e) {\n        // No current user\n    }\n    const { attributes } = schema.namespaces.user.models[modelName];\n    if (attributes) {\n        const authAttribute = attributes.find(attr => attr.type === 'auth');\n        if (authAttribute?.properties?.rules) {\n            const sortedRules = sortAuthRulesWithPriority(authAttribute.properties.rules);\n            return getAuthRules({ currentUser, rules: sortedRules });\n        }\n    }\n    return [];\n};\n\nexport { multiAuthStrategy };\n//# sourceMappingURL=multiAuthStrategy.mjs.map\n","import { InternalAPI } from '@aws-amplify/api/internals';\nimport { ConsoleLogger, Hub, Cache, Amplify } from '@aws-amplify/core';\nimport { setAutoFreeze, enablePatches, immerable, produce } from 'immer';\nimport { BackgroundProcessManager, amplifyUuid } from '@aws-amplify/core/internals/utils';\nimport { Observable, filter } from 'rxjs';\nimport { defaultAuthStrategy } from '../authModeStrategies/defaultAuthStrategy.mjs';\nimport { multiAuthStrategy } from '../authModeStrategies/multiAuthStrategy.mjs';\nimport { ModelPredicateCreator, isPredicatesAll } from '../predicates/index.mjs';\nimport { ExclusiveStorage } from '../storage/storage.mjs';\nimport { ModelRelationship } from '../storage/relationship.mjs';\nimport { SyncEngine, ControlMessage } from '../sync/index.mjs';\nimport { isIdentifierObject, AuthModeStrategyType, isNonModelFieldType, isModelFieldType, isSchemaModelWithAttributes, isGraphQLScalarType, GraphQLScalarType } from '../types.mjs';\nimport { monotonicUlidFactory, USER, establishRelationAndKeys, isModelConstructor, extractPrimaryKeyFieldNames, registerNonModelClass, errorMessages, inMemoryPagination, extractPrimaryKeysAndValues, DeferredCallbackResolver, isIdManaged, isIdOptionallyManaged, mergePatches, STORAGE, SYNC, DATASTORE, sortCompareFunction, getTimestampFields, isNullOrUndefined } from '../util.mjs';\nimport { recursivePredicateFor, internals, predicateFor } from '../predicates/next.mjs';\nimport { getIdentifierValue } from '../sync/utils.mjs';\nimport { isNode } from './utils.mjs';\nimport { ModelSortPredicateCreator } from '../predicates/sort.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nsetAutoFreeze(true);\nenablePatches();\nconst logger = new ConsoleLogger('DataStore');\nconst ulid = monotonicUlidFactory(Date.now());\nconst SETTING_SCHEMA_VERSION = 'schemaVersion';\nlet schema;\nconst modelNamespaceMap = new WeakMap();\n/**\n * Stores data for crafting the correct update mutation input for a model.\n *\n * - `Patch[]` - array of changed fields and metadata.\n * - `PersistentModel` - the source model, used for diffing object-type fields.\n */\nconst modelPatchesMap = new WeakMap();\nconst getModelDefinition = (modelConstructor) => {\n    const namespace = modelNamespaceMap.get(modelConstructor);\n    const definition = namespace\n        ? schema.namespaces[namespace].models[modelConstructor.name]\n        : undefined;\n    return definition;\n};\n/**\n * Determines whether the given object is a Model Constructor that DataStore can\n * safely use to construct objects and discover related metadata.\n *\n * @param obj The object to test.\n */\nconst isValidModelConstructor = (obj) => {\n    return isModelConstructor(obj) && modelNamespaceMap.has(obj);\n};\nconst namespaceResolver = modelConstructor => {\n    const resolver = modelNamespaceMap.get(modelConstructor);\n    if (!resolver) {\n        throw new Error(`Namespace Resolver for '${modelConstructor.name}' not found! This is probably a bug in '@amplify-js/datastore'.`);\n    }\n    return resolver;\n};\n/**\n * Creates a predicate without any conditions that can be passed to customer\n * code to have conditions added to it.\n *\n * For example, in this query:\n *\n * ```ts\n * await DataStore.query(\n * \tModel,\n * \titem => item.field.eq('value')\n * );\n * ```\n *\n * `buildSeedPredicate(Model)` is used to create `item`, which is passed to the\n * predicate function, which in turn uses that \"seed\" predicate (`item`) to build\n * a predicate tree.\n *\n * @param modelConstructor The model the predicate will query.\n */\nconst buildSeedPredicate = (modelConstructor) => {\n    if (!modelConstructor)\n        throw new Error('Missing modelConstructor');\n    const modelSchema = getModelDefinition(modelConstructor);\n    if (!modelSchema)\n        throw new Error('Missing modelSchema');\n    const pks = extractPrimaryKeyFieldNames(modelSchema);\n    if (!pks)\n        throw new Error('Could not determine PK');\n    return recursivePredicateFor({\n        builder: modelConstructor,\n        schema: modelSchema,\n        pkField: pks,\n    });\n};\n// exporting syncClasses for testing outbox.test.ts\n// TODO(eslint): refactor not to export non-constant\n// eslint-disable-next-line import/no-mutable-exports\nlet syncClasses;\nlet userClasses;\nlet dataStoreClasses;\nlet storageClasses;\n/**\n * Maps a model to its related models for memoization/immutability.\n */\nconst modelInstanceAssociationsMap = new WeakMap();\n/**\n * Describes whether and to what a model is attached for lazy loading purposes.\n */\nvar ModelAttachment;\n(function (ModelAttachment) {\n    /**\n     * Model doesn't lazy load from any data source.\n     *\n     * Related entity properties provided at instantiation are returned\n     * via the respective lazy interfaces when their properties are invoked.\n     */\n    ModelAttachment[\"Detached\"] = \"Detached\";\n    /**\n     * Model lazy loads from the global DataStore.\n     */\n    ModelAttachment[\"DataStore\"] = \"DataStore\";\n    /**\n     * Demonstrative. Not yet implemented.\n     */\n    ModelAttachment[\"API\"] = \"API\";\n})(ModelAttachment || (ModelAttachment = {}));\n/**\n * Tells us which data source a model is attached to (lazy loads from).\n *\n * If `Deatched`, the model's lazy properties will only ever return properties\n * from memory provided at construction time.\n */\nconst attachedModelInstances = new WeakMap();\n/**\n * Registers a model instance against a data source (DataStore, API, or\n * Detached/None).\n *\n * The API option is demonstrative. Lazy loading against API is not yet\n * implemented.\n *\n * @param result A model instance or array of instances\n * @param attachment A ModelAttachment data source\n * @returns passes the `result` back through after attachment\n */\nfunction attached(result, attachment) {\n    if (Array.isArray(result)) {\n        result.map(record => attached(record, attachment));\n    }\n    else {\n        result && attachedModelInstances.set(result, attachment);\n    }\n    return result;\n}\n/**\n * Determines what source a model instance should lazy load from.\n *\n * If the instace was never explicitly registered, it is detached by default.\n *\n * @param instance A model instance\n */\nconst getAttachment = (instance) => {\n    return attachedModelInstances.has(instance)\n        ? attachedModelInstances.get(instance)\n        : ModelAttachment.Detached;\n};\nconst initSchema = (userSchema) => {\n    if (schema !== undefined) {\n        console.warn('The schema has already been initialized');\n        return userClasses;\n    }\n    logger.log('validating schema', { schema: userSchema });\n    checkSchemaCodegenVersion(userSchema.codegenVersion);\n    const internalUserNamespace = {\n        name: USER,\n        ...userSchema,\n    };\n    logger.log('DataStore', 'Init models');\n    userClasses = createTypeClasses(internalUserNamespace);\n    logger.log('DataStore', 'Models initialized');\n    const dataStoreNamespace = getNamespace();\n    const storageNamespace = ExclusiveStorage.getNamespace();\n    const syncNamespace = SyncEngine.getNamespace();\n    dataStoreClasses = createTypeClasses(dataStoreNamespace);\n    storageClasses = createTypeClasses(storageNamespace);\n    syncClasses = createTypeClasses(syncNamespace);\n    schema = {\n        namespaces: {\n            [dataStoreNamespace.name]: dataStoreNamespace,\n            [internalUserNamespace.name]: internalUserNamespace,\n            [storageNamespace.name]: storageNamespace,\n            [syncNamespace.name]: syncNamespace,\n        },\n        version: userSchema.version,\n        codegenVersion: userSchema.codegenVersion,\n    };\n    Object.keys(schema.namespaces).forEach(namespace => {\n        const [relations, keys] = establishRelationAndKeys(schema.namespaces[namespace]);\n        schema.namespaces[namespace].relationships = relations;\n        schema.namespaces[namespace].keys = keys;\n        const modelAssociations = new Map();\n        Object.values(schema.namespaces[namespace].models).forEach(model => {\n            const connectedModels = [];\n            Object.values(model.fields)\n                .filter(field => field.association &&\n                field.association.connectionType === 'BELONGS_TO' &&\n                field.type.model !== model.name)\n                .forEach(field => connectedModels.push(field.type.model));\n            modelAssociations.set(model.name, connectedModels);\n            // Precompute model info (such as pk fields) so that downstream schema consumers\n            // (such as predicate builders) don't have to reach back into \"DataStore\" space\n            // to go looking for it.\n            Object.values(model.fields).forEach(field => {\n                const relatedModel = userClasses[field.type.model];\n                if (isModelConstructor(relatedModel)) {\n                    Object.defineProperty(field.type, 'modelConstructor', {\n                        get: () => {\n                            const relatedModelDefinition = getModelDefinition(relatedModel);\n                            if (!relatedModelDefinition)\n                                throw new Error(`Could not find model definition for ${relatedModel.name}`);\n                            return {\n                                builder: relatedModel,\n                                schema: relatedModelDefinition,\n                                pkField: extractPrimaryKeyFieldNames(relatedModelDefinition),\n                            };\n                        },\n                    });\n                }\n            });\n            // compatibility with legacy/pre-PK codegen for lazy loading to inject\n            // index fields into the model definition.\n            // definition.cloudFields = { ...definition.fields };\n            const { indexes } = schema.namespaces[namespace].relationships[model.name];\n            const indexFields = new Set();\n            for (const index of indexes) {\n                for (const indexField of index[1]) {\n                    indexFields.add(indexField);\n                }\n            }\n            model.allFields = {\n                ...Object.fromEntries([...indexFields.values()].map(name => [\n                    name,\n                    {\n                        name,\n                        type: 'ID',\n                        isArray: false,\n                    },\n                ])),\n                ...model.fields,\n            };\n        });\n        const result = new Map();\n        let count = 1000;\n        // eslint-disable-next-line no-constant-binary-expression\n        while (count > 0) {\n            if (modelAssociations.size === 0) {\n                break;\n            }\n            count--;\n            if (count === 0) {\n                throw new Error('Models are not topologically sortable. Please verify your schema.');\n            }\n            for (const modelName of Array.from(modelAssociations.keys())) {\n                const parents = modelAssociations.get(modelName);\n                if (parents?.every(x => result.has(x))) {\n                    result.set(modelName, parents);\n                }\n            }\n            Array.from(result.keys()).forEach(x => modelAssociations.delete(x));\n        }\n        schema.namespaces[namespace].modelTopologicalOrdering = result;\n    });\n    return userClasses;\n};\n/**\n * Throws an exception if the schema has *not* been initialized\n * by `initSchema()`.\n *\n * **To be called before trying to access schema.**\n *\n * Currently this only needs to be called in `start()` and `clear()` because\n * all other functions will call start first.\n */\nconst checkSchemaInitialized = () => {\n    if (schema === undefined) {\n        const message = 'Schema is not initialized. DataStore will not function as expected. This could happen if you have multiple versions of DataStore installed. Please see https://docs.amplify.aws/lib/troubleshooting/upgrading/q/platform/js/#check-for-duplicate-versions';\n        logger.error(message);\n        throw new Error(message);\n    }\n};\n/**\n * Throws an exception if the schema is using a codegen version that is not supported.\n *\n * Set the supported version by setting majorVersion and minorVersion\n * This functions similar to ^ version range.\n * The tested codegenVersion major version must exactly match the set majorVersion\n * The tested codegenVersion minor version must be gt or equal to the set minorVersion\n * Example: For a min supported version of 5.4.0 set majorVersion = 5 and minorVersion = 4\n *\n * This regex will not work when setting a supported range with minor version\n * of 2 or more digits.\n * i.e. minorVersion = 10 will not work\n * The regex will work for testing a codegenVersion with multi digit minor\n * versions as long as the minimum minorVersion is single digit.\n * i.e. codegenVersion = 5.30.1, majorVersion = 5, minorVersion = 4 PASSES\n *\n * @param codegenVersion schema codegenVersion\n */\nconst checkSchemaCodegenVersion = (codegenVersion) => {\n    const majorVersion = 3;\n    const minorVersion = 2;\n    let isValid = false;\n    try {\n        const versionParts = codegenVersion.split('.');\n        const [major, minor] = versionParts;\n        isValid = Number(major) === majorVersion && Number(minor) >= minorVersion;\n    }\n    catch (err) {\n        console.log(`Error parsing codegen version: ${codegenVersion}\\n${err}`);\n    }\n    if (!isValid) {\n        const message = `Models were generated with an unsupported version of codegen. Codegen artifacts are from ${codegenVersion || 'an unknown version'}, whereas ^${majorVersion}.${minorVersion}.0 is required. ` +\n            \"Update to the latest CLI and run 'amplify codegen models'.\";\n        logger.error(message);\n        throw new Error(message);\n    }\n};\nconst createTypeClasses = namespace => {\n    const classes = {};\n    Object.entries(namespace.models).forEach(([modelName, modelDefinition]) => {\n        const clazz = createModelClass(modelDefinition);\n        classes[modelName] = clazz;\n        modelNamespaceMap.set(clazz, namespace.name);\n    });\n    Object.entries(namespace.nonModels || {}).forEach(([typeName, typeDefinition]) => {\n        const clazz = createNonModelClass(typeDefinition);\n        classes[typeName] = clazz;\n    });\n    return classes;\n};\n/**\n * Collection of instantiated models to allow storage of metadata apart from\n * the model visible to the consuming app -- in case the app doesn't have\n * metadata fields (_version, _deleted, etc.) exposed on the model itself.\n */\nconst instancesMetadata = new WeakSet();\nfunction modelInstanceCreator(ModelConstructor, init) {\n    instancesMetadata.add(init);\n    return new ModelConstructor(init);\n}\nconst validateModelFields = (modelDefinition) => (k, v) => {\n    const fieldDefinition = modelDefinition.fields[k];\n    if (fieldDefinition !== undefined) {\n        const { type, isRequired, isArrayNullable, name, isArray } = fieldDefinition;\n        const timestamps = isSchemaModelWithAttributes(modelDefinition)\n            ? getTimestampFields(modelDefinition)\n            : {};\n        const isTimestampField = !!timestamps[name];\n        if (((!isArray && isRequired) || (isArray && !isArrayNullable)) &&\n            !isTimestampField &&\n            (v === null || v === undefined)) {\n            throw new Error(`Field ${name} is required`);\n        }\n        if (isSchemaModelWithAttributes(modelDefinition) &&\n            !isIdManaged(modelDefinition)) {\n            const keys = extractPrimaryKeyFieldNames(modelDefinition);\n            if (keys.includes(k) && v === '') {\n                logger.error(errorMessages.idEmptyString, { k, value: v });\n                throw new Error(errorMessages.idEmptyString);\n            }\n        }\n        if (isGraphQLScalarType(type)) {\n            const jsType = GraphQLScalarType.getJSType(type);\n            const validateScalar = GraphQLScalarType.getValidationFunction(type);\n            if (type === 'AWSJSON') {\n                if (typeof v === jsType) {\n                    return;\n                }\n                if (typeof v === 'string') {\n                    try {\n                        JSON.parse(v);\n                        return;\n                    }\n                    catch (error) {\n                        throw new Error(`Field ${name} is an invalid JSON object. ${v}`);\n                    }\n                }\n            }\n            if (isArray) {\n                let errorTypeText = jsType;\n                if (!isRequired) {\n                    errorTypeText = `${jsType} | null | undefined`;\n                }\n                if (!Array.isArray(v) && !isArrayNullable) {\n                    throw new Error(`Field ${name} should be of type [${errorTypeText}], ${typeof v} received. ${v}`);\n                }\n                if (!isNullOrUndefined(v) &&\n                    v.some(e => isNullOrUndefined(e) ? isRequired : typeof e !== jsType)) {\n                    const elemTypes = v\n                        .map(e => (e === null ? 'null' : typeof e))\n                        .join(',');\n                    throw new Error(`All elements in the ${name} array should be of type ${errorTypeText}, [${elemTypes}] received. ${v}`);\n                }\n                if (validateScalar && !isNullOrUndefined(v)) {\n                    const validationStatus = v.map(e => {\n                        if (!isNullOrUndefined(e)) {\n                            return validateScalar(e);\n                        }\n                        else if (isNullOrUndefined(e) && !isRequired) {\n                            return true;\n                        }\n                        else {\n                            return false;\n                        }\n                    });\n                    if (!validationStatus.every(s => s)) {\n                        throw new Error(`All elements in the ${name} array should be of type ${type}, validation failed for one or more elements. ${v}`);\n                    }\n                }\n            }\n            else if (!isRequired && v === undefined) ;\n            else if (typeof v !== jsType && v !== null) {\n                throw new Error(`Field ${name} should be of type ${jsType}, ${typeof v} received. ${v}`);\n            }\n            else if (!isNullOrUndefined(v) &&\n                validateScalar &&\n                !validateScalar(v) // TODO: why never, TS ... why ...\n            ) {\n                throw new Error(`Field ${name} should be of type ${type}, validation failed. ${v}`);\n            }\n        }\n        else if (isNonModelFieldType(type)) {\n            // do not check non model fields if undefined or null\n            if (!isNullOrUndefined(v)) {\n                const subNonModelDefinition = schema.namespaces.user.nonModels[type.nonModel];\n                const modelValidator = validateModelFields(subNonModelDefinition);\n                if (isArray) {\n                    let errorTypeText = type.nonModel;\n                    if (!isRequired) {\n                        errorTypeText = `${type.nonModel} | null | undefined`;\n                    }\n                    if (!Array.isArray(v)) {\n                        throw new Error(`Field ${name} should be of type [${errorTypeText}], ${typeof v} received. ${v}`);\n                    }\n                    v.forEach(item => {\n                        if ((isNullOrUndefined(item) && isRequired) ||\n                            (typeof item !== 'object' && typeof item !== 'undefined')) {\n                            throw new Error(`All elements in the ${name} array should be of type ${type.nonModel}, [${typeof item}] received. ${item}`);\n                        }\n                        if (!isNullOrUndefined(item)) {\n                            Object.keys(subNonModelDefinition.fields).forEach(subKey => {\n                                modelValidator(subKey, item[subKey]);\n                            });\n                        }\n                    });\n                }\n                else {\n                    if (typeof v !== 'object') {\n                        throw new Error(`Field ${name} should be of type ${type.nonModel}, ${typeof v} recieved. ${v}`);\n                    }\n                    Object.keys(subNonModelDefinition.fields).forEach(subKey => {\n                        modelValidator(subKey, v[subKey]);\n                    });\n                }\n            }\n        }\n    }\n};\nconst castInstanceType = (modelDefinition, k, v) => {\n    const { isArray, type } = modelDefinition.fields[k] || {};\n    // attempt to parse stringified JSON\n    if (typeof v === 'string' &&\n        (isArray ||\n            type === 'AWSJSON' ||\n            isNonModelFieldType(type) ||\n            isModelFieldType(type))) {\n        try {\n            return JSON.parse(v);\n        }\n        catch {\n            // if JSON is invalid, don't throw and let modelValidator handle it\n        }\n    }\n    // cast from numeric representation of boolean to JS boolean\n    if (typeof v === 'number' && type === 'Boolean') {\n        return Boolean(v);\n    }\n    return v;\n};\n/**\n * Records the patches (as if against an empty object) used to initialize\n * an instance of a Model. This can be used for determining which fields to\n * send to the cloud durnig a CREATE mutation.\n */\nconst initPatches = new WeakMap();\n/**\n * Attempts to apply type-aware, casted field values from a given `init`\n * object to the given `draft`.\n *\n * @param init The initialization object to extract field values from.\n * @param modelDefinition The definition describing the target object shape.\n * @param draft The draft to apply field values to.\n */\nconst initializeInstance = (init, modelDefinition, draft) => {\n    const modelValidator = validateModelFields(modelDefinition);\n    Object.entries(init).forEach(([k, v]) => {\n        const parsedValue = castInstanceType(modelDefinition, k, v);\n        modelValidator(k, parsedValue);\n        draft[k] = parsedValue;\n    });\n};\n/**\n * Updates a draft to standardize its customer-defined fields so that they are\n * consistent with the data as it would look after having been synchronized from\n * Cloud storage.\n *\n * The exceptions to this are:\n *\n * 1. Non-schema/Internal [sync] metadata fields.\n * 2. Cloud-managed fields, which are `null` until set by cloud storage.\n *\n * This function should be expanded if/when deviations between canonical Cloud\n * storage data and locally managed data are found. For now, the known areas\n * that require normalization are:\n *\n * 1. Ensuring all non-metadata fields are *defined*. (I.e., turn `undefined` -> `null`.)\n *\n * @param modelDefinition Definition for the draft. Used to discover all fields.\n * @param draft The instance draft to apply normalizations to.\n */\nconst normalize = (modelDefinition, draft) => {\n    for (const k of Object.keys(modelDefinition.fields)) {\n        if (draft[k] === undefined)\n            draft[k] = null;\n    }\n};\nconst createModelClass = (modelDefinition) => {\n    const clazz = class Model {\n        constructor(init) {\n            // we create a base instance first so we can distinguish which fields were explicitly\n            // set by customer code versus those set by normalization. only those fields\n            // which are explicitly set by customers should be part of create mutations.\n            let patches = [];\n            const baseInstance = produce(this, (draft) => {\n                initializeInstance(init, modelDefinition, draft);\n                // model is initialized inside a DataStore component (e.g. by Sync Engine, Storage Engine, etc.)\n                const isInternallyInitialized = instancesMetadata.has(init);\n                const modelInstanceMetadata = isInternallyInitialized\n                    ? init\n                    : {};\n                const { id: _id } = modelInstanceMetadata;\n                if (isIdManaged(modelDefinition)) {\n                    const isInternalModel = _id !== null && _id !== undefined;\n                    const id = isInternalModel\n                        ? _id\n                        : modelDefinition.syncable\n                            ? amplifyUuid()\n                            : ulid();\n                    draft.id = id;\n                }\n                else if (isIdOptionallyManaged(modelDefinition)) {\n                    // only auto-populate if the id was not provided\n                    draft.id =\n                        draft.id || amplifyUuid();\n                }\n                if (!isInternallyInitialized) {\n                    checkReadOnlyPropertyOnCreate(draft, modelDefinition);\n                }\n                const { _version, _lastChangedAt, _deleted } = modelInstanceMetadata;\n                if (modelDefinition.syncable) {\n                    draft._version = _version;\n                    draft._lastChangedAt = _lastChangedAt;\n                    draft._deleted = _deleted;\n                }\n            }, p => (patches = p));\n            // now that we have a list of patches that encapsulate the explicit, customer-provided\n            // fields, we can normalize. patches from normalization are ignored, because the changes\n            // are only create to provide a consistent view of the data for fields pre/post sync\n            // where possible. (not all fields can be normalized pre-sync, because they're generally\n            // \"cloud managed\" fields, like createdAt and updatedAt.)\n            const normalized = produce(baseInstance, (draft) => {\n                normalize(modelDefinition, draft);\n            });\n            initPatches.set(normalized, patches);\n            return normalized;\n        }\n        static copyOf(source, fn) {\n            const modelConstructor = Object.getPrototypeOf(source || {}).constructor;\n            if (!isValidModelConstructor(modelConstructor)) {\n                const msg = 'The source object is not a valid model';\n                logger.error(msg, { source });\n                throw new Error(msg);\n            }\n            let patches = [];\n            const model = produce(source, draft => {\n                fn(draft);\n                const keyNames = extractPrimaryKeyFieldNames(modelDefinition);\n                // Keys are immutable\n                keyNames.forEach(key => {\n                    if (draft[key] !== source[key]) {\n                        logger.warn(`copyOf() does not update PK fields. The '${key}' update is being ignored.`, { source });\n                    }\n                    draft[key] = source[key];\n                });\n                const modelValidator = validateModelFields(modelDefinition);\n                Object.entries(draft).forEach(([k, v]) => {\n                    const parsedValue = castInstanceType(modelDefinition, k, v);\n                    modelValidator(k, parsedValue);\n                });\n                normalize(modelDefinition, draft);\n            }, p => (patches = p));\n            const hasExistingPatches = modelPatchesMap.has(source);\n            if (patches.length || hasExistingPatches) {\n                if (hasExistingPatches) {\n                    const [existingPatches, existingSource] = modelPatchesMap.get(source);\n                    const mergedPatches = mergePatches(existingSource, existingPatches, patches);\n                    modelPatchesMap.set(model, [mergedPatches, existingSource]);\n                    checkReadOnlyPropertyOnUpdate(mergedPatches, modelDefinition);\n                }\n                else {\n                    modelPatchesMap.set(model, [patches, source]);\n                    checkReadOnlyPropertyOnUpdate(patches, modelDefinition);\n                }\n            }\n            else {\n                // always register patches when performing a copyOf, even if the\n                // patches list is empty. this allows `save()` to recognize when an\n                // instance is the result of a `copyOf()`. without more significant\n                // refactoring, this is the only way for `save()` to know which\n                // diffs (patches) are relevant for `storage` to use in building\n                // the list of \"changed\" fields for mutations.\n                modelPatchesMap.set(model, [[], source]);\n            }\n            return attached(model, ModelAttachment.DataStore);\n        }\n        // \"private\" method (that's hidden via `Setting`) for `withSSRContext` to use\n        // to gain access to `modelInstanceCreator` and `clazz` for persisting IDs from server to client.\n        static fromJSON(json) {\n            if (Array.isArray(json)) {\n                return json.map(init => this.fromJSON(init));\n            }\n            const instance = modelInstanceCreator(clazz, json);\n            const modelValidator = validateModelFields(modelDefinition);\n            Object.entries(instance).forEach(([k, v]) => {\n                modelValidator(k, v);\n            });\n            return attached(instance, ModelAttachment.DataStore);\n        }\n    };\n    clazz[immerable] = true;\n    Object.defineProperty(clazz, 'name', { value: modelDefinition.name });\n    // Add getters/setters for relationship fields.\n    //  getter - for lazy loading\n    //  setter - for FK management\n    const allModelRelationships = ModelRelationship.allFrom({\n        builder: clazz,\n        schema: modelDefinition,\n        pkField: extractPrimaryKeyFieldNames(modelDefinition),\n    });\n    for (const relationship of allModelRelationships) {\n        const { field } = relationship;\n        Object.defineProperty(clazz.prototype, modelDefinition.fields[field].name, {\n            set(model) {\n                if (!(typeof model === 'object' || typeof model === 'undefined'))\n                    return;\n                // if model is undefined or null, the connection should be removed\n                if (model) {\n                    // Avoid validation error when processing AppSync response with nested\n                    // selection set. Nested entitites lack version field and can not be validated\n                    // TODO: explore a more reliable method to solve this\n                    if (Object.prototype.hasOwnProperty.call(model, '_version')) {\n                        const modelConstructor = Object.getPrototypeOf(model || {})\n                            .constructor;\n                        if (!isValidModelConstructor(modelConstructor)) {\n                            const msg = `Value passed to ${modelDefinition.name}.${field} is not a valid instance of a model`;\n                            logger.error(msg, { model });\n                            throw new Error(msg);\n                        }\n                        if (modelConstructor.name.toLowerCase() !==\n                            relationship.remoteModelConstructor.name.toLowerCase()) {\n                            const msg = `Value passed to ${modelDefinition.name}.${field} is not an instance of ${relationship.remoteModelConstructor.name}`;\n                            logger.error(msg, { model });\n                            throw new Error(msg);\n                        }\n                    }\n                }\n                // if the relationship can be managed automagically, set the FK's\n                if (relationship.isComplete) {\n                    for (let i = 0; i < relationship.localJoinFields.length; i++) {\n                        this[relationship.localJoinFields[i]] =\n                            model?.[relationship.remoteJoinFields[i]];\n                    }\n                    const instanceMemos = modelInstanceAssociationsMap.has(this)\n                        ? modelInstanceAssociationsMap.get(this)\n                        : modelInstanceAssociationsMap.set(this, {}).get(this);\n                    instanceMemos[field] = model || undefined;\n                }\n            },\n            get() {\n                /**\n                 * Bucket for holding related models instances specific to `this` instance.\n                 */\n                const instanceMemos = modelInstanceAssociationsMap.has(this)\n                    ? modelInstanceAssociationsMap.get(this)\n                    : modelInstanceAssociationsMap.set(this, {}).get(this);\n                // if the memos already has a result for this field, we'll use it.\n                // there is no \"cache\" invalidation of any kind; memos are permanent to\n                // keep an immutable perception of the instance.\n                if (!Object.prototype.hasOwnProperty.call(instanceMemos, field)) {\n                    // before we populate the memo, we need to know where to look for relatives.\n                    // today, this only supports DataStore. Models aren't managed elsewhere in Amplify.\n                    if (getAttachment(this) === ModelAttachment.DataStore) {\n                        // when we fetch the results using a query constructed under the guidance\n                        // of the relationship metadata, we DO NOT AWAIT resolution. we want to\n                        // drop the promise into the memo's synchronously, eliminating the chance\n                        // for a race.\n                        const resultPromise = instance.query(relationship.remoteModelConstructor, base => base.and(q => {\n                            return relationship.remoteJoinFields.map((joinField, index) => {\n                                // TODO: anything we can use instead of `any` here?\n                                return q[joinField].eq(this[relationship.localJoinFields[index]]);\n                            });\n                        }));\n                        // results in hand, how we return them to the caller depends on the relationship type.\n                        if (relationship.type === 'HAS_MANY') {\n                            // collections should support async iteration, even though we don't\n                            // leverage it fully [yet].\n                            instanceMemos[field] = new AsyncCollection(resultPromise);\n                        }\n                        else {\n                            // non-collections should only ever return 1 value *or nothing*.\n                            // if we have more than 1 record, something's amiss. it's not our job\n                            // pick a result for the customer. it's our job to say \"something's wrong.\"\n                            instanceMemos[field] = resultPromise.then(rows => {\n                                if (rows.length > 1) {\n                                    // should never happen for a HAS_ONE or BELONGS_TO.\n                                    const err = new Error(`\n\t\t\t\t\t\t\t\t\tData integrity error.\n\t\t\t\t\t\t\t\t\tToo many records found for a HAS_ONE/BELONGS_TO field '${modelDefinition.name}.${field}'\n\t\t\t\t\t\t\t\t`);\n                                    console.error(err);\n                                    throw err;\n                                }\n                                else {\n                                    return rows[0];\n                                }\n                            });\n                        }\n                    }\n                    else if (getAttachment(this) === ModelAttachment.API) {\n                        throw new Error('Lazy loading from API is not yet supported!');\n                    }\n                    else {\n                        if (relationship.type === 'HAS_MANY') {\n                            return new AsyncCollection([]);\n                        }\n                        else {\n                            return Promise.resolve(undefined);\n                        }\n                    }\n                }\n                return instanceMemos[field];\n            },\n        });\n    }\n    return clazz;\n};\n/**\n * An eventually loaded related model instance.\n */\nclass AsyncItem extends Promise {\n}\n/**\n * A collection of related model instances.\n *\n * This collection can be async-iterated or turned directly into an array using `toArray()`.\n */\nclass AsyncCollection {\n    constructor(values) {\n        this.values = values;\n    }\n    /**\n     * Facilitates async iteration.\n     *\n     * ```ts\n     * for await (const item of collection) {\n     *   handle(item)\n     * }\n     * ```\n     *\n     * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for-await...of\n     */\n    [Symbol.asyncIterator]() {\n        let values;\n        let index = 0;\n        return {\n            next: async () => {\n                if (!values)\n                    values = await this.values;\n                if (index < values.length) {\n                    const result = {\n                        value: values[index],\n                        done: false,\n                    };\n                    index++;\n                    return result;\n                }\n                return {\n                    value: null,\n                    done: true,\n                };\n            },\n        };\n    }\n    /**\n     * Turns the collection into an array, up to the amount specified in `max` param.\n     *\n     * ```ts\n     * const all = await collection.toArray();\n     * const first100 = await collection.toArray({max: 100});\n     * ```\n     */\n    async toArray({ max = Number.MAX_SAFE_INTEGER, } = {}) {\n        const output = [];\n        let i = 0;\n        for await (const element of this) {\n            if (i < max) {\n                output.push(element);\n                i++;\n            }\n            else {\n                break;\n            }\n        }\n        return output;\n    }\n}\nconst checkReadOnlyPropertyOnCreate = (draft, modelDefinition) => {\n    const modelKeys = Object.keys(draft);\n    const { fields } = modelDefinition;\n    modelKeys.forEach(key => {\n        if (fields[key] && fields[key].isReadOnly) {\n            throw new Error(`${key} is read-only.`);\n        }\n    });\n};\nconst checkReadOnlyPropertyOnUpdate = (patches, modelDefinition) => {\n    const patchArray = patches.map(p => [p.path[0], p.value]);\n    const { fields } = modelDefinition;\n    patchArray.forEach(([key, val]) => {\n        if (!val || !fields[key])\n            return;\n        if (fields[key].isReadOnly) {\n            throw new Error(`${key} is read-only.`);\n        }\n    });\n};\nconst createNonModelClass = (typeDefinition) => {\n    const clazz = class Model {\n        constructor(init) {\n            const instance = produce(this, (draft) => {\n                initializeInstance(init, typeDefinition, draft);\n            });\n            return instance;\n        }\n    };\n    clazz[immerable] = true;\n    Object.defineProperty(clazz, 'name', { value: typeDefinition.name });\n    registerNonModelClass(clazz);\n    return clazz;\n};\nfunction isQueryOne(obj) {\n    return typeof obj === 'string';\n}\nfunction defaultConflictHandler(conflictData) {\n    const { localModel, modelConstructor, remoteModel } = conflictData;\n    const { _version } = remoteModel;\n    return modelInstanceCreator(modelConstructor, { ...localModel, _version });\n}\nfunction defaultErrorHandler(error) {\n    logger.warn(error);\n}\nfunction getModelConstructorByModelName(namespaceName, modelName) {\n    let result;\n    switch (namespaceName) {\n        case DATASTORE:\n            result = dataStoreClasses[modelName];\n            break;\n        case USER:\n            result = userClasses[modelName];\n            break;\n        case SYNC:\n            result = syncClasses[modelName];\n            break;\n        case STORAGE:\n            result = storageClasses[modelName];\n            break;\n        default:\n            throw new Error(`Invalid namespace: ${namespaceName}`);\n    }\n    if (isValidModelConstructor(result)) {\n        return result;\n    }\n    else {\n        const msg = `Model name is not valid for namespace. modelName: ${modelName}, namespace: ${namespaceName}`;\n        logger.error(msg);\n        throw new Error(msg);\n    }\n}\n/**\n * Queries the DataStore metadata tables to see if they are the expected\n * version. If not, clobbers the whole DB. If so, leaves them alone.\n * Otherwise, simply writes the schema version.\n *\n * SIDE EFFECT:\n * 1. Creates a transaction\n * 1. Updates data.\n *\n * @param storage Storage adapter containing the metadata.\n * @param version The expected schema version.\n */\nasync function checkSchemaVersion(storage, version) {\n    const SettingCtor = dataStoreClasses.Setting;\n    const modelDefinition = schema.namespaces[DATASTORE].models.Setting;\n    await storage.runExclusive(async (s) => {\n        const [schemaVersionSetting] = await s.query(SettingCtor, ModelPredicateCreator.createFromAST(modelDefinition, {\n            and: { key: { eq: SETTING_SCHEMA_VERSION } },\n        }), { page: 0, limit: 1 });\n        if (schemaVersionSetting !== undefined &&\n            schemaVersionSetting.value !== undefined) {\n            const storedValue = JSON.parse(schemaVersionSetting.value);\n            if (storedValue !== version) {\n                await s.clear(false);\n            }\n        }\n        else {\n            await s.save(modelInstanceCreator(SettingCtor, {\n                key: SETTING_SCHEMA_VERSION,\n                value: JSON.stringify(version),\n            }));\n        }\n    });\n}\nlet syncSubscription;\nfunction getNamespace() {\n    const namespace = {\n        name: DATASTORE,\n        relationships: {},\n        enums: {},\n        nonModels: {},\n        models: {\n            Setting: {\n                name: 'Setting',\n                pluralName: 'Settings',\n                syncable: false,\n                fields: {\n                    id: {\n                        name: 'id',\n                        type: 'ID',\n                        isRequired: true,\n                        isArray: false,\n                    },\n                    key: {\n                        name: 'key',\n                        type: 'String',\n                        isRequired: true,\n                        isArray: false,\n                    },\n                    value: {\n                        name: 'value',\n                        type: 'String',\n                        isRequired: true,\n                        isArray: false,\n                    },\n                },\n            },\n        },\n    };\n    return namespace;\n}\nvar DataStoreState;\n(function (DataStoreState) {\n    DataStoreState[\"NotRunning\"] = \"Not Running\";\n    DataStoreState[\"Starting\"] = \"Starting\";\n    DataStoreState[\"Running\"] = \"Running\";\n    DataStoreState[\"Stopping\"] = \"Stopping\";\n    DataStoreState[\"Clearing\"] = \"Clearing\";\n})(DataStoreState || (DataStoreState = {}));\n// TODO: How can we get rid of the non-null assertions?\n// https://github.com/aws-amplify/amplify-js/pull/10477/files#r1007363485\nclass DataStore {\n    constructor() {\n        // reference to configured category instances. Used for preserving SSR context\n        this.InternalAPI = InternalAPI;\n        this.Cache = Cache;\n        // Non-null assertions (bang operator) have been added to most of these properties\n        // to make TS happy. These properties are all expected to be set immediately after\n        // construction.\n        // TODO: Refactor to use proper DI if possible. If not possible, change these to\n        // optionals and implement conditional checks throughout. Rinse/repeat on all\n        // sync engine processors, storage engine, adapters, etc..\n        this.amplifyConfig = {};\n        this.syncPredicates = new WeakMap();\n        // object that gets passed to descendent classes. Allows us to pass these down by reference\n        this.amplifyContext = {\n            InternalAPI: this.InternalAPI,\n        };\n        /**\n         * **IMPORTANT!**\n         *\n         * Accumulator for background things that can **and MUST** be called when\n         * DataStore stops.\n         *\n         * These jobs **MUST** be *idempotent promises* that resolve ONLY\n         * once the intended jobs are completely finished and/or otherwise destroyed\n         * and cleaned up with ZERO outstanding:\n         *\n         * 1. side effects (e.g., state changes)\n         * 1. callbacks\n         * 1. subscriptions\n         * 1. calls to storage\n         * 1. *etc.*\n         *\n         * Methods that create pending promises, subscriptions, callbacks, or any\n         * type of side effect **MUST** be registered with the manager. And, a new\n         * manager must be created after each `exit()`.\n         *\n         * Failure to comply will put DataStore into a highly unpredictable state\n         * when it needs to stop or clear -- which occurs when restarting with new\n         * sync expressions, during testing, and potentially during app code\n         * recovery handling, etc..\n         *\n         * It is up to the discretion of each disposer whether to wait for job\n         * completion or to cancel operations and issue failures *as long as the\n         * disposer returns in a reasonable amount of time.*\n         *\n         * (Reasonable = *seconds*, not minutes.)\n         */\n        this.runningProcesses = new BackgroundProcessManager();\n        /**\n         * Indicates what state DataStore is in.\n         *\n         * Not [yet?] used for actual state management; but for messaging\n         * when errors occur, to help troubleshoot.\n         */\n        this.state = DataStoreState.NotRunning;\n        /**\n         * If not already done:\n         * 1. Attaches and initializes storage.\n         * 2. Loads the schema and records metadata.\n         * 3. If `this.amplifyConfig.aws_appsync_graphqlEndpoint` contains a URL,\n         * attaches a sync engine, starts it, and subscribes.\n         */\n        this.start = async () => {\n            return this.runningProcesses\n                .add(async () => {\n                this.state = DataStoreState.Starting;\n                if (this.initialized === undefined) {\n                    logger.debug('Starting DataStore');\n                    this.initialized = new Promise((resolve, reject) => {\n                        this.initResolve = resolve;\n                        this.initReject = reject;\n                    });\n                }\n                else {\n                    await this.initialized;\n                    return;\n                }\n                this.storage = new ExclusiveStorage(schema, namespaceResolver, getModelConstructorByModelName, modelInstanceCreator, this.storageAdapter, this.sessionId);\n                await this.storage.init();\n                checkSchemaInitialized();\n                await checkSchemaVersion(this.storage, schema.version);\n                const { aws_appsync_graphqlEndpoint } = this.amplifyConfig;\n                if (aws_appsync_graphqlEndpoint) {\n                    logger.debug('GraphQL endpoint available', aws_appsync_graphqlEndpoint);\n                    this.syncPredicates = await this.processSyncExpressions();\n                    this.sync = new SyncEngine(schema, namespaceResolver, syncClasses, userClasses, this.storage, modelInstanceCreator, this.conflictHandler, this.errorHandler, this.syncPredicates, this.amplifyConfig, this.authModeStrategy, this.amplifyContext, this.connectivityMonitor);\n                    const fullSyncIntervalInMilliseconds = this.fullSyncInterval * 1000 * 60; // fullSyncInterval from param is in minutes\n                    syncSubscription = this.sync\n                        .start({ fullSyncInterval: fullSyncIntervalInMilliseconds })\n                        .subscribe({\n                        next: ({ type, data }) => {\n                            /**\n                             * In Node, we need to wait for queries to be synced to prevent returning empty arrays.\n                             * In non-Node environments (the browser or React Native), we can begin returning data\n                             * once subscriptions are in place.\n                             */\n                            const readyType = isNode()\n                                ? ControlMessage.SYNC_ENGINE_SYNC_QUERIES_READY\n                                : ControlMessage.SYNC_ENGINE_STORAGE_SUBSCRIBED;\n                            if (type === readyType) {\n                                this.initResolve();\n                            }\n                            Hub.dispatch('datastore', {\n                                event: type,\n                                data,\n                            });\n                        },\n                        error: err => {\n                            logger.warn('Sync error', err);\n                            this.initReject();\n                        },\n                    });\n                }\n                else {\n                    logger.warn(\"Data won't be synchronized. No GraphQL endpoint configured. Did you forget `Amplify.configure(awsconfig)`?\", {\n                        config: this.amplifyConfig,\n                    });\n                    this.initResolve();\n                }\n                await this.initialized;\n                this.state = DataStoreState.Running;\n            }, 'datastore start')\n                .catch(this.handleAddProcError('DataStore.start()'));\n        };\n        this.query = async (modelConstructor, identifierOrCriteria, paginationProducer) => {\n            return this.runningProcesses\n                .add(async () => {\n                await this.start();\n                let result;\n                if (!this.storage) {\n                    throw new Error('No storage to query');\n                }\n                // #region Input validation\n                if (!isValidModelConstructor(modelConstructor)) {\n                    const msg = 'Constructor is not for a valid model';\n                    logger.error(msg, { modelConstructor });\n                    throw new Error(msg);\n                }\n                if (typeof identifierOrCriteria === 'string') {\n                    if (paginationProducer !== undefined) {\n                        logger.warn('Pagination is ignored when querying by id');\n                    }\n                }\n                const modelDefinition = getModelDefinition(modelConstructor);\n                if (!modelDefinition) {\n                    throw new Error('Invalid model definition provided!');\n                }\n                const pagination = this.processPagination(modelDefinition, paginationProducer);\n                const keyFields = extractPrimaryKeyFieldNames(modelDefinition);\n                if (isQueryOne(identifierOrCriteria)) {\n                    if (keyFields.length > 1) {\n                        const msg = errorMessages.queryByPkWithCompositeKeyPresent;\n                        logger.error(msg, { keyFields });\n                        throw new Error(msg);\n                    }\n                    const predicate = ModelPredicateCreator.createFromFlatEqualities(modelDefinition, { [keyFields[0]]: identifierOrCriteria });\n                    result = await this.storage.query(modelConstructor, predicate, pagination);\n                }\n                else {\n                    // Object is being queried using object literal syntax\n                    if (isIdentifierObject(identifierOrCriteria, modelDefinition)) {\n                        const predicate = ModelPredicateCreator.createForPk(modelDefinition, identifierOrCriteria);\n                        result = await this.storage.query(modelConstructor, predicate, pagination);\n                    }\n                    else if (!identifierOrCriteria ||\n                        isPredicatesAll(identifierOrCriteria)) {\n                        result = await this.storage?.query(modelConstructor, undefined, pagination);\n                    }\n                    else {\n                        const seedPredicate = recursivePredicateFor({\n                            builder: modelConstructor,\n                            schema: modelDefinition,\n                            pkField: extractPrimaryKeyFieldNames(modelDefinition),\n                        });\n                        const predicate = internals(identifierOrCriteria(seedPredicate));\n                        result = (await predicate.fetch(this.storage));\n                        result = inMemoryPagination(result, pagination);\n                    }\n                }\n                // #endregion\n                const returnOne = isQueryOne(identifierOrCriteria) ||\n                    isIdentifierObject(identifierOrCriteria, modelDefinition);\n                return attached(returnOne ? result[0] : result, ModelAttachment.DataStore);\n            }, 'datastore query')\n                .catch(this.handleAddProcError('DataStore.query()'));\n        };\n        this.save = async (model, condition) => {\n            return this.runningProcesses\n                .add(async () => {\n                await this.start();\n                if (!this.storage) {\n                    throw new Error('No storage to save to');\n                }\n                // Immer patches for constructing a correct update mutation input\n                // Allows us to only include changed fields for updates\n                const updatedPatchesTuple = modelPatchesMap.get(model);\n                // Immer patches for initial object construction. These are used if\n                // there are no `update` patches under the assumption we're performing\n                // a CREATE and wish to send only explicitly specified fields to the cloud.\n                const initPatchesTuple = initPatches.has(model)\n                    ? [initPatches.get(model), {}]\n                    : undefined;\n                // favor update patches over init/create patches, because init patches\n                // are ALWAYS present, whereas update patches are only present if copyOf\n                // was used to create the instance.\n                const patchesTuple = updatedPatchesTuple || initPatchesTuple;\n                const modelConstructor = model\n                    ? model.constructor\n                    : undefined;\n                if (!isValidModelConstructor(modelConstructor)) {\n                    const msg = 'Object is not an instance of a valid model';\n                    logger.error(msg, { model });\n                    throw new Error(msg);\n                }\n                const modelDefinition = getModelDefinition(modelConstructor);\n                if (!modelDefinition) {\n                    throw new Error('Model Definition could not be found for model');\n                }\n                const modelMeta = {\n                    builder: modelConstructor,\n                    schema: modelDefinition,\n                    pkField: extractPrimaryKeyFieldNames(modelDefinition),\n                };\n                await this.storage.runExclusive(async (s) => {\n                    // no enforcement for HAS_MANY on save, because the ~related~ entities\n                    // hold the FK in that case.\n                    const nonHasManyRelationships = ModelRelationship.allFrom(modelMeta).filter(r => r.type === 'BELONGS_TO');\n                    for (const relationship of nonHasManyRelationships) {\n                        const queryObject = relationship.createRemoteQueryObject(model);\n                        if (queryObject !== null) {\n                            const related = await s.query(relationship.remoteModelConstructor, ModelPredicateCreator.createFromFlatEqualities(relationship.remoteDefinition, queryObject));\n                            if (related.length === 0) {\n                                throw new Error([\n                                    `Data integrity error. You tried to save a ${modelDefinition.name} (${JSON.stringify(model)})`,\n                                    `but the instance assigned to the \"${relationship.field}\" property`,\n                                    `does not exist in the local database. If you're trying to create the related`,\n                                    `\"${relationship.remoteDefinition?.name}\", you must save it independently first.`,\n                                ].join(' '));\n                            }\n                        }\n                    }\n                });\n                const producedCondition = condition\n                    ? internals(condition(predicateFor(modelMeta))).toStoragePredicate()\n                    : undefined;\n                const [savedModel] = await this.storage.runExclusive(async (s) => {\n                    await s.save(model, producedCondition, undefined, patchesTuple);\n                    return s.query(modelConstructor, ModelPredicateCreator.createForPk(modelDefinition, model));\n                });\n                return attached(savedModel, ModelAttachment.DataStore);\n            }, 'datastore save')\n                .catch(this.handleAddProcError('DataStore.save()'));\n        };\n        this.setConflictHandler = (config) => {\n            const { DataStore: configDataStore } = config;\n            const conflictHandlerIsDefault = () => this.conflictHandler === defaultConflictHandler;\n            if (configDataStore && configDataStore.conflictHandler) {\n                return configDataStore.conflictHandler;\n            }\n            if (conflictHandlerIsDefault() && config.conflictHandler) {\n                return config.conflictHandler;\n            }\n            return this.conflictHandler || defaultConflictHandler;\n        };\n        this.setErrorHandler = (config) => {\n            const { DataStore: configDataStore } = config;\n            const errorHandlerIsDefault = () => this.errorHandler === defaultErrorHandler;\n            if (configDataStore && configDataStore.errorHandler) {\n                return configDataStore.errorHandler;\n            }\n            if (errorHandlerIsDefault() && config.errorHandler) {\n                return config.errorHandler;\n            }\n            return this.errorHandler || defaultErrorHandler;\n        };\n        this.delete = async (modelOrConstructor, identifierOrCriteria) => {\n            return this.runningProcesses\n                .add(async () => {\n                await this.start();\n                if (!this.storage) {\n                    throw new Error('No storage to delete from');\n                }\n                let condition;\n                if (!modelOrConstructor) {\n                    const msg = 'Model or Model Constructor required';\n                    logger.error(msg, { modelOrConstructor });\n                    throw new Error(msg);\n                }\n                if (isValidModelConstructor(modelOrConstructor)) {\n                    const modelConstructor = modelOrConstructor;\n                    if (!identifierOrCriteria) {\n                        const msg = 'Id to delete or criteria required. Do you want to delete all? Pass Predicates.ALL';\n                        logger.error(msg, { identifierOrCriteria });\n                        throw new Error(msg);\n                    }\n                    const modelDefinition = getModelDefinition(modelConstructor);\n                    if (!modelDefinition) {\n                        throw new Error('Could not find model definition for modelConstructor.');\n                    }\n                    if (typeof identifierOrCriteria === 'string') {\n                        const keyFields = extractPrimaryKeyFieldNames(modelDefinition);\n                        if (keyFields.length > 1) {\n                            const msg = errorMessages.deleteByPkWithCompositeKeyPresent;\n                            logger.error(msg, { keyFields });\n                            throw new Error(msg);\n                        }\n                        condition = ModelPredicateCreator.createFromFlatEqualities(modelDefinition, { [keyFields[0]]: identifierOrCriteria });\n                    }\n                    else {\n                        if (isIdentifierObject(identifierOrCriteria, modelDefinition)) {\n                            condition = ModelPredicateCreator.createForPk(modelDefinition, identifierOrCriteria);\n                        }\n                        else {\n                            condition = internals(identifierOrCriteria(predicateFor({\n                                builder: modelConstructor,\n                                schema: modelDefinition,\n                                pkField: extractPrimaryKeyFieldNames(modelDefinition),\n                            }))).toStoragePredicate();\n                        }\n                        if (!condition ||\n                            !ModelPredicateCreator.isValidPredicate(condition)) {\n                            const msg = 'Criteria required. Do you want to delete all? Pass Predicates.ALL';\n                            logger.error(msg, { condition });\n                            throw new Error(msg);\n                        }\n                    }\n                    const [deleted] = await this.storage.delete(modelConstructor, condition);\n                    return attached(deleted, ModelAttachment.DataStore);\n                }\n                else {\n                    const model = modelOrConstructor;\n                    const modelConstructor = Object.getPrototypeOf(model || {})\n                        .constructor;\n                    if (!isValidModelConstructor(modelConstructor)) {\n                        const msg = 'Object is not an instance of a valid model';\n                        logger.error(msg, { model });\n                        throw new Error(msg);\n                    }\n                    const modelDefinition = getModelDefinition(modelConstructor);\n                    if (!modelDefinition) {\n                        throw new Error('Could not find model definition for modelConstructor.');\n                    }\n                    const pkPredicate = ModelPredicateCreator.createForPk(modelDefinition, model);\n                    if (identifierOrCriteria) {\n                        if (typeof identifierOrCriteria !== 'function') {\n                            const msg = 'Invalid criteria';\n                            logger.error(msg, { identifierOrCriteria });\n                            throw new Error(msg);\n                        }\n                        condition = internals(identifierOrCriteria(predicateFor({\n                            builder: modelConstructor,\n                            schema: modelDefinition,\n                            pkField: extractPrimaryKeyFieldNames(modelDefinition),\n                        }))).toStoragePredicate();\n                    }\n                    else {\n                        condition = pkPredicate;\n                    }\n                    const [[deleted]] = await this.storage.delete(model, condition);\n                    return attached(deleted, ModelAttachment.DataStore);\n                }\n            }, 'datastore delete')\n                .catch(this.handleAddProcError('DataStore.delete()'));\n        };\n        this.observe = (modelOrConstructor, identifierOrCriteria) => {\n            let executivePredicate;\n            const modelConstructor = modelOrConstructor && isValidModelConstructor(modelOrConstructor)\n                ? modelOrConstructor\n                : undefined;\n            if (modelOrConstructor && modelConstructor === undefined) {\n                const model = modelOrConstructor;\n                const resolvedModelConstructor = model && Object.getPrototypeOf(model).constructor;\n                if (isValidModelConstructor(resolvedModelConstructor)) {\n                    if (identifierOrCriteria) {\n                        logger.warn('idOrCriteria is ignored when using a model instance', {\n                            model,\n                            identifierOrCriteria,\n                        });\n                    }\n                    return this.observe(resolvedModelConstructor, model.id);\n                }\n                else {\n                    const msg = 'The model is not an instance of a PersistentModelConstructor';\n                    logger.error(msg, { model });\n                    throw new Error(msg);\n                }\n            }\n            // observe should not accept object literal syntax\n            if (identifierOrCriteria &&\n                modelConstructor &&\n                isIdentifierObject(identifierOrCriteria, getModelDefinition(modelConstructor))) {\n                const msg = errorMessages.observeWithObjectLiteral;\n                logger.error(msg, { objectLiteral: identifierOrCriteria });\n                throw new Error(msg);\n            }\n            if (identifierOrCriteria !== undefined && modelConstructor === undefined) {\n                const msg = 'Cannot provide criteria without a modelConstructor';\n                logger.error(msg, identifierOrCriteria);\n                throw new Error(msg);\n            }\n            if (modelConstructor && !isValidModelConstructor(modelConstructor)) {\n                const msg = 'Constructor is not for a valid model';\n                logger.error(msg, { modelConstructor });\n                throw new Error(msg);\n            }\n            if (modelConstructor && typeof identifierOrCriteria === 'string') {\n                const buildIdPredicate = seed => seed.id.eq(identifierOrCriteria);\n                executivePredicate = internals(buildIdPredicate(buildSeedPredicate(modelConstructor)));\n            }\n            else if (modelConstructor && typeof identifierOrCriteria === 'function') {\n                executivePredicate = internals(identifierOrCriteria(buildSeedPredicate(modelConstructor)));\n            }\n            return new Observable(observer => {\n                let source;\n                this.runningProcesses\n                    .add(async () => {\n                    await this.start();\n                    // Filter the events returned by Storage according to namespace,\n                    // append original element data, and subscribe to the observable\n                    source = this.storage.observe(modelConstructor)\n                        .pipe(filter(({ model }) => namespaceResolver(model) === USER))\n                        .subscribe({\n                        next: item => this.runningProcesses.isOpen &&\n                            this.runningProcesses.add(async () => {\n                                // the `element` doesn't necessarily contain all item details or\n                                // have related records attached consistently with that of a query()\n                                // result item. for consistency, we attach them here.\n                                let message = item;\n                                // as long as we're not dealing with a DELETE, we need to fetch a fresh\n                                // item from storage to ensure it's fully populated.\n                                if (item.opType !== 'DELETE') {\n                                    const modelDefinition = getModelDefinition(item.model);\n                                    const keyFields = extractPrimaryKeyFieldNames(modelDefinition);\n                                    const primaryKeysAndValues = extractPrimaryKeysAndValues(item.element, keyFields);\n                                    const freshElement = await this.query(item.model, primaryKeysAndValues);\n                                    message = {\n                                        ...message,\n                                        element: freshElement,\n                                    };\n                                }\n                                if (!executivePredicate ||\n                                    (await executivePredicate.matches(message.element))) {\n                                    observer.next(message);\n                                }\n                            }, 'datastore observe message handler'),\n                        error: err => {\n                            observer.error(err);\n                        },\n                        complete: () => {\n                            observer.complete();\n                        },\n                    });\n                }, 'datastore observe observable initialization')\n                    .catch(this.handleAddProcError('DataStore.observe()'))\n                    .catch(error => {\n                    observer.error(error);\n                });\n                // better than no cleaner, but if the subscriber is handling the\n                // complete() message async and not registering with the context,\n                // this will still be problematic.\n                return this.runningProcesses.addCleaner(async () => {\n                    if (source) {\n                        source.unsubscribe();\n                    }\n                }, 'DataStore.observe() cleanup');\n            });\n        };\n        this.observeQuery = (model, criteria, options) => {\n            return new Observable(observer => {\n                const items = new Map();\n                const itemsChanged = new Map();\n                let deletedItemIds = [];\n                let handle;\n                // let predicate: ModelPredicate<T> | undefined;\n                let executivePredicate;\n                /**\n                 * As the name suggests, this geneates a snapshot in the form of\n                 * \t`{items: T[], isSynced: boolean}`\n                 * and sends it to the observer.\n                 *\n                 * SIDE EFFECT: The underlying generation and emission methods may touch:\n                 * `items`, `itemsChanged`, and `deletedItemIds`.\n                 *\n                 * Refer to `generateSnapshot` and `emitSnapshot` for more details.\n                 */\n                const generateAndEmitSnapshot = () => {\n                    const snapshot = generateSnapshot();\n                    emitSnapshot(snapshot);\n                };\n                // a mechanism to return data after X amount of seconds OR after the\n                // \"limit\" (itemsChanged >= this.syncPageSize) has been reached, whichever comes first\n                const limitTimerRace = new DeferredCallbackResolver({\n                    callback: generateAndEmitSnapshot,\n                    errorHandler: observer.error,\n                    maxInterval: 2000,\n                });\n                const { sort } = options || {};\n                const sortOptions = sort ? { sort } : undefined;\n                const modelDefinition = getModelDefinition(model);\n                if (!modelDefinition) {\n                    throw new Error('Could not find model definition.');\n                }\n                if (model && typeof criteria === 'function') {\n                    executivePredicate = internals(criteria(buildSeedPredicate(model)));\n                }\n                else if (isPredicatesAll(criteria)) {\n                    executivePredicate = undefined;\n                }\n                this.runningProcesses\n                    .add(async () => {\n                    try {\n                        // first, query and return any locally-available records\n                        (await this.query(model, criteria, sortOptions)).forEach(item => {\n                            const itemModelDefinition = getModelDefinition(model);\n                            const idOrPk = getIdentifierValue(itemModelDefinition, item);\n                            items.set(idOrPk, item);\n                        });\n                        // Observe the model and send a stream of updates (debounced).\n                        // We need to post-filter results instead of passing criteria through\n                        // to have visibility into items that move from in-set to out-of-set.\n                        // We need to explicitly remove those items from the existing snapshot.\n                        handle = this.observe(model).subscribe(({ element, model: observedModel, opType }) => this.runningProcesses.isOpen &&\n                            this.runningProcesses.add(async () => {\n                                const itemModelDefinition = getModelDefinition(observedModel);\n                                const idOrPk = getIdentifierValue(itemModelDefinition, element);\n                                if (executivePredicate &&\n                                    !(await executivePredicate.matches(element))) {\n                                    if (opType === 'UPDATE' &&\n                                        (items.has(idOrPk) || itemsChanged.has(idOrPk))) {\n                                        // tracking as a \"deleted item\" will include the item in\n                                        // page limit calculations and ensure it is removed from the\n                                        // final items collection, regardless of which collection(s)\n                                        // it is currently in. (I mean, it could be in both, right!?)\n                                        deletedItemIds.push(idOrPk);\n                                    }\n                                    else {\n                                        // ignore updates for irrelevant/filtered items.\n                                        return;\n                                    }\n                                }\n                                // Flag items which have been recently deleted\n                                // NOTE: Merging of separate operations to the same model instance is handled upstream\n                                // in the `mergePage` method within src/sync/merger.ts. The final state of a model instance\n                                // depends on the LATEST record (for a given id).\n                                if (opType === 'DELETE') {\n                                    deletedItemIds.push(idOrPk);\n                                }\n                                else {\n                                    itemsChanged.set(idOrPk, element);\n                                }\n                                const isSynced = this.sync?.getModelSyncedStatus(observedModel) ?? false;\n                                const limit = itemsChanged.size - deletedItemIds.length >=\n                                    this.syncPageSize;\n                                if (limit || isSynced) {\n                                    limitTimerRace.resolve();\n                                }\n                                // kicks off every subsequent race as results sync down\n                                limitTimerRace.start();\n                            }, 'handle observeQuery observed event'));\n                        // returns a set of initial/locally-available results\n                        generateAndEmitSnapshot();\n                    }\n                    catch (err) {\n                        observer.error(err);\n                    }\n                }, 'datastore observequery startup')\n                    .catch(this.handleAddProcError('DataStore.observeQuery()'))\n                    .catch(error => {\n                    observer.error(error);\n                });\n                /**\n                 * Combines the `items`, `itemsChanged`, and `deletedItemIds` collections into\n                 * a snapshot in the form of `{ items: T[], isSynced: boolean}`.\n                 *\n                 * SIDE EFFECT: The shared `items` collection is recreated.\n                 */\n                const generateSnapshot = () => {\n                    const isSynced = this.sync?.getModelSyncedStatus(model) ?? false;\n                    const itemsArray = [\n                        ...Array.from(items.values()),\n                        ...Array.from(itemsChanged.values()),\n                    ];\n                    items.clear();\n                    itemsArray.forEach(item => {\n                        const itemModelDefinition = getModelDefinition(model);\n                        const idOrPk = getIdentifierValue(itemModelDefinition, item);\n                        items.set(idOrPk, item);\n                    });\n                    // remove deleted items from the final result set\n                    deletedItemIds.forEach(idOrPk => items.delete(idOrPk));\n                    const snapshot = Array.from(items.values());\n                    // we sort after we merge the snapshots (items, itemsChanged)\n                    // otherwise, the merge may not\n                    if (options?.sort) {\n                        sortItems(snapshot);\n                    }\n                    return {\n                        items: snapshot,\n                        isSynced,\n                    };\n                };\n                /**\n                 * Emits the list of items to the observer.\n                 *\n                 * SIDE EFFECT: `itemsChanged` and `deletedItemIds` are cleared to prepare\n                 * for the next snapshot.\n                 *\n                 * @param snapshot The generated items data to emit.\n                 */\n                const emitSnapshot = (snapshot) => {\n                    // send the generated snapshot to the primary subscription.\n                    // NOTE: This observer's handler *could* be async ...\n                    observer.next(snapshot);\n                    // reset the changed items sets\n                    itemsChanged.clear();\n                    deletedItemIds = [];\n                };\n                /**\n                 * Sorts an `Array` of `T` according to the sort instructions given in the\n                 * original  `observeQuery()` call.\n                 *\n                 * @param itemsToSort A array of model type.\n                 */\n                const sortItems = (itemsToSort) => {\n                    const sortingModelDefinition = getModelDefinition(model);\n                    const pagination = this.processPagination(sortingModelDefinition, options);\n                    const sortPredicates = ModelSortPredicateCreator.getPredicates(pagination.sort);\n                    if (sortPredicates.length) {\n                        const compareFn = sortCompareFunction(sortPredicates);\n                        itemsToSort.sort(compareFn);\n                    }\n                };\n                /**\n                 * Force one last snapshot when the model is fully synced.\n                 *\n                 * This reduces latency for that last snapshot, which will otherwise\n                 * wait for the configured timeout.\n                 *\n                 * @param payload The payload from the Hub event.\n                 */\n                const hubCallback = ({ payload }) => {\n                    const { event, data } = payload;\n                    if (event === ControlMessage.SYNC_ENGINE_MODEL_SYNCED &&\n                        data?.model?.name === model.name) {\n                        generateAndEmitSnapshot();\n                        hubRemove();\n                    }\n                };\n                const hubRemove = Hub.listen('datastore', hubCallback);\n                return this.runningProcesses.addCleaner(async () => {\n                    if (handle) {\n                        handle.unsubscribe();\n                    }\n                }, 'datastore observequery cleaner');\n            });\n        };\n        this.configure = (config = {}) => {\n            this.amplifyContext.InternalAPI = this.InternalAPI;\n            const { DataStore: configDataStore, authModeStrategyType: configAuthModeStrategyType, maxRecordsToSync: configMaxRecordsToSync, syncPageSize: configSyncPageSize, fullSyncInterval: configFullSyncInterval, syncExpressions: configSyncExpressions, authProviders: configAuthProviders, storageAdapter: configStorageAdapter, ...configFromAmplify } = config;\n            const currentAppSyncConfig = Amplify.getConfig().API?.GraphQL;\n            const appSyncConfig = {\n                aws_appsync_graphqlEndpoint: currentAppSyncConfig?.endpoint,\n                aws_appsync_authenticationType: currentAppSyncConfig?.defaultAuthMode,\n                aws_appsync_region: currentAppSyncConfig?.region,\n                aws_appsync_apiKey: currentAppSyncConfig?.apiKey,\n            };\n            this.amplifyConfig = {\n                ...this.amplifyConfig,\n                ...configFromAmplify,\n                ...(currentAppSyncConfig && appSyncConfig),\n            };\n            this.conflictHandler = this.setConflictHandler(config);\n            this.errorHandler = this.setErrorHandler(config);\n            const authModeStrategyType = (configDataStore && configDataStore.authModeStrategyType) ||\n                configAuthModeStrategyType ||\n                AuthModeStrategyType.DEFAULT;\n            switch (authModeStrategyType) {\n                case AuthModeStrategyType.MULTI_AUTH:\n                    this.authModeStrategy = multiAuthStrategy(this.amplifyContext);\n                    break;\n                case AuthModeStrategyType.DEFAULT:\n                    this.authModeStrategy = defaultAuthStrategy;\n                    break;\n                default:\n                    this.authModeStrategy = defaultAuthStrategy;\n                    break;\n            }\n            // store on config object, so that Sync, Subscription, and Mutation processors can have access\n            this.amplifyConfig.authProviders =\n                (configDataStore && configDataStore.authProviders) || configAuthProviders;\n            this.syncExpressions =\n                (configDataStore && configDataStore.syncExpressions) ||\n                    configSyncExpressions ||\n                    this.syncExpressions;\n            this.maxRecordsToSync =\n                (configDataStore && configDataStore.maxRecordsToSync) ||\n                    configMaxRecordsToSync ||\n                    this.maxRecordsToSync ||\n                    10000;\n            // store on config object, so that Sync, Subscription, and Mutation processors can have access\n            this.amplifyConfig.maxRecordsToSync = this.maxRecordsToSync;\n            this.syncPageSize =\n                (configDataStore && configDataStore.syncPageSize) ||\n                    configSyncPageSize ||\n                    this.syncPageSize ||\n                    1000;\n            // store on config object, so that Sync, Subscription, and Mutation processors can have access\n            this.amplifyConfig.syncPageSize = this.syncPageSize;\n            this.fullSyncInterval =\n                (configDataStore && configDataStore.fullSyncInterval) ||\n                    configFullSyncInterval ||\n                    this.fullSyncInterval ||\n                    24 * 60; // 1 day\n            this.storageAdapter =\n                (configDataStore && configDataStore.storageAdapter) ||\n                    configStorageAdapter ||\n                    this.storageAdapter ||\n                    undefined;\n            this.sessionId = this.retrieveSessionId();\n        };\n    }\n    getModuleName() {\n        return 'DataStore';\n    }\n    /**\n     * Builds a function to capture `BackgroundManagerNotOpenError`'s to produce friendlier,\n     * more instructive errors for customers.\n     *\n     * @param operation The name of the operation (usually a Datastore method) the customer\n     * tried to call.\n     */\n    handleAddProcError(operation) {\n        /**\n         * If the tested error is a `BackgroundManagerNotOpenError`, it will be captured\n         * and replaced with a friendlier message that instructs the App Developer.\n         *\n         * @param err An error to test.\n         */\n        const handler = (err) => {\n            if (err.message.startsWith('BackgroundManagerNotOpenError')) {\n                throw new Error([\n                    `DataStoreStateError: Tried to execute \\`${operation}\\` while DataStore was \"${this.state}\".`,\n                    `This can only be done while DataStore is \"Started\" or \"Stopped\". To remedy:`,\n                    'Ensure all calls to `stop()` and `clear()` have completed first.',\n                    'If this is not possible, retry the operation until it succeeds.',\n                ].join('\\n'));\n            }\n            else {\n                throw err;\n            }\n        };\n        return handler;\n    }\n    /**\n     * Clears all data from storage and removes all data, schema info, other\n     * initialization details, and then stops DataStore.\n     *\n     * That said, reinitialization is required after clearing. This can be done\n     * by explicitiliy calling `start()` or any method that implicitly starts\n     * DataStore, such as `query()`, `save()`, or `delete()`.\n     */\n    async clear() {\n        checkSchemaInitialized();\n        this.state = DataStoreState.Clearing;\n        await this.runningProcesses.close();\n        if (this.storage === undefined) {\n            // connect to storage so that it can be cleared without fully starting DataStore\n            this.storage = new ExclusiveStorage(schema, namespaceResolver, getModelConstructorByModelName, modelInstanceCreator, this.storageAdapter, this.sessionId);\n            await this.storage.init();\n        }\n        if (syncSubscription && !syncSubscription.closed) {\n            syncSubscription.unsubscribe();\n        }\n        if (this.sync) {\n            await this.sync.stop();\n        }\n        await this.storage.clear();\n        this.initialized = undefined; // Should re-initialize when start() is called.\n        this.storage = undefined;\n        this.sync = undefined;\n        this.syncPredicates = new WeakMap();\n        await this.runningProcesses.open();\n        this.state = DataStoreState.NotRunning;\n    }\n    /**\n     * Stops all DataStore sync activities.\n     *\n     * TODO: \"Waits for graceful termination of\n     * running queries and terminates subscriptions.\"\n     */\n    async stop() {\n        this.state = DataStoreState.Stopping;\n        await this.runningProcesses.close();\n        if (syncSubscription && !syncSubscription.closed) {\n            syncSubscription.unsubscribe();\n        }\n        if (this.sync) {\n            await this.sync.stop();\n        }\n        this.initialized = undefined; // Should re-initialize when start() is called.\n        this.sync = undefined;\n        await this.runningProcesses.open();\n        this.state = DataStoreState.NotRunning;\n    }\n    /**\n     * Validates given pagination input from a query and creates a pagination\n     * argument for use against the storage layer.\n     *\n     * @param modelDefinition\n     * @param paginationProducer\n     */\n    processPagination(modelDefinition, paginationProducer) {\n        let sortPredicate;\n        const { limit, page, sort } = paginationProducer || {};\n        if (limit === undefined && page === undefined && sort === undefined) {\n            return undefined;\n        }\n        if (page !== undefined && limit === undefined) {\n            throw new Error('Limit is required when requesting a page');\n        }\n        if (page !== undefined) {\n            if (typeof page !== 'number') {\n                throw new Error('Page should be a number');\n            }\n            if (page < 0) {\n                throw new Error(\"Page can't be negative\");\n            }\n        }\n        if (limit !== undefined) {\n            if (typeof limit !== 'number') {\n                throw new Error('Limit should be a number');\n            }\n            if (limit < 0) {\n                throw new Error(\"Limit can't be negative\");\n            }\n        }\n        if (sort) {\n            sortPredicate = ModelSortPredicateCreator.createFromExisting(modelDefinition, sort);\n        }\n        return {\n            limit,\n            page,\n            sort: sortPredicate,\n        };\n    }\n    /**\n     * Examines the configured `syncExpressions` and produces a WeakMap of\n     * SchemaModel -> predicate to use during sync.\n     */\n    async processSyncExpressions() {\n        if (!this.syncExpressions || !this.syncExpressions.length) {\n            return new WeakMap();\n        }\n        const syncPredicates = await Promise.all(this.syncExpressions.map(async (syncExpression) => {\n            const { modelConstructor, conditionProducer } = await syncExpression;\n            const modelDefinition = getModelDefinition(modelConstructor);\n            // conditionProducer is either a predicate, e.g. (c) => c.field.eq(1)\n            // OR a function/promise that returns a predicate\n            const condition = await this.unwrapPromise(conditionProducer);\n            if (isPredicatesAll(condition)) {\n                return [modelDefinition, null];\n            }\n            const predicate = internals(condition(predicateFor({\n                builder: modelConstructor,\n                schema: modelDefinition,\n                pkField: extractPrimaryKeyFieldNames(modelDefinition),\n            }))).toStoragePredicate();\n            return [modelDefinition, predicate];\n        }));\n        return this.weakMapFromEntries(syncPredicates);\n    }\n    async unwrapPromise(conditionProducer) {\n        try {\n            const condition = await conditionProducer();\n            return condition || conditionProducer;\n        }\n        catch (error) {\n            if (error instanceof TypeError) {\n                return conditionProducer;\n            }\n            throw error;\n        }\n    }\n    weakMapFromEntries(entries) {\n        return entries.reduce((map, [modelDefinition, predicate]) => {\n            if (map.has(modelDefinition)) {\n                const { name } = modelDefinition;\n                logger.warn(`You can only utilize one Sync Expression per model.\n          Subsequent sync expressions for the ${name} model will be ignored.`);\n                return map;\n            }\n            if (predicate) {\n                map.set(modelDefinition, predicate);\n            }\n            return map;\n        }, new WeakMap());\n    }\n    /**\n     * A session ID to allow CMS to open databases against multiple apps.\n     * This session ID is only expected be set by AWS Amplify Studio.\n     */\n    retrieveSessionId() {\n        try {\n            const sessionId = sessionStorage.getItem('datastoreSessionId');\n            if (sessionId) {\n                const { aws_appsync_graphqlEndpoint } = this.amplifyConfig;\n                const appSyncUrl = aws_appsync_graphqlEndpoint.split('/')[2];\n                const [appSyncId] = appSyncUrl.split('.');\n                return `${sessionId}-${appSyncId}`;\n            }\n        }\n        catch { }\n        return undefined;\n    }\n}\nconst instance = new DataStore();\ninstance.configure({});\nHub.listen('core', capsule => {\n    if (capsule.payload.event === 'configure') {\n        instance.configure({});\n    }\n});\n\nexport { AsyncCollection, AsyncItem, instance as DataStore, DataStore as DataStoreClass, attached, getAttachment, initSchema, syncClasses };\n//# sourceMappingURL=datastore.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst isNode = () => typeof process !== 'undefined' &&\n    process.versions != null &&\n    process.versions.node != null;\n\nexport { isNode };\n//# sourceMappingURL=utils.mjs.map\n","import { extractPrimaryKeyFieldNames, extractPrimaryKeyValues } from '../util.mjs';\nexport { ModelSortPredicateCreator } from './sort.mjs';\n\nconst predicatesAllSet = new WeakSet();\nfunction isPredicatesAll(predicate) {\n    return predicatesAllSet.has(predicate);\n}\n/**\n * The valid logical grouping keys for a predicate group.\n */\nconst groupKeys = new Set(['and', 'or', 'not']);\n/**\n * Determines whether an object is a GraphQL style predicate \"group\", which must be an\n * object containing a single \"group key\", which then contains the child condition(s).\n *\n * E.g.,\n *\n * ```\n * { and: [ ... ] }\n * { not: { ... } }\n * ```\n *\n * @param o The object to test.\n */\nconst isGroup = o => {\n    const keys = [...Object.keys(o)];\n    return keys.length === 1 && groupKeys.has(keys[0]);\n};\n/**\n * Determines whether an object specifies no conditions and should match everything,\n * as would be the case with `Predicates.ALL`.\n *\n * @param o The object to test.\n */\nconst isEmpty = o => {\n    return !Array.isArray(o) && Object.keys(o).length === 0;\n};\n/**\n * The valid comparison operators that can be used as keys in a predicate comparison object.\n */\nconst comparisonKeys = new Set([\n    'eq',\n    'ne',\n    'gt',\n    'lt',\n    'ge',\n    'le',\n    'contains',\n    'notContains',\n    'beginsWith',\n    'between',\n]);\n/**\n * Determines whether an object is a GraphQL style predicate comparison node, which must\n * be an object containing a single \"comparison operator\" key, which then contains the\n * operand or operands to compare against.\n *\n * @param o The object to test.\n */\nconst isComparison = o => {\n    const keys = [...Object.keys(o)];\n    return !Array.isArray(o) && keys.length === 1 && comparisonKeys.has(keys[0]);\n};\n/**\n * A light check to determine whether an object is a valid GraphQL Condition AST.\n *\n * @param o The object to test.\n */\nconst isValid = o => {\n    if (Array.isArray(o)) {\n        return o.every(v => isValid(v));\n    }\n    else {\n        return Object.keys(o).length <= 1;\n    }\n};\n// This symbol is not used at runtime, only its type (unique symbol)\nconst PredicateAll = Symbol('A predicate that matches all records');\nclass Predicates {\n    static get ALL() {\n        // eslint-disable-next-line @typescript-eslint/consistent-type-assertions\n        const predicate = (c => c);\n        predicatesAllSet.add(predicate);\n        return predicate;\n    }\n}\nclass ModelPredicateCreator {\n    /**\n     * Determines whether the given storage predicate (lookup key) is a predicate\n     * key that DataStore recognizes.\n     *\n     * @param predicate The storage predicate (lookup key) to test.\n     */\n    static isValidPredicate(predicate) {\n        return ModelPredicateCreator.predicateGroupsMap.has(predicate);\n    }\n    /**\n     * Looks for the storage predicate AST that corresponds to a given storage\n     * predicate key.\n     *\n     * The key must have been created internally by a DataStore utility\n     * method, such as `ModelPredicate.createFromAST()`.\n     *\n     * @param predicate The predicate reference to look up.\n     * @param throwOnInvalid Whether to throw an exception if the predicate\n     * isn't a valid DataStore predicate.\n     */\n    static getPredicates(predicate, throwOnInvalid = true) {\n        if (throwOnInvalid && !ModelPredicateCreator.isValidPredicate(predicate)) {\n            throw new Error('The predicate is not valid');\n        }\n        return ModelPredicateCreator.predicateGroupsMap.get(predicate);\n    }\n    /**\n     * using the PK values from the given `model` (which can be a partial of T\n     * Creates a predicate that matches an instance described by `modelDefinition`\n     * that contains only PK field values.)\n     *\n     * @param modelDefinition The model definition to create a predicate for.\n     * @param model The model instance to extract value equalities from.\n     */\n    static createForPk(modelDefinition, model) {\n        const keyFields = extractPrimaryKeyFieldNames(modelDefinition);\n        const keyValues = extractPrimaryKeyValues(model, keyFields);\n        const predicate = this.createFromAST(modelDefinition, {\n            and: keyFields.map((field, idx) => {\n                const operand = keyValues[idx];\n                return { [field]: { eq: operand } };\n            }),\n        });\n        return predicate;\n    }\n    /**\n     * Searches a `Model` table for records matching the given equalities object.\n     *\n     * This only matches against fields given in the equalities object. No other\n     * fields are tested by the predicate.\n     *\n     * @param modelDefinition The model we need a predicate for.\n     * @param flatEqualities An object holding field equalities to search for.\n     */\n    static createFromFlatEqualities(modelDefinition, flatEqualities) {\n        const ast = {\n            and: Object.entries(flatEqualities).map(([k, v]) => ({ [k]: { eq: v } })),\n        };\n        return this.createFromAST(modelDefinition, ast);\n    }\n    /**\n     * Accepts a GraphQL style filter predicate tree and transforms it into an\n     * AST that can be used for a storage adapter predicate. Example input:\n     *\n     * ```js\n     * {\n     * \tand: [\n     * \t\t{ name: { eq: \"Bob Jones\" } },\n     * \t\t{ age: { between: [32, 64] } },\n     * \t\t{ not: {\n     * \t\t\tor: [\n     * \t\t\t\t{ favoriteFood: { eq: 'pizza' } },\n     * \t\t\t\t{ favoriteFood: { eq: 'tacos' } },\n     * \t\t\t]\n     * \t\t}}\n     * \t]\n     * }\n     * ```\n     *\n     * @param gql GraphQL style filter node.\n     */\n    static transformGraphQLFilterNodeToPredicateAST(gql) {\n        if (!isValid(gql)) {\n            throw new Error('Invalid GraphQL Condition or subtree: ' + JSON.stringify(gql));\n        }\n        if (isEmpty(gql)) {\n            return {\n                type: 'and',\n                predicates: [],\n            };\n        }\n        else if (isGroup(gql)) {\n            const groupkey = Object.keys(gql)[0];\n            const children = this.transformGraphQLFilterNodeToPredicateAST(gql[groupkey]);\n            return {\n                type: groupkey,\n                predicates: Array.isArray(children) ? children : [children],\n            };\n        }\n        else if (isComparison(gql)) {\n            const operatorKey = Object.keys(gql)[0];\n            return {\n                operator: operatorKey,\n                operand: gql[operatorKey],\n            };\n        }\n        else {\n            if (Array.isArray(gql)) {\n                return gql.map(o => this.transformGraphQLFilterNodeToPredicateAST(o));\n            }\n            else {\n                const fieldKey = Object.keys(gql)[0];\n                return {\n                    field: fieldKey,\n                    ...this.transformGraphQLFilterNodeToPredicateAST(gql[fieldKey]),\n                };\n            }\n        }\n    }\n    /**\n     * Accepts a GraphQL style filter predicate tree and transforms it into a predicate\n     * that storage adapters understand. Example input:\n     *\n     * ```js\n     * {\n     * \tand: [\n     * \t\t{ name: { eq: \"Bob Jones\" } },\n     * \t\t{ age: { between: [32, 64] } },\n     * \t\t{ not: {\n     * \t\t\tor: [\n     * \t\t\t\t{ favoriteFood: { eq: 'pizza' } },\n     * \t\t\t\t{ favoriteFood: { eq: 'tacos' } },\n     * \t\t\t]\n     * \t\t}}\n     * \t]\n     * }\n     * ```\n     *\n     * @param modelDefinition The model that the AST/predicate must be compatible with.\n     * @param ast The graphQL style AST that should specify conditions for `modelDefinition`.\n     */\n    static createFromAST(modelDefinition, ast) {\n        const key = {};\n        ModelPredicateCreator.predicateGroupsMap.set(key, this.transformGraphQLFilterNodeToPredicateAST(ast));\n        return key;\n    }\n}\n/**\n * Map of storage predicates (key objects) to storage predicate AST's.\n */\nModelPredicateCreator.predicateGroupsMap = new WeakMap();\n\nexport { ModelPredicateCreator, PredicateAll, Predicates, comparisonKeys, isPredicatesAll };\n//# sourceMappingURL=index.mjs.map\n","import { PredicateInternalsKey } from '../types.mjs';\nimport { ModelRelationship } from '../storage/relationship.mjs';\nimport { asyncSome, asyncEvery } from '../util.mjs';\nimport { comparisonKeys, ModelPredicateCreator } from './index.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst ops = [...comparisonKeys];\n/**\n * A map from keys (exposed to customers) to the internal predicate data\n * structures invoking code should not muck with.\n */\nconst predicateInternalsMap = new Map();\n/**\n * Creates a link between a key (and generates a key if needed) and an internal\n * `GroupCondition`, which allows us to return a key object instead of the gory\n * conditions details to customers/invoking code.\n *\n * @param condition The internal condition to keep hidden.\n * @param key The object DataStore will use to find the internal condition.\n * If no key is given, an empty one is created.\n */\nconst registerPredicateInternals = (condition, key) => {\n    const finalKey = key || new PredicateInternalsKey();\n    predicateInternalsMap.set(finalKey, condition);\n    return finalKey;\n};\n/**\n * Takes a key object from `registerPredicateInternals()` to fetch an internal\n * `GroupCondition` object, which can then be used to query storage or\n * test/match objects.\n *\n * This indirection exists to hide `GroupCondition` from public interfaces, since\n * `GroupCondition` contains extra methods and properties that public callers\n * should not use.\n *\n * @param key A key object previously returned by `registerPredicateInternals()`\n */\nconst internals = (key) => {\n    if (!predicateInternalsMap.has(key)) {\n        throw new Error(\"Invalid predicate. Terminate your predicate with a valid condition (e.g., `p => p.field.eq('value')`) or pass `Predicates.ALL`.\");\n    }\n    return predicateInternalsMap.get(key);\n};\n/**\n * Maps operators to negated operators.\n * Used to facilitate propagation of negation down a tree of conditions.\n */\nconst negations = {\n    and: 'or',\n    or: 'and',\n    not: 'and',\n    eq: 'ne',\n    ne: 'eq',\n    gt: 'le',\n    ge: 'lt',\n    lt: 'ge',\n    le: 'gt',\n    contains: 'notContains',\n    notContains: 'contains',\n};\n/**\n * A condition that can operate against a single \"primitive\" field of a model or item.\n * @member field The field of *some record* to test against.\n * @member operator The equality or comparison operator to use.\n * @member operands The operands for the equality/comparison check.\n */\nclass FieldCondition {\n    constructor(field, operator, operands) {\n        this.field = field;\n        this.operator = operator;\n        this.operands = operands;\n        this.validate();\n    }\n    /**\n     * Creates a copy of self.\n     * @param extract Not used. Present only to fulfill the `UntypedCondition` interface.\n     * @returns A new, identitical `FieldCondition`.\n     */\n    copy() {\n        return [\n            new FieldCondition(this.field, this.operator, [...this.operands]),\n            undefined,\n        ];\n    }\n    /**\n     * Produces a tree structure similar to a graphql condition. The returned\n     * structure is \"dumb\" and is intended for another query/condition\n     * generation mechanism to interpret, such as the cloud or storage query\n     * builders.\n     *\n     * E.g.,\n     *\n     * ```json\n     * {\n     * \t\"name\": {\n     * \t\t\"eq\": \"robert\"\n     * \t}\n     * }\n     * ```\n     */\n    toAST() {\n        return {\n            [this.field]: {\n                [this.operator]: this.operator === 'between'\n                    ? [this.operands[0], this.operands[1]]\n                    : this.operands[0],\n            },\n        };\n    }\n    /**\n     * Produces a new condition (`FieldCondition` or `GroupCondition`) that\n     * matches the opposite of this condition.\n     *\n     * Intended to be used when applying De Morgan's Law, which can be done to\n     * produce more efficient queries against the storage layer if a negation\n     * appears in the query tree.\n     *\n     * For example:\n     *\n     * 1. `name.eq('robert')` becomes `name.ne('robert')`\n     * 2. `price.between(100, 200)` becomes `m => m.or(m => [m.price.lt(100), m.price.gt(200)])`\n     *\n     * @param model The model meta to use when construction a new `GroupCondition`\n     * for cases where the negation requires multiple `FieldCondition`'s.\n     */\n    negated(model) {\n        if (this.operator === 'between') {\n            return new GroupCondition(model, undefined, undefined, 'or', [\n                new FieldCondition(this.field, 'lt', [this.operands[0]]),\n                new FieldCondition(this.field, 'gt', [this.operands[1]]),\n            ]);\n        }\n        else if (this.operator === 'beginsWith') {\n            // beginsWith negation doesn't have a good, safe optimation right now.\n            // just re-wrap it in negation. The adapter will have to scan-and-filter,\n            // as is likely optimal for negated beginsWith conditions *anyway*.\n            return new GroupCondition(model, undefined, undefined, 'not', [\n                new FieldCondition(this.field, 'beginsWith', [this.operands[0]]),\n            ]);\n        }\n        else {\n            return new FieldCondition(this.field, negations[this.operator], this.operands);\n        }\n    }\n    /**\n     * Not implemented. Not needed. GroupCondition instead consumes FieldConditions and\n     * transforms them into legacy predicates. (*For now.*)\n     * @param storage N/A. If ever implemented, the storage adapter to query.\n     * @returns N/A. If ever implemented, return items from `storage` that match.\n     */\n    async fetch() {\n        // eslint-disable-next-line prefer-promise-reject-errors\n        return Promise.reject('No implementation needed [yet].');\n    }\n    /**\n     * Determins whether a given item matches the expressed condition.\n     * @param item The item to test.\n     * @returns `Promise<boolean>`, `true` if matches; `false` otherwise.\n     */\n    async matches(item) {\n        const v = item[this.field];\n        const operations = {\n            eq: () => v === this.operands[0],\n            ne: () => v !== this.operands[0],\n            gt: () => v > this.operands[0],\n            ge: () => v >= this.operands[0],\n            lt: () => v < this.operands[0],\n            le: () => v <= this.operands[0],\n            contains: () => v?.indexOf(this.operands[0]) > -1,\n            notContains: () => (!v ? true : v.indexOf(this.operands[0]) === -1),\n            beginsWith: () => v?.startsWith(this.operands[0]),\n            between: () => v >= this.operands[0] && v <= this.operands[1],\n        };\n        const operation = operations[this.operator];\n        if (operation) {\n            const result = operation();\n            return result;\n        }\n        else {\n            throw new Error(`Invalid operator given: ${this.operator}`);\n        }\n    }\n    /**\n     * Checks `this.operands` for compatibility with `this.operator`.\n     */\n    validate() {\n        /**\n         * Creates a validator that checks for a particular `operands` count.\n         * Throws an exception if the `count` disagrees with `operands.length`.\n         * @param count The number of `operands` expected.\n         */\n        const argumentCount = count => {\n            const argsClause = count === 1 ? 'argument is' : 'arguments are';\n            return () => {\n                if (this.operands.length !== count) {\n                    return `Exactly ${count} ${argsClause} required.`;\n                }\n            };\n        };\n        // NOTE: validations should return a message on failure.\n        // hence, they should be \"joined\" together with logical OR's\n        // as seen in the `between:` entry.\n        const validations = {\n            eq: argumentCount(1),\n            ne: argumentCount(1),\n            gt: argumentCount(1),\n            ge: argumentCount(1),\n            lt: argumentCount(1),\n            le: argumentCount(1),\n            contains: argumentCount(1),\n            notContains: argumentCount(1),\n            beginsWith: argumentCount(1),\n            between: () => argumentCount(2)() ||\n                (this.operands[0] > this.operands[1]\n                    ? 'The first argument must be less than or equal to the second argument.'\n                    : null),\n        };\n        const validate = validations[this.operator];\n        if (validate) {\n            const e = validate();\n            if (typeof e === 'string')\n                throw new Error(`Incorrect usage of \\`${this.operator}()\\`: ${e}`);\n        }\n        else {\n            throw new Error(`Non-existent operator: \\`${this.operator}()\\``);\n        }\n    }\n}\n/**\n * Small utility function to generate a monotonically increasing ID.\n * Used by GroupCondition to help keep track of which group is doing what,\n * when, and where during troubleshooting.\n */\nconst getGroupId = (() => {\n    let seed = 1;\n    return () => `group_${seed++}`;\n})();\n/**\n * A set of sub-conditions to operate against a model, optionally scoped to\n * a specific field, combined with the given operator (one of `and`, `or`, or `not`).\n * @member groupId Used to distinguish between GroupCondition instances for\n * debugging and troublehsooting.\n * @member model A metadata object that tells GroupCondition what to query and how.\n * @member field The field on the model that the sub-conditions apply to.\n * @member operator How to group child conditions together.\n * @member operands The child conditions.\n */\nclass GroupCondition {\n    constructor(\n    /**\n     * The `ModelMeta` of the model to query and/or filter against.\n     * Expected to contain:\n     *\n     * ```js\n     * {\n     * \tbuilder: ModelConstructor,\n     * \tschema: SchemaModel,\n     * \tpkField: string[]\n     * }\n     * ```\n     */\n    model, \n    /**\n     * If populated, this group specifices a condition on a relationship.\n     *\n     * If `field` does *not* point to a related model, that's an error. It\n     * could indicate that the `GroupCondition` was instantiated with bad\n     * data, or that the model metadata is incorrect.\n     */\n    field, \n    /**\n     * If a `field` is given, whether the relationship is a `HAS_ONE`,\n     * 'HAS_MANY`, or `BELONGS_TO`.\n     *\n     * TODO: Remove this and replace with derivation using\n     * `ModelRelationship.from(this.model, this.field).relationship`;\n     */\n    relationshipType, \n    /**\n     *\n     */\n    operator, \n    /**\n     *\n     */\n    operands, \n    /**\n     * Whether this GroupCondition is the result of an optimize call.\n     *\n     * This is used to guard against infinitely fetch -> optimize -> fetch\n     * recursion.\n     */\n    isOptimized = false) {\n        this.model = model;\n        this.field = field;\n        this.relationshipType = relationshipType;\n        this.operator = operator;\n        this.operands = operands;\n        this.isOptimized = isOptimized;\n        // `groupId` was used for development/debugging.\n        // Should we leave this in for future troubleshooting?\n        this.groupId = getGroupId();\n    }\n    /**\n     * Returns a copy of a GroupCondition, which also returns the copy of a\n     * given reference node to \"extract\".\n     * @param extract A node of interest. Its copy will *also* be returned if the node exists.\n     * @returns [The full copy, the copy of `extract` | undefined]\n     */\n    copy(extract) {\n        const copied = new GroupCondition(this.model, this.field, this.relationshipType, this.operator, []);\n        let extractedCopy = extract === this ? copied : undefined;\n        this.operands.forEach(o => {\n            const [operandCopy, extractedFromOperand] = o.copy(extract);\n            copied.operands.push(operandCopy);\n            extractedCopy = extractedCopy || extractedFromOperand;\n        });\n        return [copied, extractedCopy];\n    }\n    /**\n     * Creates a new `GroupCondition` that contains only the local field conditions,\n     * omitting related model conditions. That resulting `GroupCondition` can be\n     * used to produce predicates that are compatible with the storage adapters and\n     * Cloud storage.\n     *\n     * @param negate Whether the condition tree should be negated according\n     * to De Morgan's law.\n     */\n    withFieldConditionsOnly(negate) {\n        const negateChildren = negate !== (this.operator === 'not');\n        return new GroupCondition(this.model, undefined, undefined, (negate ? negations[this.operator] : this.operator), this.operands\n            .filter(o => o instanceof FieldCondition)\n            .map(o => negateChildren ? o.negated(this.model) : o));\n    }\n    /**\n     * Returns a version of the predicate tree with unnecessary logical groups\n     * condensed and merged together. This is intended to create a dense tree\n     * with leaf nodes (`FieldCondition`'s) aggregated under as few group conditions\n     * as possible for the most efficient fetching possible -- it allows `fetch()`.\n     *\n     * E.g. a grouping like this:\n     *\n     * ```yaml\n     * and:\n     * \tand:\n     * \t\tid:\n     * \t\t\teq: \"abc\"\n     * \tand:\n     * \t\tname:\n     * \t\t\teq: \"xyz\"\n     * ```\n     *\n     * Will become this:\n     *\n     * ```yaml\n     * and:\n     * \tid:\n     * \t\teq: \"abc\"\n     * \tname:\n     * \t\teq: \"xyz\"\n     * ```\n     *\n     * This allows `fetch()` to pass both the `id` and `name` conditions to the adapter\n     * together, which can then decide what index to use based on both fields together.\n     *\n     * @param preserveNode Whether to preserve the current node and to explicitly not eliminate\n     * it during optimization. Used internally to preserve the root node and children of\n     * `not` groups. `not` groups will always have a single child, so there's nothing to\n     * optimize below a `not` (for now), and it makes the query logic simpler later.\n     */\n    optimized(preserveNode = true) {\n        const operands = this.operands.map(o => o instanceof GroupCondition ? o.optimized(this.operator === 'not') : o);\n        // we're only collapsing and/or groups that contains a single child for now,\n        // because they're much more common and much more trivial to collapse. basically,\n        // an `and`/`or` that contains a single child doesn't require the layer of\n        // logical grouping.\n        if (!preserveNode &&\n            ['and', 'or'].includes(this.operator) &&\n            !this.field &&\n            operands.length === 1) {\n            const operand = operands[0];\n            if (operand instanceof FieldCondition) {\n                // between conditions should NOT be passed up the chain. if they\n                // need to be *negated* later, it is important that they be properly\n                // contained in an AND group. when de morgan's law is applied, the\n                // conditions are reversed and the AND group flips to an OR. this\n                // doesn't work right if the a `between` doesn't live in an AND group.\n                if (operand.operator !== 'between') {\n                    return operand;\n                }\n            }\n            else {\n                return operand;\n            }\n        }\n        return new GroupCondition(this.model, this.field, this.relationshipType, this.operator, operands, true);\n    }\n    /**\n     * Fetches matching records from a given storage adapter using legacy predicates (for now).\n     * @param storage The storage adapter this predicate will query against.\n     * @param breadcrumb For debugging/troubleshooting. A list of the `groupId`'s this\n     * GroupdCondition.fetch is nested within.\n     * @param negate Whether to match on the `NOT` of `this`.\n     * @returns An `Promise` of `any[]` from `storage` matching the child conditions.\n     */\n    async fetch(storage, breadcrumb = [], negate = false) {\n        if (!this.isOptimized) {\n            return this.optimized().fetch(storage);\n        }\n        const resultGroups = [];\n        const operator = (negate ? negations[this.operator] : this.operator);\n        const negateChildren = negate !== (this.operator === 'not');\n        /**\n         * Conditions that must be branched out and used to generate a base, \"candidate\"\n         * result set.\n         *\n         * If `field` is populated, these groups select *related* records, and the base,\n         * candidate results are selected to match those.\n         */\n        const groups = this.operands.filter(op => op instanceof GroupCondition);\n        /**\n         * Simple conditions that must match the target model of `this`.\n         */\n        const conditions = this.operands.filter(op => op instanceof FieldCondition);\n        for (const g of groups) {\n            const relatives = await g.fetch(storage, [...breadcrumb, this.groupId], negateChildren);\n            // no relatives -> no need to attempt to perform a \"join\" query for\n            // candidate results:\n            //\n            // select a.* from a,b where b.id in EMPTY_SET ==> EMPTY_SET\n            //\n            // Additionally, the entire (sub)-query can be short-circuited if\n            // the operator is `AND`. Illustrated in SQL:\n            //\n            // select a.* from a where\n            //   id in [a,b,c]\n            //     AND                        <\n            //   id in EMTPY_SET            <<< Look!\n            //     AND                        <\n            //   id in [x,y,z]\n            //\n            // YIELDS: EMPTY_SET           // <-- Easy peasy. Lemon squeezy.\n            //\n            if (relatives.length === 0) {\n                // aggressively short-circuit as soon as we know the group condition will fail\n                if (operator === 'and') {\n                    return [];\n                }\n                // less aggressive short-circuit if we know the relatives will produce no\n                // candidate results; but aren't sure yet how this affects the group condition.\n                resultGroups.push([]);\n                continue;\n            }\n            if (g.field) {\n                // `relatives` are actual relatives. We'll skim them for FK query values.\n                // Use the relatives to add candidate result sets (`resultGroups`)\n                const relationship = ModelRelationship.from(this.model, g.field);\n                if (relationship) {\n                    const allJoinConditions = [];\n                    for (const relative of relatives) {\n                        const relativeConditions = [];\n                        for (let i = 0; i < relationship.localJoinFields.length; i++) {\n                            relativeConditions.push({\n                                [relationship.localJoinFields[i]]: {\n                                    eq: relative[relationship.remoteJoinFields[i]],\n                                },\n                            });\n                        }\n                        allJoinConditions.push({ and: relativeConditions });\n                    }\n                    const predicate = ModelPredicateCreator.createFromAST(this.model.schema, {\n                        or: allJoinConditions,\n                    });\n                    resultGroups.push(await storage.query(this.model.builder, predicate));\n                }\n                else {\n                    throw new Error('Missing field metadata.');\n                }\n            }\n            else {\n                // relatives are not actually relatives. they're candidate results.\n                resultGroups.push(relatives);\n            }\n        }\n        // if conditions is empty at this point, child predicates found no matches.\n        // i.e., we can stop looking and return empty.\n        if (conditions.length > 0) {\n            const predicate = this.withFieldConditionsOnly(negateChildren).toStoragePredicate();\n            resultGroups.push(await storage.query(this.model.builder, predicate));\n        }\n        else if (conditions.length === 0 && resultGroups.length === 0) {\n            resultGroups.push(await storage.query(this.model.builder));\n        }\n        // PK might be a single field, like `id`, or it might be several fields.\n        // so, we'll need to extract the list of PK fields from an object\n        // and stringify the list for easy comparison / merging.\n        const getPKValue = item => JSON.stringify(this.model.pkField.map(name => item[name]));\n        // will be used for intersecting or unioning results\n        let resultIndex;\n        if (operator === 'and') {\n            if (resultGroups.length === 0) {\n                return [];\n            }\n            // for each group, we intersect, removing items from the result index\n            // that aren't present in each subsequent group.\n            for (const group of resultGroups) {\n                if (resultIndex === undefined) {\n                    resultIndex = new Map(group.map(item => [getPKValue(item), item]));\n                }\n                else {\n                    const intersectWith = new Map(group.map(item => [getPKValue(item), item]));\n                    for (const k of resultIndex.keys()) {\n                        if (!intersectWith.has(k)) {\n                            resultIndex.delete(k);\n                        }\n                    }\n                }\n            }\n        }\n        else if (operator === 'or' || operator === 'not') {\n            // it's OK to handle NOT here, because NOT must always only negate\n            // a single child predicate. NOT logic will have been distributed down\n            // to the leaf conditions already.\n            resultIndex = new Map();\n            // just merge the groups, performing DISTINCT-ification by ID.\n            for (const group of resultGroups) {\n                for (const item of group) {\n                    resultIndex.set(getPKValue(item), item);\n                }\n            }\n        }\n        return Array.from(resultIndex?.values() || []);\n    }\n    /**\n     * Determines whether a single item matches the conditions of `this`.\n     * When checking the target `item`'s properties, each property will be `await`'d\n     * to ensure lazy-loading is respected where applicable.\n     * @param item The item to match against.\n     * @param ignoreFieldName Tells `match()` that the field name has already been dereferenced.\n     * (Used for iterating over children on HAS_MANY checks.)\n     * @returns A boolean (promise): `true` if matched, `false` otherwise.\n     */\n    async matches(item, ignoreFieldName = false) {\n        const itemToCheck = this.field && !ignoreFieldName ? await item[this.field] : item;\n        // if there is no item to check, we can stop recursing immediately.\n        // a condition cannot match against an item that does not exist. this\n        // can occur when `item.field` is optional in the schema.\n        if (!itemToCheck) {\n            return false;\n        }\n        if (this.relationshipType === 'HAS_MANY' &&\n            typeof itemToCheck[Symbol.asyncIterator] === 'function') {\n            for await (const singleItem of itemToCheck) {\n                if (await this.matches(singleItem, true)) {\n                    return true;\n                }\n            }\n            return false;\n        }\n        if (this.operator === 'or') {\n            return asyncSome(this.operands, c => c.matches(itemToCheck));\n        }\n        else if (this.operator === 'and') {\n            return asyncEvery(this.operands, c => c.matches(itemToCheck));\n        }\n        else if (this.operator === 'not') {\n            if (this.operands.length !== 1) {\n                throw new Error('Invalid arguments! `not()` accepts exactly one predicate expression.');\n            }\n            return !(await this.operands[0].matches(itemToCheck));\n        }\n        else {\n            throw new Error('Invalid group operator!');\n        }\n    }\n    /**\n     * Tranfsorm to a AppSync GraphQL compatible AST.\n     * (Does not support filtering in nested types.)\n     */\n    toAST() {\n        if (this.field)\n            throw new Error('Nested type conditions are not supported!');\n        return {\n            [this.operator]: this.operands.map(operand => operand.toAST()),\n        };\n    }\n    /**\n     * Turn this predicate group into something a storage adapter\n     * understands how to use.\n     */\n    toStoragePredicate() {\n        return ModelPredicateCreator.createFromAST(this.model.schema, this.toAST());\n    }\n    /**\n     * A JSON representation that's good for debugging.\n     */\n    toJSON() {\n        return {\n            ...this,\n            model: this.model.schema.name,\n        };\n    }\n}\n/**\n * Creates a \"seed\" predicate that can be used to build an executable condition.\n * This is used in `query()`, for example, to seed customer- E.g.,\n *\n * ```\n * const p = predicateFor({builder: modelConstructor, schema: modelSchema, pkField: string[]});\n * p.and(child => [\n *   child.field.eq('whatever'),\n *   child.childModel.childField.eq('whatever else'),\n *   child.childModel.or(child => [\n *     child.otherField.contains('x'),\n *     child.otherField.contains('y'),\n *     child.otherField.contains('z'),\n *   ])\n * ])\n * ```\n *\n * `predicateFor()` returns objecst with recursive getters. To facilitate this,\n * a `query` and `tail` can be provided to \"accumulate\" nested conditions.\n *\n * @param ModelType The ModelMeta used to build child properties.\n * @param field Scopes the query branch to a field.\n * @param query A base query to build on. Omit to start a new query.\n * @param tail The point in an existing `query` to attach new conditions to.\n * @returns A ModelPredicate (builder) that customers can create queries with.\n * (As shown in function description.)\n */\nfunction recursivePredicateFor(ModelType, allowRecursion = true, field, query, tail) {\n    // to be used if we don't have a base query or tail to build onto\n    const starter = new GroupCondition(ModelType, field, undefined, 'and', []);\n    const baseCondition = query && tail ? query : starter;\n    const tailCondition = query && tail ? tail : starter;\n    // our eventual return object, which can be built upon.\n    // next steps will be to add or(), and(), not(), and field.op() methods.\n    const link = {};\n    // so it can be looked up later with in the internals when processing conditions.\n    registerPredicateInternals(baseCondition, link);\n    const copyLink = () => {\n        const [copiedQuery, newTail] = baseCondition.copy(tailCondition);\n        const newLink = recursivePredicateFor(ModelType, allowRecursion, undefined, copiedQuery, newTail);\n        return { query: copiedQuery, newTail, newLink };\n    };\n    // Adds .or() and .and() methods to the link.\n    // TODO: If revisiting this code, consider writing a Proxy instead.\n    ['and', 'or'].forEach(op => {\n        link[op] = (builder) => {\n            // or() and and() will return a copy of the original link\n            // to head off mutability concerns.\n            const { query: copiedLinkQuery, newTail } = copyLink();\n            const childConditions = builder(recursivePredicateFor(ModelType, allowRecursion));\n            if (!Array.isArray(childConditions)) {\n                throw new Error(`Invalid predicate. \\`${op}\\` groups must return an array of child conditions.`);\n            }\n            // the customer will supply a child predicate, which apply to the `model.field`\n            // of the tail GroupCondition.\n            newTail?.operands.push(new GroupCondition(ModelType, field, undefined, op, childConditions.map(c => internals(c))));\n            // FinalPredicate\n            return registerPredicateInternals(copiedLinkQuery);\n        };\n    });\n    // TODO: If revisiting this code, consider proxy.\n    link.not = (builder) => {\n        // not() will return a copy of the original link\n        // to head off mutability concerns.\n        const { query: copiedLinkQuery, newTail } = copyLink();\n        // unlike and() and or(), the customer will supply a \"singular\" child predicate.\n        // the difference being: not() does not accept an array of predicate-like objects.\n        // it negates only a *single* predicate subtree.\n        newTail?.operands.push(new GroupCondition(ModelType, field, undefined, 'not', [\n            internals(builder(recursivePredicateFor(ModelType, allowRecursion))),\n        ]));\n        // A `FinalModelPredicate`.\n        // Return a thing that can no longer be extended, but instead used to `async filter(items)`\n        // or query storage: `.__query.fetch(storage)`.\n        return registerPredicateInternals(copiedLinkQuery);\n    };\n    // For each field on the model schema, we want to add a getter\n    // that creates the appropriate new `link` in the query chain.\n    // TODO: If revisiting, consider a proxy.\n    for (const fieldName in ModelType.schema.allFields) {\n        Object.defineProperty(link, fieldName, {\n            enumerable: true,\n            get: () => {\n                const def = ModelType.schema.allFields[fieldName];\n                if (!def.association) {\n                    // we're looking at a value field. we need to return a\n                    // \"field matcher object\", which contains all of the comparison\n                    // functions ('eq', 'ne', 'gt', etc.), scoped to operate\n                    // against the target field (fieldName).\n                    return ops.reduce((fieldMatcher, operator) => {\n                        return {\n                            ...fieldMatcher,\n                            // each operator on the fieldMatcher objcect is a function.\n                            // when the customer calls the function, it returns a new link\n                            // in the chain -- for now -- this is the \"leaf\" link that\n                            // cannot be further extended.\n                            [operator]: (...operands) => {\n                                // build off a fresh copy of the existing `link`, just in case\n                                // the same link is being used elsewhere by the customer.\n                                const { query: copiedLinkQuery, newTail } = copyLink();\n                                // normalize operands. if any of the values are `undefiend`, use\n                                // `null` instead, because that's what will be stored cross-platform.\n                                const normalizedOperands = operands.map(o => o === undefined ? null : o);\n                                // add the given condition to the link's TAIL node.\n                                // remember: the base link might go N nodes deep! e.g.,\n                                newTail?.operands.push(new FieldCondition(fieldName, operator, normalizedOperands));\n                                // A `FinalModelPredicate`.\n                                // Return a thing that can no longer be extended, but instead used to `async filter(items)`\n                                // or query storage: `.__query.fetch(storage)`.\n                                return registerPredicateInternals(copiedLinkQuery);\n                            },\n                        };\n                    }, {});\n                }\n                else {\n                    if (!allowRecursion) {\n                        throw new Error('Predication on releated models is not supported in this context.');\n                    }\n                    else if (def.association.connectionType === 'BELONGS_TO' ||\n                        def.association.connectionType === 'HAS_ONE' ||\n                        def.association.connectionType === 'HAS_MANY') {\n                        // the use has just typed '.someRelatedModel'. we need to given them\n                        // back a predicate chain.\n                        const relatedMeta = def.type.modelConstructor;\n                        if (!relatedMeta) {\n                            throw new Error('Related model metadata is missing. This is a bug! Please report it.');\n                        }\n                        // `Model.reletedModelField` returns a copy of the original link,\n                        // and will contains copies of internal GroupConditions\n                        // to head off mutability concerns.\n                        const [newquery, oldtail] = baseCondition.copy(tailCondition);\n                        const newtail = new GroupCondition(relatedMeta, fieldName, def.association.connectionType, 'and', []);\n                        // `oldtail` here refers to the *copy* of the old tail.\n                        // so, it's safe to modify at this point. and we need to modify\n                        // it to push the *new* tail onto the end of it.\n                        oldtail.operands.push(newtail);\n                        const newlink = recursivePredicateFor(relatedMeta, allowRecursion, undefined, newquery, newtail);\n                        return newlink;\n                    }\n                    else {\n                        throw new Error(\"Related model definition doesn't have a typedef. This is a bug! Please report it.\");\n                    }\n                }\n            },\n        });\n    }\n    return link;\n}\nfunction predicateFor(ModelType) {\n    // the cast here is just a cheap way to reduce the surface area from\n    // the recursive type.\n    return recursivePredicateFor(ModelType, false);\n}\n\nexport { FieldCondition, GroupCondition, internals, predicateFor, recursivePredicateFor };\n//# sourceMappingURL=next.mjs.map\n","class ModelSortPredicateCreator {\n    static createPredicateBuilder(modelDefinition) {\n        const { name: modelName } = modelDefinition;\n        const fieldNames = new Set(Object.keys(modelDefinition.fields));\n        const predicate = new Proxy({}, {\n            get(_target, propertyKey, receiver) {\n                const field = propertyKey;\n                if (!fieldNames.has(field)) {\n                    throw new Error(`Invalid field for model. field: ${String(field)}, model: ${modelName}`);\n                }\n                const result = (sortDirection) => {\n                    ModelSortPredicateCreator.sortPredicateGroupsMap\n                        .get(receiver)\n                        ?.push({ field, sortDirection });\n                    return receiver;\n                };\n                return result;\n            },\n        });\n        ModelSortPredicateCreator.sortPredicateGroupsMap.set(predicate, []);\n        return predicate;\n    }\n    static isValidPredicate(predicate) {\n        return ModelSortPredicateCreator.sortPredicateGroupsMap.has(predicate);\n    }\n    static getPredicates(predicate, throwOnInvalid = true) {\n        if (throwOnInvalid &&\n            !ModelSortPredicateCreator.isValidPredicate(predicate)) {\n            throw new Error('The predicate is not valid');\n        }\n        const predicateGroup = ModelSortPredicateCreator.sortPredicateGroupsMap.get(predicate);\n        if (predicateGroup) {\n            return predicateGroup;\n        }\n        else {\n            throw new Error('Predicate group not found');\n        }\n    }\n    // transforms cb-style predicate into Proxy\n    static createFromExisting(modelDefinition, existing) {\n        if (!existing || !modelDefinition) {\n            return undefined;\n        }\n        return existing(ModelSortPredicateCreator.createPredicateBuilder(modelDefinition));\n    }\n}\nModelSortPredicateCreator.sortPredicateGroupsMap = new WeakMap();\n\nexport { ModelSortPredicateCreator };\n//# sourceMappingURL=sort.mjs.map\n","import { OpType, QueryOne } from '../../types.mjs';\nimport { getIndexKeys, traverseModel, keysEqual, DEFAULT_PRIMARY_KEY_VALUE_SEPARATOR, validatePredicate, inMemoryPagination, getStorename } from '../../util.mjs';\nimport AsyncStorageDatabase from './AsyncStorageDatabase.mjs';\nimport { StorageAdapterBase } from './StorageAdapterBase.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nclass AsyncStorageAdapter extends StorageAdapterBase {\n    async preSetUpChecks() {\n        // no-ops for AsyncStorageAdapter\n    }\n    async preOpCheck() {\n        // no-ops for AsyncStorageAdapter\n    }\n    /**\n     * Open AsyncStorage database\n     * Create new DB if one doesn't exist\n     *\n     * Called by `StorageAdapterBase.setUp()`\n     *\n     * @returns AsyncStorageDatabase instance\n     */\n    async initDb() {\n        const db = new AsyncStorageDatabase();\n        await db.init();\n        return db;\n    }\n    async clear() {\n        await this.db.clear();\n        this.db = undefined;\n        this.initPromise = undefined;\n    }\n    async batchSave(modelConstructor, items) {\n        if (items.length === 0) {\n            return [];\n        }\n        const modelName = modelConstructor.name;\n        const namespaceName = this.namespaceResolver(modelConstructor);\n        const storeName = getStorename(namespaceName, modelName);\n        const keys = getIndexKeys(this.schema.namespaces[namespaceName], modelName);\n        const batch = [];\n        for (const item of items) {\n            const model = this.modelInstanceCreator(modelConstructor, item);\n            const connectedModels = traverseModel(modelName, model, this.schema.namespaces[namespaceName], this.modelInstanceCreator, this.getModelConstructorByModelName);\n            const keyValuesPath = this.getIndexKeyValuesPath(model);\n            const { instance } = connectedModels.find(({ instance: connectedModelInstance }) => {\n                const instanceKeyValuesPath = this.getIndexKeyValuesPath(connectedModelInstance);\n                return keysEqual([instanceKeyValuesPath], [keyValuesPath]);\n            });\n            batch.push(instance);\n        }\n        return this.db.batchSave(storeName, batch, keys);\n    }\n    async _get(storeName, keyArr) {\n        const itemKeyValuesPath = keyArr.join(DEFAULT_PRIMARY_KEY_VALUE_SEPARATOR);\n        return (await this.db.get(itemKeyValuesPath, storeName));\n    }\n    async save(model, condition) {\n        const { storeName, connectionStoreNames, modelKeyValues } = this.saveMetadata(model);\n        const fromDB = await this._get(storeName, modelKeyValues);\n        this.validateSaveCondition(condition, fromDB);\n        const result = [];\n        for await (const resItem of connectionStoreNames) {\n            const { storeName: storeNameForRestItem, item, instance, keys } = resItem;\n            const itemKeyValues = keys.map(key => item[key]);\n            const fromDBForRestItem = (await this._get(storeNameForRestItem, itemKeyValues));\n            const opType = fromDBForRestItem ? OpType.UPDATE : OpType.INSERT;\n            if (keysEqual(itemKeyValues, modelKeyValues) ||\n                opType === OpType.INSERT) {\n                await this.db.save(item, storeNameForRestItem, keys, itemKeyValues.join(DEFAULT_PRIMARY_KEY_VALUE_SEPARATOR));\n                result.push([instance, opType]);\n            }\n        }\n        return result;\n    }\n    async query(modelConstructor, predicate, pagination) {\n        const { storeName, namespaceName, queryByKey, predicates, hasSort, hasPagination, } = this.queryMetadata(modelConstructor, predicate, pagination);\n        const records = (await (async () => {\n            if (queryByKey) {\n                const keyValues = queryByKey.join(DEFAULT_PRIMARY_KEY_VALUE_SEPARATOR);\n                const record = await this.getByKey(storeName, keyValues);\n                return record ? [record] : [];\n            }\n            if (predicates) {\n                const filtered = await this.filterOnPredicate(storeName, predicates);\n                return this.inMemoryPagination(filtered, pagination);\n            }\n            if (hasSort || hasPagination) {\n                const all = await this.getAll(storeName);\n                return this.inMemoryPagination(all, pagination);\n            }\n            return this.getAll(storeName);\n        })());\n        return this.load(namespaceName, modelConstructor.name, records);\n    }\n    async getByKey(storeName, keyValuePath) {\n        return (await this.db.get(keyValuePath, storeName));\n    }\n    async getAll(storeName) {\n        return this.db.getAll(storeName);\n    }\n    async filterOnPredicate(storeName, predicates) {\n        const { predicates: predicateObjs, type } = predicates;\n        const all = (await this.getAll(storeName));\n        const filtered = predicateObjs\n            ? all.filter(m => validatePredicate(m, type, predicateObjs))\n            : all;\n        return filtered;\n    }\n    inMemoryPagination(records, pagination) {\n        return inMemoryPagination(records, pagination);\n    }\n    async queryOne(modelConstructor, firstOrLast = QueryOne.FIRST) {\n        const storeName = this.getStorenameForModel(modelConstructor);\n        const result = (await this.db.getOne(firstOrLast, storeName));\n        return result && this.modelInstanceCreator(modelConstructor, result);\n    }\n    async deleteItem(deleteQueue) {\n        for await (const deleteItem of deleteQueue) {\n            const { storeName, items } = deleteItem;\n            for await (const item of items) {\n                if (item) {\n                    if (typeof item === 'object') {\n                        const keyValuesPath = this.getIndexKeyValuesPath(item);\n                        await this.db.delete(keyValuesPath, storeName);\n                    }\n                }\n            }\n        }\n    }\n    // #region platform-specific helper methods\n    /**\n     * Retrieves concatenated primary key values from a model\n     *\n     * @param model\n     * @returns\n     */\n    getIndexKeyValuesPath(model) {\n        return this.getIndexKeyValuesFromModel(model).join(DEFAULT_PRIMARY_KEY_VALUE_SEPARATOR);\n    }\n}\nvar AsyncStorageAdapter$1 = new AsyncStorageAdapter();\n\nexport { AsyncStorageAdapter, AsyncStorageAdapter$1 as default };\n//# sourceMappingURL=AsyncStorageAdapter.mjs.map\n","import { OpType, QueryOne } from '../../types.mjs';\nimport { monotonicUlidFactory, indexNameFromKeys, DEFAULT_PRIMARY_KEY_VALUE_SEPARATOR } from '../../util.mjs';\nimport { createInMemoryStore } from './InMemoryStore.mjs';\n\nconst DB_NAME = '@AmplifyDatastore';\nconst COLLECTION = 'Collection';\nconst DATA = 'Data';\nconst monotonicFactoriesMap = new Map();\nclass AsyncStorageDatabase {\n    constructor() {\n        /**\n         * Maps storeNames to a map of ulid->id\n         */\n        this._collectionInMemoryIndex = new Map();\n        this.storage = createInMemoryStore();\n    }\n    /**\n     * Collection index is map of stores (i.e. sync, metadata, mutation event, and data)\n     * @param storeName {string} - Name of the store\n     * @returns Map of ulid->id\n     */\n    getCollectionIndex(storeName) {\n        if (!this._collectionInMemoryIndex.has(storeName)) {\n            this._collectionInMemoryIndex.set(storeName, new Map());\n        }\n        return this._collectionInMemoryIndex.get(storeName);\n    }\n    /**\n     * Return ULID for store if it exists, otherwise create a new one\n     * @param storeName {string} - Name of the store\n     * @returns ulid\n     */\n    getMonotonicFactory(storeName) {\n        if (!monotonicFactoriesMap.has(storeName)) {\n            monotonicFactoriesMap.set(storeName, monotonicUlidFactory());\n        }\n        return monotonicFactoriesMap.get(storeName);\n    }\n    async init() {\n        this._collectionInMemoryIndex.clear();\n        const allKeys = await this.storage.getAllKeys();\n        const keysForCollectionEntries = [];\n        for (const key of allKeys) {\n            const [dbName, storeName, recordType, ulidOrId, id] = key.split('::');\n            if (dbName === DB_NAME) {\n                if (recordType === DATA) {\n                    let ulid;\n                    if (id === undefined) {\n                        // It is an old entry (without ulid). Need to migrate to new key format\n                        const resolvedId = ulidOrId;\n                        const newUlid = this.getMonotonicFactory(storeName)();\n                        const oldKey = this.getLegacyKeyForItem(storeName, resolvedId);\n                        const newKey = this.getKeyForItem(storeName, resolvedId, newUlid);\n                        const item = await this.storage.getItem(oldKey);\n                        await this.storage.setItem(newKey, item);\n                        await this.storage.removeItem(oldKey);\n                        ulid = newUlid;\n                    }\n                    else {\n                        ulid = ulidOrId;\n                    }\n                    this.getCollectionIndex(storeName).set(id, ulid);\n                }\n                else if (recordType === COLLECTION) {\n                    keysForCollectionEntries.push(key);\n                }\n            }\n        }\n        if (keysForCollectionEntries.length > 0) {\n            await this.storage.multiRemove(keysForCollectionEntries);\n        }\n    }\n    async save(item, storeName, keys, keyValuesPath) {\n        const idxName = indexNameFromKeys(keys);\n        const ulid = this.getCollectionIndex(storeName)?.get(idxName) ||\n            this.getMonotonicFactory(storeName)();\n        // Retrieve db key for item\n        const itemKey = this.getKeyForItem(storeName, keyValuesPath, ulid);\n        // Set key in collection index\n        this.getCollectionIndex(storeName)?.set(keyValuesPath, ulid);\n        // Save item in db\n        await this.storage.setItem(itemKey, JSON.stringify(item));\n    }\n    async batchSave(storeName, items, keys) {\n        if (items.length === 0) {\n            return [];\n        }\n        const result = [];\n        const collection = this.getCollectionIndex(storeName);\n        const keysToDelete = new Set();\n        const keysToSave = new Set();\n        const allItemsKeys = [];\n        const itemsMap = {};\n        /* Populate allItemKeys, keysToDelete, and keysToSave */\n        for (const item of items) {\n            // Extract keys from concatenated key path, map to item values\n            const keyValues = keys.map(field => item[field]);\n            const { _deleted } = item;\n            // If id is in the store, retrieve, otherwise generate new ULID\n            const ulid = collection.get(keyValues.join(DEFAULT_PRIMARY_KEY_VALUE_SEPARATOR)) ||\n                this.getMonotonicFactory(storeName)();\n            // Generate the \"longer key\" for the item\n            const key = this.getKeyForItem(storeName, keyValues.join(DEFAULT_PRIMARY_KEY_VALUE_SEPARATOR), ulid);\n            allItemsKeys.push(key);\n            itemsMap[key] = { ulid, model: item };\n            if (_deleted) {\n                keysToDelete.add(key);\n            }\n            else {\n                keysToSave.add(key);\n            }\n        }\n        const existingRecordsMap = await this.storage.multiGet(allItemsKeys);\n        const existingRecordsKeys = existingRecordsMap\n            .filter(([, v]) => !!v)\n            .reduce((set, [k]) => set.add(k), new Set());\n        // Delete\n        await new Promise((resolve, reject) => {\n            if (keysToDelete.size === 0) {\n                resolve();\n                return;\n            }\n            const keysToDeleteArray = Array.from(keysToDelete);\n            keysToDeleteArray.forEach(key => {\n                // key: full db key\n                // keys: PK and/or SK keys\n                const primaryKeyValues = keys\n                    .map(field => itemsMap[key].model[field])\n                    .join(DEFAULT_PRIMARY_KEY_VALUE_SEPARATOR);\n                collection.delete(primaryKeyValues);\n            });\n            this.storage.multiRemove(keysToDeleteArray, (errors) => {\n                if (errors && errors.length > 0) {\n                    reject(errors);\n                }\n                else {\n                    resolve();\n                }\n            });\n        });\n        // Save\n        await new Promise((resolve, reject) => {\n            if (keysToSave.size === 0) {\n                resolve();\n                return;\n            }\n            const entriesToSet = Array.from(keysToSave).map(key => [\n                key,\n                JSON.stringify(itemsMap[key].model),\n            ]);\n            keysToSave.forEach(key => {\n                const { model, ulid } = itemsMap[key];\n                // Retrieve values from model, use as key for collection index\n                const keyValues = keys\n                    .map(field => model[field])\n                    .join(DEFAULT_PRIMARY_KEY_VALUE_SEPARATOR);\n                collection.set(keyValues, ulid);\n            });\n            this.storage.multiSet(entriesToSet, (errors) => {\n                if (errors && errors.length > 0) {\n                    reject(errors);\n                }\n                else {\n                    resolve();\n                }\n            });\n        });\n        for (const key of allItemsKeys) {\n            if (keysToDelete.has(key) && existingRecordsKeys.has(key)) {\n                result.push([itemsMap[key].model, OpType.DELETE]);\n            }\n            else if (keysToSave.has(key)) {\n                result.push([\n                    itemsMap[key].model,\n                    existingRecordsKeys.has(key) ? OpType.UPDATE : OpType.INSERT,\n                ]);\n            }\n        }\n        return result;\n    }\n    async get(keyValuePath, storeName) {\n        const ulid = this.getCollectionIndex(storeName).get(keyValuePath);\n        const itemKey = this.getKeyForItem(storeName, keyValuePath, ulid);\n        const recordAsString = await this.storage.getItem(itemKey);\n        const record = recordAsString && JSON.parse(recordAsString);\n        return record;\n    }\n    async getOne(firstOrLast, storeName) {\n        const collection = this.getCollectionIndex(storeName);\n        const [itemId, ulid] = firstOrLast === QueryOne.FIRST\n            ? (() => {\n                let resolvedId, resolvedUlid;\n                // eslint-disable-next-line no-unreachable-loop\n                for ([resolvedId, resolvedUlid] of collection)\n                    break; // Get first element of the set\n                return [resolvedId, resolvedUlid];\n            })()\n            : (() => {\n                let resolvedId, resolvedUlid;\n                for ([resolvedId, resolvedUlid] of collection)\n                    ; // Get last element of the set\n                return [resolvedId, resolvedUlid];\n            })();\n        const itemKey = this.getKeyForItem(storeName, itemId, ulid);\n        const itemString = itemKey && (await this.storage.getItem(itemKey));\n        const result = itemString ? JSON.parse(itemString) || undefined : undefined;\n        return result;\n    }\n    /**\n     * This function gets all the records stored in async storage for a particular storeName\n     * It then loads all the records for that filtered set of keys using multiGet()\n     */\n    async getAll(storeName, pagination) {\n        const collection = this.getCollectionIndex(storeName);\n        const { page = 0, limit = 0 } = pagination || {};\n        const start = Math.max(0, page * limit) || 0;\n        const end = limit > 0 ? start + limit : undefined;\n        const keysForStore = [];\n        let count = 0;\n        for (const [id, ulid] of collection) {\n            count++;\n            if (count <= start) {\n                continue;\n            }\n            keysForStore.push(this.getKeyForItem(storeName, id, ulid));\n            if (count === end) {\n                break;\n            }\n        }\n        const storeRecordStrings = await this.storage.multiGet(keysForStore);\n        const records = storeRecordStrings\n            .filter(([, value]) => value)\n            .map(([, value]) => JSON.parse(value));\n        return records;\n    }\n    async delete(key, storeName) {\n        const ulid = this.getCollectionIndex(storeName).get(key);\n        const itemKey = this.getKeyForItem(storeName, key, ulid);\n        this.getCollectionIndex(storeName).delete(key);\n        await this.storage.removeItem(itemKey);\n    }\n    /**\n     * Clear the AsyncStorage of all DataStore entries\n     */\n    async clear() {\n        const allKeys = await this.storage.getAllKeys();\n        const allDataStoreKeys = allKeys.filter(key => key.startsWith(DB_NAME));\n        await this.storage.multiRemove(allDataStoreKeys);\n        this._collectionInMemoryIndex.clear();\n    }\n    getKeyForItem(storeName, id, ulid) {\n        return `${this.getKeyPrefixForStoreItems(storeName)}::${ulid}::${id}`;\n    }\n    getLegacyKeyForItem(storeName, id) {\n        return `${this.getKeyPrefixForStoreItems(storeName)}::${id}`;\n    }\n    getKeyPrefixForStoreItems(storeName) {\n        return `${DB_NAME}::${storeName}::${DATA}`;\n    }\n}\n\nexport { AsyncStorageDatabase as default };\n//# sourceMappingURL=AsyncStorageDatabase.mjs.map\n","// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nclass InMemoryStore {\n    constructor() {\n        this.db = new Map();\n        this.getAllKeys = async () => {\n            return Array.from(this.db.keys());\n        };\n        this.multiGet = async (keys) => {\n            return keys.reduce((res, k) => {\n                res.push([k, this.db.get(k)]);\n                return res;\n            }, []);\n        };\n        this.multiRemove = async (keys, callback) => {\n            keys.forEach(k => this.db.delete(k));\n            typeof callback === 'function' && callback();\n        };\n        this.multiSet = async (entries, callback) => {\n            entries.forEach(([key, value]) => {\n                this.setItem(key, value);\n            });\n            typeof callback === 'function' && callback();\n        };\n        this.setItem = async (key, value) => {\n            return this.db.set(key, value);\n        };\n        this.removeItem = async (key) => {\n            return this.db.delete(key);\n        };\n        this.getItem = async (key) => {\n            return this.db.get(key);\n        };\n    }\n}\nfunction createInMemoryStore() {\n    return new InMemoryStore();\n}\n\nexport { InMemoryStore, createInMemoryStore };\n//# sourceMappingURL=InMemoryStore.mjs.map\n","import * as idb from 'idb';\nimport { ConsoleLogger } from '@aws-amplify/core';\nimport { OpType, QueryOne, isPredicateGroup, isPredicateObj } from '../../types.mjs';\nimport { getStorename, keysEqual, traverseModel, isPrivateMode, isSafariCompatabilityMode, validatePredicate, inMemoryPagination } from '../../util.mjs';\nimport { StorageAdapterBase } from './StorageAdapterBase.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst logger = new ConsoleLogger('DataStore');\n/**\n * The point after which queries composed of multiple simple OR conditions\n * should scan-and-filter instead of individual queries for each condition.\n *\n * At some point, this should be configurable and/or dynamic based on table\n * size and possibly even on observed average seek latency. For now, it's\n * based on an manual \"binary search\" for the breakpoint as measured in the\n * unit test suite. This isn't necessarily optimal. But, it's at least derived\n * empirically, rather than theoretically and without any verification!\n *\n * REMEMBER! If you run more realistic benchmarks and update this value, update\n * this comment so the validity and accuracy of future query tuning exercises\n * can be compared to the methods used to derive the current value. E.g.,\n *\n * 1. In browser benchmark > unit test benchmark\n * 2. Multi-browser benchmark > single browser benchmark\n * 3. Benchmarks of various table sizes > static table size benchmark\n *\n * etc...\n *\n */\nconst MULTI_OR_CONDITION_SCAN_BREAKPOINT = 7;\n//\nconst DB_VERSION = 3;\nclass IndexedDBAdapter extends StorageAdapterBase {\n    constructor() {\n        super(...arguments);\n        this.safariCompatabilityMode = false;\n        /**\n         * Checks the given path against the browser's IndexedDB implementation for\n         * necessary compatibility transformations, applying those transforms if needed.\n         *\n         * @param `keyArr` strings to compatibilize for browser-indexeddb index operations\n         * @returns An array or string, depending on and given key,\n         * that is ensured to be compatible with the IndexedDB implementation's nuances.\n         */\n        this.canonicalKeyPath = (keyArr) => {\n            if (this.safariCompatabilityMode) {\n                return keyArr.length > 1 ? keyArr : keyArr[0];\n            }\n            return keyArr;\n        };\n        // #endregion\n    }\n    // checks are called by StorageAdapterBase class\n    async preSetUpChecks() {\n        await this.checkPrivate();\n        await this.setSafariCompatabilityMode();\n    }\n    async preOpCheck() {\n        await this.checkPrivate();\n    }\n    /**\n     * Initialize IndexedDB database\n     * Create new DB if one doesn't exist\n     * Upgrade outdated DB\n     *\n     * Called by `StorageAdapterBase.setUp()`\n     *\n     * @returns IDB Database instance\n     */\n    async initDb() {\n        return idb.openDB(this.dbName, DB_VERSION, {\n            upgrade: async (db, oldVersion, newVersion, txn) => {\n                // create new database\n                if (oldVersion === 0) {\n                    Object.keys(this.schema.namespaces).forEach(namespaceName => {\n                        const namespace = this.schema.namespaces[namespaceName];\n                        Object.keys(namespace.models).forEach(modelName => {\n                            const storeName = getStorename(namespaceName, modelName);\n                            this.createObjectStoreForModel(db, namespaceName, storeName, modelName);\n                        });\n                    });\n                    return;\n                }\n                // migrate existing database to latest schema\n                if ((oldVersion === 1 || oldVersion === 2) && newVersion === 3) {\n                    try {\n                        for (const storeName of txn.objectStoreNames) {\n                            const origStore = txn.objectStore(storeName);\n                            // rename original store\n                            const tmpName = `tmp_${storeName}`;\n                            origStore.name = tmpName;\n                            const { namespaceName, modelName } = this.getNamespaceAndModelFromStorename(storeName);\n                            const modelInCurrentSchema = modelName in this.schema.namespaces[namespaceName].models;\n                            if (!modelInCurrentSchema) {\n                                // delete original\n                                db.deleteObjectStore(tmpName);\n                                continue;\n                            }\n                            const newStore = this.createObjectStoreForModel(db, namespaceName, storeName, modelName);\n                            let cursor = await origStore.openCursor();\n                            let count = 0;\n                            // Copy data from original to new\n                            while (cursor && cursor.value) {\n                                // we don't pass key, since they are all new entries in the new store\n                                await newStore.put(cursor.value);\n                                cursor = await cursor.continue();\n                                count++;\n                            }\n                            // delete original\n                            db.deleteObjectStore(tmpName);\n                            logger.debug(`${count} ${storeName} records migrated`);\n                        }\n                        // add new models created after IndexedDB, but before migration\n                        // this case may happen when a user has not opened an app for\n                        // some time and a new model is added during that time\n                        Object.keys(this.schema.namespaces).forEach(namespaceName => {\n                            const namespace = this.schema.namespaces[namespaceName];\n                            const objectStoreNames = new Set(txn.objectStoreNames);\n                            Object.keys(namespace.models)\n                                .map(modelName => {\n                                return [modelName, getStorename(namespaceName, modelName)];\n                            })\n                                .filter(([, storeName]) => !objectStoreNames.has(storeName))\n                                .forEach(([modelName, storeName]) => {\n                                this.createObjectStoreForModel(db, namespaceName, storeName, modelName);\n                            });\n                        });\n                    }\n                    catch (error) {\n                        logger.error('Error migrating IndexedDB data', error);\n                        txn.abort();\n                        throw error;\n                    }\n                }\n            },\n        });\n    }\n    async _get(storeOrStoreName, keyArr) {\n        let index;\n        if (typeof storeOrStoreName === 'string') {\n            const storeName = storeOrStoreName;\n            index = this.db.transaction(storeName, 'readonly').store.index('byPk');\n        }\n        else {\n            const store = storeOrStoreName;\n            index = store.index('byPk');\n        }\n        const result = await index.get(this.canonicalKeyPath(keyArr));\n        return result;\n    }\n    async clear() {\n        await this.checkPrivate();\n        this.db?.close();\n        await idb.deleteDB(this.dbName);\n        this.db = undefined;\n        this.initPromise = undefined;\n    }\n    async save(model, condition) {\n        await this.checkPrivate();\n        const { storeName, set, connectionStoreNames, modelKeyValues } = this.saveMetadata(model);\n        const tx = this.db.transaction([storeName, ...Array.from(set.values())], 'readwrite');\n        const store = tx.objectStore(storeName);\n        const fromDB = await this._get(store, modelKeyValues);\n        this.validateSaveCondition(condition, fromDB);\n        const result = [];\n        for await (const resItem of connectionStoreNames) {\n            const { storeName: storeNameForRestItem, item, instance, keys } = resItem;\n            const storeForRestItem = tx.objectStore(storeNameForRestItem);\n            const itemKeyValues = keys.map(key => item[key]);\n            const fromDBForRestItem = (await this._get(storeForRestItem, itemKeyValues));\n            const opType = fromDBForRestItem ? OpType.UPDATE : OpType.INSERT;\n            if (keysEqual(itemKeyValues, modelKeyValues) ||\n                opType === OpType.INSERT) {\n                const key = await storeForRestItem\n                    .index('byPk')\n                    .getKey(this.canonicalKeyPath(itemKeyValues));\n                await storeForRestItem.put(item, key);\n                result.push([instance, opType]);\n            }\n        }\n        await tx.done;\n        return result;\n    }\n    async query(modelConstructor, predicate, pagination) {\n        await this.checkPrivate();\n        const { storeName, namespaceName, queryByKey, predicates, hasSort, hasPagination, } = this.queryMetadata(modelConstructor, predicate, pagination);\n        const records = (await (async () => {\n            //\n            // NOTE: @svidgen explored removing this and letting query() take care of automatic\n            // index leveraging. This would eliminate some amount of very similar code.\n            // But, getAll is slightly slower than get()\n            //\n            // On Chrome:\n            //   ~700ms vs ~1175ms per 10k reads.\n            //\n            // You can (and should) check my work here:\n            // \thttps://gist.github.com/svidgen/74e55d573b19c3e5432b1b5bdf0f4d96\n            //\n            if (queryByKey) {\n                const record = await this.getByKey(storeName, queryByKey);\n                return record ? [record] : [];\n            }\n            if (predicates) {\n                const filtered = await this.filterOnPredicate(storeName, predicates);\n                return this.inMemoryPagination(filtered, pagination);\n            }\n            if (hasSort) {\n                const all = await this.getAll(storeName);\n                return this.inMemoryPagination(all, pagination);\n            }\n            if (hasPagination) {\n                return this.enginePagination(storeName, pagination);\n            }\n            return this.getAll(storeName);\n        })());\n        return this.load(namespaceName, modelConstructor.name, records);\n    }\n    async queryOne(modelConstructor, firstOrLast = QueryOne.FIRST) {\n        await this.checkPrivate();\n        const storeName = this.getStorenameForModel(modelConstructor);\n        const cursor = await this.db\n            .transaction([storeName], 'readonly')\n            .objectStore(storeName)\n            .openCursor(undefined, firstOrLast === QueryOne.FIRST ? 'next' : 'prev');\n        const result = cursor ? cursor.value : undefined;\n        return result && this.modelInstanceCreator(modelConstructor, result);\n    }\n    async batchSave(modelConstructor, items) {\n        await this.checkPrivate();\n        if (items.length === 0) {\n            return [];\n        }\n        const modelName = modelConstructor.name;\n        const namespaceName = this.namespaceResolver(modelConstructor);\n        const storeName = this.getStorenameForModel(modelConstructor);\n        const result = [];\n        const txn = this.db.transaction(storeName, 'readwrite');\n        const { store } = txn;\n        for (const item of items) {\n            const model = this.modelInstanceCreator(modelConstructor, item);\n            const connectedModels = traverseModel(modelName, model, this.schema.namespaces[namespaceName], this.modelInstanceCreator, this.getModelConstructorByModelName);\n            const keyValues = this.getIndexKeyValuesFromModel(model);\n            const { _deleted } = item;\n            const index = store.index('byPk');\n            const key = await index.getKey(this.canonicalKeyPath(keyValues));\n            if (!_deleted) {\n                const { instance } = connectedModels.find(({ instance: connectedModelInstance }) => {\n                    const instanceKeyValues = this.getIndexKeyValuesFromModel(connectedModelInstance);\n                    return keysEqual(instanceKeyValues, keyValues);\n                });\n                result.push([\n                    instance,\n                    key ? OpType.UPDATE : OpType.INSERT,\n                ]);\n                await store.put(instance, key);\n            }\n            else {\n                result.push([item, OpType.DELETE]);\n                if (key) {\n                    await store.delete(key);\n                }\n            }\n        }\n        await txn.done;\n        return result;\n    }\n    async deleteItem(deleteQueue) {\n        const connectionStoreNames = deleteQueue.map(({ storeName }) => {\n            return storeName;\n        });\n        const tx = this.db.transaction([...connectionStoreNames], 'readwrite');\n        for await (const deleteItem of deleteQueue) {\n            const { storeName, items } = deleteItem;\n            const store = tx.objectStore(storeName);\n            for await (const item of items) {\n                if (item) {\n                    let key;\n                    if (typeof item === 'object') {\n                        const keyValues = this.getIndexKeyValuesFromModel(item);\n                        key = await store\n                            .index('byPk')\n                            .getKey(this.canonicalKeyPath(keyValues));\n                    }\n                    else {\n                        const itemKey = item.toString();\n                        key = await store.index('byPk').getKey(itemKey);\n                    }\n                    if (key !== undefined) {\n                        await store.delete(key);\n                    }\n                }\n            }\n        }\n    }\n    // #region platform-specific helper methods\n    async checkPrivate() {\n        const isPrivate = await isPrivateMode();\n        if (isPrivate) {\n            logger.error(\"IndexedDB not supported in this browser's private mode\");\n            // eslint-disable-next-line prefer-promise-reject-errors\n            return Promise.reject(\"IndexedDB not supported in this browser's private mode\");\n        }\n        else {\n            return Promise.resolve();\n        }\n    }\n    /**\n     * Whether the browser's implementation of IndexedDB is coercing single-field\n     * indexes to a scalar key.\n     *\n     * If this returns `true`, we need to treat indexes containing a single field\n     * as scalars.\n     *\n     * See PR description for reference:\n     * https://github.com/aws-amplify/amplify-js/pull/10527\n     */\n    async setSafariCompatabilityMode() {\n        this.safariCompatabilityMode = await isSafariCompatabilityMode();\n        if (this.safariCompatabilityMode === true) {\n            logger.debug('IndexedDB Adapter is running in Safari Compatability Mode');\n        }\n    }\n    getNamespaceAndModelFromStorename(storeName) {\n        const [namespaceName, ...modelNameArr] = storeName.split('_');\n        return {\n            namespaceName,\n            modelName: modelNameArr.join('_'),\n        };\n    }\n    createObjectStoreForModel(db, namespaceName, storeName, modelName) {\n        const store = db.createObjectStore(storeName, {\n            autoIncrement: true,\n        });\n        const { indexes } = this.schema.namespaces[namespaceName].relationships[modelName];\n        indexes.forEach(([idxName, keyPath, options]) => {\n            store.createIndex(idxName, keyPath, options);\n        });\n        return store;\n    }\n    async getByKey(storeName, keyValue) {\n        return (await this._get(storeName, keyValue));\n    }\n    async getAll(storeName) {\n        return this.db.getAll(storeName);\n    }\n    /**\n     * Tries to generate an index fetcher for the given predicates. Assumes\n     * that the given predicate conditions are contained by an AND group and\n     * should therefore all match a single record.\n     *\n     * @param storeName The table to query.\n     * @param predicates The predicates to try to AND together.\n     * @param transaction\n     */\n    matchingIndexQueries(storeName, predicates, transaction) {\n        // could be expanded later to include `exec()` and a `cardinality` estimate?\n        const queries = [];\n        const predicateIndex = new Map();\n        for (const predicate of predicates) {\n            predicateIndex.set(String(predicate.field), predicate);\n        }\n        const store = transaction.objectStore(storeName);\n        for (const name of store.indexNames) {\n            const idx = store.index(name);\n            const keypath = Array.isArray(idx.keyPath) ? idx.keyPath : [idx.keyPath];\n            const matchingPredicateValues = [];\n            for (const field of keypath) {\n                const p = predicateIndex.get(field);\n                if (p && p.operand !== null && p.operand !== undefined) {\n                    matchingPredicateValues.push(p.operand);\n                }\n                else {\n                    break;\n                }\n            }\n            // if we have a matching predicate field for each component of this index,\n            // we can build a query for it. otherwise, we can't.\n            if (matchingPredicateValues.length === keypath.length) {\n                // re-create a transaction, because the transaction used to fetch the\n                // indexes may no longer be active.\n                queries.push(() => this.db\n                    .transaction(storeName)\n                    .objectStore(storeName)\n                    .index(name)\n                    .getAll(this.canonicalKeyPath(matchingPredicateValues)));\n            }\n        }\n        return queries;\n    }\n    async baseQueryIndex(storeName, predicates, transaction) {\n        let { predicates: predicateObjs, type } = predicates;\n        // the predicate objects we care about tend to be nested at least\n        // one level down: `{and: {or: {and: { <the predicates we want> }}}}`\n        // so, we unpack and/or groups until we find a group with more than 1\n        // child OR a child that is not a group (and is therefore a predicate \"object\").\n        while (predicateObjs.length === 1 &&\n            isPredicateGroup(predicateObjs[0]) &&\n            predicateObjs[0].type !== 'not') {\n            ({ type } = predicateObjs[0]);\n            predicateObjs = predicateObjs[0].predicates;\n        }\n        const fieldPredicates = predicateObjs.filter(p => isPredicateObj(p) && p.operator === 'eq');\n        // several sub-queries could occur here. explicitly start a txn here to avoid\n        // opening/closing multiple txns.\n        const txn = transaction || this.db.transaction(storeName);\n        let result = {};\n        // `or` conditions, if usable, need to generate multiple queries. this is unlike\n        // `and` conditions, which should just be combined.\n        if (type === 'or') {\n            /**\n             * Base queries for each child group.\n             *\n             * For each child group, if it's an AND condition that results in a single\n             * subordinate \"base query\", we can use it. if it's any more complicated\n             * than that, it's not a simple join condition we want to use.\n             */\n            const groupQueries = await Promise.all(predicateObjs\n                .filter(o => isPredicateGroup(o) && o.type === 'and')\n                .map(o => this.baseQueryIndex(storeName, o, txn))).then(queries => queries\n                .filter(q => q.indexedQueries.length === 1)\n                .map(i => i.indexedQueries));\n            /**\n             * Base queries for each simple child \"object\" (field condition).\n             */\n            const objectQueries = predicateObjs\n                .filter(o => isPredicateObj(o))\n                .map(o => this.matchingIndexQueries(storeName, [o], txn));\n            const indexedQueries = [...groupQueries, ...objectQueries]\n                .map(q => q[0])\n                .filter(i => i);\n            // if, after hunting for base queries, we don't have exactly 1 base query\n            // for each child group + object, stop trying to optimize. we're not dealing\n            // with a simple query that fits the intended optimization path.\n            if (predicateObjs.length > indexedQueries.length) {\n                result = {\n                    groupType: null,\n                    indexedQueries: [],\n                };\n            }\n            else {\n                result = {\n                    groupType: 'or',\n                    indexedQueries,\n                };\n            }\n        }\n        else if (type === 'and') {\n            // our potential indexes or lacks thereof.\n            // note that we're only optimizing for `eq` right now.\n            result = {\n                groupType: type,\n                indexedQueries: this.matchingIndexQueries(storeName, fieldPredicates, txn),\n            };\n        }\n        else {\n            result = {\n                groupType: null,\n                indexedQueries: [],\n            };\n        }\n        // Explicitly wait for txns from index queries to complete before proceding.\n        // This helps ensure IndexedDB is in a stable, ready state. Else, subseqeuent\n        // qeuries can sometimes appear to deadlock (at least in FakeIndexedDB).\n        // (Unless we were *given* the transaction -- we'll assume the parent handles it.)\n        if (!transaction)\n            await txn.done;\n        return result;\n    }\n    async filterOnPredicate(storeName, predicates) {\n        const { predicates: predicateObjs, type } = predicates;\n        const { groupType, indexedQueries } = await this.baseQueryIndex(storeName, predicates);\n        // where we'll accumulate candidate results, which will be filtered at the end.\n        let candidateResults;\n        // semi-naive implementation:\n        if (groupType === 'and' && indexedQueries.length > 0) {\n            // each condition must be satsified, we can form a base set with any\n            // ONE of those conditions and then filter.\n            candidateResults = await indexedQueries[0]();\n        }\n        else if (groupType === 'or' &&\n            indexedQueries.length > 0 &&\n            indexedQueries.length <= MULTI_OR_CONDITION_SCAN_BREAKPOINT) {\n            // NOTE: each condition implies a potentially distinct set. we only benefit\n            // from using indexes here if EVERY condition uses an index. if any one\n            // index requires a table scan, we gain nothing from the indexes.\n            // NOTE: results must be DISTINCT-ified if we leverage indexes.\n            const distinctResults = new Map();\n            for (const query of indexedQueries) {\n                const resultGroup = await query();\n                for (const item of resultGroup) {\n                    const distinctificationString = JSON.stringify(item);\n                    distinctResults.set(distinctificationString, item);\n                }\n            }\n            // we could conceivably check for special conditions and return early here.\n            // but, this is simpler and has not yet had a measurable performance impact.\n            candidateResults = Array.from(distinctResults.values());\n        }\n        else {\n            // nothing intelligent we can do with `not` groups unless or until we start\n            // smashing comparison operators against indexes -- at which point we could\n            // perform some reversal here.\n            candidateResults = (await this.getAll(storeName));\n        }\n        const filtered = predicateObjs\n            ? candidateResults.filter(m => validatePredicate(m, type, predicateObjs))\n            : candidateResults;\n        return filtered;\n    }\n    inMemoryPagination(records, pagination) {\n        return inMemoryPagination(records, pagination);\n    }\n    async enginePagination(storeName, pagination) {\n        let result;\n        if (pagination) {\n            const { page = 0, limit = 0 } = pagination;\n            const initialRecord = Math.max(0, page * limit) || 0;\n            let cursor = await this.db\n                .transaction(storeName)\n                .objectStore(storeName)\n                .openCursor();\n            if (cursor && initialRecord > 0) {\n                await cursor.advance(initialRecord);\n            }\n            const pageResults = [];\n            const hasLimit = typeof limit === 'number' && limit > 0;\n            while (cursor && cursor.value) {\n                pageResults.push(cursor.value);\n                if (hasLimit && pageResults.length === limit) {\n                    break;\n                }\n                cursor = await cursor.continue();\n            }\n            result = pageResults;\n        }\n        else {\n            result = (await this.db.getAll(storeName));\n        }\n        return result;\n    }\n}\nvar IndexedDBAdapter$1 = new IndexedDBAdapter();\n\nexport { IndexedDBAdapter$1 as default };\n//# sourceMappingURL=IndexedDBAdapter.mjs.map\n","import { ConsoleLogger } from '@aws-amplify/core';\nimport { ModelPredicateCreator } from '../../predicates/index.mjs';\nimport { isPredicateObj } from '../../types.mjs';\nimport { getStorename, getIndexKeys, extractPrimaryKeyValues, traverseModel, validatePredicate, isModelConstructor, extractPrimaryKeyFieldNames } from '../../util.mjs';\nimport { ModelRelationship } from '../relationship.mjs';\n\nconst logger = new ConsoleLogger('DataStore');\nconst DB_NAME = 'amplify-datastore';\nclass StorageAdapterBase {\n    constructor() {\n        this.dbName = DB_NAME;\n    }\n    /**\n     * Initializes local DB\n     *\n     * @param theSchema\n     * @param namespaceResolver\n     * @param modelInstanceCreator\n     * @param getModelConstructorByModelName\n     * @param sessionId\n     */\n    async setUp(theSchema, namespaceResolver, modelInstanceCreator, getModelConstructorByModelName, sessionId) {\n        await this.preSetUpChecks();\n        if (!this.initPromise) {\n            this.initPromise = new Promise((resolve, reject) => {\n                this.resolve = resolve;\n                this.reject = reject;\n            });\n        }\n        else {\n            await this.initPromise;\n            return;\n        }\n        if (sessionId) {\n            this.dbName = `${DB_NAME}-${sessionId}`;\n        }\n        this.schema = theSchema;\n        this.namespaceResolver = namespaceResolver;\n        this.modelInstanceCreator = modelInstanceCreator;\n        this.getModelConstructorByModelName = getModelConstructorByModelName;\n        try {\n            if (!this.db) {\n                this.db = await this.initDb();\n                this.resolve();\n            }\n        }\n        catch (error) {\n            this.reject(error);\n        }\n    }\n    /**\n     * @param modelConstructor\n     * @returns local DB table name\n     */\n    getStorenameForModel(modelConstructor) {\n        const namespace = this.namespaceResolver(modelConstructor);\n        const { name: modelName } = modelConstructor;\n        return getStorename(namespace, modelName);\n    }\n    /**\n     *\n     * @param model - instantiated model record\n     * @returns the record's primary key values\n     */\n    getIndexKeyValuesFromModel(model) {\n        const modelConstructor = Object.getPrototypeOf(model)\n            .constructor;\n        const namespaceName = this.namespaceResolver(modelConstructor);\n        const keys = getIndexKeys(this.schema.namespaces[namespaceName], modelConstructor.name);\n        return extractPrimaryKeyValues(model, keys);\n    }\n    /**\n     * Common metadata for `save` operation\n     * used by individual storage adapters\n     *\n     * @param model\n     */\n    saveMetadata(model) {\n        const modelConstructor = Object.getPrototypeOf(model)\n            .constructor;\n        const storeName = this.getStorenameForModel(modelConstructor);\n        const namespaceName = this.namespaceResolver(modelConstructor);\n        const connectedModels = traverseModel(modelConstructor.name, model, this.schema.namespaces[namespaceName], this.modelInstanceCreator, this.getModelConstructorByModelName);\n        const set = new Set();\n        const connectionStoreNames = Object.values(connectedModels).map(({ modelName, item, instance }) => {\n            const resolvedStoreName = getStorename(namespaceName, modelName);\n            set.add(resolvedStoreName);\n            const keys = getIndexKeys(this.schema.namespaces[namespaceName], modelName);\n            return { storeName: resolvedStoreName, item, instance, keys };\n        });\n        const modelKeyValues = this.getIndexKeyValuesFromModel(model);\n        return { storeName, set, connectionStoreNames, modelKeyValues };\n    }\n    /**\n     * Enforces conditional save. Throws if condition is not met.\n     * used by individual storage adapters\n     *\n     * @param model\n     */\n    validateSaveCondition(condition, fromDB) {\n        if (!(condition && fromDB)) {\n            return;\n        }\n        const predicates = ModelPredicateCreator.getPredicates(condition);\n        const { predicates: predicateObjs, type } = predicates;\n        const isValid = validatePredicate(fromDB, type, predicateObjs);\n        if (!isValid) {\n            const msg = 'Conditional update failed';\n            logger.error(msg, { model: fromDB, condition: predicateObjs });\n            throw new Error(msg);\n        }\n    }\n    /**\n     * Instantiate models from POJO records returned from the database\n     *\n     * @param namespaceName - string model namespace\n     * @param srcModelName - string model name\n     * @param records - array of uninstantiated records\n     * @returns\n     */\n    async load(namespaceName, srcModelName, records) {\n        const namespace = this.schema.namespaces[namespaceName];\n        const relations = namespace.relationships[srcModelName].relationTypes;\n        const connectionStoreNames = relations.map(({ modelName }) => {\n            return getStorename(namespaceName, modelName);\n        });\n        const modelConstructor = this.getModelConstructorByModelName(namespaceName, srcModelName);\n        if (connectionStoreNames.length === 0) {\n            return records.map(record => this.modelInstanceCreator(modelConstructor, record));\n        }\n        return records.map(record => this.modelInstanceCreator(modelConstructor, record));\n    }\n    /**\n     * Extracts operands from a predicate group into an array of key values\n     * Used in the query method\n     *\n     * @param predicates - predicate group\n     * @param keyPath - string array of key names ['id', 'sortKey']\n     * @returns string[] of key values\n     *\n     * @example\n     * ```js\n     * { and:[{ id: { eq: 'abc' }}, { sortKey: { eq: 'def' }}] }\n     * ```\n     * Becomes\n     * ```\n     * ['abc', 'def']\n     * ```\n     */\n    keyValueFromPredicate(predicates, keyPath) {\n        const { predicates: predicateObjs } = predicates;\n        if (predicateObjs.length !== keyPath.length) {\n            return;\n        }\n        const keyValues = [];\n        for (const key of keyPath) {\n            const predicateObj = predicateObjs.find(p => \n            // it's a relevant predicate object only if it's an equality\n            // operation for a key field from the key:\n            isPredicateObj(p) &&\n                p.field === key &&\n                p.operator === 'eq' &&\n                p.operand !== null &&\n                p.operand !== undefined);\n            predicateObj && keyValues.push(predicateObj.operand);\n        }\n        return keyValues.length === keyPath.length ? keyValues : undefined;\n    }\n    /**\n     * Common metadata for `query` operation\n     * used by individual storage adapters\n     *\n     * @param modelConstructor\n     * @param predicate\n     * @param pagination\n     */\n    queryMetadata(modelConstructor, predicate, pagination) {\n        const storeName = this.getStorenameForModel(modelConstructor);\n        const namespaceName = this.namespaceResolver(modelConstructor);\n        const predicates = predicate && ModelPredicateCreator.getPredicates(predicate);\n        const keyPath = getIndexKeys(this.schema.namespaces[namespaceName], modelConstructor.name);\n        const queryByKey = predicates && this.keyValueFromPredicate(predicates, keyPath);\n        const hasSort = pagination && pagination.sort;\n        const hasPagination = pagination && pagination.limit;\n        return {\n            storeName,\n            namespaceName,\n            queryByKey,\n            predicates,\n            hasSort,\n            hasPagination,\n        };\n    }\n    /**\n     * Delete record\n     * Cascades to related records (for Has One and Has Many relationships)\n     *\n     * @param modelOrModelConstructor\n     * @param condition\n     * @returns\n     */\n    async delete(modelOrModelConstructor, condition) {\n        await this.preOpCheck();\n        const deleteQueue = [];\n        if (isModelConstructor(modelOrModelConstructor)) {\n            const modelConstructor = modelOrModelConstructor;\n            const namespace = this.namespaceResolver(modelConstructor);\n            const models = await this.query(modelConstructor, condition);\n            if (condition !== undefined) {\n                await this.deleteTraverse(models, modelConstructor, namespace, deleteQueue);\n                await this.deleteItem(deleteQueue);\n                const deletedModels = deleteQueue.reduce((acc, { items }) => acc.concat(items), []);\n                return [models, deletedModels];\n            }\n            else {\n                await this.deleteTraverse(models, modelConstructor, namespace, deleteQueue);\n                await this.deleteItem(deleteQueue);\n                const deletedModels = deleteQueue.reduce((acc, { items }) => acc.concat(items), []);\n                return [models, deletedModels];\n            }\n        }\n        else {\n            const model = modelOrModelConstructor;\n            const modelConstructor = Object.getPrototypeOf(model)\n                .constructor;\n            const namespaceName = this.namespaceResolver(modelConstructor);\n            const storeName = this.getStorenameForModel(modelConstructor);\n            if (condition) {\n                const keyValues = this.getIndexKeyValuesFromModel(model);\n                const fromDB = await this._get(storeName, keyValues);\n                if (fromDB === undefined) {\n                    const msg = 'Model instance not found in storage';\n                    logger.warn(msg, { model });\n                    return [[model], []];\n                }\n                const predicates = ModelPredicateCreator.getPredicates(condition);\n                const { predicates: predicateObjs, type } = predicates;\n                const isValid = validatePredicate(fromDB, type, predicateObjs);\n                if (!isValid) {\n                    const msg = 'Conditional update failed';\n                    logger.error(msg, { model: fromDB, condition: predicateObjs });\n                    throw new Error(msg);\n                }\n                await this.deleteTraverse([model], modelConstructor, namespaceName, deleteQueue);\n            }\n            else {\n                await this.deleteTraverse([model], modelConstructor, namespaceName, deleteQueue);\n            }\n            await this.deleteItem(deleteQueue);\n            const deletedModels = deleteQueue.reduce((acc, { items }) => acc.concat(items), []);\n            return [[model], deletedModels];\n        }\n    }\n    /**\n     * Recursively traverse relationship graph and add\n     * all Has One and Has Many relations to `deleteQueue` param\n     *\n     * Actual deletion of records added to `deleteQueue` occurs in the `delete` method\n     *\n     * @param models\n     * @param modelConstructor\n     * @param namespace\n     * @param deleteQueue\n     */\n    async deleteTraverse(models, modelConstructor, namespace, deleteQueue) {\n        const cascadingRelationTypes = ['HAS_ONE', 'HAS_MANY'];\n        for await (const model of models) {\n            const modelDefinition = this.schema.namespaces[namespace].models[modelConstructor.name];\n            const modelMeta = {\n                builder: modelConstructor,\n                schema: modelDefinition,\n                pkField: extractPrimaryKeyFieldNames(modelDefinition),\n            };\n            const relationships = ModelRelationship.allFrom(modelMeta).filter(r => cascadingRelationTypes.includes(r.type));\n            for await (const r of relationships) {\n                const queryObject = r.createRemoteQueryObject(model);\n                if (queryObject !== null) {\n                    const relatedRecords = await this.query(r.remoteModelConstructor, ModelPredicateCreator.createFromFlatEqualities(r.remoteDefinition, queryObject));\n                    await this.deleteTraverse(relatedRecords, r.remoteModelConstructor, namespace, deleteQueue);\n                }\n            }\n        }\n        deleteQueue.push({\n            storeName: getStorename(namespace, modelConstructor.name),\n            items: models,\n        });\n    }\n}\n\nexport { StorageAdapterBase };\n//# sourceMappingURL=StorageAdapterBase.mjs.map\n","import { isBrowser, isWebWorker } from '@aws-amplify/core/internals/utils';\nimport IndexedDBAdapter from '../IndexedDBAdapter.mjs';\nimport AsyncStorageAdapter from '../AsyncStorageAdapter.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst getDefaultAdapter = () => {\n    if ((isBrowser && window.indexedDB) || (isWebWorker() && self.indexedDB)) {\n        return IndexedDBAdapter;\n    }\n    return AsyncStorageAdapter;\n};\n\nexport { getDefaultAdapter as default };\n//# sourceMappingURL=index.mjs.map\n","import { isFieldAssociation } from '../types.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n/**\n * Defines a relationship from a LOCAL model.field to a REMOTE model.field and helps\n * navigate the relationship, providing a simplified peek at the relationship details\n * pertinent to setting FK's and constructing join conditions.\n *\n * Because I mean, relationships are tough.\n *\n */\nclass ModelRelationship {\n    /**\n     * @param modelDefinition The \"local\" model.\n     * @param field The \"local\" model field.\n     */\n    constructor(model, field) {\n        if (!isFieldAssociation(model.schema, field)) {\n            throw new Error(`${model.schema.name}.${field} is not a relationship.`);\n        }\n        this.localModel = model;\n        this._field = field;\n    }\n    /**\n     * Returns a ModelRelationship for the the given model and field if the pair\n     * indicates a relationship to another model. Else, returns `null`.\n     *\n     * @param model The model the relationship field exists in.\n     * @param field The field that may relates the local model to the remote model.\n     */\n    static from(model, field) {\n        if (isFieldAssociation(model.schema, field)) {\n            return new this(model, field);\n        }\n        else {\n            return null;\n        }\n    }\n    /**\n     * Enumerates all valid `ModelRelationship`'s on the given model.\n     *\n     * @param model The model definition to enumerate relationships of.\n     */\n    static allFrom(model) {\n        const relationships = [];\n        for (const field of Object.keys(model.schema.fields)) {\n            const relationship = ModelRelationship.from(model, field);\n            relationship && relationships.push(relationship);\n        }\n        return relationships;\n    }\n    get localDefinition() {\n        return this.localModel.schema;\n    }\n    /**\n     * The virtual/computed field on the local model that should contain\n     * the related model.\n     */\n    get field() {\n        return this._field;\n    }\n    /**\n     * The constructor that can be used to query DataStore or create instance for\n     * the local model.\n     */\n    get localConstructor() {\n        return this.localModel.builder;\n    }\n    /**\n     * The name/type of the relationship the local model has with the remote model\n     * via the defined local model field.\n     */\n    get type() {\n        return this.localAssocation.connectionType;\n    }\n    /**\n     * Raw details about the local FK as-is from the local model's field definition in\n     * the schema. This field requires interpretation.\n     *\n     * @see localJoinFields\n     * @see localAssociatedWith\n     */\n    get localAssocation() {\n        return this.localDefinition.fields[this.field].association;\n    }\n    /**\n     * The field names on the local model that can be used to query or queried to match\n     * with instances of the remote model.\n     *\n     * Fields are returned in-order to match the order of `this.remoteKeyFields`.\n     */\n    get localJoinFields() {\n        /**\n         * This is relatively straightforward, actually.\n         *\n         * If we have explicitly stated targetNames, codegen is telling us authoritatively\n         * to use those fields for this relationship. The local model \"points to\" fields\n         * in the remote one.\n         *\n         * In other cases, the remote model points to this one's\n         */\n        if (this.localAssocation.targetName) {\n            // This case is theoretically unnecessary going forward.\n            return [this.localAssocation.targetName];\n        }\n        else if (this.localAssocation.targetNames) {\n            return this.localAssocation.targetNames;\n        }\n        else {\n            return this.localPKFields;\n        }\n    }\n    /**\n     * The field names on the local model that uniquely identify it.\n     *\n     * These fields may or may not be relevant to the join fields.\n     */\n    get localPKFields() {\n        return this.localModel.pkField;\n    }\n    get remoteDefinition() {\n        return this.remoteModelType.modelConstructor?.schema;\n    }\n    get remoteModelType() {\n        return this.localDefinition.fields[this.field].type;\n    }\n    /**\n     * Constructor that can be used to query DataStore or create instances for\n     * the remote model.\n     */\n    get remoteModelConstructor() {\n        return this.remoteModelType.modelConstructor.builder;\n    }\n    /**\n     * The field names on the remote model that uniquely identify it.\n     *\n     * These fields may or may not be relevant to the join fields.\n     */\n    get remotePKFields() {\n        return this.remoteModelType.modelConstructor?.pkField || ['id'];\n    }\n    /**\n     * The `associatedWith` fields from the local perspective.\n     *\n     * When present, these fields indicate which fields on the remote model to use\n     * when looking for a remote association and/or determining the final remote\n     * key fields.\n     */\n    get localAssociatedWith() {\n        if (this.localAssocation.connectionType === 'HAS_MANY' ||\n            this.localAssocation.connectionType === 'HAS_ONE') {\n            // This de-arraying is theoretically unnecessary going forward.\n            return Array.isArray(this.localAssocation.associatedWith)\n                ? this.localAssocation.associatedWith\n                : [this.localAssocation.associatedWith];\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * The `remote` model's associated field's `assocation` metadata, if\n     * present.\n     *\n     * This is used when determining if the remote model's associated field\n     * specifies which FK fields to use. If this value is `undefined`, the\n     * name of the remote field (`this.localAssociatedWith`) *is* the remote\n     * key field.\n     */\n    get explicitRemoteAssociation() {\n        if (this.localAssociatedWith) {\n            if (this.localAssociatedWith.length === 1) {\n                return this.remoteDefinition.fields[this.localAssociatedWith[0]]\n                    ?.association;\n            }\n            else {\n                return undefined;\n            }\n        }\n    }\n    /**\n     * The field names on the remote model that can used to query or queried to match\n     * with instances of the local model.\n     *\n     * Fields are returned in-order to match the order of `this.localKeyFields`.\n     */\n    get remoteJoinFields() {\n        /**\n         * If the local relationship explicitly names \"associated with\" fields, we\n         * need to see if this points direction to a reciprocating assocation. If it\n         * does, the remote assocation indicates what fields to use.\n         */\n        if (this.explicitRemoteAssociation?.targetName) {\n            // This case is theoretically unnecessary going forward.\n            return [this.explicitRemoteAssociation.targetName];\n        }\n        else if (this.explicitRemoteAssociation?.targetNames) {\n            // eslint-disable-next-line @typescript-eslint/no-non-null-asserted-optional-chain\n            return this.explicitRemoteAssociation?.targetNames;\n        }\n        else if (this.localAssociatedWith) {\n            return this.localAssociatedWith;\n        }\n        else {\n            return this.remotePKFields;\n        }\n    }\n    /**\n     * Whether this relationship everything necessary to get, set, and query from\n     * the perspective of the local model provided at instantiation.\n     */\n    get isComplete() {\n        return this.localJoinFields.length > 0 && this.remoteJoinFields.length > 0;\n    }\n    /**\n     * Creates an FK mapper object with respect to the given related instance.\n     *\n     * E.g., if the local FK fields are `[parentId, parentName]` and point to\n     * `[customId, name]` on the remote model, `createLocalFKObject(remote)`\n     * will return:\n     *\n     * ```\n     * {\n     * \tparentId: remote.customId,\n     * \tparentName: remote.name\n     * }\n     * ```\n     *\n     * @param remote The remote related instance.\n     */\n    createLocalFKObject(remote) {\n        const fk = {};\n        for (let i = 0; i < this.localJoinFields.length; i++) {\n            fk[this.localJoinFields[i]] = remote[this.remoteJoinFields[i]];\n        }\n        return fk;\n    }\n    /**\n     * Creates an query mapper object to help fetch the remote instance(s) or\n     * `null` if any of the necessary local fields are `null` or `undefined`.\n     *\n     * E.g., if the local FK fields are `[parentId, parentName]` and point to\n     * `[customId, name]` on the remote model, `createLocalFKObject(remote)`\n     * will return:\n     *\n     * ```\n     * {\n     * \tcustomId: local.parentId\n     * \tname: local.parentName\n     * }\n     * ```\n     *\n     * If the local fields are not populated, returns\n     *\n     * @param local The local instance.\n     */\n    createRemoteQueryObject(local) {\n        const query = {};\n        for (let i = 0; i < this.remoteJoinFields.length; i++) {\n            const localValue = local[this.localJoinFields[i]];\n            if (localValue === null || localValue === undefined)\n                return null;\n            query[this.remoteJoinFields[i]] = local[this.localJoinFields[i]];\n        }\n        return query;\n    }\n}\n\nexport { ModelRelationship };\n//# sourceMappingURL=relationship.mjs.map\n","import { Subject, filter, map } from 'rxjs';\nimport { Mutex } from '@aws-amplify/core/internals/utils';\nimport { ConsoleLogger } from '@aws-amplify/core';\nimport { ModelPredicateCreator } from '../predicates/index.mjs';\nimport { QueryOne, OpType, isTargetNameAssociation } from '../types.mjs';\nimport { isModelConstructor, validatePredicate, valuesEqual, STORAGE } from '../util.mjs';\nimport { getIdentifierValue } from '../sync/utils.mjs';\nimport getDefaultAdapter from './adapter/getDefaultAdapter/index.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst logger = new ConsoleLogger('DataStore');\nclass StorageClass {\n    constructor(schema, namespaceResolver, getModelConstructorByModelName, modelInstanceCreator, adapter, sessionId) {\n        this.schema = schema;\n        this.namespaceResolver = namespaceResolver;\n        this.getModelConstructorByModelName = getModelConstructorByModelName;\n        this.modelInstanceCreator = modelInstanceCreator;\n        this.adapter = adapter;\n        this.sessionId = sessionId;\n        this.adapter = this.adapter || getDefaultAdapter();\n        this.pushStream = new Subject();\n    }\n    static getNamespace() {\n        const namespace = {\n            name: STORAGE,\n            relationships: {},\n            enums: {},\n            models: {},\n            nonModels: {},\n        };\n        return namespace;\n    }\n    async init() {\n        if (this.initialized !== undefined) {\n            await this.initialized;\n            return;\n        }\n        logger.debug('Starting Storage');\n        let resolve;\n        let reject;\n        this.initialized = new Promise((_resolve, _reject) => {\n            resolve = _resolve;\n            reject = _reject;\n        });\n        this.adapter.setUp(this.schema, this.namespaceResolver, this.modelInstanceCreator, this.getModelConstructorByModelName, this.sessionId).then(resolve, reject);\n        await this.initialized;\n    }\n    async save(model, condition, mutator, patchesTuple) {\n        await this.init();\n        if (!this.adapter) {\n            throw new Error('Storage adapter is missing');\n        }\n        const result = await this.adapter.save(model, condition);\n        result.forEach(r => {\n            const [savedElement, opType] = r;\n            // truthy when save is called by the Merger\n            const syncResponse = !!mutator;\n            let updateMutationInput;\n            // don't attempt to calc mutation input when storage.save\n            // is called by Merger, i.e., when processing an AppSync response\n            if ((opType === OpType.UPDATE || opType === OpType.INSERT) &&\n                !syncResponse) {\n                //\n                // TODO: LOOK!!!\n                // the `model` used here is in effect regardless of what model\n                // comes back from adapter.save().\n                // Prior to fix, SQLite adapter had been returning two models\n                // of different types, resulting in invalid outbox entries.\n                //\n                // the bug is essentially fixed in SQLite adapter.\n                // leaving as-is, because it's currently unclear whether anything\n                // depends on this remaining as-is.\n                //\n                updateMutationInput = this.getChangedFieldsInput(model, savedElement, patchesTuple);\n                // // an update without changed user fields\n                // => don't create mutationEvent\n                if (updateMutationInput === null) {\n                    return result;\n                }\n            }\n            const element = updateMutationInput || savedElement;\n            const modelConstructor = Object.getPrototypeOf(savedElement)\n                .constructor;\n            this.pushStream.next({\n                model: modelConstructor,\n                opType,\n                element,\n                mutator,\n                condition: (condition &&\n                    ModelPredicateCreator.getPredicates(condition, false)) ||\n                    null,\n                savedElement,\n            });\n        });\n        return result;\n    }\n    async delete(modelOrModelConstructor, condition, mutator) {\n        await this.init();\n        if (!this.adapter) {\n            throw new Error('Storage adapter is missing');\n        }\n        let models;\n        let deleted;\n        [models, deleted] = await this.adapter.delete(modelOrModelConstructor, condition);\n        const modelConstructor = isModelConstructor(modelOrModelConstructor)\n            ? modelOrModelConstructor\n            : Object.getPrototypeOf(modelOrModelConstructor || {})\n                .constructor;\n        const namespaceName = this.namespaceResolver(modelConstructor);\n        const modelDefinition = this.schema.namespaces[namespaceName].models[modelConstructor.name];\n        const modelIds = new Set(models.map(model => {\n            const modelId = getIdentifierValue(modelDefinition, model);\n            return modelId;\n        }));\n        if (!isModelConstructor(modelOrModelConstructor) &&\n            !Array.isArray(deleted)) {\n            deleted = [deleted];\n        }\n        deleted.forEach(model => {\n            const resolvedModelConstructor = Object.getPrototypeOf(model)\n                .constructor;\n            let theCondition;\n            if (!isModelConstructor(modelOrModelConstructor)) {\n                const modelId = getIdentifierValue(modelDefinition, model);\n                theCondition = modelIds.has(modelId)\n                    ? ModelPredicateCreator.getPredicates(condition, false)\n                    : undefined;\n            }\n            this.pushStream.next({\n                model: resolvedModelConstructor,\n                opType: OpType.DELETE,\n                element: model,\n                mutator,\n                condition: theCondition || null,\n            });\n        });\n        return [models, deleted];\n    }\n    async query(modelConstructor, predicate, pagination) {\n        await this.init();\n        if (!this.adapter) {\n            throw new Error('Storage adapter is missing');\n        }\n        return this.adapter.query(modelConstructor, predicate, pagination);\n    }\n    async queryOne(modelConstructor, firstOrLast = QueryOne.FIRST) {\n        await this.init();\n        if (!this.adapter) {\n            throw new Error('Storage adapter is missing');\n        }\n        return this.adapter.queryOne(modelConstructor, firstOrLast);\n    }\n    observe(modelConstructor, predicate, skipOwn) {\n        const listenToAll = !modelConstructor;\n        const { predicates, type } = (predicate && ModelPredicateCreator.getPredicates(predicate, false)) ||\n            {};\n        let result = this.pushStream\n            .pipe(filter(({ mutator }) => {\n            return !skipOwn || mutator !== skipOwn;\n        }))\n            .pipe(map(({ mutator: _mutator, ...message }) => message));\n        if (!listenToAll) {\n            result = result.pipe(filter(({ model, element }) => {\n                if (modelConstructor !== model) {\n                    return false;\n                }\n                if (!!predicates && !!type) {\n                    return validatePredicate(element, type, predicates);\n                }\n                return true;\n            }));\n        }\n        return result;\n    }\n    async clear(completeObservable = true) {\n        this.initialized = undefined;\n        if (!this.adapter) {\n            throw new Error('Storage adapter is missing');\n        }\n        await this.adapter.clear();\n        if (completeObservable) {\n            this.pushStream.complete();\n        }\n    }\n    async batchSave(modelConstructor, items, mutator) {\n        await this.init();\n        if (!this.adapter) {\n            throw new Error('Storage adapter is missing');\n        }\n        const result = await this.adapter.batchSave(modelConstructor, items);\n        result.forEach(([element, opType]) => {\n            this.pushStream.next({\n                model: modelConstructor,\n                opType,\n                element,\n                mutator,\n                condition: null,\n            });\n        });\n        return result;\n    }\n    // returns null if no user fields were changed (determined by value comparison)\n    getChangedFieldsInput(model, originalElement, patchesTuple) {\n        const containsPatches = patchesTuple && patchesTuple.length;\n        if (!containsPatches) {\n            return null;\n        }\n        const [patches, source] = patchesTuple;\n        const updatedElement = {};\n        // extract array of updated fields from patches\n        const updatedFields = patches.map(patch => patch.path && patch.path[0]);\n        // check model def for association and replace with targetName if exists\n        const modelConstructor = Object.getPrototypeOf(model)\n            .constructor;\n        const namespace = this.namespaceResolver(modelConstructor);\n        const { fields } = this.schema.namespaces[namespace].models[modelConstructor.name];\n        const { primaryKey, compositeKeys = [] } = this.schema.namespaces[namespace].keys?.[modelConstructor.name] || {};\n        // set original values for these fields\n        updatedFields.forEach((field) => {\n            const targetNames = isTargetNameAssociation(fields[field]?.association);\n            if (Array.isArray(targetNames)) {\n                // if field refers to a belongsTo relation, use the target field instead\n                for (const targetName of targetNames) {\n                    // check field values by value. Ignore unchanged fields\n                    if (!valuesEqual(source[targetName], originalElement[targetName])) {\n                        // if the field was updated to 'undefined', replace with 'null' for compatibility with JSON and GraphQL\n                        updatedElement[targetName] =\n                            originalElement[targetName] === undefined\n                                ? null\n                                : originalElement[targetName];\n                        for (const fieldSet of compositeKeys) {\n                            // include all of the fields that comprise the composite key\n                            if (fieldSet.has(targetName)) {\n                                for (const compositeField of fieldSet) {\n                                    updatedElement[compositeField] =\n                                        originalElement[compositeField];\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n            else {\n                // Backwards compatibility pre-CPK\n                // if field refers to a belongsTo relation, use the target field instead\n                const key = targetNames || field;\n                // check field values by value. Ignore unchanged fields\n                if (!valuesEqual(source[key], originalElement[key])) {\n                    // if the field was updated to 'undefined', replace with 'null' for compatibility with JSON and GraphQL\n                    updatedElement[key] =\n                        originalElement[key] === undefined ? null : originalElement[key];\n                    for (const fieldSet of compositeKeys) {\n                        // include all of the fields that comprise the composite key\n                        if (fieldSet.has(key)) {\n                            for (const compositeField of fieldSet) {\n                                updatedElement[compositeField] =\n                                    originalElement[compositeField];\n                            }\n                        }\n                    }\n                }\n            }\n        });\n        // Exit early when there are no changes introduced in the update mutation\n        if (Object.keys(updatedElement).length === 0) {\n            return null;\n        }\n        // include field(s) from custom PK if one is specified for the model\n        if (primaryKey && primaryKey.length) {\n            for (const pkField of primaryKey) {\n                updatedElement[pkField] = originalElement[pkField];\n            }\n        }\n        const { id, _version, _lastChangedAt, _deleted } = originalElement;\n        // For update mutations we only want to send fields with changes\n        // and the required internal fields\n        return {\n            ...updatedElement,\n            id,\n            _version,\n            _lastChangedAt,\n            _deleted,\n        };\n    }\n}\nclass ExclusiveStorage {\n    constructor(schema, namespaceResolver, getModelConstructorByModelName, modelInstanceCreator, adapter, sessionId) {\n        this.mutex = new Mutex();\n        this.storage = new StorageClass(schema, namespaceResolver, getModelConstructorByModelName, modelInstanceCreator, adapter, sessionId);\n    }\n    runExclusive(fn) {\n        return this.mutex.runExclusive(fn.bind(this, this.storage));\n    }\n    async save(model, condition, mutator, patchesTuple) {\n        return this.runExclusive(storage => storage.save(model, condition, mutator, patchesTuple));\n    }\n    async delete(modelOrModelConstructor, condition, mutator) {\n        return this.runExclusive(storage => {\n            if (isModelConstructor(modelOrModelConstructor)) {\n                const modelConstructor = modelOrModelConstructor;\n                return storage.delete(modelConstructor, condition, mutator);\n            }\n            else {\n                const model = modelOrModelConstructor;\n                return storage.delete(model, condition, mutator);\n            }\n        });\n    }\n    async query(modelConstructor, predicate, pagination) {\n        return this.runExclusive(storage => storage.query(modelConstructor, predicate, pagination));\n    }\n    async queryOne(modelConstructor, firstOrLast = QueryOne.FIRST) {\n        return this.runExclusive(storage => storage.queryOne(modelConstructor, firstOrLast));\n    }\n    static getNamespace() {\n        return StorageClass.getNamespace();\n    }\n    observe(modelConstructor, predicate, skipOwn) {\n        return this.storage.observe(modelConstructor, predicate, skipOwn);\n    }\n    async clear() {\n        await this.runExclusive(storage => storage.clear());\n    }\n    batchSave(modelConstructor, items) {\n        return this.storage.batchSave(modelConstructor, items);\n    }\n    async init() {\n        return this.storage.init();\n    }\n}\n\nexport { ExclusiveStorage };\n//# sourceMappingURL=storage.mjs.map\n","import { Observable } from 'rxjs';\nimport { ReachabilityMonitor } from './datastoreReachability/index.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst RECONNECTING_IN = 5000; // 5s this may be configurable in the future\nclass DataStoreConnectivity {\n    constructor() {\n        this.connectionStatus = {\n            online: false,\n        };\n    }\n    status() {\n        if (this.observer) {\n            throw new Error('Subscriber already exists');\n        }\n        return new Observable(observer => {\n            this.observer = observer;\n            // Will be used to forward socket connection changes, enhancing Reachability\n            this.subscription = ReachabilityMonitor.subscribe(({ online }) => {\n                this.connectionStatus.online = online;\n                const observerResult = { ...this.connectionStatus }; // copyOf status\n                observer.next(observerResult);\n            });\n            return () => {\n                clearTimeout(this.timeout);\n                this.unsubscribe();\n            };\n        });\n    }\n    unsubscribe() {\n        if (this.subscription) {\n            clearTimeout(this.timeout);\n            this.subscription.unsubscribe();\n        }\n    }\n    // for consistency with other background processors.\n    async stop() {\n        this.unsubscribe();\n    }\n    socketDisconnected() {\n        if (this.observer && typeof this.observer.next === 'function') {\n            this.observer.next({ online: false }); // Notify network issue from the socket\n            this.timeout = setTimeout(() => {\n                const observerResult = { ...this.connectionStatus }; // copyOf status\n                this.observer.next(observerResult);\n            }, RECONNECTING_IN); // giving time for socket cleanup and network status stabilization\n        }\n    }\n}\n\nexport { DataStoreConnectivity as default };\n//# sourceMappingURL=datastoreConnectivity.mjs.map\n","import { Reachability } from '@aws-amplify/core/internals/utils';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst ReachabilityMonitor = new Reachability().networkMonitor();\n\nexport { ReachabilityMonitor };\n//# sourceMappingURL=index.mjs.map\n","import { BackgroundProcessManager } from '@aws-amplify/core/internals/utils';\nimport { ConsoleLogger, Hub } from '@aws-amplify/core';\nimport { Observable, filter, of } from 'rxjs';\nimport { CONTROL_MSG as CONTROL_MSG$1, CONNECTION_STATE_CHANGE, ConnectionState } from '@aws-amplify/api-graphql';\nimport { ModelPredicateCreator } from '../predicates/index.mjs';\nimport { OpType } from '../types.mjs';\nimport { getNow, USER, SYNC } from '../util.mjs';\nimport DataStoreConnectivity from './datastoreConnectivity.mjs';\nimport { ModelMerger } from './merger.mjs';\nimport { MutationEventOutbox } from './outbox.mjs';\nimport { MutationProcessor } from './processors/mutation.mjs';\nimport { SubscriptionProcessor, CONTROL_MSG } from './processors/subscription.mjs';\nimport { SyncProcessor } from './processors/sync.mjs';\nimport { predicateToGraphQLCondition, createMutationInstanceFromModelOperation, getIdentifierValue } from './utils.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst logger = new ConsoleLogger('DataStore');\nconst ownSymbol = Symbol('sync');\nvar ControlMessage;\n(function (ControlMessage) {\n    ControlMessage[\"SYNC_ENGINE_STORAGE_SUBSCRIBED\"] = \"storageSubscribed\";\n    ControlMessage[\"SYNC_ENGINE_SUBSCRIPTIONS_ESTABLISHED\"] = \"subscriptionsEstablished\";\n    ControlMessage[\"SYNC_ENGINE_SYNC_QUERIES_STARTED\"] = \"syncQueriesStarted\";\n    ControlMessage[\"SYNC_ENGINE_SYNC_QUERIES_READY\"] = \"syncQueriesReady\";\n    ControlMessage[\"SYNC_ENGINE_MODEL_SYNCED\"] = \"modelSynced\";\n    ControlMessage[\"SYNC_ENGINE_OUTBOX_MUTATION_ENQUEUED\"] = \"outboxMutationEnqueued\";\n    ControlMessage[\"SYNC_ENGINE_OUTBOX_MUTATION_PROCESSED\"] = \"outboxMutationProcessed\";\n    ControlMessage[\"SYNC_ENGINE_OUTBOX_STATUS\"] = \"outboxStatus\";\n    ControlMessage[\"SYNC_ENGINE_NETWORK_STATUS\"] = \"networkStatus\";\n    ControlMessage[\"SYNC_ENGINE_READY\"] = \"ready\";\n})(ControlMessage || (ControlMessage = {}));\nclass SyncEngine {\n    getModelSyncedStatus(modelConstructor) {\n        return this.modelSyncedStatus.get(modelConstructor);\n    }\n    constructor(schema, namespaceResolver, modelClasses, userModelClasses, storage, modelInstanceCreator, conflictHandler, errorHandler, syncPredicates, amplifyConfig = {}, authModeStrategy, amplifyContext, connectivityMonitor) {\n        this.schema = schema;\n        this.namespaceResolver = namespaceResolver;\n        this.modelClasses = modelClasses;\n        this.userModelClasses = userModelClasses;\n        this.storage = storage;\n        this.modelInstanceCreator = modelInstanceCreator;\n        this.syncPredicates = syncPredicates;\n        this.amplifyConfig = amplifyConfig;\n        this.authModeStrategy = authModeStrategy;\n        this.amplifyContext = amplifyContext;\n        this.connectivityMonitor = connectivityMonitor;\n        this.online = false;\n        this.modelSyncedStatus = new WeakMap();\n        this.connectionDisrupted = false;\n        this.runningProcesses = new BackgroundProcessManager();\n        this.waitForSleepState = new Promise(resolve => {\n            this.syncQueriesObservableStartSleeping = resolve;\n        });\n        const MutationEventCtor = this.modelClasses\n            .MutationEvent;\n        this.outbox = new MutationEventOutbox(this.schema, MutationEventCtor, modelInstanceCreator, ownSymbol);\n        this.modelMerger = new ModelMerger(this.outbox, ownSymbol);\n        this.syncQueriesProcessor = new SyncProcessor(this.schema, this.syncPredicates, this.amplifyConfig, this.authModeStrategy, errorHandler, this.amplifyContext);\n        this.subscriptionsProcessor = new SubscriptionProcessor(this.schema, this.syncPredicates, this.amplifyConfig, this.authModeStrategy, errorHandler, this.amplifyContext);\n        this.mutationsProcessor = new MutationProcessor(this.schema, this.storage, this.userModelClasses, this.outbox, this.modelInstanceCreator, MutationEventCtor, this.amplifyConfig, this.authModeStrategy, errorHandler, conflictHandler, this.amplifyContext);\n        this.datastoreConnectivity =\n            this.connectivityMonitor || new DataStoreConnectivity();\n    }\n    start(params) {\n        return new Observable(observer => {\n            logger.log('starting sync engine...');\n            let subscriptions = [];\n            this.runningProcesses.add(async () => {\n                try {\n                    await this.setupModels(params);\n                }\n                catch (err) {\n                    observer.error(err);\n                    return;\n                }\n                // this is awaited at the bottom. so, we don't need to register\n                // this explicitly with the context. it's already contained.\n                const startPromise = new Promise((resolve, reject) => {\n                    const doneStarting = resolve;\n                    const failedStarting = reject;\n                    this.datastoreConnectivity.status().subscribe(async ({ online }) => this.runningProcesses.isOpen &&\n                        this.runningProcesses.add(async (onTerminate) => {\n                            // From offline to online\n                            if (online && !this.online) {\n                                this.online = online;\n                                observer.next({\n                                    type: ControlMessage.SYNC_ENGINE_NETWORK_STATUS,\n                                    data: {\n                                        active: this.online,\n                                    },\n                                });\n                                this.stopDisruptionListener = this.startDisruptionListener();\n                                // #region GraphQL Subscriptions\n                                const [ctlSubsObservable, dataSubsObservable] = this.subscriptionsProcessor.start();\n                                try {\n                                    await new Promise((_resolve, _reject) => {\n                                        onTerminate.then(_reject);\n                                        const ctlSubsSubscription = ctlSubsObservable.subscribe({\n                                            next: msg => {\n                                                if (msg === CONTROL_MSG.CONNECTED) {\n                                                    _resolve();\n                                                }\n                                            },\n                                            error: err => {\n                                                _reject(err);\n                                                const handleDisconnect = this.disconnectionHandler();\n                                                handleDisconnect(err);\n                                            },\n                                        });\n                                        subscriptions.push(ctlSubsSubscription);\n                                    });\n                                }\n                                catch (err) {\n                                    observer.error(err);\n                                    failedStarting();\n                                    return;\n                                }\n                                logger.log('Realtime ready');\n                                observer.next({\n                                    type: ControlMessage.SYNC_ENGINE_SUBSCRIPTIONS_ESTABLISHED,\n                                });\n                                // #endregion\n                                // #region Base & Sync queries\n                                try {\n                                    await new Promise((_resolve, _reject) => {\n                                        const syncQuerySubscription = this.syncQueriesObservable().subscribe({\n                                            next: message => {\n                                                const { type } = message;\n                                                if (type ===\n                                                    ControlMessage.SYNC_ENGINE_SYNC_QUERIES_READY) {\n                                                    _resolve();\n                                                }\n                                                observer.next(message);\n                                            },\n                                            complete: () => {\n                                                _resolve();\n                                            },\n                                            error: error => {\n                                                _reject(error);\n                                            },\n                                        });\n                                        if (syncQuerySubscription) {\n                                            subscriptions.push(syncQuerySubscription);\n                                        }\n                                    });\n                                }\n                                catch (error) {\n                                    observer.error(error);\n                                    failedStarting();\n                                    return;\n                                }\n                                // #endregion\n                                // #region process mutations (outbox)\n                                subscriptions.push(this.mutationsProcessor\n                                    .start()\n                                    .subscribe(({ modelDefinition, model: item, hasMore }) => this.runningProcesses.add(async () => {\n                                    const modelConstructor = this.userModelClasses[modelDefinition.name];\n                                    const model = this.modelInstanceCreator(modelConstructor, item);\n                                    await this.storage.runExclusive(storage => this.modelMerger.merge(storage, model, modelDefinition));\n                                    observer.next({\n                                        type: ControlMessage.SYNC_ENGINE_OUTBOX_MUTATION_PROCESSED,\n                                        data: {\n                                            model: modelConstructor,\n                                            element: model,\n                                        },\n                                    });\n                                    observer.next({\n                                        type: ControlMessage.SYNC_ENGINE_OUTBOX_STATUS,\n                                        data: {\n                                            isEmpty: !hasMore,\n                                        },\n                                    });\n                                }, 'mutation processor event')));\n                                // #endregion\n                                // #region Merge subscriptions buffer\n                                subscriptions.push(dataSubsObservable.subscribe(([_transformerMutationType, modelDefinition, item]) => this.runningProcesses.add(async () => {\n                                    const modelConstructor = this.userModelClasses[modelDefinition.name];\n                                    const model = this.modelInstanceCreator(modelConstructor, item);\n                                    await this.storage.runExclusive(storage => this.modelMerger.merge(storage, model, modelDefinition));\n                                }, 'subscription dataSubsObservable event')));\n                                // #endregion\n                            }\n                            else if (!online) {\n                                this.online = online;\n                                observer.next({\n                                    type: ControlMessage.SYNC_ENGINE_NETWORK_STATUS,\n                                    data: {\n                                        active: this.online,\n                                    },\n                                });\n                                subscriptions.forEach(sub => {\n                                    sub.unsubscribe();\n                                });\n                                subscriptions = [];\n                            }\n                            doneStarting();\n                        }, 'datastore connectivity event'));\n                });\n                this.storage\n                    .observe(null, null, ownSymbol)\n                    .pipe(filter(({ model }) => {\n                    const modelDefinition = this.getModelDefinition(model);\n                    return modelDefinition.syncable === true;\n                }))\n                    .subscribe({\n                    next: async ({ opType, model, element, condition }) => this.runningProcesses.add(async () => {\n                        const namespace = this.schema.namespaces[this.namespaceResolver(model)];\n                        const MutationEventConstructor = this.modelClasses\n                            .MutationEvent;\n                        const modelDefinition = this.getModelDefinition(model);\n                        const graphQLCondition = predicateToGraphQLCondition(condition, modelDefinition);\n                        const mutationEvent = createMutationInstanceFromModelOperation(namespace.relationships, this.getModelDefinition(model), opType, model, element, graphQLCondition, MutationEventConstructor, this.modelInstanceCreator);\n                        await this.outbox.enqueue(this.storage, mutationEvent);\n                        observer.next({\n                            type: ControlMessage.SYNC_ENGINE_OUTBOX_MUTATION_ENQUEUED,\n                            data: {\n                                model,\n                                element,\n                            },\n                        });\n                        observer.next({\n                            type: ControlMessage.SYNC_ENGINE_OUTBOX_STATUS,\n                            data: {\n                                isEmpty: false,\n                            },\n                        });\n                        await startPromise;\n                        // Set by the this.datastoreConnectivity.status().subscribe() loop\n                        if (this.online) {\n                            this.mutationsProcessor.resume();\n                        }\n                    }, 'storage event'),\n                });\n                observer.next({\n                    type: ControlMessage.SYNC_ENGINE_STORAGE_SUBSCRIBED,\n                });\n                const hasMutationsInOutbox = (await this.outbox.peek(this.storage)) === undefined;\n                observer.next({\n                    type: ControlMessage.SYNC_ENGINE_OUTBOX_STATUS,\n                    data: {\n                        isEmpty: hasMutationsInOutbox,\n                    },\n                });\n                await startPromise;\n                observer.next({\n                    type: ControlMessage.SYNC_ENGINE_READY,\n                });\n            }, 'sync start');\n        });\n    }\n    async getModelsMetadataWithNextFullSync(currentTimeStamp) {\n        const modelLastSync = new Map((await this.runningProcesses.add(() => this.getModelsMetadata(), 'sync/index getModelsMetadataWithNextFullSync')).map(({ namespace, model, lastSync, lastFullSync, fullSyncInterval }) => {\n            const nextFullSync = lastFullSync + fullSyncInterval;\n            const syncFrom = !lastFullSync || nextFullSync < currentTimeStamp\n                ? 0 // perform full sync if expired\n                : lastSync; // perform delta sync\n            return [\n                this.schema.namespaces[namespace].models[model],\n                [namespace, syncFrom],\n            ];\n        }));\n        return modelLastSync;\n    }\n    syncQueriesObservable() {\n        if (!this.online) {\n            return of({}); // TODO(v6): fix this\n        }\n        return new Observable(observer => {\n            let syncQueriesSubscription;\n            this.runningProcesses.isOpen &&\n                this.runningProcesses.add(async (onTerminate) => {\n                    let terminated = false;\n                    while (!observer.closed && !terminated) {\n                        const count = new WeakMap();\n                        const modelLastSync = await this.getModelsMetadataWithNextFullSync(Date.now());\n                        const paginatingModels = new Set(modelLastSync.keys());\n                        let lastFullSyncStartedAt;\n                        let syncInterval;\n                        let start;\n                        let syncDuration;\n                        let lastStartedAt;\n                        await new Promise((resolve, _reject) => {\n                            if (!this.runningProcesses.isOpen)\n                                resolve();\n                            onTerminate.then(() => {\n                                resolve();\n                            });\n                            syncQueriesSubscription = this.syncQueriesProcessor\n                                .start(modelLastSync)\n                                .subscribe({\n                                next: async ({ namespace, modelDefinition, items, done, startedAt, isFullSync, }) => {\n                                    const modelConstructor = this.userModelClasses[modelDefinition.name];\n                                    if (!count.has(modelConstructor)) {\n                                        count.set(modelConstructor, {\n                                            new: 0,\n                                            updated: 0,\n                                            deleted: 0,\n                                        });\n                                        start = getNow();\n                                        lastStartedAt =\n                                            lastStartedAt === undefined\n                                                ? startedAt\n                                                : Math.max(lastStartedAt, startedAt);\n                                    }\n                                    /**\n                                     * If there are mutations in the outbox for a given id, those need to be\n                                     * merged individually. Otherwise, we can merge them in batches.\n                                     */\n                                    await this.storage.runExclusive(async (storage) => {\n                                        const idsInOutbox = await this.outbox.getModelIds(storage);\n                                        const oneByOne = [];\n                                        const page = items.filter(item => {\n                                            const itemId = getIdentifierValue(modelDefinition, item);\n                                            if (!idsInOutbox.has(itemId)) {\n                                                return true;\n                                            }\n                                            oneByOne.push(item);\n                                            return false;\n                                        });\n                                        const opTypeCount = [];\n                                        for (const item of oneByOne) {\n                                            const opType = await this.modelMerger.merge(storage, item, modelDefinition);\n                                            if (opType !== undefined) {\n                                                opTypeCount.push([item, opType]);\n                                            }\n                                        }\n                                        opTypeCount.push(...(await this.modelMerger.mergePage(storage, modelConstructor, page, modelDefinition)));\n                                        const counts = count.get(modelConstructor);\n                                        opTypeCount.forEach(([, opType]) => {\n                                            switch (opType) {\n                                                case OpType.INSERT:\n                                                    counts.new++;\n                                                    break;\n                                                case OpType.UPDATE:\n                                                    counts.updated++;\n                                                    break;\n                                                case OpType.DELETE:\n                                                    counts.deleted++;\n                                                    break;\n                                                default:\n                                                    throw new Error(`Invalid opType ${opType}`);\n                                            }\n                                        });\n                                    });\n                                    if (done) {\n                                        const { name: modelName } = modelDefinition;\n                                        // #region update last sync for type\n                                        let modelMetadata = await this.getModelMetadata(namespace, modelName);\n                                        const { lastFullSync, fullSyncInterval } = modelMetadata;\n                                        syncInterval = fullSyncInterval;\n                                        lastFullSyncStartedAt =\n                                            lastFullSyncStartedAt === undefined\n                                                ? lastFullSync\n                                                : Math.max(lastFullSyncStartedAt, isFullSync ? startedAt : lastFullSync);\n                                        modelMetadata = this.modelClasses\n                                            .ModelMetadata.copyOf(modelMetadata, draft => {\n                                            draft.lastSync = startedAt;\n                                            draft.lastFullSync = isFullSync\n                                                ? startedAt\n                                                : modelMetadata.lastFullSync;\n                                        });\n                                        await this.storage.save(modelMetadata, undefined, ownSymbol);\n                                        // #endregion\n                                        const counts = count.get(modelConstructor);\n                                        this.modelSyncedStatus.set(modelConstructor, true);\n                                        observer.next({\n                                            type: ControlMessage.SYNC_ENGINE_MODEL_SYNCED,\n                                            data: {\n                                                model: modelConstructor,\n                                                isFullSync,\n                                                isDeltaSync: !isFullSync,\n                                                counts,\n                                            },\n                                        });\n                                        paginatingModels.delete(modelDefinition);\n                                        if (paginatingModels.size === 0) {\n                                            syncDuration = getNow() - start;\n                                            resolve();\n                                            observer.next({\n                                                type: ControlMessage.SYNC_ENGINE_SYNC_QUERIES_READY,\n                                            });\n                                            syncQueriesSubscription.unsubscribe();\n                                        }\n                                    }\n                                },\n                                error: error => {\n                                    observer.error(error);\n                                },\n                            });\n                            observer.next({\n                                type: ControlMessage.SYNC_ENGINE_SYNC_QUERIES_STARTED,\n                                data: {\n                                    models: Array.from(paginatingModels).map(({ name }) => name),\n                                },\n                            });\n                        });\n                        // null is cast to 0 resulting in unexpected behavior.\n                        // undefined in arithmetic operations results in NaN also resulting in unexpected behavior.\n                        // If lastFullSyncStartedAt is null this is the first sync.\n                        // Assume lastStartedAt is is also newest full sync.\n                        let msNextFullSync;\n                        if (!lastFullSyncStartedAt) {\n                            msNextFullSync = syncInterval - syncDuration;\n                        }\n                        else {\n                            msNextFullSync =\n                                lastFullSyncStartedAt +\n                                    syncInterval -\n                                    (lastStartedAt + syncDuration);\n                        }\n                        logger.debug(`Next fullSync in ${msNextFullSync / 1000} seconds. (${new Date(Date.now() + msNextFullSync)})`);\n                        // TODO: create `BackgroundProcessManager.sleep()` ... but, need to put\n                        // a lot of thought into what that contract looks like to\n                        //  support possible use-cases:\n                        //\n                        //  1. non-cancelable\n                        //  2. cancelable, unsleep on exit()\n                        //  3. cancelable, throw Error on exit()\n                        //  4. cancelable, callback first on exit()?\n                        //  5. ... etc. ? ...\n                        //\n                        // TLDR; this is a lot of complexity here for a sleep(),\n                        // but, it's not clear to me yet how to support an\n                        // extensible, centralized cancelable `sleep()` elegantly.\n                        await this.runningProcesses.add(async (onRunningProcessTerminate) => {\n                            let unsleep;\n                            const sleep = new Promise(resolve => {\n                                unsleep = resolve;\n                                setTimeout(unsleep, msNextFullSync);\n                            });\n                            onRunningProcessTerminate.then(() => {\n                                terminated = true;\n                                this.syncQueriesObservableStartSleeping();\n                                unsleep();\n                            });\n                            this.unsleepSyncQueriesObservable = unsleep;\n                            this.syncQueriesObservableStartSleeping();\n                            return sleep;\n                        }, 'syncQueriesObservable sleep');\n                        this.unsleepSyncQueriesObservable = null;\n                        this.waitForSleepState = new Promise(resolve => {\n                            this.syncQueriesObservableStartSleeping = resolve;\n                        });\n                    }\n                }, 'syncQueriesObservable main');\n        });\n    }\n    disconnectionHandler() {\n        return (msg) => {\n            // This implementation is tied to AWSAppSyncRealTimeProvider 'Connection closed', 'Timeout disconnect' msg\n            if (CONTROL_MSG$1.CONNECTION_CLOSED === msg ||\n                CONTROL_MSG$1.TIMEOUT_DISCONNECT === msg) {\n                this.datastoreConnectivity.socketDisconnected();\n            }\n        };\n    }\n    unsubscribeConnectivity() {\n        this.datastoreConnectivity.unsubscribe();\n    }\n    /**\n     * Stops all subscription activities and resolves when all activies report\n     * that they're disconnected, done retrying, etc..\n     */\n    async stop() {\n        logger.debug('stopping sync engine');\n        /**\n         * Gracefully disconnecting subscribers first just prevents *more* work\n         * from entering the pipelines.\n         */\n        this.unsubscribeConnectivity();\n        /**\n         * Stop listening for websocket connection disruption\n         */\n        this.stopDisruptionListener && this.stopDisruptionListener();\n        /**\n         * aggressively shut down any lingering background processes.\n         * some of this might be semi-redundant with unsubscribing. however,\n         * unsubscribing doesn't allow us to wait for settling.\n         * (Whereas `stop()` does.)\n         */\n        await this.mutationsProcessor.stop();\n        await this.subscriptionsProcessor.stop();\n        await this.datastoreConnectivity.stop();\n        await this.syncQueriesProcessor.stop();\n        await this.runningProcesses.close();\n        await this.runningProcesses.open();\n        logger.debug('sync engine stopped and ready to restart');\n    }\n    async setupModels(params) {\n        const { fullSyncInterval } = params;\n        const ModelMetadataConstructor = this.modelClasses\n            .ModelMetadata;\n        const models = [];\n        let savedModel;\n        Object.values(this.schema.namespaces).forEach(namespace => {\n            Object.values(namespace.models)\n                .filter(({ syncable }) => syncable)\n                .forEach(model => {\n                models.push([namespace.name, model]);\n                if (namespace.name === USER) {\n                    const modelConstructor = this.userModelClasses[model.name];\n                    this.modelSyncedStatus.set(modelConstructor, false);\n                }\n            });\n        });\n        const promises = models.map(async ([namespace, model]) => {\n            const modelMetadata = await this.getModelMetadata(namespace, model.name);\n            const syncPredicate = ModelPredicateCreator.getPredicates(this.syncPredicates.get(model), false);\n            const lastSyncPredicate = syncPredicate\n                ? JSON.stringify(syncPredicate)\n                : null;\n            if (modelMetadata === undefined) {\n                [[savedModel]] = await this.storage.save(this.modelInstanceCreator(ModelMetadataConstructor, {\n                    model: model.name,\n                    namespace,\n                    lastSync: null,\n                    fullSyncInterval,\n                    lastFullSync: null,\n                    lastSyncPredicate,\n                }), undefined, ownSymbol);\n            }\n            else {\n                const prevSyncPredicate = modelMetadata.lastSyncPredicate\n                    ? modelMetadata.lastSyncPredicate\n                    : null;\n                const syncPredicateUpdated = prevSyncPredicate !== lastSyncPredicate;\n                [[savedModel]] = await this.storage.save(ModelMetadataConstructor.copyOf(modelMetadata, draft => {\n                    draft.fullSyncInterval = fullSyncInterval;\n                    // perform a base sync if the syncPredicate changed in between calls to DataStore.start\n                    // ensures that the local store contains all the data specified by the syncExpression\n                    if (syncPredicateUpdated) {\n                        draft.lastSync = null;\n                        draft.lastFullSync = null;\n                        draft.lastSyncPredicate = lastSyncPredicate;\n                    }\n                }));\n            }\n            return savedModel;\n        });\n        const result = {};\n        for (const modelMetadata of await Promise.all(promises)) {\n            const { model: modelName } = modelMetadata;\n            result[modelName] = modelMetadata;\n        }\n        return result;\n    }\n    async getModelsMetadata() {\n        const ModelMetadataCtor = this.modelClasses\n            .ModelMetadata;\n        const modelsMetadata = await this.storage.query(ModelMetadataCtor);\n        return modelsMetadata;\n    }\n    async getModelMetadata(namespace, model) {\n        const ModelMetadataCtor = this.modelClasses\n            .ModelMetadata;\n        const predicate = ModelPredicateCreator.createFromAST(this.schema.namespaces[SYNC].models[ModelMetadataCtor.name], { and: [{ namespace: { eq: namespace } }, { model: { eq: model } }] });\n        const [modelMetadata] = await this.storage.query(ModelMetadataCtor, predicate, {\n            page: 0,\n            limit: 1,\n        });\n        return modelMetadata;\n    }\n    getModelDefinition(modelConstructor) {\n        const namespaceName = this.namespaceResolver(modelConstructor);\n        const modelDefinition = this.schema.namespaces[namespaceName].models[modelConstructor.name];\n        return modelDefinition;\n    }\n    static getNamespace() {\n        const namespace = {\n            name: SYNC,\n            relationships: {},\n            enums: {\n                OperationType: {\n                    name: 'OperationType',\n                    values: ['CREATE', 'UPDATE', 'DELETE'],\n                },\n            },\n            nonModels: {},\n            models: {\n                MutationEvent: {\n                    name: 'MutationEvent',\n                    pluralName: 'MutationEvents',\n                    syncable: false,\n                    fields: {\n                        id: {\n                            name: 'id',\n                            type: 'ID',\n                            isRequired: true,\n                            isArray: false,\n                        },\n                        model: {\n                            name: 'model',\n                            type: 'String',\n                            isRequired: true,\n                            isArray: false,\n                        },\n                        data: {\n                            name: 'data',\n                            type: 'String',\n                            isRequired: true,\n                            isArray: false,\n                        },\n                        modelId: {\n                            name: 'modelId',\n                            type: 'String',\n                            isRequired: true,\n                            isArray: false,\n                        },\n                        operation: {\n                            name: 'operation',\n                            type: {\n                                enum: 'Operationtype',\n                            },\n                            isArray: false,\n                            isRequired: true,\n                        },\n                        condition: {\n                            name: 'condition',\n                            type: 'String',\n                            isArray: false,\n                            isRequired: true,\n                        },\n                    },\n                },\n                ModelMetadata: {\n                    name: 'ModelMetadata',\n                    pluralName: 'ModelsMetadata',\n                    syncable: false,\n                    fields: {\n                        id: {\n                            name: 'id',\n                            type: 'ID',\n                            isRequired: true,\n                            isArray: false,\n                        },\n                        namespace: {\n                            name: 'namespace',\n                            type: 'String',\n                            isRequired: true,\n                            isArray: false,\n                        },\n                        model: {\n                            name: 'model',\n                            type: 'String',\n                            isRequired: true,\n                            isArray: false,\n                        },\n                        lastSync: {\n                            name: 'lastSync',\n                            type: 'Int',\n                            isRequired: false,\n                            isArray: false,\n                        },\n                        lastFullSync: {\n                            name: 'lastFullSync',\n                            type: 'Int',\n                            isRequired: false,\n                            isArray: false,\n                        },\n                        fullSyncInterval: {\n                            name: 'fullSyncInterval',\n                            type: 'Int',\n                            isRequired: true,\n                            isArray: false,\n                        },\n                        lastSyncPredicate: {\n                            name: 'lastSyncPredicate',\n                            type: 'String',\n                            isRequired: false,\n                            isArray: false,\n                        },\n                    },\n                },\n            },\n        };\n        return namespace;\n    }\n    /**\n     * listen for websocket connection disruption\n     *\n     * May indicate there was a period of time where messages\n     * from AppSync were missed. A sync needs to be triggered to\n     * retrieve the missed data.\n     */\n    startDisruptionListener() {\n        return Hub.listen('api', (data) => {\n            if (data.source === 'PubSub' &&\n                data.payload.event === CONNECTION_STATE_CHANGE) {\n                const connectionState = data.payload.data\n                    .connectionState;\n                switch (connectionState) {\n                    // Do not need to listen for ConnectionDisruptedPendingNetwork\n                    // Normal network reconnection logic will handle the sync\n                    case ConnectionState.ConnectionDisrupted:\n                        this.connectionDisrupted = true;\n                        break;\n                    case ConnectionState.Connected:\n                        if (this.connectionDisrupted) {\n                            this.scheduleSync();\n                        }\n                        this.connectionDisrupted = false;\n                        break;\n                }\n            }\n        });\n    }\n    /*\n     * Schedule a sync to start when syncQueriesObservable enters sleep state\n     * Start sync immediately if syncQueriesObservable is already in sleep state\n     */\n    scheduleSync() {\n        return (this.runningProcesses.isOpen &&\n            this.runningProcesses.add(() => this.waitForSleepState.then(() => {\n                // unsleepSyncQueriesObservable will be set if waitForSleepState has resolved\n                this.unsleepSyncQueriesObservable();\n            })));\n    }\n}\n\nexport { ControlMessage, SyncEngine };\n//# sourceMappingURL=index.mjs.map\n","import { OpType } from '../types.mjs';\nimport { getIdentifierValue } from './utils.mjs';\n\n// https://github.com/aws-amplify/amplify-js/blob/datastore-docs/packages/datastore/docs/sync-engine.md#merger\nclass ModelMerger {\n    constructor(outbox, ownSymbol) {\n        this.outbox = outbox;\n        this.ownSymbol = ownSymbol;\n    }\n    /**\n     *\n     * @param storage Storage adapter that contains the data.\n     * @param model The model from an outbox mutation.\n     * @returns The type of operation (INSERT/UPDATE/DELETE)\n     */\n    async merge(storage, model, modelDefinition) {\n        let result;\n        const mutationsForModel = await this.outbox.getForModel(storage, model, modelDefinition);\n        const isDelete = model._deleted;\n        if (mutationsForModel.length === 0) {\n            if (isDelete) {\n                result = OpType.DELETE;\n                await storage.delete(model, undefined, this.ownSymbol);\n            }\n            else {\n                [[, result]] = await storage.save(model, undefined, this.ownSymbol);\n            }\n        }\n        return result;\n    }\n    async mergePage(storage, modelConstructor, items, modelDefinition) {\n        const itemsMap = new Map();\n        for (const item of items) {\n            // merge items by model id. Latest record for a given id remains.\n            const modelId = getIdentifierValue(modelDefinition, item);\n            itemsMap.set(modelId, item);\n        }\n        const page = [...itemsMap.values()];\n        return storage.batchSave(modelConstructor, page, this.ownSymbol);\n    }\n}\n\nexport { ModelMerger };\n//# sourceMappingURL=merger.mjs.map\n","import { ModelPredicateCreator } from '../predicates/index.mjs';\nimport { QueryOne } from '../types.mjs';\nimport { SYNC, directedValueEquality, USER } from '../util.mjs';\nimport { TransformerMutationType, getIdentifierValue } from './utils.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\n// TODO: Persist deleted ids\n// https://github.com/aws-amplify/amplify-js/blob/datastore-docs/packages/datastore/docs/sync-engine.md#outbox\nclass MutationEventOutbox {\n    constructor(schema, _MutationEvent, modelInstanceCreator, ownSymbol) {\n        this.schema = schema;\n        this._MutationEvent = _MutationEvent;\n        this.modelInstanceCreator = modelInstanceCreator;\n        this.ownSymbol = ownSymbol;\n    }\n    async enqueue(storage, mutationEvent) {\n        await storage.runExclusive(async (s) => {\n            const mutationEventModelDefinition = this.schema.namespaces[SYNC].models.MutationEvent;\n            // `id` is the key for the record in the mutationEvent;\n            // `modelId` is the key for the actual record that was mutated\n            const predicate = ModelPredicateCreator.createFromAST(mutationEventModelDefinition, {\n                and: [\n                    { modelId: { eq: mutationEvent.modelId } },\n                    { id: { ne: this.inProgressMutationEventId } },\n                ],\n            });\n            // Check if there are any other records with same id\n            const [first] = await s.query(this._MutationEvent, predicate);\n            // No other record with same modelId, so enqueue\n            if (first === undefined) {\n                await s.save(mutationEvent, undefined, this.ownSymbol);\n                return;\n            }\n            // There was an enqueued mutation for the modelId, so continue\n            const { operation: incomingMutationType } = mutationEvent;\n            if (first.operation === TransformerMutationType.CREATE) {\n                if (incomingMutationType === TransformerMutationType.DELETE) {\n                    await s.delete(this._MutationEvent, predicate);\n                }\n                else {\n                    // first gets updated with the incoming mutation's data, condition intentionally skipped\n                    // we need to merge the fields for a create and update mutation to prevent\n                    // data loss, since update mutations only include changed fields\n                    const merged = this.mergeUserFields(first, mutationEvent);\n                    await s.save(this._MutationEvent.copyOf(first, draft => {\n                        draft.data = merged.data;\n                    }), undefined, this.ownSymbol);\n                }\n            }\n            else {\n                const { condition: incomingConditionJSON } = mutationEvent;\n                const incomingCondition = JSON.parse(incomingConditionJSON);\n                let merged;\n                // If no condition\n                if (Object.keys(incomingCondition).length === 0) {\n                    merged = this.mergeUserFields(first, mutationEvent);\n                    // delete all for model\n                    await s.delete(this._MutationEvent, predicate);\n                }\n                merged = merged || mutationEvent;\n                // Enqueue new one\n                await s.save(merged, undefined, this.ownSymbol);\n            }\n        });\n    }\n    async dequeue(storage, record, recordOp) {\n        const head = await this.peek(storage);\n        if (record) {\n            await this.syncOutboxVersionsOnDequeue(storage, record, head, recordOp);\n        }\n        if (head) {\n            await storage.delete(head);\n        }\n        this.inProgressMutationEventId = undefined;\n        return head;\n    }\n    /**\n     * Doing a peek() implies that the mutation goes \"inProgress\"\n     *\n     * @param storage\n     */\n    async peek(storage) {\n        const head = await storage.queryOne(this._MutationEvent, QueryOne.FIRST);\n        this.inProgressMutationEventId = head ? head.id : undefined;\n        return head;\n    }\n    async getForModel(storage, model, userModelDefinition) {\n        const mutationEventModelDefinition = this.schema.namespaces[SYNC].models.MutationEvent;\n        const modelId = getIdentifierValue(userModelDefinition, model);\n        const mutationEvents = await storage.query(this._MutationEvent, ModelPredicateCreator.createFromAST(mutationEventModelDefinition, {\n            and: { modelId: { eq: modelId } },\n        }));\n        return mutationEvents;\n    }\n    async getModelIds(storage) {\n        const mutationEvents = await storage.query(this._MutationEvent);\n        const result = new Set();\n        mutationEvents.forEach(({ modelId }) => result.add(modelId));\n        return result;\n    }\n    // applies _version from the AppSync mutation response to other items\n    // in the mutation queue with the same id\n    // see https://github.com/aws-amplify/amplify-js/pull/7354 for more details\n    async syncOutboxVersionsOnDequeue(storage, record, head, recordOp) {\n        if (head?.operation !== recordOp) {\n            return;\n        }\n        const { _version, _lastChangedAt, _deleted, ..._incomingData } = record;\n        const incomingData = this.removeTimestampFields(head.model, _incomingData);\n        const data = JSON.parse(head.data);\n        if (!data) {\n            return;\n        }\n        const { _version: __version, _lastChangedAt: __lastChangedAt, _deleted: __deleted, ..._outgoingData } = data;\n        const outgoingData = this.removeTimestampFields(head.model, _outgoingData);\n        // Don't sync the version when the data in the response does not match the data\n        // in the request, i.e., when there's a handled conflict\n        //\n        // NOTE: `incomingData` contains all the fields in the record received from AppSync\n        // and `outgoingData` only contains updated fields sent to AppSync\n        // If all send data isn't matched in the returned data then the update was rejected\n        // by AppSync and we should not update the version on other outbox entries for this\n        // object\n        if (!directedValueEquality(outgoingData, incomingData, true)) {\n            return;\n        }\n        const mutationEventModelDefinition = this.schema.namespaces[SYNC].models.MutationEvent;\n        const userModelDefinition = this.schema.namespaces.user.models[head.model];\n        const recordId = getIdentifierValue(userModelDefinition, record);\n        const predicate = ModelPredicateCreator.createFromAST(mutationEventModelDefinition, {\n            and: [\n                { modelId: { eq: recordId } },\n                { id: { ne: this.inProgressMutationEventId } },\n            ],\n        });\n        const outdatedMutations = await storage.query(this._MutationEvent, predicate);\n        if (!outdatedMutations.length) {\n            return;\n        }\n        const reconciledMutations = outdatedMutations.map(m => {\n            const oldData = JSON.parse(m.data);\n            const newData = { ...oldData, _version, _lastChangedAt };\n            return this._MutationEvent.copyOf(m, draft => {\n                draft.data = JSON.stringify(newData);\n            });\n        });\n        await storage.delete(this._MutationEvent, predicate);\n        await Promise.all(reconciledMutations.map(async (m) => storage.save(m, undefined, this.ownSymbol)));\n    }\n    mergeUserFields(previous, current) {\n        const { _version, _lastChangedAt, _deleted, ...previousData } = JSON.parse(previous.data);\n        const { _version: __version, _lastChangedAt: __lastChangedAt, _deleted: __deleted, ...currentData } = JSON.parse(current.data);\n        const data = JSON.stringify({\n            _version,\n            _lastChangedAt,\n            _deleted,\n            ...previousData,\n            ...currentData,\n        });\n        return this.modelInstanceCreator(this._MutationEvent, {\n            ...current,\n            data,\n        });\n    }\n    /*\n    if a model is using custom timestamp fields\n    the custom field names will be stored in the model attributes\n\n    e.g.\n    \"attributes\": [\n    {\n            \"type\": \"model\",\n            \"properties\": {\n                \"timestamps\": {\n                    \"createdAt\": \"createdOn\",\n                    \"updatedAt\": \"updatedOn\"\n                }\n            }\n    }\n    ]\n    */\n    removeTimestampFields(model, record) {\n        const CREATED_AT_DEFAULT_KEY = 'createdAt';\n        const UPDATED_AT_DEFAULT_KEY = 'updatedAt';\n        let createdTimestampKey = CREATED_AT_DEFAULT_KEY;\n        let updatedTimestampKey = UPDATED_AT_DEFAULT_KEY;\n        const modelAttributes = this.schema.namespaces[USER].models[model].attributes?.find(attr => attr.type === 'model');\n        const timestampFieldsMap = modelAttributes?.properties?.timestamps;\n        if (timestampFieldsMap) {\n            createdTimestampKey = timestampFieldsMap[CREATED_AT_DEFAULT_KEY];\n            updatedTimestampKey = timestampFieldsMap[UPDATED_AT_DEFAULT_KEY];\n        }\n        delete record[createdTimestampKey];\n        delete record[updatedTimestampKey];\n        return record;\n    }\n}\n\nexport { MutationEventOutbox };\n//# sourceMappingURL=outbox.mjs.map\n","import { resolveServiceErrorStatusCode } from '../utils.mjs';\n\nconst connectionTimeout = error => /^Connection failed: Connection Timeout/.test(error.message);\nconst serverError = error => resolveServiceErrorStatusCode(error) >= 500;\nconst mutationErrorMap = {\n    BadModel: () => false,\n    BadRecord: error => {\n        const { message } = error;\n        return (/^Cannot return \\w+ for [\\w-_]+ type/.test(message) ||\n            /^Variable '.+' has coerced Null value for NonNull type/.test(message)); // newly required field, out of date client\n    },\n    ConfigError: () => false,\n    Transient: error => connectionTimeout(error) || serverError(error),\n    Unauthorized: error => error.message === 'Unauthorized' ||\n        resolveServiceErrorStatusCode(error) === 401,\n};\nconst subscriptionErrorMap = {\n    BadModel: () => false,\n    BadRecord: () => false,\n    ConfigError: () => false,\n    Transient: observableError => {\n        const error = unwrapObservableError(observableError);\n        return connectionTimeout(error) || serverError(error);\n    },\n    Unauthorized: observableError => {\n        const error = unwrapObservableError(observableError);\n        return /Connection failed.+Unauthorized/.test(error.message);\n    },\n};\nconst syncErrorMap = {\n    BadModel: () => false,\n    BadRecord: error => /^Cannot return \\w+ for [\\w-_]+ type/.test(error.message),\n    ConfigError: () => false,\n    Transient: error => connectionTimeout(error) || serverError(error),\n    Unauthorized: error => error.errorType === 'Unauthorized',\n};\n/**\n * Get the first error reason of an observable.\n * Allows for error maps to be easily applied to observable errors\n *\n * @param observableError an error from ZenObservable subscribe error callback\n */\nfunction unwrapObservableError(observableError) {\n    const { errors: [error], } = (observableError);\n    return error;\n}\nfunction getMutationErrorType(error) {\n    return mapErrorToType(mutationErrorMap, error);\n}\nfunction getSubscriptionErrorType(error) {\n    return mapErrorToType(subscriptionErrorMap, error);\n}\nfunction getSyncErrorType(error) {\n    return mapErrorToType(syncErrorMap, error);\n}\n/**\n * Categorizes an error with a broad error type, intended to make\n * customer error handling code simpler.\n * @param errorMap Error names and a list of patterns that indicate them (each pattern as a regex or function)\n * @param error The underying error to categorize.\n */\nfunction mapErrorToType(errorMap, error) {\n    const errorTypes = [...Object.keys(errorMap)];\n    for (const errorType of errorTypes) {\n        const matcher = errorMap[errorType];\n        if (matcher?.(error)) {\n            return errorType;\n        }\n    }\n    return 'Unknown';\n}\n\nexport { getMutationErrorType, getSubscriptionErrorType, getSyncErrorType, mapErrorToType, mutationErrorMap, subscriptionErrorMap, syncErrorMap };\n//# sourceMappingURL=errorMaps.mjs.map\n","import { InternalAPI } from '@aws-amplify/api/internals';\nimport { jitteredBackoff, BackgroundProcessManager, retry, Category, DataStoreAction, NonRetryableError } from '@aws-amplify/core/internals/utils';\nimport { Observable } from 'rxjs';\nimport { ConsoleLogger } from '@aws-amplify/core';\nimport { ProcessName, DISCARD, isModelFieldType, isTargetNameAssociation, OpType } from '../../types.mjs';\nimport { extractTargetNamesFromSrc, USER, ID } from '../../util.mjs';\nimport { buildGraphQLOperation, getModelAuthModes, getTokenForCustomAuth, createMutationInstanceFromModelOperation, TransformerMutationType } from '../utils.mjs';\nimport { getMutationErrorType } from './errorMaps.mjs';\n\nconst MAX_ATTEMPTS = 10;\nconst logger = new ConsoleLogger('DataStore');\nclass MutationProcessor {\n    constructor(schema, storage, userClasses, outbox, modelInstanceCreator, _MutationEvent, amplifyConfig = {}, authModeStrategy, errorHandler, conflictHandler, amplifyContext) {\n        this.schema = schema;\n        this.storage = storage;\n        this.userClasses = userClasses;\n        this.outbox = outbox;\n        this.modelInstanceCreator = modelInstanceCreator;\n        this._MutationEvent = _MutationEvent;\n        this.amplifyConfig = amplifyConfig;\n        this.authModeStrategy = authModeStrategy;\n        this.errorHandler = errorHandler;\n        this.conflictHandler = conflictHandler;\n        this.amplifyContext = amplifyContext;\n        this.typeQuery = new WeakMap();\n        this.processing = false;\n        this.runningProcesses = new BackgroundProcessManager();\n        this.amplifyContext.InternalAPI =\n            this.amplifyContext.InternalAPI || InternalAPI;\n        this.generateQueries();\n    }\n    generateQueries() {\n        Object.values(this.schema.namespaces).forEach(namespace => {\n            Object.values(namespace.models)\n                .filter(({ syncable }) => syncable)\n                .forEach(model => {\n                const [createMutation] = buildGraphQLOperation(namespace, model, 'CREATE');\n                const [updateMutation] = buildGraphQLOperation(namespace, model, 'UPDATE');\n                const [deleteMutation] = buildGraphQLOperation(namespace, model, 'DELETE');\n                this.typeQuery.set(model, [\n                    createMutation,\n                    updateMutation,\n                    deleteMutation,\n                ]);\n            });\n        });\n    }\n    isReady() {\n        return this.observer !== undefined;\n    }\n    start() {\n        this.runningProcesses = new BackgroundProcessManager();\n        const observable = new Observable(observer => {\n            this.observer = observer;\n            try {\n                this.resume();\n            }\n            catch (error) {\n                logger.error('mutations processor start error', error);\n                throw error;\n            }\n            return this.runningProcesses.addCleaner(async () => {\n                // The observer has unsubscribed and/or `stop()` has been called.\n                this.removeObserver();\n                this.pause();\n            });\n        });\n        return observable;\n    }\n    async stop() {\n        this.removeObserver();\n        await this.runningProcesses.close();\n        await this.runningProcesses.open();\n    }\n    removeObserver() {\n        this.observer?.complete?.();\n        this.observer = undefined;\n    }\n    async resume() {\n        if (this.runningProcesses.isOpen) {\n            await this.runningProcesses.add(async (onTerminate) => {\n                if (this.processing ||\n                    !this.isReady() ||\n                    !this.runningProcesses.isOpen) {\n                    return;\n                }\n                this.processing = true;\n                let head;\n                const namespaceName = USER;\n                // start to drain outbox\n                while (this.processing &&\n                    this.runningProcesses.isOpen &&\n                    (head = await this.outbox.peek(this.storage)) !== undefined) {\n                    const { model, operation, data, condition } = head;\n                    const modelConstructor = this.userClasses[model];\n                    let result = undefined;\n                    let opName = undefined;\n                    let modelDefinition = undefined;\n                    try {\n                        const modelAuthModes = await getModelAuthModes({\n                            authModeStrategy: this.authModeStrategy,\n                            defaultAuthMode: this.amplifyConfig.aws_appsync_authenticationType,\n                            modelName: model,\n                            schema: this.schema,\n                        });\n                        const operationAuthModes = modelAuthModes[operation.toUpperCase()];\n                        let authModeAttempts = 0;\n                        const authModeRetry = async () => {\n                            try {\n                                logger.debug(`Attempting mutation with authMode: ${operationAuthModes[authModeAttempts]}`);\n                                const response = await this.jitteredRetry(namespaceName, model, operation, data, condition, modelConstructor, this._MutationEvent, head, operationAuthModes[authModeAttempts], onTerminate);\n                                logger.debug(`Mutation sent successfully with authMode: ${operationAuthModes[authModeAttempts]}`);\n                                return response;\n                            }\n                            catch (error) {\n                                authModeAttempts++;\n                                if (authModeAttempts >= operationAuthModes.length) {\n                                    logger.debug(`Mutation failed with authMode: ${operationAuthModes[authModeAttempts - 1]}`);\n                                    try {\n                                        // eslint-disable-next-line @typescript-eslint/no-confusing-void-expression\n                                        await this.errorHandler({\n                                            recoverySuggestion: 'Ensure app code is up to date, auth directives exist and are correct on each model, and that server-side data has not been invalidated by a schema change. If the problem persists, search for or create an issue: https://github.com/aws-amplify/amplify-js/issues',\n                                            localModel: null,\n                                            message: error.message,\n                                            model: modelConstructor.name,\n                                            operation: opName,\n                                            errorType: getMutationErrorType(error),\n                                            process: ProcessName.sync,\n                                            remoteModel: null,\n                                            cause: error,\n                                        });\n                                    }\n                                    catch (e) {\n                                        logger.error('Mutation error handler failed with:', e);\n                                    }\n                                    throw error;\n                                }\n                                logger.debug(`Mutation failed with authMode: ${operationAuthModes[authModeAttempts - 1]}. Retrying with authMode: ${operationAuthModes[authModeAttempts]}`);\n                                return authModeRetry();\n                            }\n                        };\n                        [result, opName, modelDefinition] = await authModeRetry();\n                    }\n                    catch (error) {\n                        if (error.message === 'Offline' ||\n                            error.message === 'RetryMutation') {\n                            continue;\n                        }\n                    }\n                    if (result === undefined) {\n                        logger.debug('done retrying');\n                        await this.storage.runExclusive(async (storage) => {\n                            await this.outbox.dequeue(storage);\n                        });\n                        continue;\n                    }\n                    const record = result.data[opName];\n                    let hasMore = false;\n                    await this.storage.runExclusive(async (storage) => {\n                        // using runExclusive to prevent possible race condition\n                        // when another record gets enqueued between dequeue and peek\n                        await this.outbox.dequeue(storage, record, operation);\n                        hasMore = (await this.outbox.peek(storage)) !== undefined;\n                    });\n                    this.observer?.next?.({\n                        operation,\n                        modelDefinition,\n                        model: record,\n                        hasMore,\n                    });\n                }\n                // pauses itself\n                this.pause();\n            }, 'mutation resume loop');\n        }\n    }\n    async jitteredRetry(namespaceName, model, operation, data, condition, modelConstructor, MutationEventCtor, mutationEvent, authMode, onTerminate) {\n        return retry(async (retriedModel, retriedOperation, retriedData, retriedCondition, retriedModelConstructor, retiredMutationEventCtor, retiredMutationEvent) => {\n            const [query, variables, graphQLCondition, opName, modelDefinition] = this.createQueryVariables(namespaceName, retriedModel, retriedOperation, retriedData, retriedCondition);\n            const authToken = await getTokenForCustomAuth(authMode, this.amplifyConfig);\n            const tryWith = {\n                query,\n                variables,\n                authMode,\n                authToken,\n            };\n            let attempt = 0;\n            const opType = this.opTypeFromTransformerOperation(retriedOperation);\n            const customUserAgentDetails = {\n                category: Category.DataStore,\n                action: DataStoreAction.GraphQl,\n            };\n            do {\n                try {\n                    const result = (await this.amplifyContext.InternalAPI.graphql(tryWith, undefined, customUserAgentDetails));\n                    // Use `as any` because TypeScript doesn't seem to like passing tuples\n                    // through generic params.\n                    return [result, opName, modelDefinition];\n                }\n                catch (err) {\n                    if (err.errors && err.errors.length > 0) {\n                        const [error] = err.errors;\n                        const { originalError: { code = null } = {} } = error;\n                        if (error.errorType === 'Unauthorized') {\n                            throw new NonRetryableError('Unauthorized');\n                        }\n                        if (error.message === 'Network Error' ||\n                            code === 'ERR_NETWORK' // refers to axios timeout error caused by device's bad network condition\n                        ) {\n                            if (!this.processing) {\n                                throw new NonRetryableError('Offline');\n                            }\n                            // TODO: Check errors on different env (react-native or other browsers)\n                            throw new Error('Network Error');\n                        }\n                        if (error.errorType === 'ConflictUnhandled') {\n                            // TODO: add on ConflictConditionalCheck error query last from server\n                            attempt++;\n                            let retryWith;\n                            if (attempt > MAX_ATTEMPTS) {\n                                retryWith = DISCARD;\n                            }\n                            else {\n                                try {\n                                    retryWith = await this.conflictHandler({\n                                        modelConstructor: retriedModelConstructor,\n                                        localModel: this.modelInstanceCreator(retriedModelConstructor, variables.input),\n                                        remoteModel: this.modelInstanceCreator(retriedModelConstructor, error.data),\n                                        operation: opType,\n                                        attempts: attempt,\n                                    });\n                                }\n                                catch (caughtErr) {\n                                    logger.warn('conflict trycatch', caughtErr);\n                                    continue;\n                                }\n                            }\n                            if (retryWith === DISCARD) {\n                                // Query latest from server and notify merger\n                                const [[, builtOpName, builtQuery]] = buildGraphQLOperation(this.schema.namespaces[namespaceName], modelDefinition, 'GET');\n                                const newAuthToken = await getTokenForCustomAuth(authMode, this.amplifyConfig);\n                                const serverData = (await this.amplifyContext.InternalAPI.graphql({\n                                    query: builtQuery,\n                                    variables: { id: variables.input.id },\n                                    authMode,\n                                    authToken: newAuthToken,\n                                }, undefined, customUserAgentDetails));\n                                // onTerminate cancel graphql()\n                                return [serverData, builtOpName, modelDefinition];\n                            }\n                            const namespace = this.schema.namespaces[namespaceName];\n                            // convert retry with to tryWith\n                            const updatedMutation = createMutationInstanceFromModelOperation(namespace.relationships, modelDefinition, opType, retriedModelConstructor, retryWith, graphQLCondition, retiredMutationEventCtor, this.modelInstanceCreator, retiredMutationEvent.id);\n                            await this.storage.save(updatedMutation);\n                            throw new NonRetryableError('RetryMutation');\n                        }\n                        else {\n                            try {\n                                this.errorHandler({\n                                    recoverySuggestion: 'Ensure app code is up to date, auth directives exist and are correct on each model, and that server-side data has not been invalidated by a schema change. If the problem persists, search for or create an issue: https://github.com/aws-amplify/amplify-js/issues',\n                                    localModel: variables.input,\n                                    message: error.message,\n                                    operation: retriedOperation,\n                                    errorType: getMutationErrorType(error),\n                                    errorInfo: error.errorInfo,\n                                    process: ProcessName.mutate,\n                                    cause: error,\n                                    remoteModel: error.data\n                                        ? this.modelInstanceCreator(retriedModelConstructor, error.data)\n                                        : null,\n                                });\n                            }\n                            catch (caughtErr) {\n                                logger.warn('Mutation error handler failed with:', caughtErr);\n                            }\n                            finally {\n                                // Return empty tuple, dequeues the mutation\n                                // eslint-disable-next-line no-unsafe-finally\n                                return error.data\n                                    ? [\n                                        { data: { [opName]: error.data } },\n                                        opName,\n                                        modelDefinition,\n                                    ]\n                                    : [];\n                            }\n                        }\n                    }\n                    else {\n                        // Catch-all for client-side errors that don't come back in the `GraphQLError` format.\n                        // These errors should not be retried.\n                        throw new NonRetryableError(err);\n                    }\n                }\n                // eslint-disable-next-line no-unmodified-loop-condition\n            } while (tryWith);\n        }, [\n            model,\n            operation,\n            data,\n            condition,\n            modelConstructor,\n            MutationEventCtor,\n            mutationEvent,\n        ], safeJitteredBackoff, onTerminate);\n    }\n    createQueryVariables(namespaceName, model, operation, data, condition) {\n        const modelDefinition = this.schema.namespaces[namespaceName].models[model];\n        const { primaryKey } = this.schema.namespaces[namespaceName].keys[model];\n        const auth = modelDefinition.attributes?.find(a => a.type === 'auth');\n        const ownerFields = auth?.properties?.rules\n            .map(rule => rule.ownerField)\n            .filter(f => f) || ['owner'];\n        const queriesTuples = this.typeQuery.get(modelDefinition);\n        const [, opName, query] = queriesTuples.find(([transformerMutationType]) => transformerMutationType === operation);\n        const { _version, ...parsedData } = JSON.parse(data);\n        // include all the fields that comprise a custom PK if one is specified\n        const deleteInput = {};\n        if (primaryKey && primaryKey.length) {\n            for (const pkField of primaryKey) {\n                deleteInput[pkField] = parsedData[pkField];\n            }\n        }\n        else {\n            deleteInput[ID] = parsedData.id;\n        }\n        let mutationInput;\n        if (operation === TransformerMutationType.DELETE) {\n            // For DELETE mutations, only the key(s) are included in the input\n            mutationInput = deleteInput;\n        }\n        else {\n            // Otherwise, we construct the mutation input with the following logic\n            mutationInput = {};\n            const modelFields = Object.values(modelDefinition.fields);\n            for (const { name, type, association, isReadOnly } of modelFields) {\n                // omit readonly fields. cloud storage doesn't need them and won't take them!\n                if (isReadOnly) {\n                    continue;\n                }\n                // omit owner fields if it's `null`. cloud storage doesn't allow it.\n                if (ownerFields.includes(name) && parsedData[name] === null) {\n                    continue;\n                }\n                // model fields should be stripped out from the input\n                if (isModelFieldType(type)) {\n                    // except for belongs to relations - we need to replace them with the correct foreign key(s)\n                    if (isTargetNameAssociation(association) &&\n                        association.connectionType === 'BELONGS_TO') {\n                        const targetNames = extractTargetNamesFromSrc(association);\n                        if (targetNames) {\n                            // instead of including the connected model itself, we add its key(s) to the mutation input\n                            for (const targetName of targetNames) {\n                                mutationInput[targetName] = parsedData[targetName];\n                            }\n                        }\n                    }\n                    continue;\n                }\n                // scalar fields / non-model types\n                if (operation === TransformerMutationType.UPDATE) {\n                    if (!Object.prototype.hasOwnProperty.call(parsedData, name)) {\n                        // for update mutations - strip out a field if it's unchanged\n                        continue;\n                    }\n                }\n                // all other fields are added to the input object\n                mutationInput[name] = parsedData[name];\n            }\n        }\n        // Build mutation variables input object\n        const input = {\n            ...mutationInput,\n            _version,\n        };\n        const graphQLCondition = JSON.parse(condition);\n        const variables = {\n            input,\n            ...(operation === TransformerMutationType.CREATE\n                ? {}\n                : {\n                    condition: Object.keys(graphQLCondition).length > 0\n                        ? graphQLCondition\n                        : null,\n                }),\n        };\n        return [query, variables, graphQLCondition, opName, modelDefinition];\n    }\n    opTypeFromTransformerOperation(operation) {\n        switch (operation) {\n            case TransformerMutationType.CREATE:\n                return OpType.INSERT;\n            case TransformerMutationType.DELETE:\n                return OpType.DELETE;\n            case TransformerMutationType.UPDATE:\n                return OpType.UPDATE;\n            case TransformerMutationType.GET: // Intentionally blank\n                break;\n            default:\n                throw new Error(`Invalid operation ${operation}`);\n        }\n        // because it makes TS happy ...\n        return undefined;\n    }\n    pause() {\n        this.processing = false;\n    }\n}\nconst MAX_RETRY_DELAY_MS = 5 * 60 * 1000;\nconst originalJitteredBackoff = jitteredBackoff(MAX_RETRY_DELAY_MS);\n/**\n * @private\n * Internal use of Amplify only.\n *\n * Wraps the jittered backoff calculation to retry Network Errors indefinitely.\n * Backs off according to original jittered retry logic until the original retry\n * logic hits its max. After this occurs, if the error is a Network Error, we\n * ignore the attempt count and return MAX_RETRY_DELAY_MS to retry forever (until\n * the request succeeds).\n *\n * @param attempt ignored\n * @param _args ignored\n * @param error tested to see if `.message` is 'Network Error'\n * @returns number | false :\n */\nconst safeJitteredBackoff = (attempt, _args, error) => {\n    const attemptResult = originalJitteredBackoff(attempt);\n    // If this is the last attempt and it is a network error, we retry indefinitively every 5 minutes\n    if (attemptResult === false &&\n        (error || {}).message === 'Network Error') {\n        return MAX_RETRY_DELAY_MS;\n    }\n    return attemptResult;\n};\n\nexport { MutationProcessor, safeJitteredBackoff };\n//# sourceMappingURL=mutation.mjs.map\n","import { InternalAPI } from '@aws-amplify/api/internals';\nimport { ConsoleLogger, fetchAuthSession, Hub } from '@aws-amplify/core';\nimport { BackgroundProcessManager, Category, DataStoreAction } from '@aws-amplify/core/internals/utils';\nimport { Observable } from 'rxjs';\nimport { CONTROL_MSG as CONTROL_MSG$1 } from '@aws-amplify/api-graphql';\nimport { ProcessName } from '../../types.mjs';\nimport { buildSubscriptionGraphQLOperation, getAuthorizationRules, getUserGroupsFromToken, getModelAuthModes, TransformerMutationType, RTFError, generateRTFRemediation, getTokenForCustomAuth, predicateToGraphQLFilter } from '../utils.mjs';\nimport { ModelPredicateCreator } from '../../predicates/index.mjs';\nimport { validatePredicate } from '../../util.mjs';\nimport { getSubscriptionErrorType } from './errorMaps.mjs';\n\nconst logger = new ConsoleLogger('DataStore');\nvar CONTROL_MSG;\n(function (CONTROL_MSG) {\n    CONTROL_MSG[\"CONNECTED\"] = \"CONNECTED\";\n})(CONTROL_MSG || (CONTROL_MSG = {}));\nvar USER_CREDENTIALS;\n(function (USER_CREDENTIALS) {\n    USER_CREDENTIALS[USER_CREDENTIALS[\"none\"] = 0] = \"none\";\n    USER_CREDENTIALS[USER_CREDENTIALS[\"unauth\"] = 1] = \"unauth\";\n    USER_CREDENTIALS[USER_CREDENTIALS[\"auth\"] = 2] = \"auth\";\n})(USER_CREDENTIALS || (USER_CREDENTIALS = {}));\nclass SubscriptionProcessor {\n    constructor(schema, syncPredicates, amplifyConfig = {}, authModeStrategy, errorHandler, amplifyContext = {\n        InternalAPI,\n    }) {\n        this.schema = schema;\n        this.syncPredicates = syncPredicates;\n        this.amplifyConfig = amplifyConfig;\n        this.authModeStrategy = authModeStrategy;\n        this.errorHandler = errorHandler;\n        this.amplifyContext = amplifyContext;\n        this.typeQuery = new WeakMap();\n        this.buffer = [];\n        this.runningProcesses = new BackgroundProcessManager();\n    }\n    buildSubscription(namespace, model, transformerMutationType, userCredentials, oidcTokenPayload, authMode, filterArg = false) {\n        const { aws_appsync_authenticationType } = this.amplifyConfig;\n        const { isOwner, ownerField, ownerValue } = this.getAuthorizationInfo(model, userCredentials, aws_appsync_authenticationType, oidcTokenPayload, authMode) || {};\n        const [opType, opName, query] = buildSubscriptionGraphQLOperation(namespace, model, transformerMutationType, isOwner, ownerField, filterArg);\n        return { authMode, opType, opName, query, isOwner, ownerField, ownerValue };\n    }\n    getAuthorizationInfo(model, userCredentials, defaultAuthType, oidcTokenPayload, authMode) {\n        const rules = getAuthorizationRules(model);\n        // Return null if user doesn't have proper credentials for private API with IAM auth\n        const iamPrivateAuth = authMode === 'iam' &&\n            rules.find(rule => rule.authStrategy === 'private' && rule.provider === 'iam');\n        if (iamPrivateAuth && userCredentials === USER_CREDENTIALS.unauth) {\n            return null;\n        }\n        // Group auth should take precedence over owner auth, so we are checking\n        // if rule(s) have group authorization as well as if either the Cognito or\n        // OIDC token has a groupClaim. If so, we are returning auth info before\n        // any further owner-based auth checks.\n        const groupAuthRules = rules.filter(rule => rule.authStrategy === 'groups' &&\n            ['userPools', 'oidc'].includes(rule.provider));\n        const validGroup = (authMode === 'oidc' || authMode === 'userPool') &&\n            // eslint-disable-next-line array-callback-return\n            groupAuthRules.find(groupAuthRule => {\n                // validate token against groupClaim\n                if (oidcTokenPayload) {\n                    const oidcUserGroups = getUserGroupsFromToken(oidcTokenPayload, groupAuthRule);\n                    return [...oidcUserGroups].find(userGroup => {\n                        return groupAuthRule.groups.find(group => group === userGroup);\n                    });\n                }\n            });\n        if (validGroup) {\n            return {\n                authMode,\n                isOwner: false,\n            };\n        }\n        let ownerAuthInfo;\n        if (ownerAuthInfo) {\n            return ownerAuthInfo;\n        }\n        // Owner auth needs additional values to be returned in order to create the subscription with\n        // the correct parameters so we are getting the owner value from the OIDC token via the\n        // identityClaim from the auth rule.\n        const oidcOwnerAuthRules = authMode === 'oidc' || authMode === 'userPool'\n            ? rules.filter(rule => rule.authStrategy === 'owner' &&\n                (rule.provider === 'oidc' || rule.provider === 'userPools'))\n            : [];\n        oidcOwnerAuthRules.forEach(ownerAuthRule => {\n            const ownerValue = oidcTokenPayload?.[ownerAuthRule.identityClaim];\n            const singleOwner = model.fields[ownerAuthRule.ownerField]?.isArray !== true;\n            const isOwnerArgRequired = singleOwner && !ownerAuthRule.areSubscriptionsPublic;\n            if (ownerValue) {\n                ownerAuthInfo = {\n                    authMode,\n                    isOwner: isOwnerArgRequired,\n                    ownerField: ownerAuthRule.ownerField,\n                    ownerValue: String(ownerValue),\n                };\n            }\n        });\n        if (ownerAuthInfo) {\n            return ownerAuthInfo;\n        }\n        // Fallback: return authMode or default auth type\n        return {\n            authMode: authMode || defaultAuthType,\n            isOwner: false,\n        };\n    }\n    hubQueryCompletionListener(completed, capsule) {\n        const { payload: { event }, } = capsule;\n        if (event === CONTROL_MSG$1.SUBSCRIPTION_ACK) {\n            completed();\n        }\n    }\n    start() {\n        this.runningProcesses =\n            this.runningProcesses || new BackgroundProcessManager();\n        const ctlObservable = new Observable(observer => {\n            const promises = [];\n            // Creating subs for each model/operation combo so they can be unsubscribed\n            // independently, since the auth retry behavior is asynchronous.\n            let subscriptions = {};\n            let oidcTokenPayload;\n            let userCredentials = USER_CREDENTIALS.none;\n            this.runningProcesses.add(async () => {\n                try {\n                    // retrieving current AWS Credentials\n                    const credentials = (await fetchAuthSession()).tokens?.accessToken;\n                    userCredentials = credentials\n                        ? USER_CREDENTIALS.auth\n                        : USER_CREDENTIALS.unauth;\n                }\n                catch (err) {\n                    // best effort to get AWS credentials\n                }\n                try {\n                    // retrieving current token info from Cognito UserPools\n                    const session = await fetchAuthSession();\n                    oidcTokenPayload = session.tokens?.idToken?.payload;\n                }\n                catch (err) {\n                    // best effort to get jwt from Cognito\n                }\n                Object.values(this.schema.namespaces).forEach(namespace => {\n                    Object.values(namespace.models)\n                        .filter(({ syncable }) => syncable)\n                        .forEach(modelDefinition => this.runningProcesses.isOpen &&\n                        this.runningProcesses.add(async () => {\n                            const modelAuthModes = await getModelAuthModes({\n                                authModeStrategy: this.authModeStrategy,\n                                defaultAuthMode: this.amplifyConfig.aws_appsync_authenticationType,\n                                modelName: modelDefinition.name,\n                                schema: this.schema,\n                            });\n                            // subscriptions are created only based on the READ auth mode(s)\n                            const readAuthModes = modelAuthModes.READ;\n                            subscriptions = {\n                                ...subscriptions,\n                                [modelDefinition.name]: {\n                                    [TransformerMutationType.CREATE]: [],\n                                    [TransformerMutationType.UPDATE]: [],\n                                    [TransformerMutationType.DELETE]: [],\n                                },\n                            };\n                            const operations = [\n                                TransformerMutationType.CREATE,\n                                TransformerMutationType.UPDATE,\n                                TransformerMutationType.DELETE,\n                            ];\n                            const operationAuthModeAttempts = {\n                                [TransformerMutationType.CREATE]: 0,\n                                [TransformerMutationType.UPDATE]: 0,\n                                [TransformerMutationType.DELETE]: 0,\n                            };\n                            const predicatesGroup = ModelPredicateCreator.getPredicates(this.syncPredicates.get(modelDefinition), false);\n                            const addFilterArg = predicatesGroup !== undefined;\n                            // Retry subscriptions that failed for one of the following reasons:\n                            // 1. unauthorized - retry with next auth mode (if available)\n                            // 2. RTF error - retry without sending filter arg. (filtering will fall back to clientside)\n                            const subscriptionRetry = async (operation, addFilter = addFilterArg) => {\n                                const { opType: transformerMutationType, opName, query, isOwner, ownerField, ownerValue, authMode, } = this.buildSubscription(namespace, modelDefinition, operation, userCredentials, oidcTokenPayload, readAuthModes[operationAuthModeAttempts[operation]], addFilter);\n                                const authToken = await getTokenForCustomAuth(authMode, this.amplifyConfig);\n                                const variables = {};\n                                const customUserAgentDetails = {\n                                    category: Category.DataStore,\n                                    action: DataStoreAction.Subscribe,\n                                };\n                                if (addFilter && predicatesGroup) {\n                                    variables.filter =\n                                        predicateToGraphQLFilter(predicatesGroup);\n                                }\n                                if (isOwner) {\n                                    if (!ownerValue) {\n                                        observer.error('Owner field required, sign in is needed in order to perform this operation');\n                                        return;\n                                    }\n                                    variables[ownerField] = ownerValue;\n                                }\n                                logger.debug(`Attempting ${operation} subscription with authMode: ${readAuthModes[operationAuthModeAttempts[operation]]}`);\n                                const queryObservable = this.amplifyContext.InternalAPI.graphql({\n                                    query,\n                                    variables,\n                                    ...{ authMode },\n                                    authToken,\n                                }, undefined, customUserAgentDetails);\n                                let subscriptionReadyCallback;\n                                // TODO: consider onTerminate.then(() => API.cancel(...))\n                                subscriptions[modelDefinition.name][transformerMutationType].push(queryObservable.subscribe({\n                                    next: result => {\n                                        const { data, errors } = result;\n                                        if (Array.isArray(errors) && errors.length > 0) {\n                                            const messages = errors.map(({ message }) => message);\n                                            logger.warn(`Skipping incoming subscription. Messages: ${messages.join('\\n')}`);\n                                            this.drainBuffer();\n                                            return;\n                                        }\n                                        const resolvedPredicatesGroup = ModelPredicateCreator.getPredicates(this.syncPredicates.get(modelDefinition), false);\n                                        const { [opName]: record } = data;\n                                        // checking incoming subscription against syncPredicate.\n                                        // once AppSync implements filters on subscriptions, we'll be\n                                        // able to set these when establishing the subscription instead.\n                                        // Until then, we'll need to filter inbound\n                                        if (this.passesPredicateValidation(record, resolvedPredicatesGroup)) {\n                                            this.pushToBuffer(transformerMutationType, modelDefinition, record);\n                                        }\n                                        this.drainBuffer();\n                                    },\n                                    error: async (subscriptionError) => {\n                                        const { errors: [{ message = '' } = {}], } = (subscriptionError);\n                                        const isRTFError = \n                                        // only attempt catch if a filter variable was added to the subscription query\n                                        addFilter &&\n                                            this.catchRTFError(message, modelDefinition, predicatesGroup);\n                                        // Catch RTF errors\n                                        if (isRTFError) {\n                                            // Unsubscribe and clear subscription array for model/operation\n                                            subscriptions[modelDefinition.name][transformerMutationType].forEach(subscription => subscription.unsubscribe());\n                                            subscriptions[modelDefinition.name][transformerMutationType] = [];\n                                            // retry subscription connection without filter\n                                            subscriptionRetry(operation, false);\n                                            return;\n                                        }\n                                        if (message.includes(CONTROL_MSG$1.REALTIME_SUBSCRIPTION_INIT_ERROR) ||\n                                            message.includes(CONTROL_MSG$1.CONNECTION_FAILED)) {\n                                            // Unsubscribe and clear subscription array for model/operation\n                                            subscriptions[modelDefinition.name][transformerMutationType].forEach(subscription => subscription.unsubscribe());\n                                            subscriptions[modelDefinition.name][transformerMutationType] = [];\n                                            operationAuthModeAttempts[operation]++;\n                                            if (operationAuthModeAttempts[operation] >=\n                                                readAuthModes.length) {\n                                                // last auth mode retry. Continue with error\n                                                logger.debug(`${operation} subscription failed with authMode: ${readAuthModes[operationAuthModeAttempts[operation] - 1]}`);\n                                            }\n                                            else {\n                                                // retry with different auth mode. Do not trigger\n                                                // observer error or error handler\n                                                logger.debug(`${operation} subscription failed with authMode: ${readAuthModes[operationAuthModeAttempts[operation] - 1]}. Retrying with authMode: ${readAuthModes[operationAuthModeAttempts[operation]]}`);\n                                                subscriptionRetry(operation);\n                                                return;\n                                            }\n                                        }\n                                        logger.warn('subscriptionError', message);\n                                        try {\n                                            // eslint-disable-next-line @typescript-eslint/no-confusing-void-expression\n                                            await this.errorHandler({\n                                                recoverySuggestion: 'Ensure app code is up to date, auth directives exist and are correct on each model, and that server-side data has not been invalidated by a schema change. If the problem persists, search for or create an issue: https://github.com/aws-amplify/amplify-js/issues',\n                                                localModel: null,\n                                                message,\n                                                model: modelDefinition.name,\n                                                operation,\n                                                errorType: getSubscriptionErrorType(subscriptionError),\n                                                process: ProcessName.subscribe,\n                                                remoteModel: null,\n                                                cause: subscriptionError,\n                                            });\n                                        }\n                                        catch (e) {\n                                            logger.error('Subscription error handler failed with:', e);\n                                        }\n                                        if (typeof subscriptionReadyCallback === 'function') {\n                                            subscriptionReadyCallback();\n                                        }\n                                        if (message.includes('\"errorType\":\"Unauthorized\"') ||\n                                            message.includes('\"errorType\":\"OperationDisabled\"')) {\n                                            return;\n                                        }\n                                        observer.error(message);\n                                    },\n                                }));\n                                promises.push((async () => {\n                                    let boundFunction;\n                                    let removeBoundFunctionListener;\n                                    await new Promise(resolve => {\n                                        subscriptionReadyCallback = resolve;\n                                        boundFunction = this.hubQueryCompletionListener.bind(this, resolve);\n                                        removeBoundFunctionListener = Hub.listen('api', boundFunction);\n                                    });\n                                    removeBoundFunctionListener();\n                                })());\n                            };\n                            operations.forEach(op => subscriptionRetry(op));\n                        }));\n                });\n                this.runningProcesses.isOpen &&\n                    this.runningProcesses.add(() => Promise.all(promises).then(() => {\n                        observer.next(CONTROL_MSG.CONNECTED);\n                    }));\n            }, 'subscription processor new subscriber');\n            return this.runningProcesses.addCleaner(async () => {\n                Object.keys(subscriptions).forEach(modelName => {\n                    subscriptions[modelName][TransformerMutationType.CREATE].forEach(subscription => {\n                        subscription.unsubscribe();\n                    });\n                    subscriptions[modelName][TransformerMutationType.UPDATE].forEach(subscription => {\n                        subscription.unsubscribe();\n                    });\n                    subscriptions[modelName][TransformerMutationType.DELETE].forEach(subscription => {\n                        subscription.unsubscribe();\n                    });\n                });\n            });\n        });\n        const dataObservable = new Observable(observer => {\n            this.dataObserver = observer;\n            this.drainBuffer();\n            return this.runningProcesses.addCleaner(async () => {\n                this.dataObserver = null;\n            });\n        });\n        return [ctlObservable, dataObservable];\n    }\n    async stop() {\n        await this.runningProcesses.close();\n        await this.runningProcesses.open();\n    }\n    passesPredicateValidation(record, predicatesGroup) {\n        if (!predicatesGroup) {\n            return true;\n        }\n        const { predicates, type } = predicatesGroup;\n        return validatePredicate(record, type, predicates);\n    }\n    pushToBuffer(transformerMutationType, modelDefinition, data) {\n        this.buffer.push([transformerMutationType, modelDefinition, data]);\n    }\n    drainBuffer() {\n        if (this.dataObserver) {\n            this.buffer.forEach(data => {\n                this.dataObserver.next(data);\n            });\n            this.buffer = [];\n        }\n    }\n    /**\n     * @returns true if the service returned an RTF subscription error\n     * @remarks logs a warning with remediation instructions\n     *\n     */\n    catchRTFError(message, modelDefinition, predicatesGroup) {\n        const header = 'Backend subscriptions filtering error.\\n' +\n            'Subscriptions filtering will be applied clientside.\\n';\n        const messageErrorTypeMap = {\n            'UnknownArgument: Unknown field argument filter': RTFError.UnknownField,\n            'Filters exceed maximum attributes limit': RTFError.MaxAttributes,\n            'Filters combination exceed maximum limit': RTFError.MaxCombinations,\n            'filter uses same fieldName multiple time': RTFError.RepeatedFieldname,\n            \"The variables input contains a field name 'not'\": RTFError.NotGroup,\n            'The variables input contains a field that is not defined for input object type': RTFError.FieldNotInType,\n        };\n        const [_errorMsg, errorType] = Object.entries(messageErrorTypeMap).find(([errorMsg]) => message.includes(errorMsg)) || [];\n        if (errorType !== undefined) {\n            const remediationMessage = generateRTFRemediation(errorType, modelDefinition, predicatesGroup);\n            logger.warn(`${header}\\n${message}\\n${remediationMessage}`);\n            return true;\n        }\n        return false;\n    }\n}\n\nexport { CONTROL_MSG, SubscriptionProcessor, USER_CREDENTIALS };\n//# sourceMappingURL=subscription.mjs.map\n","import { InternalAPI } from '@aws-amplify/api/internals';\nimport { Observable } from 'rxjs';\nimport { BackgroundProcessManager, jitteredExponentialRetry, Category, DataStoreAction, NonRetryableError } from '@aws-amplify/core/internals/utils';\nimport { ConsoleLogger, Hub } from '@aws-amplify/core';\nimport { ProcessName } from '../../types.mjs';\nimport { buildGraphQLOperation, predicateToGraphQLFilter, getModelAuthModes, getTokenForCustomAuth, getClientSideAuthError, getForbiddenError } from '../utils.mjs';\nimport { ModelPredicateCreator } from '../../predicates/index.mjs';\nimport { getSyncErrorType } from './errorMaps.mjs';\n\nconst opResultDefaults = {\n    items: [],\n    nextToken: null,\n    startedAt: null,\n};\nconst logger = new ConsoleLogger('DataStore');\nclass SyncProcessor {\n    constructor(schema, syncPredicates, amplifyConfig = {}, authModeStrategy, errorHandler, amplifyContext) {\n        this.schema = schema;\n        this.syncPredicates = syncPredicates;\n        this.amplifyConfig = amplifyConfig;\n        this.authModeStrategy = authModeStrategy;\n        this.errorHandler = errorHandler;\n        this.amplifyContext = amplifyContext;\n        this.typeQuery = new WeakMap();\n        this.runningProcesses = new BackgroundProcessManager();\n        amplifyContext.InternalAPI = amplifyContext.InternalAPI || InternalAPI;\n        this.generateQueries();\n    }\n    generateQueries() {\n        Object.values(this.schema.namespaces).forEach(namespace => {\n            Object.values(namespace.models)\n                .filter(({ syncable }) => syncable)\n                .forEach(model => {\n                const [[, ...opNameQuery]] = buildGraphQLOperation(namespace, model, 'LIST');\n                this.typeQuery.set(model, opNameQuery);\n            });\n        });\n    }\n    graphqlFilterFromPredicate(model) {\n        if (!this.syncPredicates) {\n            return null;\n        }\n        const predicatesGroup = ModelPredicateCreator.getPredicates(this.syncPredicates.get(model), false);\n        if (!predicatesGroup) {\n            return null;\n        }\n        return predicateToGraphQLFilter(predicatesGroup);\n    }\n    async retrievePage(modelDefinition, lastSync, nextToken, limit = null, filter, onTerminate) {\n        const [opName, query] = this.typeQuery.get(modelDefinition);\n        const variables = {\n            limit,\n            nextToken,\n            lastSync,\n            filter,\n        };\n        const modelAuthModes = await getModelAuthModes({\n            authModeStrategy: this.authModeStrategy,\n            defaultAuthMode: this.amplifyConfig.aws_appsync_authenticationType,\n            modelName: modelDefinition.name,\n            schema: this.schema,\n        });\n        // sync only needs the READ auth mode(s)\n        const readAuthModes = modelAuthModes.READ;\n        let authModeAttempts = 0;\n        const authModeRetry = async () => {\n            if (!this.runningProcesses.isOpen) {\n                throw new Error('sync.retreievePage termination was requested. Exiting.');\n            }\n            try {\n                logger.debug(`Attempting sync with authMode: ${readAuthModes[authModeAttempts]}`);\n                const response = await this.jitteredRetry({\n                    query,\n                    variables,\n                    opName,\n                    modelDefinition,\n                    authMode: readAuthModes[authModeAttempts],\n                    onTerminate,\n                });\n                logger.debug(`Sync successful with authMode: ${readAuthModes[authModeAttempts]}`);\n                return response;\n            }\n            catch (error) {\n                authModeAttempts++;\n                if (authModeAttempts >= readAuthModes.length) {\n                    const authMode = readAuthModes[authModeAttempts - 1];\n                    logger.debug(`Sync failed with authMode: ${authMode}`, error);\n                    if (getClientSideAuthError(error) || getForbiddenError(error)) {\n                        // return empty list of data so DataStore will continue to sync other models\n                        logger.warn(`User is unauthorized to query ${opName} with auth mode ${authMode}. No data could be returned.`);\n                        return {\n                            data: {\n                                [opName]: opResultDefaults,\n                            },\n                        };\n                    }\n                    throw error;\n                }\n                logger.debug(`Sync failed with authMode: ${readAuthModes[authModeAttempts - 1]}. Retrying with authMode: ${readAuthModes[authModeAttempts]}`);\n                return authModeRetry();\n            }\n        };\n        const { data } = await authModeRetry();\n        const { [opName]: opResult } = data;\n        const { items, nextToken: newNextToken, startedAt } = opResult;\n        return {\n            nextToken: newNextToken,\n            startedAt,\n            items,\n        };\n    }\n    async jitteredRetry({ query, variables, opName, modelDefinition, authMode, onTerminate, }) {\n        return jitteredExponentialRetry(async (retriedQuery, retriedVariables) => {\n            try {\n                const authToken = await getTokenForCustomAuth(authMode, this.amplifyConfig);\n                const customUserAgentDetails = {\n                    category: Category.DataStore,\n                    action: DataStoreAction.GraphQl,\n                };\n                return await this.amplifyContext.InternalAPI.graphql({\n                    query: retriedQuery,\n                    variables: retriedVariables,\n                    authMode,\n                    authToken,\n                }, undefined, customUserAgentDetails);\n                // TODO: onTerminate.then(() => API.cancel(...))\n            }\n            catch (error) {\n                // Catch client-side (GraphQLAuthError) & 401/403 errors here so that we don't continue to retry\n                const clientOrForbiddenErrorMessage = getClientSideAuthError(error) || getForbiddenError(error);\n                if (clientOrForbiddenErrorMessage) {\n                    logger.error('Sync processor retry error:', error);\n                    throw new NonRetryableError(clientOrForbiddenErrorMessage);\n                }\n                const hasItems = Boolean(error?.data?.[opName]?.items);\n                const unauthorized = error?.errors &&\n                    error.errors.some(err => err.errorType === 'Unauthorized');\n                const otherErrors = error?.errors &&\n                    error.errors.filter(err => err.errorType !== 'Unauthorized');\n                const result = error;\n                if (hasItems) {\n                    result.data[opName].items = result.data[opName].items.filter(item => item !== null);\n                }\n                if (hasItems && otherErrors?.length) {\n                    await Promise.all(otherErrors.map(async (err) => {\n                        try {\n                            // eslint-disable-next-line @typescript-eslint/no-confusing-void-expression\n                            await this.errorHandler({\n                                recoverySuggestion: 'Ensure app code is up to date, auth directives exist and are correct on each model, and that server-side data has not been invalidated by a schema change. If the problem persists, search for or create an issue: https://github.com/aws-amplify/amplify-js/issues',\n                                localModel: null,\n                                message: err.message,\n                                model: modelDefinition.name,\n                                operation: opName,\n                                errorType: getSyncErrorType(err),\n                                process: ProcessName.sync,\n                                remoteModel: null,\n                                cause: err,\n                            });\n                        }\n                        catch (e) {\n                            logger.error('Sync error handler failed with:', e);\n                        }\n                    }));\n                    Hub.dispatch('datastore', {\n                        event: 'nonApplicableDataReceived',\n                        data: {\n                            errors: otherErrors,\n                            modelName: modelDefinition.name,\n                        },\n                    });\n                }\n                /**\n                 * Handle $util.unauthorized() in resolver request mapper, which responses with something\n                 * like this:\n                 *\n                 * ```\n                 * {\n                 * \tdata: { syncYourModel: null },\n                 * \terrors: [\n                 * \t\t{\n                 * \t\t\tpath: ['syncLegacyJSONComments'],\n                 * \t\t\tdata: null,\n                 * \t\t\terrorType: 'Unauthorized',\n                 * \t\t\terrorInfo: null,\n                 * \t\t\tlocations: [{ line: 2, column: 3, sourceName: null }],\n                 * \t\t\tmessage:\n                 * \t\t\t\t'Not Authorized to access syncYourModel on type Query',\n                 * \t\t\t},\n                 * \t\t],\n                 * \t}\n                 * ```\n                 *\n                 * The correct handling for this is to signal that we've encountered a non-retryable error,\n                 * since the server has responded with an auth error and *NO DATA* at this point.\n                 */\n                if (unauthorized) {\n                    this.errorHandler({\n                        recoverySuggestion: 'Ensure app code is up to date, auth directives exist and are correct on each model, and that server-side data has not been invalidated by a schema change. If the problem persists, search for or create an issue: https://github.com/aws-amplify/amplify-js/issues',\n                        localModel: null,\n                        message: error.message,\n                        model: modelDefinition.name,\n                        operation: opName,\n                        errorType: getSyncErrorType(error.errors[0]),\n                        process: ProcessName.sync,\n                        remoteModel: null,\n                        cause: error,\n                    });\n                    throw new NonRetryableError(error);\n                }\n                if (result.data?.[opName]?.items?.length) {\n                    return result;\n                }\n                throw error;\n            }\n        }, [query, variables], undefined, onTerminate);\n    }\n    start(typesLastSync) {\n        const { maxRecordsToSync, syncPageSize } = this.amplifyConfig;\n        const parentPromises = new Map();\n        const observable = new Observable(observer => {\n            const sortedTypesLastSyncs = Object.values(this.schema.namespaces).reduce((map, namespace) => {\n                for (const modelName of Array.from(namespace.modelTopologicalOrdering.keys())) {\n                    const typeLastSync = typesLastSync.get(namespace.models[modelName]);\n                    map.set(namespace.models[modelName], typeLastSync);\n                }\n                return map;\n            }, new Map());\n            const allModelsReady = Array.from(sortedTypesLastSyncs.entries())\n                .filter(([{ syncable }]) => syncable)\n                .map(([modelDefinition, [namespace, lastSync]]) => this.runningProcesses.isOpen &&\n                this.runningProcesses.add(async (onTerminate) => {\n                    let done = false;\n                    let nextToken = null;\n                    let startedAt = null;\n                    let items = null;\n                    let recordsReceived = 0;\n                    const filter = this.graphqlFilterFromPredicate(modelDefinition);\n                    const parents = this.schema.namespaces[namespace].modelTopologicalOrdering.get(modelDefinition.name);\n                    const promises = parents.map(parent => parentPromises.get(`${namespace}_${parent}`));\n                    // eslint-disable-next-line no-async-promise-executor\n                    const promise = new Promise(async (resolve) => {\n                        await Promise.all(promises);\n                        do {\n                            /**\n                             * If `runningProcesses` is not open, it means that the sync processor has been\n                             * stopped (for example by calling `DataStore.clear()` upstream) and has not yet\n                             * finished terminating and/or waiting for its background processes to complete.\n                             */\n                            if (!this.runningProcesses.isOpen) {\n                                logger.debug(`Sync processor has been stopped, terminating sync for ${modelDefinition.name}`);\n                                resolve();\n                                return;\n                            }\n                            const limit = Math.min(maxRecordsToSync - recordsReceived, syncPageSize);\n                            /**\n                             * It's possible that `retrievePage` will fail.\n                             * If it does fail, continue merging the rest of the data,\n                             * and invoke the error handler for non-applicable data.\n                             */\n                            try {\n                                ({ items, nextToken, startedAt } = await this.retrievePage(modelDefinition, lastSync, nextToken, limit, filter, onTerminate));\n                            }\n                            catch (error) {\n                                try {\n                                    // eslint-disable-next-line @typescript-eslint/no-confusing-void-expression\n                                    await this.errorHandler({\n                                        recoverySuggestion: 'Ensure app code is up to date, auth directives exist and are correct on each model, and that server-side data has not been invalidated by a schema change. If the problem persists, search for or create an issue: https://github.com/aws-amplify/amplify-js/issues',\n                                        localModel: null,\n                                        message: error.message,\n                                        model: modelDefinition.name,\n                                        operation: null,\n                                        errorType: getSyncErrorType(error),\n                                        process: ProcessName.sync,\n                                        remoteModel: null,\n                                        cause: error,\n                                    });\n                                }\n                                catch (e) {\n                                    logger.error('Sync error handler failed with:', e);\n                                }\n                                /**\n                                 * If there's an error, this model fails, but the rest of the sync should\n                                 * continue. To facilitate this, we explicitly mark this model as `done`\n                                 * with no items and allow the loop to continue organically. This ensures\n                                 * all callbacks (subscription messages) happen as normal, so anything\n                                 * waiting on them knows the model is as done as it can be.\n                                 */\n                                done = true;\n                                items = [];\n                            }\n                            recordsReceived += items.length;\n                            done =\n                                nextToken === null || recordsReceived >= maxRecordsToSync;\n                            observer.next({\n                                namespace,\n                                modelDefinition,\n                                items,\n                                done,\n                                startedAt,\n                                isFullSync: !lastSync,\n                            });\n                        } while (!done);\n                        resolve();\n                    });\n                    parentPromises.set(`${namespace}_${modelDefinition.name}`, promise);\n                    await promise;\n                }, `adding model ${modelDefinition.name}`));\n            Promise.all(allModelsReady).then(() => {\n                observer.complete();\n            });\n        });\n        return observable;\n    }\n    async stop() {\n        logger.debug('stopping sync processor');\n        await this.runningProcesses.close();\n        await this.runningProcesses.open();\n        logger.debug('sync processor stopped');\n    }\n}\n\nexport { SyncProcessor };\n//# sourceMappingURL=sync.mjs.map\n","import { GraphQLAuthError } from '@aws-amplify/api';\nimport { ConsoleLogger } from '@aws-amplify/core';\nimport { isSchemaModel, isSchemaModelWithAttributes, isGraphQLScalarType, isEnumFieldType, isTargetNameAssociation, isNonModelFieldType, OpType, isPredicateObj, isPredicateGroup, ModelOperation } from '../types.mjs';\nimport { establishRelationAndKeys, extractPrimaryKeyFieldNames, IDENTIFIER_KEY_SEPARATOR } from '../util.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst logger = new ConsoleLogger('DataStore');\nconst GraphQLOperationType = {\n    LIST: 'query',\n    CREATE: 'mutation',\n    UPDATE: 'mutation',\n    DELETE: 'mutation',\n    GET: 'query',\n};\nvar TransformerMutationType;\n(function (TransformerMutationType) {\n    TransformerMutationType[\"CREATE\"] = \"Create\";\n    TransformerMutationType[\"UPDATE\"] = \"Update\";\n    TransformerMutationType[\"DELETE\"] = \"Delete\";\n    TransformerMutationType[\"GET\"] = \"Get\";\n})(TransformerMutationType || (TransformerMutationType = {}));\nconst dummyMetadata = {\n    _version: undefined,\n    _lastChangedAt: undefined,\n    _deleted: undefined,\n};\nconst metadataFields = Object.keys(dummyMetadata);\nfunction getMetadataFields() {\n    return metadataFields;\n}\nfunction generateSelectionSet(namespace, modelDefinition) {\n    const scalarFields = getScalarFields(modelDefinition);\n    const nonModelFields = getNonModelFields(namespace, modelDefinition);\n    const implicitOwnerField = getImplicitOwnerField(modelDefinition, scalarFields);\n    let scalarAndMetadataFields = Object.values(scalarFields)\n        .map(({ name }) => name)\n        .concat(implicitOwnerField)\n        .concat(nonModelFields);\n    if (isSchemaModel(modelDefinition)) {\n        scalarAndMetadataFields = scalarAndMetadataFields\n            .concat(getMetadataFields())\n            .concat(getConnectionFields(modelDefinition, namespace));\n    }\n    const result = scalarAndMetadataFields.join('\\n');\n    return result;\n}\nfunction getImplicitOwnerField(modelDefinition, scalarFields) {\n    const ownerFields = getOwnerFields(modelDefinition);\n    if (!scalarFields.owner && ownerFields.includes('owner')) {\n        return ['owner'];\n    }\n    return [];\n}\nfunction getOwnerFields(modelDefinition) {\n    const ownerFields = [];\n    if (isSchemaModelWithAttributes(modelDefinition)) {\n        modelDefinition.attributes.forEach(attr => {\n            if (attr.properties && attr.properties.rules) {\n                const rule = attr.properties.rules.find(currentRule => currentRule.allow === 'owner');\n                if (rule && rule.ownerField) {\n                    ownerFields.push(rule.ownerField);\n                }\n            }\n        });\n    }\n    return ownerFields;\n}\nfunction getScalarFields(modelDefinition) {\n    const { fields } = modelDefinition;\n    const result = Object.values(fields)\n        .filter(field => {\n        if (isGraphQLScalarType(field.type) || isEnumFieldType(field.type)) {\n            return true;\n        }\n        return false;\n    })\n        .reduce((acc, field) => {\n        acc[field.name] = field;\n        return acc;\n    }, {});\n    return result;\n}\n// Used for generating the selection set for queries and mutations\nfunction getConnectionFields(modelDefinition, namespace) {\n    const result = [];\n    Object.values(modelDefinition.fields)\n        .filter(({ association }) => association && Object.keys(association).length)\n        .forEach(({ name, association }) => {\n        const { connectionType } = association || {};\n        switch (connectionType) {\n            case 'HAS_ONE':\n            case 'HAS_MANY':\n                // Intentionally blank\n                break;\n            case 'BELONGS_TO':\n                if (isTargetNameAssociation(association)) {\n                    // New codegen (CPK)\n                    if (association.targetNames && association.targetNames.length > 0) {\n                        // Need to retrieve relations in order to get connected model keys\n                        const [relations] = establishRelationAndKeys(namespace);\n                        const connectedModelName = modelDefinition.fields[name].type.model;\n                        const byPkIndex = relations[connectedModelName].indexes.find(([currentName]) => currentName === 'byPk');\n                        const keyFields = byPkIndex && byPkIndex[1];\n                        const keyFieldSelectionSet = keyFields?.join(' ');\n                        // We rely on `_deleted` when we process the sync query (e.g. in batchSave in the adapters)\n                        result.push(`${name} { ${keyFieldSelectionSet} _deleted }`);\n                    }\n                    else {\n                        // backwards-compatability for schema generated prior to custom primary key support\n                        result.push(`${name} { id _deleted }`);\n                    }\n                }\n                break;\n            default:\n                throw new Error(`Invalid connection type ${connectionType}`);\n        }\n    });\n    return result;\n}\nfunction getNonModelFields(namespace, modelDefinition) {\n    const result = [];\n    Object.values(modelDefinition.fields).forEach(({ name, type }) => {\n        if (isNonModelFieldType(type)) {\n            const typeDefinition = namespace.nonModels[type.nonModel];\n            const scalarFields = Object.values(getScalarFields(typeDefinition)).map(({ name: currentName }) => currentName);\n            const nested = [];\n            Object.values(typeDefinition.fields).forEach(field => {\n                const { type: fieldType, name: fieldName } = field;\n                if (isNonModelFieldType(fieldType)) {\n                    const nonModelTypeDefinition = namespace.nonModels[fieldType.nonModel];\n                    nested.push(`${fieldName} { ${generateSelectionSet(namespace, nonModelTypeDefinition)} }`);\n                }\n            });\n            result.push(`${name} { ${scalarFields.join(' ')} ${nested.join(' ')} }`);\n        }\n    });\n    return result;\n}\nfunction getAuthorizationRules(modelDefinition) {\n    // Searching for owner authorization on attributes\n    const authConfig = []\n        .concat(modelDefinition.attributes || [])\n        .find(attr => attr && attr.type === 'auth');\n    const { properties: { rules = [] } = {} } = authConfig || {};\n    const resultRules = [];\n    // Multiple rules can be declared for allow: owner\n    rules.forEach(rule => {\n        // setting defaults for backwards compatibility with old cli\n        const { identityClaim = 'cognito:username', ownerField = 'owner', operations = ['create', 'update', 'delete', 'read'], provider = 'userPools', groupClaim = 'cognito:groups', allow: authStrategy = 'iam', groups = [], groupsField = '', } = rule;\n        const isReadAuthorized = operations.includes('read');\n        const isOwnerAuth = authStrategy === 'owner';\n        if (!isReadAuthorized && !isOwnerAuth) {\n            return;\n        }\n        const authRule = {\n            identityClaim,\n            ownerField,\n            provider,\n            groupClaim,\n            authStrategy,\n            groups,\n            groupsField,\n            areSubscriptionsPublic: false,\n        };\n        if (isOwnerAuth) {\n            // look for the subscription level override\n            // only pay attention to the public level\n            const modelConfig = []\n                .concat(modelDefinition.attributes || [])\n                .find(attr => attr && attr.type === 'model');\n            // find the subscriptions level. ON is default\n            const { properties: { subscriptions: { level = 'on' } = {} } = {} } = modelConfig || {};\n            // treat subscriptions as public for owner auth with unprotected reads\n            // when `read` is omitted from `operations`\n            authRule.areSubscriptionsPublic =\n                !operations.includes('read') || level === 'public';\n        }\n        if (isOwnerAuth) {\n            // owner rules has least priority\n            resultRules.push(authRule);\n            return;\n        }\n        resultRules.unshift(authRule);\n    });\n    return resultRules;\n}\nfunction buildSubscriptionGraphQLOperation(namespace, modelDefinition, transformerMutationType, isOwnerAuthorization, ownerField, filterArg = false) {\n    const selectionSet = generateSelectionSet(namespace, modelDefinition);\n    const { name: typeName } = modelDefinition;\n    const opName = `on${transformerMutationType}${typeName}`;\n    const docArgs = [];\n    const opArgs = [];\n    if (filterArg) {\n        docArgs.push(`$filter: ModelSubscription${typeName}FilterInput`);\n        opArgs.push('filter: $filter');\n    }\n    if (isOwnerAuthorization) {\n        docArgs.push(`$${ownerField}: String!`);\n        opArgs.push(`${ownerField}: $${ownerField}`);\n    }\n    const docStr = docArgs.length ? `(${docArgs.join(',')})` : '';\n    const opStr = opArgs.length ? `(${opArgs.join(',')})` : '';\n    return [\n        transformerMutationType,\n        opName,\n        `subscription operation${docStr}{\n\t\t\t${opName}${opStr}{\n\t\t\t\t${selectionSet}\n\t\t\t}\n\t\t}`,\n    ];\n}\nfunction buildGraphQLOperation(namespace, modelDefinition, graphQLOpType) {\n    let selectionSet = generateSelectionSet(namespace, modelDefinition);\n    const { name: typeName, pluralName: pluralTypeName } = modelDefinition;\n    let operation;\n    let documentArgs;\n    let operationArgs;\n    let transformerMutationType;\n    switch (graphQLOpType) {\n        case 'LIST':\n            operation = `sync${pluralTypeName}`;\n            documentArgs = `($limit: Int, $nextToken: String, $lastSync: AWSTimestamp, $filter: Model${typeName}FilterInput)`;\n            operationArgs =\n                '(limit: $limit, nextToken: $nextToken, lastSync: $lastSync, filter: $filter)';\n            selectionSet = `items {\n\t\t\t\t\t\t\t${selectionSet}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tnextToken\n\t\t\t\t\t\tstartedAt`;\n            break;\n        case 'CREATE':\n            operation = `create${typeName}`;\n            documentArgs = `($input: Create${typeName}Input!)`;\n            operationArgs = '(input: $input)';\n            transformerMutationType = TransformerMutationType.CREATE;\n            break;\n        case 'UPDATE':\n            operation = `update${typeName}`;\n            documentArgs = `($input: Update${typeName}Input!, $condition: Model${typeName}ConditionInput)`;\n            operationArgs = '(input: $input, condition: $condition)';\n            transformerMutationType = TransformerMutationType.UPDATE;\n            break;\n        case 'DELETE':\n            operation = `delete${typeName}`;\n            documentArgs = `($input: Delete${typeName}Input!, $condition: Model${typeName}ConditionInput)`;\n            operationArgs = '(input: $input, condition: $condition)';\n            transformerMutationType = TransformerMutationType.DELETE;\n            break;\n        case 'GET':\n            operation = `get${typeName}`;\n            documentArgs = `($id: ID!)`;\n            operationArgs = '(id: $id)';\n            transformerMutationType = TransformerMutationType.GET;\n            break;\n        default:\n            throw new Error(`Invalid graphQlOpType ${graphQLOpType}`);\n    }\n    return [\n        [\n            transformerMutationType,\n            operation,\n            `${GraphQLOperationType[graphQLOpType]} operation${documentArgs}{\n\t\t${operation}${operationArgs}{\n\t\t\t${selectionSet}\n\t\t}\n\t}`,\n        ],\n    ];\n}\nfunction createMutationInstanceFromModelOperation(relationships, modelDefinition, opType, model, element, condition, MutationEventConstructor, modelInstanceCreator, id) {\n    let operation;\n    switch (opType) {\n        case OpType.INSERT:\n            operation = TransformerMutationType.CREATE;\n            break;\n        case OpType.UPDATE:\n            operation = TransformerMutationType.UPDATE;\n            break;\n        case OpType.DELETE:\n            operation = TransformerMutationType.DELETE;\n            break;\n        default:\n            throw new Error(`Invalid opType ${opType}`);\n    }\n    // stringify nested objects of type AWSJSON\n    // this allows us to return parsed JSON to users (see `castInstanceType()` in datastore.ts),\n    // but still send the object correctly over the wire\n    const replacer = (k, v) => {\n        const isAWSJSON = k &&\n            v !== null &&\n            typeof v === 'object' &&\n            modelDefinition.fields[k] &&\n            modelDefinition.fields[k].type === 'AWSJSON';\n        if (isAWSJSON) {\n            return JSON.stringify(v);\n        }\n        return v;\n    };\n    const modelId = getIdentifierValue(modelDefinition, element);\n    const optionalId = OpType.INSERT && id ? { id } : {};\n    const mutationEvent = modelInstanceCreator(MutationEventConstructor, {\n        ...optionalId,\n        data: JSON.stringify(element, replacer),\n        modelId,\n        model: model.name,\n        operation: operation,\n        condition: JSON.stringify(condition),\n    });\n    return mutationEvent;\n}\nfunction predicateToGraphQLCondition(predicate, modelDefinition) {\n    const result = {};\n    if (!predicate || !Array.isArray(predicate.predicates)) {\n        return result;\n    }\n    // This is compatible with how the GQL Transform currently generates the Condition Input,\n    // i.e. any PK and SK fields are omitted and can't be used as conditions.\n    // However, I think this limits usability.\n    // What if we want to delete all records where SK > some value\n    // Or all records where PK = some value but SKs are different values\n    // TODO: if the Transform gets updated we'll need to modify this logic to only omit\n    // key fields from the predicate/condition when ALL of the keyFields are present and using `eq` operators\n    const keyFields = extractPrimaryKeyFieldNames(modelDefinition);\n    return predicateToGraphQLFilter(predicate, keyFields);\n}\n/**\n * @param predicatesGroup - Predicate Group\n    @returns GQL Filter Expression from Predicate Group\n\n    @remarks Flattens redundant list predicates\n    @example\n\n    ```js\n    { and:[{ and:[{ username:  { eq: 'bob' }}] }] }\n    ```\n    Becomes\n    ```js\n    { and:[{ username: { eq: 'bob' }}] }\n    ```\n    */\nfunction predicateToGraphQLFilter(predicatesGroup, fieldsToOmit = [], root = true) {\n    const result = {};\n    if (!predicatesGroup || !Array.isArray(predicatesGroup.predicates)) {\n        return result;\n    }\n    const { type, predicates } = predicatesGroup;\n    const isList = type === 'and' || type === 'or';\n    result[type] = isList ? [] : {};\n    const children = [];\n    predicates.forEach(predicate => {\n        if (isPredicateObj(predicate)) {\n            const { field, operator, operand } = predicate;\n            if (fieldsToOmit.includes(field))\n                return;\n            const gqlField = {\n                [field]: { [operator]: operand },\n            };\n            children.push(gqlField);\n            return;\n        }\n        const child = predicateToGraphQLFilter(predicate, fieldsToOmit, false);\n        if (Object.keys(child).length > 0) {\n            children.push(child);\n        }\n    });\n    // flatten redundant list predicates\n    if (children.length === 1) {\n        const [child] = children;\n        if (\n        // any nested list node\n        (isList && !root) ||\n            // root list node where the only child is also a list node\n            (isList && root && ('and' in child || 'or' in child))) {\n            delete result[type];\n            Object.assign(result, child);\n            return result;\n        }\n    }\n    children.forEach(child => {\n        if (isList) {\n            result[type].push(child);\n        }\n        else {\n            result[type] = child;\n        }\n    });\n    if (isList) {\n        if (result[type].length === 0)\n            return {};\n    }\n    else {\n        if (Object.keys(result[type]).length === 0)\n            return {};\n    }\n    return result;\n}\n/**\n *\n * @param group - selective sync predicate group\n * @returns set of distinct field names in the filter group\n */\nfunction filterFields(group) {\n    const fields = new Set();\n    if (!group || !Array.isArray(group.predicates))\n        return fields;\n    const { predicates } = group;\n    const stack = [...predicates];\n    while (stack.length > 0) {\n        const current = stack.pop();\n        if (isPredicateObj(current)) {\n            fields.add(current.field);\n        }\n        else if (isPredicateGroup(current)) {\n            stack.push(...current.predicates);\n        }\n    }\n    return fields;\n}\n/**\n *\n * @param modelDefinition\n * @returns set of field names used with dynamic auth modes configured for the provided model definition\n */\nfunction dynamicAuthFields(modelDefinition) {\n    const rules = getAuthorizationRules(modelDefinition);\n    const fields = new Set();\n    for (const rule of rules) {\n        if (rule.groupsField && !rule.groups.length) {\n            // dynamic group rule will have no values in `rule.groups`\n            fields.add(rule.groupsField);\n        }\n        else if (rule.ownerField) {\n            fields.add(rule.ownerField);\n        }\n    }\n    return fields;\n}\n/**\n *\n * @param group - selective sync predicate group\n * @returns the total number of OR'd predicates in the filter group\n *\n * @example returns 2\n * ```js\n * { type: \"or\", predicates: [\n * { field: \"username\", operator: \"beginsWith\", operand: \"a\" },\n * { field: \"title\", operator: \"contains\", operand: \"abc\" },\n * ]}\n * ```\n */\nfunction countFilterCombinations(group) {\n    if (!group || !Array.isArray(group.predicates))\n        return 0;\n    let count = 0;\n    const stack = [group];\n    while (stack.length > 0) {\n        const current = stack.pop();\n        if (isPredicateGroup(current)) {\n            const { predicates, type } = current;\n            // ignore length = 1; groups with 1 predicate will get flattened when converted to gqlFilter\n            if (type === 'or' && predicates.length > 1) {\n                count += predicates.length;\n            }\n            stack.push(...predicates);\n        }\n    }\n    // if we didn't encounter any OR groups, default to 1\n    return count || 1;\n}\n/**\n *\n * @param group - selective sync predicate group\n * @returns name of repeated field | null\n *\n * @example returns \"username\"\n * ```js\n * { type: \"and\", predicates: [\n * \t\t{ field: \"username\", operator: \"beginsWith\", operand: \"a\" },\n * \t\t{ field: \"username\", operator: \"contains\", operand: \"abc\" },\n * ] }\n * ```\n */\nfunction repeatedFieldInGroup(group) {\n    if (!group || !Array.isArray(group.predicates))\n        return null;\n    // convert to filter in order to flatten redundant groups\n    const gqlFilter = predicateToGraphQLFilter(group);\n    const stack = [gqlFilter];\n    const hasGroupRepeatedFields = (fields) => {\n        const seen = {};\n        for (const f of fields) {\n            const [fieldName] = Object.keys(f);\n            if (seen[fieldName]) {\n                return fieldName;\n            }\n            seen[fieldName] = true;\n        }\n        return null;\n    };\n    while (stack.length > 0) {\n        const current = stack.pop();\n        const [key] = Object.keys(current);\n        const values = current[key];\n        if (!Array.isArray(values)) {\n            return null;\n        }\n        // field value will be single object\n        const predicateObjects = values.filter(v => !Array.isArray(Object.values(v)[0]));\n        // group value will be an array\n        const predicateGroups = values.filter(v => Array.isArray(Object.values(v)[0]));\n        if (key === 'and') {\n            const repeatedField = hasGroupRepeatedFields(predicateObjects);\n            if (repeatedField) {\n                return repeatedField;\n            }\n        }\n        stack.push(...predicateGroups);\n    }\n    return null;\n}\nvar RTFError;\n(function (RTFError) {\n    RTFError[RTFError[\"UnknownField\"] = 0] = \"UnknownField\";\n    RTFError[RTFError[\"MaxAttributes\"] = 1] = \"MaxAttributes\";\n    RTFError[RTFError[\"MaxCombinations\"] = 2] = \"MaxCombinations\";\n    RTFError[RTFError[\"RepeatedFieldname\"] = 3] = \"RepeatedFieldname\";\n    RTFError[RTFError[\"NotGroup\"] = 4] = \"NotGroup\";\n    RTFError[RTFError[\"FieldNotInType\"] = 5] = \"FieldNotInType\";\n})(RTFError || (RTFError = {}));\nfunction generateRTFRemediation(errorType, modelDefinition, predicatesGroup) {\n    const selSyncFields = filterFields(predicatesGroup);\n    const selSyncFieldStr = [...selSyncFields].join(', ');\n    const dynamicAuthModeFields = dynamicAuthFields(modelDefinition);\n    const dynamicAuthFieldsStr = [...dynamicAuthModeFields].join(', ');\n    const filterCombinations = countFilterCombinations(predicatesGroup);\n    const repeatedField = repeatedFieldInGroup(predicatesGroup);\n    switch (errorType) {\n        case RTFError.UnknownField:\n            return (`Your API was generated with an older version of the CLI that doesn't support backend subscription filtering.` +\n                'To enable backend subscription filtering, upgrade your Amplify CLI to the latest version and push your app by running `amplify upgrade` followed by `amplify push`');\n        case RTFError.MaxAttributes: {\n            let message = `Your selective sync expression for ${modelDefinition.name} contains ${selSyncFields.size} different model fields: ${selSyncFieldStr}.\\n\\n`;\n            if (dynamicAuthModeFields.size > 0) {\n                message +=\n                    `Note: the number of fields you can use with selective sync is affected by @auth rules configured on the model.\\n\\n` +\n                        `Dynamic auth modes, such as owner auth and dynamic group auth each utilize 1 field.\\n` +\n                        `You currently have ${dynamicAuthModeFields.size} dynamic auth mode(s) configured on this model: ${dynamicAuthFieldsStr}.`;\n            }\n            return message;\n        }\n        case RTFError.MaxCombinations: {\n            let message = `Your selective sync expression for ${modelDefinition.name} contains ${filterCombinations} field combinations (total number of predicates in an OR expression).\\n\\n`;\n            if (dynamicAuthModeFields.size > 0) {\n                message +=\n                    `Note: the number of fields you can use with selective sync is affected by @auth rules configured on the model.\\n\\n` +\n                        `Dynamic auth modes, such as owner auth and dynamic group auth factor in to the number of combinations you're using.\\n` +\n                        `You currently have ${dynamicAuthModeFields.size} dynamic auth mode(s) configured on this model: ${dynamicAuthFieldsStr}.`;\n            }\n            return message;\n        }\n        case RTFError.RepeatedFieldname:\n            return `Your selective sync expression for ${modelDefinition.name} contains multiple entries for ${repeatedField} in the same AND group.`;\n        case RTFError.NotGroup:\n            return (`Your selective sync expression for ${modelDefinition.name} uses a \\`not\\` group. If you'd like to filter subscriptions in the backend, ` +\n                `rewrite your expression using \\`ne\\` or \\`notContains\\` operators.`);\n        case RTFError.FieldNotInType:\n            // no remediation instructions. We'll surface the message directly\n            return '';\n    }\n}\nfunction getUserGroupsFromToken(token, rule) {\n    // validate token against groupClaim\n    let userGroups = token[rule.groupClaim] || [];\n    if (typeof userGroups === 'string') {\n        let parsedGroups;\n        try {\n            parsedGroups = JSON.parse(userGroups);\n        }\n        catch (e) {\n            parsedGroups = userGroups;\n        }\n        userGroups = [].concat(parsedGroups);\n    }\n    return userGroups;\n}\nasync function getModelAuthModes({ authModeStrategy, defaultAuthMode, modelName, schema, }) {\n    const operations = Object.values(ModelOperation);\n    const modelAuthModes = {\n        CREATE: [],\n        READ: [],\n        UPDATE: [],\n        DELETE: [],\n    };\n    try {\n        await Promise.all(operations.map(async (operation) => {\n            const authModes = await authModeStrategy({\n                schema,\n                modelName,\n                operation,\n            });\n            if (typeof authModes === 'string') {\n                modelAuthModes[operation] = [authModes];\n            }\n            else if (Array.isArray(authModes) && authModes.length) {\n                modelAuthModes[operation] = authModes;\n            }\n            else {\n                // Use default auth mode if nothing is returned from authModeStrategy\n                modelAuthModes[operation] = [defaultAuthMode];\n            }\n        }));\n    }\n    catch (error) {\n        logger.debug(`Error getting auth modes for model: ${modelName}`, error);\n    }\n    return modelAuthModes;\n}\nfunction getForbiddenError(error) {\n    const forbiddenErrorCodes = [401, 403];\n    let forbiddenError;\n    if (error && error.errors) {\n        forbiddenError = error.errors.find(err => forbiddenErrorCodes.includes(resolveServiceErrorStatusCode(err)));\n    }\n    else if (error && error.message) {\n        forbiddenError = error;\n    }\n    if (forbiddenError) {\n        return (forbiddenError.message ??\n            `Request failed with status code ${resolveServiceErrorStatusCode(forbiddenError)}`);\n    }\n    return null;\n}\nfunction resolveServiceErrorStatusCode(error) {\n    if (error?.$metadata?.httpStatusCode) {\n        return Number(error?.$metadata?.httpStatusCode);\n    }\n    else if (error?.originalError) {\n        return resolveServiceErrorStatusCode(error?.originalError);\n    }\n    else {\n        return null;\n    }\n}\nfunction getClientSideAuthError(error) {\n    const clientSideAuthErrors = Object.values(GraphQLAuthError);\n    const clientSideError = error &&\n        error.message &&\n        clientSideAuthErrors.find(clientError => error.message.includes(clientError));\n    return clientSideError || null;\n}\nasync function getTokenForCustomAuth(authMode, amplifyConfig = {}) {\n    if (authMode === 'lambda') {\n        const { authProviders: { functionAuthProvider } = { functionAuthProvider: null }, } = amplifyConfig;\n        if (functionAuthProvider && typeof functionAuthProvider === 'function') {\n            try {\n                const { token } = await functionAuthProvider();\n                return token;\n            }\n            catch (error) {\n                throw new Error(`Error retrieving token from \\`functionAuthProvider\\`: ${error}`);\n            }\n        }\n        else {\n            // TODO: add docs link once available\n            throw new Error('You must provide a `functionAuthProvider` function to `DataStore.configure` when using lambda');\n        }\n    }\n}\n// Util that takes a modelDefinition and model and returns either the id value(s) or the custom primary key value(s)\nfunction getIdentifierValue(modelDefinition, model) {\n    const pkFieldNames = extractPrimaryKeyFieldNames(modelDefinition);\n    const idOrPk = pkFieldNames.map(f => model[f]).join(IDENTIFIER_KEY_SEPARATOR);\n    return idOrPk;\n}\n\nexport { RTFError, TransformerMutationType, buildGraphQLOperation, buildSubscriptionGraphQLOperation, countFilterCombinations, createMutationInstanceFromModelOperation, dynamicAuthFields, filterFields, generateRTFRemediation, generateSelectionSet, getAuthorizationRules, getClientSideAuthError, getForbiddenError, getIdentifierValue, getMetadataFields, getModelAuthModes, getTokenForCustomAuth, getUserGroupsFromToken, predicateToGraphQLCondition, predicateToGraphQLFilter, repeatedFieldInGroup, resolveServiceErrorStatusCode };\n//# sourceMappingURL=utils.mjs.map\n","import { isAWSIPAddress, isAWSPhone, isAWSURL, isAWSJSON, isAWSEmail, isAWSTimestamp, isAWSDateTime, isAWSTime, isAWSDate, extractPrimaryKeyFieldNames } from './util.mjs';\n\n/**\n * @private\n * @param obj\n * @returns `true` if the given object likely represents a model in a schema.\n */\nfunction isSchemaModel(obj) {\n    return obj && obj.pluralName !== undefined;\n}\n/**\n * @private\n * @param m\n * @returns `true` if the given schema entry defines Schema Model attributes.\n */\nfunction isSchemaModelWithAttributes(m) {\n    return isSchemaModel(m) && m.attributes !== undefined;\n}\n/**\n * @private\n * @param obj\n * @returns `true` if the object is an `AssociatedWith` definition.\n */\nfunction isAssociatedWith(obj) {\n    return obj && obj.associatedWith;\n}\n/**\n * @private\n * @param obj\n * @returns `true` if the given object specifies either `targetName` or `targetNames`.\n */\nfunction isTargetNameAssociation(obj) {\n    return obj?.targetName || obj?.targetNames;\n}\n/**\n * @private\n * @param obj\n * @param fieldName\n * @returns Truthy if the object has a `FieldAssociation` for the given `fieldName`.\n */\nfunction isFieldAssociation(obj, fieldName) {\n    return obj?.fields[fieldName]?.association?.connectionType;\n}\n/**\n * @private\n * @param attr\n * @returns `true` if the given attribute is an auth attribute with rules.\n */\nfunction isModelAttributeAuth(attr) {\n    return (attr.type === 'auth' &&\n        attr.properties &&\n        attr.properties.rules &&\n        attr.properties.rules.length > 0);\n}\n/**\n * @private\n * @param attr\n * @returns `true` if the given attribute is a key field.\n */\nfunction isModelAttributeKey(attr) {\n    return (attr.type === 'key' &&\n        attr.properties &&\n        attr.properties.fields &&\n        attr.properties.fields.length > 0);\n}\n/**\n * @private\n * @param attr\n * @returns `true` if the given attribute is a primary key, indicated by the key being unnamed.\n */\nfunction isModelAttributePrimaryKey(attr) {\n    return isModelAttributeKey(attr) && attr.properties.name === undefined;\n}\n/**\n * @private\n * @param attr\n * @returns `true` if the given attribute represents a composite key with multiple fields.\n */\nfunction isModelAttributeCompositeKey(attr) {\n    return (isModelAttributeKey(attr) &&\n        attr.properties.name !== undefined &&\n        attr.properties.fields.length > 2);\n}\nvar ModelAttributeAuthAllow;\n(function (ModelAttributeAuthAllow) {\n    ModelAttributeAuthAllow[\"CUSTOM\"] = \"custom\";\n    ModelAttributeAuthAllow[\"OWNER\"] = \"owner\";\n    ModelAttributeAuthAllow[\"GROUPS\"] = \"groups\";\n    ModelAttributeAuthAllow[\"PRIVATE\"] = \"private\";\n    ModelAttributeAuthAllow[\"PUBLIC\"] = \"public\";\n})(ModelAttributeAuthAllow || (ModelAttributeAuthAllow = {}));\nvar ModelAttributeAuthProvider;\n(function (ModelAttributeAuthProvider) {\n    ModelAttributeAuthProvider[\"FUNCTION\"] = \"function\";\n    ModelAttributeAuthProvider[\"USER_POOLS\"] = \"userPools\";\n    ModelAttributeAuthProvider[\"OIDC\"] = \"oidc\";\n    ModelAttributeAuthProvider[\"IAM\"] = \"iam\";\n    ModelAttributeAuthProvider[\"API_KEY\"] = \"apiKey\";\n})(ModelAttributeAuthProvider || (ModelAttributeAuthProvider = {}));\nvar GraphQLScalarType;\n(function (GraphQLScalarType) {\n    GraphQLScalarType[GraphQLScalarType[\"ID\"] = 0] = \"ID\";\n    GraphQLScalarType[GraphQLScalarType[\"String\"] = 1] = \"String\";\n    GraphQLScalarType[GraphQLScalarType[\"Int\"] = 2] = \"Int\";\n    GraphQLScalarType[GraphQLScalarType[\"Float\"] = 3] = \"Float\";\n    GraphQLScalarType[GraphQLScalarType[\"Boolean\"] = 4] = \"Boolean\";\n    GraphQLScalarType[GraphQLScalarType[\"AWSDate\"] = 5] = \"AWSDate\";\n    GraphQLScalarType[GraphQLScalarType[\"AWSTime\"] = 6] = \"AWSTime\";\n    GraphQLScalarType[GraphQLScalarType[\"AWSDateTime\"] = 7] = \"AWSDateTime\";\n    GraphQLScalarType[GraphQLScalarType[\"AWSTimestamp\"] = 8] = \"AWSTimestamp\";\n    GraphQLScalarType[GraphQLScalarType[\"AWSEmail\"] = 9] = \"AWSEmail\";\n    GraphQLScalarType[GraphQLScalarType[\"AWSJSON\"] = 10] = \"AWSJSON\";\n    GraphQLScalarType[GraphQLScalarType[\"AWSURL\"] = 11] = \"AWSURL\";\n    GraphQLScalarType[GraphQLScalarType[\"AWSPhone\"] = 12] = \"AWSPhone\";\n    GraphQLScalarType[GraphQLScalarType[\"AWSIPAddress\"] = 13] = \"AWSIPAddress\";\n})(GraphQLScalarType || (GraphQLScalarType = {}));\n// eslint-disable-next-line @typescript-eslint/no-namespace\n(function (GraphQLScalarType) {\n    function getJSType(scalar) {\n        switch (scalar) {\n            case 'Boolean':\n                return 'boolean';\n            case 'ID':\n            case 'String':\n            case 'AWSDate':\n            case 'AWSTime':\n            case 'AWSDateTime':\n            case 'AWSEmail':\n            case 'AWSURL':\n            case 'AWSPhone':\n            case 'AWSIPAddress':\n                return 'string';\n            case 'Int':\n            case 'Float':\n            case 'AWSTimestamp':\n                return 'number';\n            case 'AWSJSON':\n                return 'object';\n            default:\n                throw new Error('Invalid scalar type');\n        }\n    }\n    GraphQLScalarType.getJSType = getJSType;\n    function getValidationFunction(scalar) {\n        switch (scalar) {\n            case 'AWSDate':\n                return isAWSDate;\n            case 'AWSTime':\n                return isAWSTime;\n            case 'AWSDateTime':\n                return isAWSDateTime;\n            case 'AWSTimestamp':\n                return isAWSTimestamp;\n            case 'AWSEmail':\n                return isAWSEmail;\n            case 'AWSJSON':\n                return isAWSJSON;\n            case 'AWSURL':\n                return isAWSURL;\n            case 'AWSPhone':\n                return isAWSPhone;\n            case 'AWSIPAddress':\n                return isAWSIPAddress;\n            default:\n                return undefined;\n        }\n    }\n    GraphQLScalarType.getValidationFunction = getValidationFunction;\n})(GraphQLScalarType || (GraphQLScalarType = {}));\n/**\n * @private\n * @returns `true` if the given field specifies a scalar type.\n */\nfunction isGraphQLScalarType(obj) {\n    return obj && GraphQLScalarType[obj] !== undefined;\n}\n/**\n * @private\n * @param obj\n * @returns `true` if the given field specifies a Model.\n */\nfunction isModelFieldType(obj) {\n    const modelField = 'model';\n    if (obj && obj[modelField])\n        return true;\n    return false;\n}\n/**\n * @private\n * @param obj\n * @returns `true` if the given field specifies a custom non-model type.\n */\nfunction isNonModelFieldType(obj) {\n    const typeField = 'nonModel';\n    if (obj && obj[typeField])\n        return true;\n    return false;\n}\n/**\n * @private\n * @param obj\n * @returns `true` if the object is an `EnumFieldType`.\n */\nfunction isEnumFieldType(obj) {\n    const modelField = 'enum';\n    if (obj && obj[modelField])\n        return true;\n    return false;\n}\n/**\n * @private\n * @param obj\n * @param modelDefinition\n * @returns `true` if the given item is an object that has all identifier fields populated.\n */\nfunction isIdentifierObject(obj, modelDefinition) {\n    const keys = extractPrimaryKeyFieldNames(modelDefinition);\n    return (typeof obj === 'object' && obj && keys.every(k => obj[k] !== undefined));\n}\n// #endregion\n// #region Subscription messages\nvar OpType;\n(function (OpType) {\n    OpType[\"INSERT\"] = \"INSERT\";\n    OpType[\"UPDATE\"] = \"UPDATE\";\n    OpType[\"DELETE\"] = \"DELETE\";\n})(OpType || (OpType = {}));\n/**\n * @private\n * @param obj\n * @returns `true` if the given predicate field object, specifying an [in-]equality test against a field.\n */\nfunction isPredicateObj(obj) {\n    return obj && obj.field !== undefined;\n}\n/**\n * @private\n * @param obj\n * @returns `true` if the given predicate object is a \"group\" like \"and\", \"or\", or \"not\".\n */\nfunction isPredicateGroup(obj) {\n    return obj && obj.type !== undefined;\n}\nvar QueryOne;\n(function (QueryOne) {\n    QueryOne[QueryOne[\"FIRST\"] = 0] = \"FIRST\";\n    QueryOne[QueryOne[\"LAST\"] = 1] = \"LAST\";\n})(QueryOne || (QueryOne = {}));\nvar SortDirection;\n(function (SortDirection) {\n    SortDirection[\"ASCENDING\"] = \"ASCENDING\";\n    SortDirection[\"DESCENDING\"] = \"DESCENDING\";\n})(SortDirection || (SortDirection = {}));\nvar AuthModeStrategyType;\n(function (AuthModeStrategyType) {\n    AuthModeStrategyType[\"DEFAULT\"] = \"DEFAULT\";\n    AuthModeStrategyType[\"MULTI_AUTH\"] = \"MULTI_AUTH\";\n})(AuthModeStrategyType || (AuthModeStrategyType = {}));\nvar ModelOperation;\n(function (ModelOperation) {\n    ModelOperation[\"CREATE\"] = \"CREATE\";\n    ModelOperation[\"READ\"] = \"READ\";\n    ModelOperation[\"UPDATE\"] = \"UPDATE\";\n    ModelOperation[\"DELETE\"] = \"DELETE\";\n})(ModelOperation || (ModelOperation = {}));\n/**\n * Build an expression that can be used to filter which items of a given Model\n * are synchronized down from the GraphQL service. E.g.,\n *\n * ```ts\n * import { DataStore, syncExpression } from 'aws-amplify/datastore';\n * import { Post, Comment } from './models';\n *\n *\n * DataStore.configure({\n * \tsyncExpressions: [\n * \t\tsyncExpression(Post, () => {\n * \t\t\treturn (post) => post.rating.gt(5);\n * \t\t}),\n * \t\tsyncExpression(Comment, () => {\n * \t\t\treturn (comment) => comment.status.eq('active');\n * \t\t})\n * \t]\n * });\n * ```\n *\n * When DataStore starts syncing, only Posts with `rating > 5` and Comments with\n * `status === 'active'` will be synced down to the user's local store.\n *\n * @param modelConstructor The Model from the schema.\n * @param conditionProducer A function that builds a condition object that can describe how to filter the model.\n * @returns An sync expression object that can be attached to the DataStore `syncExpressions` configuration property.\n */\nasync function syncExpression(modelConstructor, conditionProducer) {\n    return {\n        modelConstructor,\n        conditionProducer,\n    };\n}\nvar ProcessName;\n(function (ProcessName) {\n    ProcessName[\"sync\"] = \"sync\";\n    ProcessName[\"mutate\"] = \"mutate\";\n    ProcessName[\"subscribe\"] = \"subscribe\";\n})(ProcessName || (ProcessName = {}));\nconst DISCARD = Symbol('DISCARD');\nvar LimitTimerRaceResolvedValues;\n(function (LimitTimerRaceResolvedValues) {\n    LimitTimerRaceResolvedValues[\"LIMIT\"] = \"LIMIT\";\n    LimitTimerRaceResolvedValues[\"TIMER\"] = \"TIMER\";\n})(LimitTimerRaceResolvedValues || (LimitTimerRaceResolvedValues = {}));\n/**\n * A pointer used by DataStore internally to lookup predicate details\n * that should not be exposed on public customer interfaces.\n */\nclass PredicateInternalsKey {\n    constructor() {\n        this.__isPredicateInternalsKeySentinel = true;\n    }\n}\n// #endregion\n\nexport { AuthModeStrategyType, DISCARD, GraphQLScalarType, LimitTimerRaceResolvedValues, ModelAttributeAuthAllow, ModelAttributeAuthProvider, ModelOperation, OpType, PredicateInternalsKey, ProcessName, QueryOne, SortDirection, isAssociatedWith, isEnumFieldType, isFieldAssociation, isGraphQLScalarType, isIdentifierObject, isModelAttributeAuth, isModelAttributeCompositeKey, isModelAttributeKey, isModelAttributePrimaryKey, isModelFieldType, isNonModelFieldType, isPredicateGroup, isPredicateObj, isSchemaModel, isSchemaModelWithAttributes, isTargetNameAssociation, syncExpression };\n//# sourceMappingURL=types.mjs.map\n","import { monotonicFactory } from 'ulid';\nimport { amplifyUuid, AmplifyUrl, WordArray } from '@aws-amplify/core/internals/utils';\nimport { produce, applyPatches } from 'immer';\nimport { isPredicateObj, isPredicateGroup, SortDirection, LimitTimerRaceResolvedValues, isModelAttributeCompositeKey, isModelAttributeKey, isModelAttributePrimaryKey } from './types.mjs';\nimport './predicates/index.mjs';\nimport { ModelSortPredicateCreator } from './predicates/sort.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst ID = 'id';\n/**\n * Used by the Async Storage Adapter to concatenate key values\n * for a record. For instance, if a model has the following keys:\n * `customId: ID! @primaryKey(sortKeyFields: [\"createdAt\"])`,\n * we concatenate the `customId` and `createdAt` as:\n * `12-234-5#2022-09-28T00:00:00.000Z`\n */\nconst DEFAULT_PRIMARY_KEY_VALUE_SEPARATOR = '#';\n/**\n * Used for generating spinal-cased index name from an array of\n * key field names.\n * E.g. for keys `[id, title]` => 'id-title'\n */\nconst IDENTIFIER_KEY_SEPARATOR = '-';\nconst errorMessages = {\n    idEmptyString: 'An index field cannot contain an empty string value',\n    queryByPkWithCompositeKeyPresent: 'Models with composite primary keys cannot be queried by a single key value. Use object literal syntax for composite keys instead: https://docs.amplify.aws/lib/datastore/advanced-workflows/q/platform/js/#querying-records-with-custom-primary-keys',\n    deleteByPkWithCompositeKeyPresent: 'Models with composite primary keys cannot be deleted by a single key value, unless using a predicate. Use object literal syntax for composite keys instead: https://docs.amplify.aws/lib/datastore/advanced-workflows/q/platform/js/#querying-records-with-custom-primary-keys',\n    observeWithObjectLiteral: 'Object literal syntax cannot be used with observe. Use a predicate instead: https://docs.amplify.aws/lib/datastore/data-access/q/platform/js/#predicates',\n};\nvar NAMESPACES;\n(function (NAMESPACES) {\n    NAMESPACES[\"DATASTORE\"] = \"datastore\";\n    NAMESPACES[\"USER\"] = \"user\";\n    NAMESPACES[\"SYNC\"] = \"sync\";\n    NAMESPACES[\"STORAGE\"] = \"storage\";\n})(NAMESPACES || (NAMESPACES = {}));\nconst { DATASTORE } = NAMESPACES;\nconst { USER } = NAMESPACES;\nconst { SYNC } = NAMESPACES;\nconst { STORAGE } = NAMESPACES;\nconst exhaustiveCheck = (obj, throwOnError = true) => {\n    if (throwOnError) {\n        throw new Error(`Invalid ${obj}`);\n    }\n};\nconst isNullOrUndefined = (val) => {\n    return typeof val === 'undefined' || val === undefined || val === null;\n};\nconst validatePredicate = (model, groupType, predicatesOrGroups) => {\n    let filterType;\n    let isNegation = false;\n    if (predicatesOrGroups.length === 0) {\n        return true;\n    }\n    switch (groupType) {\n        case 'not':\n            filterType = 'every';\n            isNegation = true;\n            break;\n        case 'and':\n            filterType = 'every';\n            break;\n        case 'or':\n            filterType = 'some';\n            break;\n        default:\n            throw new Error(`Invalid ${groupType}`);\n    }\n    const result = predicatesOrGroups[filterType](predicateOrGroup => {\n        if (isPredicateObj(predicateOrGroup)) {\n            const { field, operator, operand } = predicateOrGroup;\n            const value = model[field];\n            return validatePredicateField(value, operator, operand);\n        }\n        if (isPredicateGroup(predicateOrGroup)) {\n            const { type, predicates } = predicateOrGroup;\n            return validatePredicate(model, type, predicates);\n        }\n        throw new Error('Not a predicate or group');\n    });\n    return isNegation ? !result : result;\n};\nconst validatePredicateField = (value, operator, operand) => {\n    switch (operator) {\n        case 'ne':\n            return value !== operand;\n        case 'eq':\n            return value === operand;\n        case 'le':\n            return value <= operand;\n        case 'lt':\n            return value < operand;\n        case 'ge':\n            return value >= operand;\n        case 'gt':\n            return value > operand;\n        case 'between': {\n            const [min, max] = operand;\n            return value >= min && value <= max;\n        }\n        case 'beginsWith':\n            return (!isNullOrUndefined(value) &&\n                value.startsWith(operand));\n        case 'contains':\n            return (!isNullOrUndefined(value) &&\n                value.indexOf(operand) > -1);\n        case 'notContains':\n            return (isNullOrUndefined(value) ||\n                value.indexOf(operand) ===\n                    -1);\n        default:\n            return false;\n    }\n};\nconst isModelConstructor = (obj) => {\n    return (obj && typeof obj.copyOf === 'function');\n};\nconst nonModelClasses = new WeakSet();\nfunction registerNonModelClass(clazz) {\n    nonModelClasses.add(clazz);\n}\nconst isNonModelConstructor = (obj) => {\n    return nonModelClasses.has(obj);\n};\nconst topologicallySortedModels = new WeakMap();\nconst traverseModel = (srcModelName, instance, namespace, modelInstanceCreator, getModelConstructorByModelName) => {\n    const modelConstructor = getModelConstructorByModelName(namespace.name, srcModelName);\n    const result = [];\n    const newInstance = modelConstructor.copyOf(instance, () => {\n        // no-op\n    });\n    result.unshift({\n        modelName: srcModelName,\n        item: newInstance,\n        instance: newInstance,\n    });\n    if (!topologicallySortedModels.has(namespace)) {\n        topologicallySortedModels.set(namespace, Array.from(namespace.modelTopologicalOrdering.keys()));\n    }\n    const sortedModels = topologicallySortedModels.get(namespace);\n    result.sort((a, b) => {\n        return (sortedModels.indexOf(a.modelName) - sortedModels.indexOf(b.modelName));\n    });\n    return result;\n};\nlet privateModeCheckResult;\nconst isPrivateMode = () => {\n    return new Promise(resolve => {\n        const dbname = amplifyUuid();\n        // eslint-disable-next-line prefer-const\n        let db;\n        const isPrivate = () => {\n            privateModeCheckResult = false;\n            resolve(true);\n        };\n        const isNotPrivate = async () => {\n            if (db && db.result && typeof db.result.close === 'function') {\n                await db.result.close();\n            }\n            await indexedDB.deleteDatabase(dbname);\n            privateModeCheckResult = true;\n            resolve(false);\n        };\n        if (privateModeCheckResult === true) {\n            return isNotPrivate();\n        }\n        if (privateModeCheckResult === false) {\n            isPrivate();\n            return;\n        }\n        if (indexedDB === null) {\n            isPrivate();\n            return;\n        }\n        db = indexedDB.open(dbname);\n        db.onerror = isPrivate;\n        db.onsuccess = isNotPrivate;\n    });\n};\nlet safariCompatabilityModeResult;\n/**\n * Whether the browser's implementation of IndexedDB breaks on array lookups\n * against composite indexes whose keypath contains a single column.\n *\n * E.g., Whether `store.createIndex(indexName, ['id'])` followed by\n * `store.index(indexName).get([1])` will *ever* return records.\n *\n * In all known, modern Safari browsers as of Q4 2022, the query against an index like\n * this will *always* return `undefined`. So, the index needs to be created as a scalar.\n */\nconst isSafariCompatabilityMode = async () => {\n    try {\n        const dbName = amplifyUuid();\n        const storeName = 'indexedDBFeatureProbeStore';\n        const indexName = 'idx';\n        if (indexedDB === null)\n            return false;\n        if (safariCompatabilityModeResult !== undefined) {\n            return safariCompatabilityModeResult;\n        }\n        const db = await new Promise(resolve => {\n            const dbOpenRequest = indexedDB.open(dbName);\n            dbOpenRequest.onerror = () => {\n                resolve(false);\n            };\n            dbOpenRequest.onsuccess = () => {\n                const openedDb = dbOpenRequest.result;\n                resolve(openedDb);\n            };\n            dbOpenRequest.onupgradeneeded = (event) => {\n                const upgradedDb = event?.target?.result;\n                upgradedDb.onerror = () => {\n                    resolve(false);\n                };\n                const store = upgradedDb.createObjectStore(storeName, {\n                    autoIncrement: true,\n                });\n                store.createIndex(indexName, ['id']);\n            };\n        });\n        if (!db) {\n            throw new Error('Could not open probe DB');\n        }\n        const rwTx = db.transaction(storeName, 'readwrite');\n        const rwStore = rwTx.objectStore(storeName);\n        rwStore.add({\n            id: 1,\n        });\n        rwTx.commit();\n        const result = await new Promise(resolve => {\n            const tx = db.transaction(storeName, 'readonly');\n            const store = tx.objectStore(storeName);\n            const index = store.index(indexName);\n            const getRequest = index.get([1]);\n            getRequest.onerror = () => {\n                resolve(false);\n            };\n            getRequest.onsuccess = (event) => {\n                resolve(event?.target?.result);\n            };\n        });\n        if (db && typeof db.close === 'function') {\n            // eslint-disable-next-line @typescript-eslint/no-confusing-void-expression\n            await db.close();\n        }\n        await indexedDB.deleteDatabase(dbName);\n        if (result === undefined) {\n            safariCompatabilityModeResult = true;\n        }\n        else {\n            safariCompatabilityModeResult = false;\n        }\n    }\n    catch (error) {\n        safariCompatabilityModeResult = false;\n    }\n    return safariCompatabilityModeResult;\n};\nconst HEX_TO_SHORT = {};\nfor (let i = 0; i < 256; i++) {\n    let encodedByte = i.toString(16).toLowerCase();\n    if (encodedByte.length === 1) {\n        encodedByte = `0${encodedByte}`;\n    }\n    HEX_TO_SHORT[encodedByte] = i;\n}\nconst getBytesFromHex = (encoded) => {\n    if (encoded.length % 2 !== 0) {\n        throw new Error('Hex encoded strings must have an even number length');\n    }\n    const out = new Uint8Array(encoded.length / 2);\n    for (let i = 0; i < encoded.length; i += 2) {\n        const encodedByte = encoded.slice(i, i + 2).toLowerCase();\n        if (encodedByte in HEX_TO_SHORT) {\n            out[i / 2] = HEX_TO_SHORT[encodedByte];\n        }\n        else {\n            throw new Error(`Cannot decode unrecognized sequence ${encodedByte} as hexadecimal`);\n        }\n    }\n    return out;\n};\nconst randomBytes = (nBytes) => {\n    const str = new WordArray().random(nBytes).toString();\n    return getBytesFromHex(str);\n};\nconst prng = () => randomBytes(1)[0] / 0xff;\nfunction monotonicUlidFactory(seed) {\n    const ulid = monotonicFactory(prng);\n    return () => {\n        return ulid(seed);\n    };\n}\n/**\n * Uses performance.now() if available, otherwise, uses Date.now() (e.g. react native without a polyfill)\n *\n * The values returned by performance.now() always increase at a constant rate,\n * independent of the system clock (which might be adjusted manually or skewed\n * by software like NTP).\n *\n * Otherwise, performance.timing.navigationStart + performance.now() will be\n * approximately equal to Date.now()\n *\n * See: https://developer.mozilla.org/en-US/docs/Web/API/Performance/now#Example\n */\nfunction getNow() {\n    if (typeof performance !== 'undefined' &&\n        performance &&\n        typeof performance.now === 'function') {\n        return performance.now() | 0; // convert to integer\n    }\n    else {\n        return Date.now();\n    }\n}\nfunction sortCompareFunction(sortPredicates) {\n    return function compareFunction(a, b) {\n        // enable multi-field sort by iterating over predicates until\n        // a comparison returns -1 or 1\n        for (const predicate of sortPredicates) {\n            const { field, sortDirection } = predicate;\n            // reverse result when direction is descending\n            const sortMultiplier = sortDirection === SortDirection.ASCENDING ? 1 : -1;\n            if (a[field] < b[field]) {\n                return -1 * sortMultiplier;\n            }\n            if (a[field] > b[field]) {\n                return 1 * sortMultiplier;\n            }\n        }\n        return 0;\n    };\n}\n/* deep directed comparison ensuring that all fields on \"from\" object exist and\n * are equal to values on an \"against\" object\n *\n * Note: This same guarauntee is not applied for values on \"against\" that aren't on \"from\"\n *\n * @param fromObject - The object that may be an equal subset of the againstObject.\n * @param againstObject - The object that may be an equal superset of the fromObject.\n *\n * @returns True if fromObject is a equal subset of againstObject and False otherwise.\n */\nfunction directedValueEquality(fromObject, againstObject, nullish = false) {\n    const aKeys = Object.keys(fromObject);\n    for (const key of aKeys) {\n        const fromValue = fromObject[key];\n        const againstValue = againstObject[key];\n        if (!valuesEqual(fromValue, againstValue, nullish)) {\n            return false;\n        }\n    }\n    return true;\n}\n// deep compare any 2 values\n// primitives or object types (including arrays, Sets, and Maps)\n// returns true if equal by value\n// if nullish is true, treat undefined and null values as equal\n// to normalize for GQL response values for undefined fields\nfunction valuesEqual(valA, valB, nullish = false) {\n    let a = valA;\n    let b = valB;\n    const nullishCompare = (_a, _b) => {\n        return ((_a === undefined || _a === null) && (_b === undefined || _b === null));\n    };\n    // if one of the values is a primitive and the other is an object\n    if ((a instanceof Object && !(b instanceof Object)) ||\n        (!(a instanceof Object) && b instanceof Object)) {\n        return false;\n    }\n    // compare primitive types\n    if (!(a instanceof Object)) {\n        if (nullish && nullishCompare(a, b)) {\n            return true;\n        }\n        return a === b;\n    }\n    // make sure object types match\n    if ((Array.isArray(a) && !Array.isArray(b)) ||\n        (Array.isArray(b) && !Array.isArray(a))) {\n        return false;\n    }\n    if (a instanceof Set && b instanceof Set) {\n        a = [...a];\n        b = [...b];\n    }\n    if (a instanceof Map && b instanceof Map) {\n        a = Object.fromEntries(a);\n        b = Object.fromEntries(b);\n    }\n    const aKeys = Object.keys(a);\n    const bKeys = Object.keys(b);\n    // last condition is to ensure that [] !== [null] even if nullish. However [undefined] === [null] when nullish\n    if (aKeys.length !== bKeys.length && (!nullish || Array.isArray(a))) {\n        return false;\n    }\n    // iterate through the longer set of keys\n    // e.g., for a nullish comparison of a={ a: 1 } and b={ a: 1, b: null }\n    // we want to iterate through bKeys\n    const keys = aKeys.length >= bKeys.length ? aKeys : bKeys;\n    for (const key of keys) {\n        const aVal = a[key];\n        const bVal = b[key];\n        if (!valuesEqual(aVal, bVal, nullish)) {\n            return false;\n        }\n    }\n    return true;\n}\n/**\n * Statelessly extracts the specified page from an array.\n *\n * @param records - The source array to extract a page from.\n * @param pagination - A definition of the page to extract.\n * @returns This items from `records` matching the `pagination` definition.\n */\nfunction inMemoryPagination(records, pagination) {\n    if (pagination && records.length > 1) {\n        if (pagination.sort) {\n            const sortPredicates = ModelSortPredicateCreator.getPredicates(pagination.sort);\n            if (sortPredicates.length) {\n                const compareFn = sortCompareFunction(sortPredicates);\n                records.sort(compareFn);\n            }\n        }\n        const { page = 0, limit = 0 } = pagination;\n        const start = Math.max(0, page * limit) || 0;\n        const end = limit > 0 ? start + limit : records.length;\n        return records.slice(start, end);\n    }\n    return records;\n}\n/**\n * An `aysnc` implementation of `Array.some()`. Returns as soon as a match is found.\n * @param items The items to check.\n * @param matches The async matcher function, expected to\n * return Promise<boolean>: `true` for a matching item, `false` otherwise.\n * @returns A `Promise<boolean>`, `true` if \"some\" items match; `false` otherwise.\n */\nasync function asyncSome(items, matches) {\n    for (const item of items) {\n        if (await matches(item)) {\n            return true;\n        }\n    }\n    return false;\n}\n/**\n * An `aysnc` implementation of `Array.every()`. Returns as soon as a non-match is found.\n * @param items The items to check.\n * @param matches The async matcher function, expected to\n * return Promise<boolean>: `true` for a matching item, `false` otherwise.\n * @returns A `Promise<boolean>`, `true` if every item matches; `false` otherwise.\n */\nasync function asyncEvery(items, matches) {\n    for (const item of items) {\n        if (!(await matches(item))) {\n            return false;\n        }\n    }\n    return true;\n}\n/**\n * An `async` implementation of `Array.filter()`. Returns after all items have been filtered.\n * TODO: Return AsyncIterable.\n * @param items The items to filter.\n * @param matches The `async` matcher function, expected to\n * return Promise<boolean>: `true` for a matching item, `false` otherwise.\n * @returns A `Promise<T>` of matching items.\n */\nasync function asyncFilter(items, matches) {\n    const results = [];\n    for (const item of items) {\n        if (await matches(item)) {\n            results.push(item);\n        }\n    }\n    return results;\n}\nconst isAWSDate = (val) => {\n    return !!/^\\d{4}-\\d{2}-\\d{2}(Z|[+-]\\d{2}:\\d{2}($|:\\d{2}))?$/.exec(val);\n};\nconst isAWSTime = (val) => {\n    return !!/^\\d{2}:\\d{2}(:\\d{2}(.\\d+)?)?(Z|[+-]\\d{2}:\\d{2}($|:\\d{2}))?$/.exec(val);\n};\nconst isAWSDateTime = (val) => {\n    return !!/^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}(:\\d{2}(.\\d+)?)?(Z|[+-]\\d{2}:\\d{2}($|:\\d{2}))?$/.exec(val);\n};\nconst isAWSTimestamp = (val) => {\n    return !!/^\\d+$/.exec(String(val));\n};\nconst isAWSEmail = (val) => {\n    return !!/^[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$/.exec(val);\n};\nconst isAWSJSON = (val) => {\n    try {\n        JSON.parse(val);\n        return true;\n    }\n    catch {\n        return false;\n    }\n};\nconst isAWSURL = (val) => {\n    try {\n        return !!new AmplifyUrl(val);\n    }\n    catch {\n        return false;\n    }\n};\nconst isAWSPhone = (val) => {\n    return !!/^\\+?\\d[\\d\\s-]+$/.exec(val);\n};\nconst isAWSIPAddress = (val) => {\n    return !!/((^((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))$)|(^((([0-9A-Fa-f]{1,4}:){7}([0-9A-Fa-f]{1,4}|:))|(([0-9A-Fa-f]{1,4}:){6}(:[0-9A-Fa-f]{1,4}|((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){5}(((:[0-9A-Fa-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){4}(((:[0-9A-Fa-f]{1,4}){1,3})|((:[0-9A-Fa-f]{1,4})?:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){3}(((:[0-9A-Fa-f]{1,4}){1,4})|((:[0-9A-Fa-f]{1,4}){0,2}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){2}(((:[0-9A-Fa-f]{1,4}){1,5})|((:[0-9A-Fa-f]{1,4}){0,3}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){1}(((:[0-9A-Fa-f]{1,4}){1,6})|((:[0-9A-Fa-f]{1,4}){0,4}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:))|(:(((:[0-9A-Fa-f]{1,4}){1,7})|((:[0-9A-Fa-f]{1,4}){0,5}:((25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)(\\.(25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]?\\d)){3}))|:)))(%.+)?$))$/.exec(val);\n};\nclass DeferredPromise {\n    constructor() {\n        // eslint-disable-next-line @typescript-eslint/no-this-alias\n        const self = this;\n        this.promise = new Promise((resolve, reject) => {\n            self.resolve = resolve;\n            self.reject = reject;\n        });\n    }\n}\nclass DeferredCallbackResolver {\n    constructor(options) {\n        this.limitPromise = new DeferredPromise();\n        this.raceInFlight = false;\n        this.callback = () => {\n            // no-op\n        };\n        this.defaultErrorHandler = (msg = 'DeferredCallbackResolver error') => {\n            throw new Error(msg);\n        };\n        this.callback = options.callback;\n        this.errorHandler = options.errorHandler || this.defaultErrorHandler;\n        this.maxInterval = options.maxInterval || 2000;\n    }\n    startTimer() {\n        this.timerPromise = new Promise((resolve, _reject) => {\n            this.timer = setTimeout(() => {\n                resolve(LimitTimerRaceResolvedValues.TIMER);\n            }, this.maxInterval);\n        });\n    }\n    async racePromises() {\n        let winner;\n        try {\n            this.raceInFlight = true;\n            this.startTimer();\n            winner = await Promise.race([\n                this.timerPromise,\n                this.limitPromise.promise,\n            ]);\n            this.callback();\n        }\n        catch (err) {\n            this.errorHandler(err);\n        }\n        finally {\n            // reset for the next race\n            this.clear();\n            this.raceInFlight = false;\n            this.limitPromise = new DeferredPromise();\n            // eslint-disable-next-line no-unsafe-finally\n            return winner;\n        }\n    }\n    start() {\n        if (!this.raceInFlight)\n            this.racePromises();\n    }\n    clear() {\n        clearTimeout(this.timer);\n    }\n    resolve() {\n        this.limitPromise.resolve(LimitTimerRaceResolvedValues.LIMIT);\n    }\n}\n/**\n * merge two sets of patches created by immer produce.\n * newPatches take precedent over oldPatches for patches modifying the same path.\n * In the case many consecutive pathces are merged the original model should\n * always be the root model.\n *\n * Example:\n * A -> B, patches1\n * B -> C, patches2\n *\n * mergePatches(A, patches1, patches2) to get patches for A -> C\n *\n * @param originalSource the original Model the patches should be applied to\n * @param oldPatches immer produce patch list\n * @param newPatches immer produce patch list (will take precedence)\n * @return merged patches\n */\nfunction mergePatches(originalSource, oldPatches, newPatches) {\n    const patchesToMerge = oldPatches.concat(newPatches);\n    let patches;\n    produce(originalSource, draft => {\n        applyPatches(draft, patchesToMerge);\n    }, p => {\n        patches = p;\n    });\n    return patches;\n}\nconst getStorename = (namespace, modelName) => {\n    const storeName = `${namespace}_${modelName}`;\n    return storeName;\n};\n// #region Key Utils\n/*\n  When we have GSI(s) with composite sort keys defined on a model\n    There are some very particular rules regarding which fields must be included in the update mutation input\n    The field selection becomes more complex as the number of GSIs with composite sort keys grows\n\n    To summarize: any time we update a field that is part of the composite sort key of a GSI, we must include:\n     1. all of the other fields in that composite sort key\n     2. all of the fields from any other composite sort key that intersect with the fields from 1.\n\n     E.g.,\n     Model @model\n        @key(name: 'key1' fields: ['hk', 'a', 'b', 'c'])\n        @key(name: 'key2' fields: ['hk', 'a', 'b', 'd'])\n        @key(name: 'key3' fields: ['hk', 'x', 'y', 'z'])\n\n    Model.a is updated => include ['a', 'b', 'c', 'd']\n    Model.c is updated => include ['a', 'b', 'c', 'd']\n    Model.d is updated => include ['a', 'b', 'c', 'd']\n    Model.x is updated => include ['x', 'y', 'z']\n\n    This function accepts a model's attributes and returns grouped sets of composite key fields\n    Using our example Model above, the function will return:\n    [\n        Set('a', 'b', 'c', 'd'),\n        Set('x', 'y', 'z'),\n    ]\n\n    This gives us the opportunity to correctly include the required fields for composite keys\n    When crafting the mutation input in Storage.getUpdateMutationInput\n\n    See 'processCompositeKeys' test in util.test.ts for more examples\n*/\nconst processCompositeKeys = (attributes) => {\n    const extractCompositeSortKey = ({ properties: { \n    // ignore the HK (fields[0]) we only need to include the composite sort key fields[1...n]\n    fields: [, ...sortKeyFields], }, }) => sortKeyFields;\n    const compositeKeyFields = attributes\n        .filter(isModelAttributeCompositeKey)\n        .map(extractCompositeSortKey);\n    /*\n        if 2 sets of fields have any intersecting fields => combine them into 1 union set\n        e.g., ['a', 'b', 'c'] and ['a', 'b', 'd'] => ['a', 'b', 'c', 'd']\n    */\n    const combineIntersecting = (fields) => fields.reduce((combined, sortKeyFields) => {\n        const sortKeyFieldsSet = new Set(sortKeyFields);\n        if (combined.length === 0) {\n            combined.push(sortKeyFieldsSet);\n            return combined;\n        }\n        // does the current set share values with another set we've already added to `combined`?\n        const intersectingSetIdx = combined.findIndex(existingSet => {\n            return [...existingSet].some(f => sortKeyFieldsSet.has(f));\n        });\n        if (intersectingSetIdx > -1) {\n            const union = new Set([\n                ...combined[intersectingSetIdx],\n                ...sortKeyFieldsSet,\n            ]);\n            // combine the current set with the intersecting set we found above\n            combined[intersectingSetIdx] = union;\n        }\n        else {\n            // none of the sets in `combined` have intersecting values with the current set\n            combined.push(sortKeyFieldsSet);\n        }\n        return combined;\n    }, []);\n    const initial = combineIntersecting(compositeKeyFields);\n    // a single pass pay not be enough to correctly combine all the fields\n    // call the function once more to get a final merged list of sets\n    const combined = combineIntersecting(initial);\n    return combined;\n};\nconst extractKeyIfExists = (modelDefinition) => {\n    const keyAttribute = modelDefinition?.attributes?.find(isModelAttributeKey);\n    return keyAttribute;\n};\nconst extractPrimaryKeyFieldNames = (modelDefinition) => {\n    const keyAttribute = extractKeyIfExists(modelDefinition);\n    if (keyAttribute && isModelAttributePrimaryKey(keyAttribute)) {\n        return keyAttribute.properties.fields;\n    }\n    return [ID];\n};\nconst extractPrimaryKeyValues = (model, keyFields) => {\n    return keyFields.map(key => model[key]);\n};\nconst extractPrimaryKeysAndValues = (model, keyFields) => {\n    const primaryKeysAndValues = {};\n    keyFields.forEach(key => (primaryKeysAndValues[key] = model[key]));\n    return primaryKeysAndValues;\n};\n// IdentifierFields<ManagedIdentifier>\n// Default behavior without explicit @primaryKey defined\nconst isIdManaged = (modelDefinition) => {\n    const keyAttribute = extractKeyIfExists(modelDefinition);\n    if (keyAttribute && isModelAttributePrimaryKey(keyAttribute)) {\n        return false;\n    }\n    return true;\n};\n// IdentifierFields<OptionallyManagedIdentifier>\n// @primaryKey with explicit `id` in the PK. Single key or composite\nconst isIdOptionallyManaged = (modelDefinition) => {\n    const keyAttribute = extractKeyIfExists(modelDefinition);\n    if (keyAttribute && isModelAttributePrimaryKey(keyAttribute)) {\n        return keyAttribute.properties.fields[0] === ID;\n    }\n    return false;\n};\nconst establishRelationAndKeys = (namespace) => {\n    const relationship = {};\n    const keys = {};\n    Object.keys(namespace.models).forEach((mKey) => {\n        relationship[mKey] = { indexes: [], relationTypes: [] };\n        keys[mKey] = {};\n        const model = namespace.models[mKey];\n        Object.keys(model.fields).forEach((attr) => {\n            const fieldAttribute = model.fields[attr];\n            if (typeof fieldAttribute.type === 'object' &&\n                'model' in fieldAttribute.type) {\n                const { connectionType } = fieldAttribute.association;\n                relationship[mKey].relationTypes.push({\n                    fieldName: fieldAttribute.name,\n                    modelName: fieldAttribute.type.model,\n                    relationType: connectionType,\n                    targetName: fieldAttribute.association.targetName,\n                    targetNames: fieldAttribute.association.targetNames,\n                    // eslint-disable-next-line dot-notation\n                    associatedWith: fieldAttribute.association['associatedWith'],\n                });\n                if (connectionType === 'BELONGS_TO') {\n                    const targetNames = extractTargetNamesFromSrc(fieldAttribute.association);\n                    if (targetNames) {\n                        const idxName = indexNameFromKeys(targetNames);\n                        const idxExists = relationship[mKey].indexes.find(([index]) => index === idxName);\n                        if (!idxExists) {\n                            relationship[mKey].indexes.push([idxName, targetNames]);\n                        }\n                    }\n                }\n            }\n        });\n        if (model.attributes) {\n            keys[mKey].compositeKeys = processCompositeKeys(model.attributes);\n            for (const attribute of model.attributes) {\n                if (!isModelAttributeKey(attribute)) {\n                    continue;\n                }\n                const { fields } = attribute.properties;\n                if (isModelAttributePrimaryKey(attribute)) {\n                    keys[mKey].primaryKey = fields;\n                    continue;\n                }\n                // create indexes for all other keys\n                const idxName = indexNameFromKeys(fields);\n                const idxExists = relationship[mKey].indexes.find(([index]) => index === idxName);\n                if (!idxExists) {\n                    relationship[mKey].indexes.push([idxName, fields]);\n                }\n            }\n        }\n        // set 'id' as the PK for models without a custom PK explicitly defined\n        if (!keys[mKey].primaryKey) {\n            keys[mKey].primaryKey = [ID];\n        }\n        // create primary index\n        relationship[mKey].indexes.push([\n            'byPk',\n            keys[mKey].primaryKey,\n            { unique: true },\n        ]);\n    });\n    return [relationship, keys];\n};\nconst getIndex = (rel, src) => {\n    let indexName;\n    // eslint-disable-next-line array-callback-return\n    rel.some((relItem) => {\n        if (relItem.modelName === src) {\n            const targetNames = extractTargetNamesFromSrc(relItem);\n            indexName = targetNames && indexNameFromKeys(targetNames);\n            return true;\n        }\n    });\n    return indexName;\n};\nconst getIndexFromAssociation = (indexes, src) => {\n    let indexName;\n    if (Array.isArray(src)) {\n        indexName = indexNameFromKeys(src);\n    }\n    else {\n        indexName = src;\n    }\n    const associationIndex = indexes.find(([idxName]) => idxName === indexName);\n    return associationIndex && associationIndex[0];\n};\n/**\n * Backwards-compatability for schema generated prior to custom primary key support:\nthe single field `targetName` has been replaced with an array of `targetNames`.\n`targetName` and `targetNames` are exclusive (will never exist on the same schema)\n * @param src {RelationType | ModelAssociation | undefined}\n * @returns array of targetNames, or `undefined`\n */\nconst extractTargetNamesFromSrc = (src) => {\n    const targetName = src?.targetName;\n    const targetNames = src?.targetNames;\n    if (Array.isArray(targetNames)) {\n        return targetNames;\n    }\n    else if (typeof targetName === 'string') {\n        return [targetName];\n    }\n    else {\n        return undefined;\n    }\n};\n// Generates spinal-cased index name from an array of key field names\n// E.g. for keys `[id, title]` => 'id-title'\nconst indexNameFromKeys = (keys) => {\n    return keys.reduce((prev, cur, idx) => {\n        if (idx === 0) {\n            return cur;\n        }\n        return `${prev}${IDENTIFIER_KEY_SEPARATOR}${cur}`;\n    }, '');\n};\nconst keysEqual = (keysA, keysB) => {\n    if (keysA.length !== keysB.length) {\n        return false;\n    }\n    return keysA.every((key, idx) => key === keysB[idx]);\n};\n// Returns primary keys for a model\nconst getIndexKeys = (namespace, modelName) => {\n    const keyPath = namespace?.keys?.[modelName]?.primaryKey;\n    if (keyPath) {\n        return keyPath;\n    }\n    return [ID];\n};\n// #endregion\n/**\n * Determine what the managed timestamp field names are for the given model definition\n * and return the mapping.\n *\n * All timestamp fields are included in the mapping, regardless of whether the final field\n * names are the defaults or customized in the `@model` directive.\n *\n * @see https://docs.amplify.aws/cli/graphql/data-modeling/#customize-creation-and-update-timestamps\n *\n * @param definition modelDefinition to inspect.\n * @returns An object mapping `createdAt` and `updatedAt` to their field names.\n */\nconst getTimestampFields = (definition) => {\n    const modelAttributes = definition.attributes?.find(attr => attr.type === 'model');\n    const timestampFieldsMap = modelAttributes?.properties?.timestamps;\n    const defaultFields = {\n        createdAt: 'createdAt',\n        updatedAt: 'updatedAt',\n    };\n    const customFields = timestampFieldsMap || {};\n    return {\n        ...defaultFields,\n        ...customFields,\n    };\n};\n\nexport { DATASTORE, DEFAULT_PRIMARY_KEY_VALUE_SEPARATOR, DeferredCallbackResolver, DeferredPromise, ID, IDENTIFIER_KEY_SEPARATOR, NAMESPACES, STORAGE, SYNC, USER, asyncEvery, asyncFilter, asyncSome, directedValueEquality, errorMessages, establishRelationAndKeys, exhaustiveCheck, extractKeyIfExists, extractPrimaryKeyFieldNames, extractPrimaryKeyValues, extractPrimaryKeysAndValues, extractTargetNamesFromSrc, getIndex, getIndexFromAssociation, getIndexKeys, getNow, getStorename, getTimestampFields, inMemoryPagination, indexNameFromKeys, isAWSDate, isAWSDateTime, isAWSEmail, isAWSIPAddress, isAWSJSON, isAWSPhone, isAWSTime, isAWSTimestamp, isAWSURL, isIdManaged, isIdOptionallyManaged, isModelConstructor, isNonModelConstructor, isNullOrUndefined, isPrivateMode, isSafariCompatabilityMode, keysEqual, mergePatches, monotonicUlidFactory, processCompositeKeys, registerNonModelClass, sortCompareFunction, traverseModel, validatePredicate, validatePredicateField, valuesEqual };\n//# sourceMappingURL=util.mjs.map\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","import { USER, traverseModel, validatePredicate, isNonModelConstructor, isModelConstructor } from './util.mjs';\nexport { NAMESPACES } from './util.mjs';\nexport { AsyncCollection, AsyncItem, DataStore, DataStoreClass, initSchema } from './datastore/datastore.mjs';\nexport { ModelPredicateCreator, Predicates } from './predicates/index.mjs';\nexport { AuthModeStrategyType, DISCARD, GraphQLScalarType, LimitTimerRaceResolvedValues, ModelAttributeAuthAllow, ModelAttributeAuthProvider, ModelOperation, OpType, PredicateInternalsKey, ProcessName, QueryOne, SortDirection, isAssociatedWith, isEnumFieldType, isFieldAssociation, isGraphQLScalarType, isIdentifierObject, isModelAttributeAuth, isModelAttributeCompositeKey, isModelAttributeKey, isModelAttributePrimaryKey, isModelFieldType, isNonModelFieldType, isPredicateGroup, isPredicateObj, isSchemaModel, isSchemaModelWithAttributes, isTargetNameAssociation, syncExpression } from './types.mjs';\nexport { ModelSortPredicateCreator } from './predicates/sort.mjs';\n\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nconst utils = {\n    USER,\n    traverseModel,\n    validatePredicate,\n    isNonModelConstructor,\n    isModelConstructor,\n};\n\nexport { utils };\n//# sourceMappingURL=index.mjs.map\n"],"names":[],"sourceRoot":""}